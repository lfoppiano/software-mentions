<?xml version='1.0' encoding='UTF-8'?>
<teiCorpus xmlns="http://www.tei-c.org/ns/1.0" version="3.3.0">
  <tei>
<teiHeader>
<fileDesc id="f186695288"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:17+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Empirical evidence shows that the rate of irregular usage of English verbs exhibits discontinuity as a function of their frequency: the most frequent verbs tend to be totally irregular. We aim to qualitatively understand the origin of this feature by studying simple agent-based models of language dynamics, where each agent adopts an inflectional state for a verb and may change it upon interaction with other agents. At the same time, agents are replaced at some rate by new agents adopting the regular form. In models with only two inflectional states (regular and irregular), we observe that either all verbs regularize irrespective of their frequency, or a continuous transition occurs between a low-frequency state, where the lemma becomes fully regular, and a high-frequency one, where both forms coexist. Introducing a third (mixed) state, wherein agents may use either form, we find that a third, qualitatively different behavior may emerge, namely, a discontinuous transition in frequency. We introduce and solve analytically a very general class of three-state models that allows us to fully understand these behaviors in a unified framework. Realistic sets of interaction rules, including the well-known naming game (NG) model, result in a discontinuous transition, in agreement with recent empirical findings. We also point out that the distinction between speaker and hearer in the interaction has no effect on the collective behavior. The results for the general three-state model, although discussed in terms of language dynamics, are widely applicable.</p>
<p>Language is structured by rules [1,2]-but linguistic rules often have exceptions. This fact kindled a longstanding debate in cognitive science centering on how individual learners accommodate rule sets rife with exceptions (e.g., see Refs. [3,4]). However, how exceptions arise and evolve over time within a language system remains a largely open question.</p>
<p>The study of the English past tense is widely used as an exemplar of the interplay between rules and exceptions [5][6][7][8]. A recent study of historical corpus data [9] looks at rules in the language system rather than individual learners, shedding light on the relationship between the verb frequency and regularity (Fig. 1). Each verb in the language can be characterized by I , the fraction of irregular past tense tokens over the total number of tokens in the past tense, and ν, its frequency of usage. An interesting transition is found in the behavior of I as a function of ν: regular verbs dominate the low-frequency range, while most irregular verbs are located at higher frequencies (see also Refs. [10,11]). For intermediate values of ν fully regular (I = 0) and fully irregular (I = 1) verbs coexist. Only a small subset of verbs exhibit both regular and irregular forms (0 &lt; I &lt; 1) and occur primarily in a rather narrow range of frequencies between the dominant regular and irregular states.</p>
<p>The work presented in this paper takes a theoretical approach to the relationship between rules and exceptions in a population of interacting speakers. We investigate the dynamics of a set of very simple agent-based models aimed at describing the fundamental mechanisms by which rules and exceptions may be shared or disappear in a population, in the same spirit of the naming game (NG) [12,13] investigations of the emergence of shared naming conventions. We consider a single lemma and examine two-state and three-state models. In a two-state model, an individual has an internal inflectional inventory, which can contain either the regular (R) or irregular (I ) inflection for the lemma. In a three-state model, the inflectional state can be either R, I , or mixed (M). The mixed state represents intraspeaker variation [14], where an individual may accommodate both regular and irregular forms for a single word [15]. For example, there is evidence that regular and irregular past-tense verb forms are simultaneously known and potentially used in seemingly free variation within a single speaker (e.g., both sneaked and snuck are acceptable [15]). Agents are endowed at the start of the dynamics with some inflectional state for the word and engage at rate ν in pairwise interactions, i.e., one of them utters the verb under consideration and the other listens to it. During interaction, the inflectional states of the speaker and hearer change according to a predefined set of interaction rules. In addition to interaction events, we implement a replacement mechanism: at rate r an agent is replaced with a "child" who engages in overregularization: these "child" agents assume the regular inflection applies to all words in the vocabulary, representing a known bias of child learners [16][17][18]. Replacement represents turnover in the population: as a child learner enters, an adult leaves (i.e., is replaced), so that the population size remains constant.</p>
<p>We first approach some specific models analytically, within the framework of mean-field theory. This analytical approach (Adapted from Ref. [9].) allows for quantitative predictions regarding which state a population of speakers will reach given a particular set of interaction rules and the type of transition which may occur depending on the ratio between the frequency and replacement rates. It turns out that different interaction rules lead to qualitatively different types of behavior. Two-state models lead to total regularization or to a continuous transition as a function of r/ν. Three-state models, on the other hand, have the potential to exhibit a discontinuous transition with some highly frequent, mostly irregular words, reminiscent of findings in empirical data. To understand these variations and understand their origin, we introduce a very general three-state model, encompassing all possible sets of interaction rules that do not favor either the regular or irregular state in their outcome. We provide a formal solution for any value of the model parameters and study in detail the conditions under which no transition (i.e., total regularization) occurs, and the conditions under which we observe a continuous or discontinuous transition. Our analysis also shows that assuming asymmetric influence of the speaker over the hearer in the interaction has no effect on the collective behavior. The results for this general model are discussed in terms of language dynamics, but their applicability is fully general: they give the solution for any three-state model of population dynamics with unbiased interaction rules and biased replacement.</p>
<p>Let us start by considering two-state models, where each individual can be found in one of two possible rule states, regular (R) or irregular (I ). While in this case the two states represent regular and irregular inflections, this framework can represent any set of binary options (e.g., the choice between two possible words to name an object, two alternative opinions on a given topic, etc.). As a specific example, the Abrams-Strogatz model [19] used a two-state approach to examine the dynamics of endangered languages, providing a prime example of the dynamics of languages in competition more generally.</p>
<p>Using this general two-state model approach, we focus here on the binary options of regular (R) or irregular (I ) inflection for a single word, characterized by its frequency of usage, ν. At each interaction step, two agents are selected at random (i.e., mixing is homogeneous) and assigned the role of either speaker or hearer. With probability ν they engage in a pairwise interaction (i.e., the speaker utters the verb under consideration to the hearer), which affects their inflectional states according to specific interaction rules. Then, with probability r, one individual in the population is replaced with a "child" having its inflectional state set to R. This part of the dynamics mimics the turnover of some segment of the adult population into child learners at rate r, keeping the population size N fixed, and assuming over-regularization behavior in new learners. In this way the population replacement is biased toward one of the two options, in this case, regularity. The quantity 1/r can be interpreted as the life expectancy of an individual in the population.</p>
<p>Among the possible two-state interaction rules, we consider the sets presented in Table I. In the irregular-biased (A) and regular-biased (B) models, the speaker and the hearer roles are symmetric; in other words, which agent identifies as speaker or hearer is irrelevant, but the presence of an I (R) state in the interaction leads the rules. In A(B) an agent switches to the I (R) state whenever interacting with a partner in the I (R) state, regardless of which agent is the speaker and which the hearer. In these cases the speaker can affect the hearer's state, and the hearer can also affect the speaker's. In the speaker-leads model (C), the roles are not symmetric: the speaker never changes its state and the hearer always adopts the state of the speaker. TABLE I. Interaction rules for the two-state models. The two columns on the left refer to the status of speaker and hearer prior to interaction. The next three pairs of columns refer to the status of speaker and hearer after the interaction in the three models.</p>
<p>The irregular-biased model is perfectly equivalent to one of the most fundamental models of nonequilibrium statistical physics: the contact process [20]. The temporal behavior of this model is easily understood by writing down the mean-field evolution equation for the density ρ I of individuals in the I state (the density of R individuals, ρ R , being trivially 1ρ I ) ρI = -rρ I + 2νρ I (1ρ I ).</p>
<p>(</p>
<p>Equation ( 1) is solved straightforwardly and yields, for any initial configuration ρ I (0), ρ R (0) = 1ρ I (0),</p>
<p>where n = r/ν. For long time scales, the system reaches (for any initial configuration) a stationary state that exhibits a continuous transition for a critical value n c = 2, between a fully regular state (ρ I = 0) for n &gt; n c , and a state with individuals in both the R and the I state (ρ I &gt; 0):</p>
<p>The solutions for the regular-biased and speaker-leads models are obtained from Eq. ( 2) by simply replacing n → -n and n → ∞, respectively, and both result in an exponential relaxation to the stationary fully regular state (ρ I = 0) for any physical value of n. Unlike in case A, in these two cases the interaction rules are biased in favor of R (case B) or unbiased (C) and they cannot compensate for the increase in R states due to replacement, leading to a fully regular absorbing state. As it will be demonstrated in Sec. IV A, no two-state model can give rise to a discontinuous transition between the fully regular state and a state with ρ I &gt; 0. Empirical data, however, exhibit such a discontinuous transition, and research shows that speakers can accommodate regular and irregular forms simultaneously [15]. For these reasons, we now turn our attention to a more complex modeling scheme that integrates a third, mixed state (M), wherein agents accommodate either the R or I . We will show that introducing this psychologically plausible, mixed state, a qualitatively different behavior appears, namely, a discontinuous transition in regularity, reminiscent of empirical data.</p>
<p>In three-state models there are still only two alternative inflections that can be applied to a word (R and I ) during an interaction event, but internally, each individual can be in one of the three possible states: R (regular), I (irregular), and M (mixed). In the mixed state the individual can accommodate both R and I forms; this accounts for agents undecided on which is the correct form to use, or that consider both the regular and the irregular form acceptable.</p>
<p>The study of three-state models has a long history in the investigation of language dynamics (for a review see Ref. [21]). In particular, Wang and Minett proposed [22,23] deterministic models for the competition of two languages, which included a third potential state of bilingual individuals. Castelló et al. [24] proposed a modified version of the voter TABLE II. Interaction rules for the three examples of three-state models. The two columns on the left refer to the status of speaker and hearer prior to the interaction. The following three pairs of columns refer to the status of speaker and hearer after the interaction for the three different rule sets: the naming game (NG), the continuous transition (CT) model, and the no transition (NT) model. When two alternative inflections are possible because of a mixed state, the probability of each of them is 1/2. In the only case with three alternative outcomes (I,I ) and (R,R) occur each with probability 1/4, while (M,M) occurs probability 1/2.</p>
<p>Model NG Model CT Model NT
Speaker Hearer Speaker Hearer Speaker Hearer Speaker Hearer
</p>
<p>model [25,26] to examine language that included bilingual individuals, the so-called AB model. Synonymy, the possibility for having multiple potential names for a single meaning (much like multiple inflections for a single verb as in the mixed state) has also been examined in the classic naming game (NG) model [12,27]. The naming game and its variants have examined structures of increasing complexity, often including agents who can have multiple internal states, from the categorization of colors [28,29] to basic syntactic structures [30].</p>
<p>We now study the dynamics of three specific examples in the class of three-state models, with different microscopic rules leading to qualitatively different behaviors (see Table II). The first set of rules is known as the naming game.</p>
<p>The interaction dynamics of the naming game with three states are as follows: first, at each time step a speaker and a hearer are selected at random. With the probability ν they interact; the speaker conveys to the hearer either the R or I form depending on his inventory (if in the mixed state he utters R or I with equal probability). If the hearer's inventory contains the inflection used in the utterance, both agents update their inventories keeping only the form involved in the interaction. Otherwise, the hearer adds the form to his inventory (thus switching to the mixed state). Table II (first four columns) summarizes these interaction rules. In addition to these rules, the population turnover is implemented as in the previous two-state models: at each time step an individual is selected at random and, with probability r, is replaced by a new individual in state R.</p>
<p>In a generic three-state model, two densities are needed to specify the global state of the system. We choose ρ I and ρ R , the density of the mixed state being ρ M = 1ρ Rρ I . The mean-field equations for the naming game with biased replacement are ρI = -rρ</p>
<p>Notice that the equations for the usual naming game with three states [12,31] are recovered by setting r = 0 and ν = 1. Imposing the stationarity condition, after some algebra one finds that the density of individuals in the irregular state is given by the fourth order equation</p>
<p>where n = r/ν. One solution is, for any n, the trivial value (ρ (1) I ,ρ (1) R ) = (0,1), corresponding to the fully regular state. Regarding the three other solutions, since (1 + n) 3 is always larger than 1, it follows that one solution (ρ (4) I ,ρ (4) R ) is always real but unphysical (being larger than 1), while the two others are complex for n &gt; (2 3 √ 4/3 -1) ≈ 0.0583. Below this critical value (corresponding to a saddle-node bifurcation), these two solutions are real and physical:</p>
<p>with the stationary value of ρ R given by</p>
<p>For n = 0 the solutions converge to the values found for the usual naming game [12,31]</p>
<p>). The physical stationary solutions are represented in Fig. 2 as a function of n. The stability of the generic solution (ρ * I ,ρ * R ) as a function of n is investigated by looking at the eigenvalues and eigenvectors of the stability matrix, defined through the equations:</p>
<p>The eigenvalues are given by</p>
<p>Figure 3 reports the complete phase flow in the space (ρ I , ρ R ) for n = 0 and n = 0.025. For (ρ (1) I ,ρ (1) R ) = (0,1) both eigenvalues are negative: the fully regular state is always attractive and stable and for n &gt; ( I , while green (light gray) and red (dark gray) curves indicate solutions ρ (2) I (stable) and ρ (3) I (unstable), respectively. Symbols are the stationary values of the fraction of irregulars ρ I and regulars ρ R from numerical simulations with different initial conditions: from top to bottom ρ I (t = 0) = 0.8, 0.5, and 0.3. The three panels show the dependence of the stationary state on the initial condition.</p>
<p>the two other physical solutions appear. (ρ (2) I , ρ (2) R ) is always stable and attractive and, for n &gt; 0, it always corresponds to states for which ρ I + ρ R &lt; 1. Let us now focus on the (ρ (3) I , ρ (3) R ) solution. This solution corresponds to a saddle point (the red circles in Fig. 3) since it has one positive and one 2), while the red circles are the solution (3) that correspond to a saddle point with an attractive and a repulsive direction. Only the fraction of the physical phase space with ρ I + ρ R &lt; 1 is represented. negative eigenvalue. The separatrix in the attractive direction corresponds to the eigenvector associated to the negative eigenvalue:</p>
<p>I (the thick red solid line in the figure). The other separatrix is locally approximated in the neighborhood of (ρ (3) I , ρ (3) R ), by</p>
<p>(the thin green solid line in the Fig. 3). In Appendix A we report the explicit expressions for the limit case n = 0, i.e., the original naming game. The model exhibits a discontinuous transition between a phase (high values of n = r/ν) where, whatever the initial condition, the stationary state is fully regular and a phase (low values of n) where both the fully regular state [solution (1)] and a state with a large fraction of irregulars [solution (2)] are stable. As depicted in Fig. 3, the initial condition determines which one of the two states is asymptotically reached. In particular, if the initial condition is above the separatrix corresponding to the attractive direction (thick red line) all individuals converge to the fully regular state [solution (1)]; on the other hand, if the initial condition is below that separatrix the system converges to the solution (2) where a fraction ρ (2) I (ρ (2) I = 1 for the case with no replacement, n = 0) of irregulars coexists dynamically with regular and mixed individuals. Only initial conditions exactly on the separatrix (thick red line) lead to convergence to solution (3). The predictions of the MF theory are confirmed by numerical simulations of the actual agent-based model (Fig. 2).</p>
<p>In summary, the naming game with biased population replacement exhibits a discontinuous transition as a function of n. The discontinuity also implies a dependence of the final steady state on the initial condition, which provides a theoretical justification for the observation of a range of frequencies where both fully regular and mostly irregular verbs exist (see Fig. 1). For every frequency in this interval, verbs will converge to the fully regular state (1) or to the mostly irregular state (2), depending on the initial values of ρ R and ρ I . This phenomenology is in agreement the empirical findings reported in [9] of the existence of a discontinuous transition between regular and irregular forms as a function of the frequency of usage.</p>
<p>We now consider a model with the interaction rules presented in Table II, columns CT, which differs from the NG case essentially because the hearer never discards the mixed state. The mean-field equations for the evolution of the densities in this case are written as</p>
<p>By imposing the stationarity condition ρI = ρR = 0 and summing and subtracting the two equations it is possible to reduce them to</p>
<p>where we have introduced the auxiliary variables x = ρ R + ρ I and y = ρ Rρ I . From the second equation one obtains x = (n + 1 + y 2 /2)/(n + 3/2). Inserting this expression into the first equation, one is left with a third-order algebraic equation, which always admits three real solutions. One of them is, for any n, the fully regular solution (x,y) = (1,1). The two others are always unphysical (being larger than 1 or smaller than -1) except for n n c = ( √ 17 -3)/4 ≈ 0.2807. In such a case another physical solution appears,</p>
<p>where</p>
<p>. The expressions for ρ R and ρ I are obtained from the relations ρ R = (x + y)/2 and ρ I = (xy)/2. The physical stationary solutions are reported in Fig. 4, along with the results of the numerical simulations of the agentbased model that well fit the theoretical predictions. The plot illustrates that the transition occurring at n c = ( √ 17 -3)/4 is continuous.</p>
<p>Let us now focus on another set of rules, reported in Table II, column NT. Consider the case in which an individual in the mixed state M is undecided about which one of R and I is acceptable, and let the interactions between speaker and hearer be symmetric. When an individual in a state I interacts with one in a state R both become confused on which form is right and therefore both switch to M. When an individual in a state M interacts with one in a state I or R, the outcome of the interaction depends on which form the individual in the mixed state uses: if it is the same one used by his partner (with probability 1/2) then nothing changes, if it is the alternative one (with probability 1/2) then the partner becomes confused and also switches to the mixed state M. Interactions among individuals both in the same state I or R do not produce any change. The outcome of an interaction among two individuals in a state M depends on which form they use: if they both use the regular inflection (with probability 1/4) they both switch to status R, if they both use the irregular inflection (probability 1/4) they both switch to status I , if they use different inflections (probability 1/2) they both remain in the mixed state M, coherently with the rules regulating the outcomes of the previous interactions.</p>
<p>It is easily seen that under this rule set the system converges to the fully regular state for any value of the ratio r/ν. The MF equations are 2 . Summing and subtracting the first equation from the second, one obtains</p>
<p>which shows that, for n &gt; 0, the fully regular state ρ R = 1, ρ I = 0 is the only possible stationary state. The conclusion is that, for any value of ν (and n &gt; 0), this set of rules always leads to a completely regular state for all individuals.</p>
<p>Unlike the previous models this one is discontinuous in the limit n → 0: the model with replacement does not converge in the limit of vanishing replacement to the model with n = 0. It is easy to see that in the case n = 0 from Eq. ( 17) ẏ ≡ 0; therefore, the unbalance y 0 between ρ I and ρ R present in the initial condition is preserved during the dynamics, while x converges to (1 + y 0 )/2. Therefore, the stationary state is continuously dependent on the initial condition, and given by ρ R = (1 + y 0 ) 2 /4, ρ I = (1y 0 ) 2 /4, which gives the fully regular solution only as long as the system is initiated in the fully regular state.</p>
<p>To conclude this section, we observe that in three-state models different microscopic interaction rules give rise to qualitatively different behaviors. In the next section we present a general approach to the modeling schemes presented so far, clarifying why they give rise to different phenomenologies.</p>
<p>In this section we present a very general three-state model that provides a unified framework for generic sets of interaction rules, and we solve it analytically within the mean-field approximation. This framework allows us to comprehend the origin of the different behaviors found in the specific models investigated in the previous sections, providing a complete understanding of the global phenomenology of three-state models. We start by considering a general two-state model first, as this elucidates why the more complex three-state model is needed and how it behaves. We then consider a very general three-state model, encompassing all models considered before as particular cases. This approach will clarify a number of general points. In particular, it will show how the nature of the transition for both two and three-state models depends on the microscopic rules and clarify the role of asymmetries in the behavior of the speaker and hearer in the communication process.</p>
<p>Each individual is either in state R or I . At rate r each individual is replaced by one in state R. At rate ν an interaction occurs among two randomly selected individuals, the speaker and the hearer. We indicate the state of the pair of individuals in interaction as (X,Y ), where X is the state of the speaker and Y of the hearer. As reasonable, we assume that nothing happens if the two individuals are in the same state [(R,R) → (R,R), (I,I ) → (I,I )]. We first consider the case of deterministic rules, i.e., the state at the end of the interaction is fully determined by the initial state. Starting with the state (R,I ) we parametrize the interaction rule by means of the coefficient γ RI , which gives the variation in the number of individuals in state I. For example, for the interaction [(R,I ) → (R,R)] γ RI = -1, while for [(R,I ) → (I,I )] γ RI = 1. Analogously, when the initial state is (I,R) the rule is parametrized by γ I R .</p>
<p>The mean-field equation for this process is simply</p>
<p>Obviously, ρ R = 1ρ I . It follows immediately from Eq. ( 18) that assuming distinct asymmetric roles between speaker and hearer has no effect whatsoever on the collective behavior, since only the cumulative coefficient γ = γ RI + γ I R enters the equation. The distinction between hearer and speaker is therefore irrelevant and any model defined by an asymmetric set of rules behaves exactly as its symmetrized version. This observation allows us to specify any two-state model by means of just one parameter, γ , with values between -2 and 2. The general solution of Eq. ( 18) is obtained by replacing n with 2n/γ in Eqs. ( 2) and (3). The sign of γ determines the nature of the transition: for γ &gt; 0 (rules biased in favor of I ) there exists a continuous transition with n c = γ , while for γ 0 (rules unbiased or biased against I ) there is no transition, and the fully regular state is the only stationary solution. Therefore, we conclude in general that the system is driven toward a fully regular state unless a bias in the interactions compensates for the increase in the R population due to replacement.</p>
<p>In the most general case, the outcome of each interaction is decided probabilistically. In this case, γ I R and γ RI are defined as the average increase in I states in the interaction, each of them assuming any real value in [-1,1]. Correspondingly, γ can assume any real value in [-2,2]. It is immediate to realize that the dynamics is again described by Eq. ( 18) and all the above conclusions hold.</p>
<p>As demonstrated explicitly in the case of two-state models, asymmetric interaction rules (such as those in Table II) produce exactly the same behavior as their symmetrized version also in three-state models. It is therefore possible to express all possible interaction rules among individuals in a way analogous of what we have done for the two-state case. Let us define γ i , φ i , and δ i as the average variation in the number of individuals in state I , R, or M, respectively, occurring when an interaction of type i takes place. We will denote with i = 1 the interactions with initial state (I,R) and (R,I ), i = 2 for (R,M) and (M,R), i = 3 for (I,M) and (M,I ), and i = 4 for (M,M). As above, we are assuming that no change occurs when two individuals in state R (or two individual in state I ) interact. The interaction is instead nontrivial in the case (M,M). Conservation of the number of individuals implies γ i + φ i + δ i = 0, for any i = 1,2,3,4, which reduces the number of independent parameters from 12 to 8. Notice that these quantities may be noninteger when we allow for different possible final states from a given initial state (each with a given probability).</p>
<p>With this parametrization of the dynamical rules we can write the rate equations for the evolution of the system in the most general case:</p>
<p>where n = r/ν is the rate of the replacement process relative to the frequency of interaction.</p>
<p>We now focus on the case of unbiased interactions that do not favor either the regular or the irregular form of the verb. In other words, the interaction rules are perfectly symmetric under the exchange between R and I ; the only mechanism that breaks the symmetry between the regular and the irregular form is replacement, which favors the diffusion of the former. This choice is based on the observation that, while in the two-state case unbiased interaction rules always drive the system toward the fully regular state, the existence of a mixed state allows the survival of the irregular form even for some R-I symmetric interactions. This can be deduced from the three models presented in the previous section, which all have unbiased rules yet exhibit three qualitatively different behaviors. Hence symmetric interaction rules are general enough to lead to continuous or discontinuous transitions or to the absence of any transition.</p>
<p>The assumption of unbiased interaction implies the following additional relations among the parameters:</p>
<p>thus reducing the number of free parameters to 4 (we choose to use the four γ i ). The values of these parameters are not arbitrary. An (R,I ) interaction cannot produce an increase in the number of individuals in the I state, since the same change must occur also for individuals in the R state, since γ 1 = φ 1 ; hence, γ 1 0. In the same interaction the number of irregulars cannot decrease by more than 1; -1 γ 1 . With similar considerations it is not difficult to verify that the γ i parameters are bounded as follows:</p>
<p>Introducing the relation Eqs. (20) in Eqs. (19) it is possible to write Eqs. ( 19) in a particularly simple form by defining the auxiliary quantities x = ρ R + ρ I and y = ρ Rρ I , which represent the fraction of individuals in an unmixed state, and the excess fraction of R states with respect to I states, respectively:</p>
<p>Physically sensible solutions must be in the range 0 x 1 and -x y x. Notice that c 0, f 0, while the sign of a and d may vary and the coefficients are related by</p>
<p>Equation ( 24) implies that, for any choice of the parameters, (x,y) = (1,1) [which corresponds to the fully regular state (ρ R = 1,ρ I = 0)] is always a stationary solution of Eq. (22). By imposing stationarity in Eqs. (22), other stationary solutions can be determined. For specific values of the parameters γ i it is always straightforward to solve analytically for the stationary solutions of Eqs. (22) (which boils down to the solution of a third-order algebraic equation) and study their behavior as a function of n.</p>
<p>In the following we derive instead in full generality conditions on the parameters γ i for the existence, as a function of n, of a continuous transition, a discontinuous one or no transition at all.</p>
<p>Let us first consider the special class of models with γ 3 = γ 2 . In this case the second of Eqs. ( 22) trivially yields at stationarity y = 1, giving the two solutions (x 1 ,y 1 ) = (1,1) and (x 2 ,y 2 ) = [-(2d + a)/a,1]. The second solution is always unphysical. Indeed, from Eq. ( 24) it follows that -(2d + a) &gt; 0. Hence, x 2 is smaller than 0 if a &lt; 0. On the other hand, TABLE III. The table summarizes the values of the set of γ i parameters for the three models studied in the previous section.</p>
<p>Model CT Model NG</p>
<p>for γ 3 = γ 2 the value of γ 3 + γ 2 is always positive, since γ 2 0. This implies -(2d + a) &gt; a so that x 2 &gt; 1 if a &gt; 0. We conclude that when γ 3 = γ 2 the only possible stationary state is the fully regular one: no transition may occur. As shown in Table III the NT model considered in the previous section falls in this class of models, featuring γ 2 = γ 3 = 0. We will see below that also the degenerate case γ 1 = 0 implies no transition, irrespective of the value of the other parameters.</p>
<p>Assuming now γ 3 = γ 2 , and imposing stationarity in Eq. ( 22), we get</p>
<p>]. The solutions of Eq. ( 25) are given by the intersections between two conic sections C 1 and C 2 . C 2 is a hyperbola with asymptotes y = 0, and x = 1 -. Depending on the sign of , the two branches of the hyperbola lie in different quadrants with respect to the asymptotes (see Fig. 5). In the limit → 0, which corresponds to the case with no replacement, the hyperbola degenerates into the pair of asymptotes, y = 0 and x = 1. The conic section C 1 is an ellipse for a &gt; 0 and an hyperbola for a &lt; 0, turning into a parabola for a = 0, with axes in all cases parallel to the Cartesian coordinate system. The intersections of C 1 with the y = 0 axis are, for a = 0,</p>
<p>where</p>
<p>It is not difficult to show that x 1 is always physical (between 0 and 1) while x 2 is always unphysical (see Appendix B). In particular, x 2 &gt; 1 if a &gt; 0 and x 2 &lt; 0 if a &lt; 0. In the limit a → 0, x 1 → -f/(2d) (which is the intersection point for the parabolic case a = 0) while x 2 → ±∞, depending on the sign of a. Hence, despite the change in the global behavior for different values of a, C 1 has always a similar shape in the region of physical interest 0 x 1: it crosses the y = 0 axis for x = x 1 and is concave toward the right, passing through the two points (x,y) = (1,1) and (x,y) = (1, -1) for any value of the parameters. Notice that also C 2 always goes through the point (x,y) = (1,1), so that the fully regular state is always a stationary solution.</p>
<p>We now investigate in full generality the possible existence of other stationary solutions, i.e., other intersections in the physical region. Only the case c = 0 (γ 1 = 0) needs to be treated separately, because the conic section C 1 degenerates into a pair of lines: (x -1)[x + (2d + a)/a] = 0, one (x = 1) on the boundary of the physical region, the other outside it. The fully regular solution (x,y) = (1,1) is then the only stationary state, and there is no transition. We will assume c = 0 in what follows.</p>
<p>γ 3 &gt; γ 2 : Discontinuous transition. For γ 3 &gt; γ 2 ( &gt; 0), the hyperbola C 2 lies in the upper-right and lower-left quadrants with respect to the asymptotes (see Fig. 5). Notice that the vertical asymptote is always at x &lt; 1. Apart from the fully regular solution, one intersection occurs always for x &lt; 0 or x &gt; 1 and is thus unphysical. Two other intersections may instead occur between C 1 and the lower-left branch of C 2 . For large n these intersections do not exist as it can be recognized by observing that for &gt; 1 the lower branch of C 2 has x &lt; 0 while C 1 has x &gt; x 1 &gt; 0. However, when n → 0, C 2 shrinks toward its asymptotes x = 1and y = 0, while C 1 does not change much. At some critical value n = n c , C 2 starts intersecting C 1 , so that for n &lt; n c there are two intersections (see Fig. 5), both in the physical region because the derivative of</p>
<p>In this case the system undergoes a discontinuous transition at n c . Notice when these two solutions exist they are in the region y 0, implying that ρ I ρ R , i.e., the fraction of individuals in the I state is larger than the fraction of those in the R state. As indicated in Table III, the model NG, which features γ 3γ 2 = 1/2, belong to this class and this explains why it undergoes a discontinuous transition. γ 3 &lt; γ 2 : Continuous transition. For γ 3 &lt; γ 2 ( &lt; 0), the hyperbola C 2 lies in the upper-left and lower-right quadrants (see Fig. 5). The lower branch has x &gt; 1 -&gt; 1 and hence is unphysical. Therefore, at most two of the four solutions (the intersections of the upper branch with C 1 ) are physical. One of them is the fully regular state. To investigate the location of the other intersection one can compare the slope of the two conic sections for x = 1. If the slope of C 1 is larger than the slope of C 2 (which happens for large n) the second intersection occurs for x &gt; 1, it is unphysical and as a consequence the fully regular state is the only stationary solution. If n is reduced, the slope of C 1 at x = 1 decreases while the slope of C 2 grows. At a critical value n c the two slopes are equal and for n &lt; n c the second intersection becomes physical (x &lt; 1). We conclude therefore that the system undergoes a continuous transition between a fully regular state and a state with coexisting regular and irregular individuals. Notice that in this case, since the physical intersections have y 0, necessarily ρ I ρ R . The value of n c is easily determined by the condition that the two slopes are equal and turns out to be (27) which has always one positive value (the other being always negative), coherently with the fact that there is always a transition. Remarkably, the value of n c does not depend at all on the coefficient γ 4 , regulating the M-M interaction. The model CT in the previous section has γ 3 = 0, γ 2 = 1/4, and γ 1 = -1/2 (see Table III). These values explain why it undergoes a continuous transition at n c = ( √ 17 -3)/4.</p>
<p>So far we have shown that below some critical value of n additional stationary solutions appear, beyond the fully regular solution. To complete the demonstration of the existence of phase transitions we must analyze their stability.</p>
<p>By linearizing Eqs. ( 22) around the solution (x * ,y * ), one gets 1 2ν For the fully regular state (x * ,y * ) = (1,1) the eigenvalues of the stability matrix M can be evaluated explicitly yielding</p>
<p>where the trace of the matrix is tr(M) = γ 1γ 2γ 3n and 1 = (γ 1 + γ 2 + γ 3 ) 2 -8γ 1 γ 2 0. Notice that 1 is independent of n and positive, implying that the two eigenvalues are always real.</p>
<p>In the case γ 3 &gt; γ 2 , both eigenvalues are negative, as can be deduced by considering that tr(M) (the sum of the eigenvalues) is always negative (being the sum of four negative terms) and det(M) = n 2 /4n(γ 1γ 2γ 3 )/2γ 1 (γ 3γ 2 ) (the product of the eigenvalues) is always positive for n &gt; 0. This last condition can be understood by considering that det(M) is a parabola with upward concavity and zeros for negative values of n [given by Eq. ( 27)]. Hence, the fully regular state is always stable. For small n, the two other solutions appearing in the physical region are a saddle and a stable fixed point [see Fig. 6]: a discontinuous transition occurs.</p>
<p>In the case γ 3 &lt; γ 2 , corresponding to a continuous transition, det(M) is positive for large n, but it changes sign for n &lt; n c [where n c is the only positive determination of Eq. ( 27)] thus implying that one of the eigenvalues becomes positive. Hence, below the transition the fully regular state corresponds to a saddle, while the other solution appearing in the physical region is stable [see Fig. 6].</p>
<p>Finally, we remark that the parameters corresponding to the naming game, considered in the previous section as an example of models with discontinuous transition, give 1 = 0, corresponding to two degenerate eigenvalues, and only one eigenvector. In this case the fully regular state is stable but defective: in principle arbitrarily small changes of the parameters may result in a standard stable fixed point if 1 &gt; 0, or in a stable spiral when 1 &lt; 0. This last case would change the physical picture, because spiralling trajectories would cross the boundary of the physical domain before reaching the fixed point, and therefore the physical system would be driven toward the boundary of the physical region without reaching the fixed point. However, this possibility is ruled out by the condition 1 0, which holds for physically sensible values of the parameters γ i .</p>
<p>The conclusions that follow from the theory presented in this section are very general and simple. The existence and the nature of a transition depends only on the sign of γ 3γ 2 . If γ 3 &gt; γ 2 , as the frequency increases a discontinuous transition occurs between a fully regular state and a state with coexistence of fully regular and mostly irregular inflections. If γ 3 &lt; γ 2 , the transition is instead continuous. If γ 3 = γ 2 , no transition occurs and the system always reaches a fully regular state.</p>
<p>It is important to notice that the condition γ 3 &gt; γ 2 has a very natural interpretation in the context of language dynamics. It simply means that (recalling that γ 2 = φ 3 ) an interaction between an individual in state M and one in state I will produce an increment in the use of the irregular inflection larger than the increment in the use of the regular inflection. The fact that this asymmetry alone is sufficient to give rise to a discontinuous transition is a strong indication of the relevance of these theoretical modeling efforts for the interpretation of empirical data.</p>
<p>This work has presented an investigation of agent-based models aimed at understanding the processes regulating the interplay between rules and exceptions in language dynamics. In particular, the models aim to investigate the observed behavior of verbs in natural language. Corpus data from natural language points to the existence of a discontinuous transition as a function of the frequency of usage: high-frequency items are highly irregular and low-frequency ones are regular, while in an intermediate frequency range coexistence between the two behaviors is observed.</p>
<p>In the minimal models considered each agent is endowed with an inventory, containing the possible inflections (regular or irregular) of a lemma. Two processes have the potential to change agents' inventories over time: interaction and replacement. In interaction, individuals influence each other, adding or deleting forms from their inventories according to a specific set of interaction rules. In replacement events, agents are substituted by new "child" individuals, who are automatically biased toward the regular form by being "born" with a regular inventory.</p>
<p>We analyze two classes of models. In the first one each individual may store in the inventory only one of the two competing inflections, either the regular or the irregular one. Three-state models instead integrate a mixed state, which represents an individual who finds both the regular and irregular forms acceptable. We solve these models analytically within the mean-field framework and confirm the results by means of numerical simulations. We first focus on a few specific models, including the naming game for language dynamics. The analysis reveals that the the global phenomenology changes qualitatively depending on the interaction rules: one can observe the absence of a transition with a move to total regularity, a continuous transition, or a discontinuous one. We then consider a very general three-state model, encompassing all previous examples as special cases, which allows the description of the previous models with a set of four minimal parameters describing the interaction rules. From this comprehensive approach several results follow:</p>
<p>(i) Asymmetries in the influence of the speaker and of the hearer in interaction do not play any role in the collective behavior of the system.</p>
<p>(ii) In two-state models the fully regular state is the only attractor unless the interaction rules are biased in favor of the irregular inflection; the three-state models have instead nontrivial behavior even when the rules are unbiased;</p>
<p>(iii) Allowing for a third state is crucial for the appearance of a discontinuous transition that cannot arise in two-state versions of the model.</p>
<p>(iv) In three-state models the quantity γ 3γ 2 rules the macroscopic behavior by changing the nature of the transition: when γ 3 &gt; γ 2 , a discontinuous transition is observed to a state where irregular inflection is prevalent (ρ I &gt; ρ R ); in the opposite case, when γ 3 &gt; γ 2 a continuous transition is observed, to a state with 0 &lt; ρ R &lt; ρ I ; in the case γ 3 = γ 2 there is no transition and the fully regular state is reached for any frequency.</p>
<p>(v) In the case γ 3 &gt; γ 2 , above the discontinuous transition the steady state depends on the initial condition: verbs with the same frequency can end up as fully regular or mostly irregular, similarly to what is observed in empirical data.</p>
<p>(vi) In the context of language dynamics, the condition γ 3 &gt; γ 2 is satisfied by sets of more plausible rules, so that a discontinuous transition is to be expected.</p>
<p>This model provides a framework that could potentially be used to consider additional, more complex aspects of rule dynamics in language. In particular, empirical data shows that the growth of language contributes to the expansion of regularity [9], since a core aspect of a linguistic rule's utility is that it can be generatively applied to new forms (e.g., the past tense of the neologism selfie is uncontroversially selfied). Our model considers a word's frequency to be static over time; however, natural languages are living, and populations, vocabulary sizes, and turnover rates are not static. Furthermore, there are other cognitive mechanisms beyond child learner biases that may contribute to regularity dynamics. General memory constraints may contribute to the persistence of highly frequent irregular forms [32], and adult learners may possess qualitatively different regularization biases from children [33]. Moreover, the use of a disordered topology for the pattern of interaction, as opposed to the homogeneous mixing assumed by the MF approach, combined with the interaction among the different lemmas in the agents' inventories may lead to different patterns of regularization in frequency. Future models might also consider another key aspect in the persistence of irregularity: the notion that irregular forms are not always exceptions, but sometimes constitute subrules [34] (e.g., footfeet/goose-geese, sing-sang/ring-rang). Our model provides a basic starting point from which to consider the complex dynamics underlying temporal trends of the rules that form the core of language.</p>
<p>Finally, it is very important to stress that while models and results are presented in this paper in terms of linguistic rule dynamics, they are fully general and apply to any system where individuals have three possible internal states and the population exhibits turnover. The results presented in this paper, and in particular the conditions determining the existence of a transition and its nature, may have strong implications not only for linguistic rules, but also for all those systems.</p>
<p>This work was supported by the European Science Foundation as part of the DRUST project, a EUROCORES EuroUnderstanding programme.</p>
<p>In this appendix we report the stability analysis for the naming game without biased replacement, i.e., with n = 0 as discussed in Sec. III A. For the case n = 0 the stability matrix is given by</p>
<p>whose eigenvalues are</p>
<p>where, as before, (ρ * I , ρ * R ) indicates the generic stationary solution. For (ρ (1) I , ρ (1) R ) and (ρ (2) I , ρ (2) R ) both eigenvalues are negative and the solutions are both stable. For (ρ (3) I 0.382, ρ (3) R 0.382) the eigenvalues are one positive (λ 1 = 2.236) and one negative (λ 2 = -4.236) and this corresponds to a saddle point with an attractive and a repulsive direction. The separatrix in Fig. 3 (left) in the attractive direction corresponds to the eigenvector associated to the negative eigenvalue: ρ R = ρ I (the red line in figure). The other separatrix is locally approximated in the neighborhood of (ρ (3) I , ρ (3) R ), by the eigenvector associated to the positive eigenvalue ρ R = -ρ I + 2ρ (3) I (the green line in figure). The phase flow is such that if the initial condition is such that ρ I &lt; ρ R (ρ I &gt; ρ R ) the system will deterministically converge to the regular (irregular) state. On the other hand, if the initial condition is such that ρ I = ρ R the system will converge to the stationary solution (ρ (3) I , ρ (3) R ) (see also Refs. [12,31]).</p>
<p>In this appendix, we provide explicit proofs that the intersections x 1 and x 2 of the conic section C 1 with the axis y = 0 [see Eq. ( 26)] are always physical and always unphysical, respectively.</p>
<p>Let us first consider the case a &gt; 0. A crucial point to recognize is that, since a</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f82833909"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Modern scientific experiments crucially depend on the control and monitoring of many parallel streams of data. Multiple measurement devices, from video cameras, microphones, and pressure sensors to neural electrodes, must simultaneously send their data in real-time to a recording system. General purpose digital computers have gradually replaced many of the specialized analog and digital technologies used for this kind of data acquisition and experiment control, largely due to the flexibility of programming and the exponential growth in computing power. However, the serial nature of programming instructions and shared memory makes it a challenge, even for experienced programmers, to develop software that can elegantly deal with the asynchronous, parallel nature of scientific data.</p>
<p>Another challenge arises from the need for software integration. Each hardware vendor provides their own set of drivers and programming interfaces for configuring and acquiring data from their devices. In addition, the growth of the open-source movement has greatly increased the number of freely available technologies for different data processing domains. Integration of these diverse software and hardware components remains a major challenge for researchers.</p>
<p>These difficulties lead to increased development times when setting up an experiment. Moreover, it requires experimenters to pursue specialized training outside their domain of research. This limits the ability to rapidly prototype and try out new designs and can quickly become the factor limiting the kinds of questions that are amenable to scientific investigation.</p>
<p>Scientific data, like the world we live in, is inherently parallel. To monitor this complexity, modern experimenters are often forced to use multiple electronic instruments simultaneously, each with their own independent sampling rates. As data arrives at the acquisition computer, there are two main approaches to log and process these asynchronous data streams. The first approach is to use a polling strategy: a single sequential process in the computer runs a processing loop that goes through each device in sequence and gathers the available data. In this case, data from only one device is being collected and manipulated at any point in time. The second approach is to use an event-driven (reactive) architecture: processes are setup in parallel to collect data from all the devices simultaneously. Whenever new data is available, notifications are sent to the appropriate software routines that collect and process the data as soon as possible. When only a single processor is available, the difference between these two strategies is negligible: only one instruction at a time can be executed by the computer. However, with modern multi-processor cores and dedicated data transfer circuits, the performance difference between the two approaches will significantly influence the throughput of a data acquisition and processing system. Unfortunately, software tools to support and facilitate the "reactive" approach to data stream processing are only just now starting to be adopted and most software systems are still built from the sequential composition of simple program routines. Many of the assumptions of the sequential processing scenario do not scale to handle parallel execution, especially when shared memory and resources are involved.</p>
<p>A common requirement when designing and manipulating dataflows is the ability to visualize the state of the data at different stages of processing. We have therefore included a set of visualizers to assist debugging and inspection of data elements, including images and signal waveforms (Figure 1). These visualizers are automatically associated with the output data type of each node and can be launched at any time in parallel with the execution of the dataflow. Furthermore, it is often desirable to be able to manipulate processing parameters online for calibration purposes. Each node has a set of properties which parameterize the operation of that particular source or combinator (Figure 1). This allows, for example, changing the cutoff frequency of a signal</p>
<p>The processing of the elements of each window happens independently, as if there was a new isolated dataflow running for each of the sequences. We can exploit this independence in order to dynamically turn dataflows on and off during an experiment. In the video splitting example of More generally, we can use this idea to implement discrete transitions between different processing modes, and chain these states together to design complex control structures such as finite state machines (FSMs). FSMs are widely used to model environments and behavioral assays in systems and cognitive neuroscience. One example is illustrated in Figure 3F, where we depict the control scheme of a stimulus-response apparatus for a simple reaction time task. In this task, there are only two states: Ready and Go. In the Ready state, no stimulus is presented and a timer is armed. Whenever the timer fires, the task transitions into the Go state, and a stimulus is presented. The subject is instructed to press a key as fast as possible upon presentation of the stimulus. As soon as the key is pressed, the system goes back to the Ready state to start another trial. In a FSM, nodes represent states, e.g., stimulus availability or reward delivery, and edges represent transitions between states that are caused by events in the assay, e.g., a key press. In each state, a number of output variables and control parameters are set (e.g., turning on a light) which represent the behavior of the machine in that state.</p>
<p>Many of the control tasks in experiments have this sequential trial-based structure, which has allowed us to rapidly prototype complex behavior assays, such as closed-loop rodent decision making tasks, simply by leveraging the flexibility of the data stream slicing operators.</p>
<p>Although graphical user interfaces have played a crucial role in the widespread proliferation of computing technology throughout various scientific fields, the majority of these interfaces tend to be applied to relatively narrow domains, such as the operation of a specific instrument. Their goal is often to provide access to all the various configuration parameters of the hardware and to provide basic data acquisition functionality. There is often no opportunity to parameterize or condition the behavior of the instrument beyond the possibilities presented by the interface, and interconnections with other devices are often limited to simple hardware triggers. The alternative, when available, is to access low-level application programming interfaces (APIs), and program the desired behavior from scratch.</p>
<p>In the more flexible domains of data analysis, behavior control and software simulations, the use of more versatile graphical interfaces has become increasingly prevalent. In these scenarios, it is not uncommon to encounter the development of domain-specific languages (DSLs), where graphical building blocks related to the domain of application can be combined together by the user to generate new behaviors, such as the The color of each Bonsai node serves as a visual aid to identify their role in dataflow processing pipelines. Most of these categories are actually specializations of the very general combinator and are meant to visually depict their specific data processing semantics.</p>
<p>sequence of steps in a psychophysics experiment or a statemachine diagram used to control stimuli and rewards in operant conditioning. While providing more flexibility to the end user, such DSLs are usually not conceived, at their core, to be applied to wildly different domains (e.g., an operant conditioning state machine is not expected to be able to filter continuous electrophysiology signals). In fact, most DSLs will not even allow the user to extend the set of built-in operations. In those that do, the developer may find a customization pit (Cook et al., 2007), where concepts and operations that are within the range of what the DSL can express are easy to develop, whereas tasks that are a little bit outside of the boundaries of the language quickly become impossible or too cumbersome to implement.</p>
<p>One important caveat of developing asynchronous systems is that debugging can be more difficult in situations where the precise timing and ordering of events is required to reproduce an offending behavior. In synchronized and sequential execution environments, one can easily go step by step through the precise cascade of transformations that resulted in a problem. In contrast, when multiple processes are executing concurrently, it can be harder to analyze the program flow in a similarly reproducible, deterministic manner. However, it should be noted that this issue is not unique to reactive environments with real asynchronous devices. A sequential polling strategy will be equally deficient in reproducing a particular execution sequence when data from parallel input devices is being accessed.</p>
<p>The integration of all these diverse components for data acquisition and experiment control does not only allow for the rapid deployment of established protocols. In fact, the modular nature of their integration (i.e., how they can be combined together) opens up new avenues for research, by allowing a rich, rapid exploration of novel methodologies. To demonstrate this, we created a dynamic virtual environment for freely moving rodents where the visual presentation of a stimulus is tightly controlled in closed-loop to the actions of the animal. We used a projection setup similar to the low-cost multi-touch sensing table proposed by Han (2005), where a visible light rearprojection system is coupled with infrared illumination and an infrared imaging sensor to detect in real-time where the animal is located with respect to the visual display surface (Supplementary Video 2).</p>
<p>How would designing such a scenario feel like in a reactive programming language? Figure 5C shows a possible specification of the 1-site foraging task in reactive terms. In this case, we have two sources of events from the environment: one timer signaling the availability of reward (A); and a sampling event (S) which is triggered every time the animal checks the location for food. Both BOX 2 | Under the Hood</p>
<p>All experiments were approved by the Champalimaud Foundation Bioethics Committee and the Portuguese National Authority for Animal Health, Direcção-Geral de Alimentação e Veterinária (DGAV).</p>
<p>Larval zebrafish (6 dpf) were filmed with a high-speed monochrome video camera (Flea3, Point Gray, CA) under IR illumination. Fish swam freely in a custom-built arena that was laser cut from transparent acrylic that consisted of three separate chambers, each 40 × 100 mm. The position and orientation of the zebrafish in the central chamber was continuously tracked in real-time, while the video of the entire arena (1.3 Megapixel) was compressed to a high-quality H.264 encoded file that was used for subsequent offline analysis of the interaction between individuals and groups of zebrafish placed in either of the side chambers.</p>
<p>Freely behaving mice were filmed with a video camera (PlayStation Eye, Sony, JP) under white light illumination in their own homecages. A fiberoptic setup was developed to monitor bulk fluorescence changes in specific neuron populations using genetically encoded calcium indicators. Changes in fluorescence caused by neuronal activity were transmitted by an optical fiber and recorded with a CCD camera (Pike, Allied Vision Technologies, DE). The position and orientation of the mice was continuously tracked in real-time, while the mean pixel value of the area of the camera facing the fiber optic was continuously calculated. Both videos were compressed to high-quality H.264 encoded files to be used in subsequent offline analysis.</p>
<p>Individual Drosophila melanogaster flies were allowed to freely feed on the flyPAD (Itskov et al., 2014) while their feeding behavior was monitored at 50 Hz with a video camera (Flea3, Point Gray, CA) mounted on a Zeiss Discovery v.12 Stereo Microscope (Carl Zeiss, DE). flyPAD measures fly's behavior on the food source by recording the capacitance at 100 Hz between the electrode on which the fly stands and the food. Videos were compressed to high-quality H.264 encoded files and subsequently manually annotated by a human observer to be used as a benchmark for the development of the automatic algorithms for the extraction of feeding behavior from the capacitive trace. For more info, visit http://flypad.pt/.</p>
<p>Frontiers in Neuroinformatics | www.frontiersin.org</p>
<p>April 2015 | Volume 9 | Article 7</p>
<p>Conceived and developed the project: GL, NB, JF; Developed software: GL; Conceived and developed the experiments: GL, NB, JF, JN, BA, SS, LM, SM, PI, PC, RM, LC, ED, JP, AK; Performed and analyzed experiments: GL, JF, JN, BA, SS, LM, SM, PI, PC, RM, LC, ED; wrote the manuscript: GL, AK.</p>
<p>The Supplementary Material for this article can be found online at: http://www.frontiersin.org/journal/10.3389/fninf.2015.</p>
<p>Conflict of Interest Statement: The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f81755791"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T05:59+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Background: Without an understanding of evolution, members of the public are unlikely to fully grasp many important issues necessary for the understanding science. In addition, evolutionary science plays an important role in advancing many other STEM disciplines. In stark contrast to the importance of the evolutionary sciences, is its enigmatic acceptance by the general American public. This acceptance is also not uniform within African American, Hispanic, and American Indian populations, who show higher rates of rejection of evolutionary reasoning. In an effort to advance our scientific community, it is imperative that we recruit highly quality students from an ever-increasing diverse population. Thus, the field is failing to attract and maintain the diversity desired in America's scientific workforce with the above-mentioned minority groups, which are even further underrepresented in evolutionary science.</p>
<p>Methods: To examine why underrepresented minorities may not choose careers in evolutionary sciences, we surveyed 184 people who have chosen to pursue a career in science. The two questions we examined were: (1) what factors influence the career choices of underrepresented minorities (URMs) interested in science? and ( 2) what factors influence these URM students to choose careers in other sub-disciplines in biology rather than careers in evolutionary science? A survey was created from previously published research, and our analysis examined statistical differences between different racial/ethnic groups.</p>
<p>Results: Our data suggest there are significant differences among racial/ethnic groups in factors that appear to influence their career paths, specifically African Americans and non-Puerto Rican Hispanic/Latino(a)s place greater emphasis on the presence of people of similar racial/ethnic background. Additionally we found differences between the URM groups in terms of their interest in, and understanding of, evolutionary biology; which appears to result in less likelihood of choosing careers in evolutionary science. And for some African Americans, reluctance to pursue evolutionary biology may be tied to holding misconceptions about evolution and higher levels of religiosity.</p>
<p>Conclusions: Our current work is preliminary, but once there is a better understanding of why URMs do not pursue evolutionary science, strategic steps can be taken to overcome these barriers. When an inclusive culture is at work, a diverse scientific team becomes capable of producing a broad range of original and engaging ideas not possible among homogenous groups. Educators, researchers, and equality advocates will be able to target the specific causes of underrepresentation in the evolutionary sciences and improve representation of racial and ethnic minorities in evolutionary science, to the ultimate benefit of the greater scientific community and the world at large.</p>
<p>Despite the vast and ever-increasing evidence for the theory and fact of evolution (Gregory 2008), and overwhelming acceptance among scientists, many factions of American society continue to show low rates of acceptance of evolution (Table 1) (Pew Research 2009;Pew Research 2013;Gallop News 2014), and rates in the U.S. are among the lowest of many industrial countries (Miller et al. 2006). These data are not new to any of us working in the field of evolution education. Polls (Pew Research 2013) and studies (Fuerst 1984;Ingram and Nelson 2006;Paz-y-Minos and Espinosa 2009b;Rice et al. 2011) suggest understanding of evolution increases with years of education, therefore one might expect levels of evolution acceptance to be high among college students, particularly those interested in the STEM (science, technology, engineering, and mathematics) disciplines. However, a review of studies investigating evolution acceptance among undergraduate students (see Additional file 1: Table S1) suggests low rates of acceptance of evolution, even among the STEM student population (Blackwell et al. 2003;Rutledge and Sadler 2007). These studies also suggest a positive relationship between understanding science and acceptance of evolution (Fuerst 1984;Lombrozo et al. 2008), and a negative relationship between religiosity and acceptance of evolution (Lombrozo et al. 2008;Bailey et al. 2011;Paz-y-Minos and Espinosa 2009a;Paz-y-Miño and Espinosa 2011;Rissler et al. 2014). A recent study suggests that religiosity is even more important factor than education (Rissler et al. 2014). Whereas many studies focus on religiosity as the main driver, others attempt to delineate additional factors influencing evolution acceptance (Brem et al. 2003;Sinatra et al. 2003;Hawley et al. 2011). We discovered that many studies sample populations that include racial/ethnic minority students, however few of them disaggregate evolution acceptance by race/ethnicity. In contrast, Bailey et al. (2011) did disaggregate minority student responses and found greater religiosity among African American students compared to non-African Americans, and this was negatively correlated with evolution acceptance. Surprisingly, however, Bailey et al. (2011) also found a negative correlation between knowledge of evolution and acceptance of evolution; the more students appeared to know about evolution, the less likely they were to accept evolution. These results suggest it may be important to evaluate racial/ethnic differences in evolution acceptance and understanding, particularly if recruitment and retention of underrepresented minority (URM) students in STEM disciplines that apply or require evolutionary reasoning is a priority.</p>
<p>Evolutionary science informs a wide range of science and technology facets within US society (Larder et al. 1989;Back 1996;Nesse and Williams 1996;Khachatourians 1998;Dufour 2006;Perron et al. 2006;Pike and Williams 2006;Coello et al. 2007;Graves 2011). In contrast to the importance of the evolutionary sciences, it is clearly not gaining acceptance among college-educated students; and equally disturbing, it is failing to attract and maintain the diversity desired in America's scientific workforce with African Americans, Hispanics, and American Indians, which are significantly underrepresented in evolutionary science compared with many other sciences. In 2011, within the broad field of biological sciences, the largest numbers of doctoral degrees were awarded in neuroscience, biochemistry, and molecular biology, with the distribution of European Americans, Hispanics, and African Americans receiving degrees in these fields as follows: neuroscience: 535, 49, 32; biochemistry: 377, 39, 26; and molecular biology: 365, 35, 23. Across each of these fields the proportions are relatively consistent (86% of degrees were awarded to European Americans, 8% were awarded to Hispanics, and 5% awarded to African Americans. In stark comparison, the numbers of individuals receiving doctoral degrees in evolutionary biology by ethnicity were 135, 8, and 0 (NSF/NIH/USED/USDA/NEH/NASA Survey of Earned Doctorates 2011). Overall, not only were there substantially fewer students receiving degrees in evolutionary biology, when compared to these three most popular disciplines only 9% of all degrees were awarded in evolutionary biology, the distribution of degrees within racial/ethnic groups was also quite different. The ratio of European Americans, Hispanics, and African Americans receiving doctoral degrees in evolutionary biology as compared to the other disciplines was 0.11, 0.06, and 0.00, respectively. European Americans were twice as likely to pursue a degree in evolutionary biology as compared to Hispanics, and no African Americans received a degree in this field in 2011. We recognize this is just a snapshot and that governmental agencies have just begun to record Ph.D. attainment by race/ethnicity, however the small numbers of African Americans and Hispanics in professional evolutionary science careers strongly suggests this situation is not new. We also have personal observations of the field from the last quarter century indicating that the snap shots are an accurate reflection of its demography (Graves 2012).</p>
<p>A number of studies have identified factors influencing career choices and the success of URM students in the STEM disciplines (Chemers et al. 2011;Eccles 2011;Jaeger et al. 2013;MacPhee et al. 2013;Merolla and Serpe 2013;Thoman et al. 2014), but little is known about the attitudes of URM students toward evolutionary biology, and how these views might influence their decisions to pursue STEM disciplines that require a working understanding of this fundamental concept. We therefore sought to generate information about evolution acceptance and knowledge as potential variables impacting the career choices of undergraduate students who already show an interest in pursuing a career path in science. To study the reasons for science career choice, we created a survey to examine the factors that (1) influence the career choices of underrepresented minorities (URMs) interested in science, and (2) may influence these URM students to choose careers in other sub-disciplines in biology rather than careers in evolutionary science.</p>
<p>Surveys were administered to participants at two scientific conferences, the Annual Biomedical Research Conference for Minority Students (ABRCMS) in November 2013 and the National Conference of the Society for the Advancement of Chicanos and Native Americans in Science (SACNAS) in October 2103. These two conferences differ considerably with regard to the demography of student attendees. Students attending ABRCMS are primarily African Americans, whereas SACNAS participants are primarily Latinos (Mexican American, Puerto Rican, etc.) and American Indians. We chose to focus on these student populations because most are already engaged in scientific research, and therefore represent an excellent source of URM students committed to STEM careers. We understood that these participants would not necessarily be representative of either the attitudes towards, or knowledge of, evolution we would expect to find in the general population of underrepresented minority (URM) students.</p>
<p>At both conferences, the survey was administered via a booth run by the BEACON Center for the Study of Evolution in Action. We asked all visitors to the booth to complete the survey. While we targeted undergraduates, our sample did include a few individuals with degrees, and a few faculty members as well. Everyone surveyed who met the criteria were included regardless of level of education (six participants had completed a PhD). We collected all data following Michigan State University Institutional Review Board guidelines, IRB #i040365.</p>
<p>To assess career choice, religiosity, and evolution understanding, we created a 65-item survey with items belonging to four general categories of social dynamic hypotheses: Religiosity (R); Educational Background (EB); Career Choice Factors (CCF); and Evolution Understanding (UE). In order to examine if our surveyed variables (individual variables and constructs) had any effect on choice of career, we used an open-ended question to identify a student's desired career discipline. These responses were then classified into five categories: evolutionary sciences, general biology, medicine, physical sciences (chemistry/physics), and other science (e.g., Earth sciences). Students choosing computer science and engineering were not included in this analysis.</p>
<p>Items assessing Religiosity were taken from the Evolution Attitudes and Literacy Survey (EALS; Hawley et al. 2011), and we maintained their scale of 1 to 7 for consistency and future comparison with previously collected EALS data. The remaining items were also Likert-type questions, scaled from 1 to 5, and developed to address our preliminary questions. The second category inquired about the person's schooling, with specific reference to training in evolutionary biology. The third category examined possible reasons for career selection, information about the people or other sources of influence for career selection, and familiarity with other URMs in their chosen field. The final category assessed understanding of basic evolutionary processes. We developed statements based on preliminary surveys administered to undergraduates and experts. The complete 65-question survey is available in the Additional file 2: Table S2.</p>
<p>The evolution understanding items have not been previously published or tested for validity and reliability. Thus, the factor analysis of the evolution understanding items will also serve as a test for validity and reliability among our population.</p>
<p>In addition to the five major constructs examined in the factor analyses, other single items from the survey were included in the statistical analyses to examine differences among racial/ethnic groups and career choice (e.g., evolution, biology, or medicine). In order to examine if there were any differences in response to surveyed variables by race/ethnicity, a series of ANOVAs were conducted using the self-identified race/ethnicity as selected from nine ("choose all that apply") choices by the participants. For the ANOVAs examining career choice, the open-ended stated area of study was categorized and used. For all ANOVAs that resulted in a significant difference at p &lt; 0.05, Bonferroni-corrected pairwise t-tests were conducted to test which specific groups were significantly different from one another.</p>
<p>A total of 184 people attending either the ABRCMS in November 2013 or the Annual SACNAS Conference in October 2013 completed the survey. Our sample included 68 males, 115 females, and 1 other. The self-reported racial/ethnic background of people completing the surveys was 89 Hispanic/Latino(a) (48.4%), 38 African American (20.7%), 22 "other" (11.9%), 19 European American (10.3%), 11 American Indian (6.0%), and 5 "no response" (2.7%) (Table 2). Only a few participants self-reported as Asian/ Asian American or Middle Eastern/Middle Eastern American; we therefore categorized these as "other" because of the small sample size, and our specific interest in underrepresented minorities (URM) as defined by the National Science Foundation. Current level of education of survey participants included 2 high schoolers, 4 freshmen, 22 sophomores, 47 juniors, 75 seniors, and 5 in grad school for masters' degrees, 17 in graduate school for Ph.Ds. In addition, 6 had completed MS degrees and 6 had completed Ph.Ds.</p>
<p>Based on our categorization of self-identified career pursuit (Table 2), 117 indicated biology. This category did not include those indicating evolutionary biology (n = 9), nor did it include those planning to become medical doctors or veterinarians (n = 22). However, the biology category did include those pursing medical science research or medical academic careers (e.g., neuroscience research). The remaining respondents indicated interest in physics/chemistry (n = 22), other science disciplines (e.g., Earth science, oceanography, environmental science, astronomy) (n = 14).</p>
<p>Personal factors-Three different constructs of personal factors and influences were predicted based on various groups of survey items. These three constructs (i.e., (1) influence from friends, family, and loved ones; (2) influence from teachers, mentors, and other educators; and</p>
<p>(3) influences from pop culture and media sources) were examined in separate factor analyses because we wanted to compare them, as separate constructs, to career choice and race/ethnicity. The items in each of these three constructs strongly factored together (Table 3) indicating that each group of items can be used to compare with career choice and racial/ethnic identity.</p>
<p>For the family and friends construct, all factor loadings were above the common threshold of 0.32 (Table 3). One factor was satisfactory for examining this construct because there was a steep drop-off illustrated in the scree plot from the first eigenvalue factor to the second. The first factor explained 37% of the variance. The Kaiser-Meyer-Olkin measure of sampling adequacy was 0.84, and Bartlett's test of sphericity was significant (Χ 2 (153) = 2033.415, p &lt; 0.001). In addition, the Cronbach's Alpha was 0.90.</p>
<p>For the teachers and mentors construct, all factor loadings were above the common threshold of 0.32 (Table 3). One factor was satisfactory for examining this construct because there was a steep drop off illustrated in the scree plot from the first eigenvalue factor to the second. The first factor explained 36% of the variance. The Kaiser-Meyer-Olkin measure of sampling adequacy was 0.77, and Bartlett's test of sphericity was significant For the popular culture construct, all factor loadings were above the common threshold of 0.32 (Table 3). One factor was satisfactory for examining this construct, again, there was a steep drop off illustrated in the scree plot from the first eigenvalue factor to the second. The first factor explained 44% of the variance. The Kaiser-Meyer-Olkin measure of sampling adequacy was 0.71, and Bartlett's test of sphericity was significant (Χ 2 (10) = 323.948, p &lt; 0.001). The Cronbach's Alpha was 0.79.</p>
<p>Religiosity-The religiosity items taken from the Evolution Attitudes and Literacy Survey (EALS; Hawley et al. 2011) factored together (Table 4). One factor was satisfactory for examining this construct because there was only one eigenvalue greater than one and there was a steep drop off illustrated in the scree plot from the first eigenvalue factor to the second. The first factor explained 74% of the variance. The Kaiser-Meyer-Olkin measure of sampling adequacy was 0.87, and Bartlett's test of sphericity was significant (Χ 2 (10) = 852.189, p &lt; 0.001). The Cronbach's Alpha was 0.93.</p>
<p>The 12 evolution content items that were used to assess evolution understanding have not been published previously. Each of the 12 Likert-type items was examined in a factor analysis resulting in two different factors (Table 4). The eigenvalues for the two factors were both above one. The first factor explained 23% of the variance, and the second factor explained an additional 16%. The Kaiser-Meyer-Olkin measure of sampling adequacy was 0.81, and Bartlett's test of sphericity was significant (Χ 2 (66) = 705.146, p &lt; 0.001). In addition, the Cronbach's Alpha was 0.80. These two factors broadly correspond to misconceptions (Factor 1) and basic evolutionary processes (Factor 2). Answering in agreement with items in Factor 1 would indicate an individual holds common misconceptions about evolution in general. Answering in agreement to items in Factor 2 would suggest a good understanding of the basic processes required for evolution.</p>
<p>Racial/ethnic group comparisons-When choosing a science discipline within which to pursue as a career, our data suggest African Americans and non-Puerto Rican Latino(a)s are more strongly influenced by the presence of people in that chosen discipline that identify as being part of the same racial/ethnic group (African Americans: p = 0.02; non-Puerto Rican Latino(a)s: p = 0.01) as compared with European Americans (Table 5). European Americans were significantly more likely to gain interest in science from their parent or guardian compared with Native Americans (p = 0.01) and Latino(a)s/Hispanics (p = 0.05). In addition, European Americans were exposed to evolutionary sciences earlier, in middle school, with a significant difference found for the comparison with Puerto Ricans, who report first being exposed to evolutionary science in late high school (p = 0.02). We also found a significant difference in agreement with the idea that evolutionary science is a valid academic discipline, European Americans showed a significant difference from those classified as "other" in our study.</p>
<p>African Americans exhibit higher rates of religiosity than all other racial/ethnic groups (Table 5) and there was a significant difference between African Americans and both European Americans (p &lt; 0.001) and Latino(a)s/ Hispanics (p &lt; 0.001). With respect to understanding evolution, African Americans exhibited a significantly lower understanding of evolution (Table 6) than European Americans (p = 0.05).</p>
<p>We found a significant difference between students pursing a career in medicine as compared to evolutionary biology, in their perception of the importance of evolutionary science to our global society (Table 6). Not surprisingly, we also found differences among groups in their current level of interest in evolutionary science, those students pursing evolutionary biology were more interested in the discipline compared to students pursing general biology, medicine, or a physical science.</p>
<p>Students in evolutionary biology were also significantly less religious than those in biology (p = 0.03) or medicine (p &lt; 0.001). Students interested in medicine indicated higher religiosity than people interested in pursuing a career in chemistry/physics (p =0.01). There was not a significant difference in degree of religiosity between individuals interested in pursuing a career in biology as compared to medicine.</p>
<p>People planning to or currently pursuing a career in evolutionary science have a significantly greater understanding of evolution than people choosing other careers, whether that is within biology or medicine or the physical sciences. Within the first evolution-understanding construct, people pursuing a career in evolutionary biology have a significantly greater understanding than those pursuing medicine (p = 0.04) and those planning to go into chemistry/physics (p = 0.02). Within the second evolution-understanding construct, we found people seeking careers in medicine show significantly less understanding of evolutionary principles than those pursuing either general biology (p = 0.005) or evolutionary biology (p &lt; 0.008).</p>
<p>Our ultimate goal was to obtain preliminary data that provided insight and could inform how we recruit and retain URM students in evolutionary science. Based on *AA = African Americans, Lat/His = Latino(a)/Hispanic, NA = Native American, EA = European American, PR = Puerto Rican.</p>
<p>our survey of 184 students exhibiting interests in pursuing careers in science, URM students do show differences, when compared to European American students, in factors that appear to influence their career paths, as well as the specific disciplines they choose to pursue. We also identified differences between URM groups in terms of their interest in, and understanding of, evolutionary biology, and identified differences among those students intending on pursuing career paths in evolutionary biology as compared to careers in other biological sciences. We have noted several patterns that may start to explain why underrepresented minorities are less likely to choose careers in evolutionary science, and some possible recommendations for future research.</p>
<p>Our data suggest a few factors that may be important as URM students consider disciplines to pursue beyond their undergraduate training. We observed differences among URM groups with respect to exposure to science and the presence of individuals of similar racial/ethnic background currently working in the discipline appears important for African Americans and non-Puerto Rican Latino/a(s). Of potential importance is the difference between Puerto Ricans and non-Puerto Rican Latino(a)s with regard to the influence of similar individuals in the field. Puerto Rican youths who grow up in Puerto Rico, a society where their day-to-day role models are also Puerto Rican (police, teachers, ministers, politicians, etc.), may see individuals like themselves in fields that can be dominated by European Americans in other regions of the United States. Other studies have found URM success in STEM programs is tied to self-efficacy, and identifying as a scientist (Chemers et al. 2011;Merolla and Serpe 2013). These combined results reiterate the importance of providing URM students interested in STEM disciplines an opportunity to interact with other URM scientists as role models or mentors.</p>
<p>In addition, African Americans exhibited higher rates of religiosity, and perhaps most important for our attempts to recruit African Americans into evolutionary biology, significantly higher rates of religiosity when compared to other URM groups. These findings concur with those of Bailey et al. (2011), who found higher rates of religiosity among African American undergraduate non-majors. These data suggest additional challenges to recruiting African American students into the sciences, and in particular, to disciplines that require an understanding of evolution, which can clearly conflict with many religious beliefs.</p>
<p>Of the 126 URMs who were biology majors, only 8 identified themselves as interested in pursuing careers in evolutionary biology (1 African American, 7 Hispanic/ Latino(a)s); no Native Americans indicated an interest in evolutionary biology. Despite the fact that we biased our sample toward URM students interested in STEM fields, we still found European Americans 1.5 to 5 times more likely to be interested in a career in evolutionary biology when compared to Hispanic/Latino(a)s or African Americans, respectively. Significant differences in understanding of evolution may help explain these results. Among those URM students choosing careers in STEM fields, those pursing medicine and non-biological fields such as chemistry and physics exhibited more misconceptions, and those pursing medicine specifically showed lower overall understanding of evolutionary processes. With respect to recruiting and retaining URM students into evolutionary biology, these findings are potentially worrisome if we are to assume the population we sampled represents highly trained STEM students. Religiosity may also contribute to career choices, particularly when it comes to evolutionary biology. Perhaps not surprisingly, URM students indicating an interest in evolutionary biology were significantly less religious than those pursuing careers in biological sciences in general, and medicine in particular. We also found proportionally more African Americans chose careers in medicine. Higher rates of religiosity may drive African Americans to choose disciplines that do not require training in evolutionary biology, perhaps to minimize conflict with their religious beliefs. Despite recent calls for the inclusion of evolution into medical school curriculum (Stearns 2011;Alcock and Schwartz 2011;Meikle and Scott 2011;National Research Council and National Academy of Sciences 2012 Thinking Evolutionarily), evolutionary medicine is still viewed as an elective.</p>
<p>Our results suggest that religiosity may be of greater importance to African Americans than other URM groups in deciding to pursue a career in evolutionary biology. Although a great deal of research exists that demonstrates socioeconomic, religious, and educational effects are correlated with evolution acceptance (Hawley et al., 2011), the ultimate cause and effect between religiosity and evolution understanding is still unclear. Do African Americans have a poorer understanding of evolution because they believe that evolutionary theory is in opposition to their religious beliefs, and thus ignore or dismiss the subject of evolution when it is taught in school? Or do African Americans receive less exposure to evolution in school than do European Americans or other URMs, limiting their opportunity to learn about the topic in the first place?</p>
<p>States differ in their expected support for evolution in the elementary and secondary school system. It is relevant that the distributions of African American and Hispanic populations differ by state from that of European Americans (U.S. Bureau of the Census, 2012). In 2009, the grading of state science standards relative to the teaching of evolution in public schools was reported (Mead and Mates 2009). Based on these grades, the mean grade for states with the highest numbers of African Americans was 2.30 (C-) but for Hispanic Americans was 2.70 (C+), compared to European Americans at 3.00 (B-). Bailey et al. (2011) reported minimum exposure to evolution in high school courses (rank 1.97 on a 5-point Likert scale) among African American students in their study. It is not difficult to imagine how a self-reinforcing cycle of low understanding and enthusiasm for evolution may develop in African American communities. This cycle, in concert with resistance to evolution for religious reasons, may lead to lower preferences for evolutionary science careers among African Americans.</p>
<p>We sought to explore potential variables influencing career choices among URM students interested in science, with a particular focus on factors that influence URM students to choose a career in evolutionary biology. Of the 126 URMs surveyed who were biology majors, only 8 identified themselves as interested in pursuing an evolutionary science careers (1 African American, 7 Hispanic/ Latino(a)s). Our results emphasize the importance of exposing URM students to African American and Hispanic/ Latino(a) evolutionary biologists, in an effort to increase the opportunities that these students see themselves as evolutionary scientists. In addition, religiosity and evolution understanding were clearly correlated with a lack of diversity in the evolutionary sciences. African Americans, in particular, showed higher religiosity and lower understanding of evolution compared with Hispanic/Latino(a) participants, pointing to the need to address these factors within African American communities specifically.</p>
<p>Our findings also highlight the importance of including analysis of racial/ethnic data when investigating factors influencing evolution acceptance and understanding. Continued analysis of these factors will increase our understanding of why URMs are not pursuing evolutionary science, allowing us to take steps to address these factors. Educators, researchers, and equality advocates can then target specific causes for underrepresentation in the evolutionary sciences and work towards more equal representation.</p>
<p>An important next step to improving the understanding of why URMs are not pursuing evolutionary science as a career is to survey larger and more diverse populations across the United States. Future large-scale studies at a wide range of universities and colleges across America, targeting URM career choice in STEM and non-STEM fields, would provide a wealth of information about the reasoning for career choice, as well as how career choice and ethnicity relate to evolution understanding and acceptance.</p>
<p>Ranges reflect variation in polls and populations sampled.</p>
<p>We would like to thank Emily Stafford for reading and reviewing early versions of the manuscript and two anonymous reviewers for comments on the initial submission. The BEACON Center for the Study of Evolution in Action funded the project.</p>
<p>Below is the link to the electronic supplementary material.</p>
<p>Additional file 1: Table S1. A review of published studies that investigate the acceptance of evolution among college undergraduates (Fuerst 1984;Johnson and Peebles 1987;Blackwell et al. 2003;Brem et al. 2003;Sinatra et al. 2003;Ingram and Nelson 2006;Rutledge and Sadler 2007;Hokayem and BouJaoude 2008;Lombrozo et al. 2008;Cunning and Wescott 2009;Moore et al. 2009 Additional file 2: Table S2. SACNAS / ABRCMS Survey.</p>
<p>The authors declared that they have no competing interests.</p>
<p>The initial idea for the study arose out of a catalysis meeting at the National Evolutionary Synthesis Center, organized by JBC, JLG, and LSM. This catalysis meeting was attended by evolutionary science researchers as well as researchers in evolution education. In addition, many of the participants were from the minority groups that were the subject of this study. LSM and JBC managed the project. All authors contributed to the creation of the survey. FF administered the survey at the two conferences mentioned in the paper and conducted the statistical analyses. All authors contributed to writing portions of the manuscript, and LSM revised manuscript according to reviewer comments. All authors read and approved the final manuscript.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f564337581"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:37+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>printing is an emerging additive manufacturing (AM) technology that adds a time-dependent reconfiguration dimension to three-dimensional (3D) printed products. It enables the creation of on-demand, dynamically controllable shapes, or properties in response to external stimuli such as temperature, magnetic field, and light. Thermally responsive structures are among the most popular types of currently available 4D-printed structures due to their convenience. However, applications like soft robots are hindered by the temperature-sensitive structures' stagnating actuation. This research was driven by a requirement for a rapid and effective design and optimisation strategy for 4D-printed bi-stable thermally responsive structures for use in soft robotics. In this study, the response surface method (RSM) optimization with the aid of numerical solutions was used to investigate effective parameters in the design of a bi-stable, 4D-printed soft robotic gripper. This approach is proposed to accelerate the actuation of thermally responsive shape-morphing structures that can be controlled by the in situ strains and post-manufacturing heat stimuli as variable parameters. By using RSM solution the individual effects as well as the coupling effects of variable parameters on the output responses, including the maximum strain energy and the average distance between the clamps of the structure, are evaluated. The obtained results can be employed to develop the designation and improve the acceleration of soft robotic grippers such as fast buckling and bending, which is desirable for soft robotic applications.</p>
<p>The use of smart materials in additive manufacturing (AM) and four-dimensional (4D) printing has recently become much more feasible due to advancements in synthetic smart materials, new printers, and mathematical modelling [1,2]. The ability to reassemble simple components into a complex structure that cannot be built with existing manufacturing technologies is a notable case of the design flexibility enabled by 4D printing. Robots [3], automobiles [4], healthcare [5], and aerospace [6] are just some of the emerging markets for three-dimensional (3D) printing technologies, and there has also been a notable shift towards using 4D printing technology to create soft robotics for use in a multitude of environments. The field of soft robotics is a relatively new area of study, with much of the current research being inspired by the systems in nature that have been modified over generations to achieve a certain purpose. Since rigid robots are often constructed from inflexible materials, they are unable to bend and conform elastically, just as a mouse or octopus can squeeze through a small hole without causing detrimental internal pressures and stress concentrations, to overcome physical impediments [7].</p>
<p>However, soft robotics introduces an interesting new paradigm in engineering that drives us to re-evaluate how we develop materials and mechanisms to make them more practical, versatile, and adaptive in various interactions [8]. Closed-loop 4D-printed soft robots [5,9] were introduced with potential applications in food sorting [9] and autonomous surgeries [10], which conventional robots are challenged to handle [11]. Finite element method (FEM) and 4D printing techniques are necessary for designing a closed-loop soft robot to attain a targeted design suitable for a practical application due to the varying physical responses of the integrated materials [9]. Tawk et al. [12] used FEM to improve the gripper's soft fingers. It was shown that the FE simulations were successful in improving the gripper's performance by precisely predicting the fingers' behaviour and performance in terms of deformation and tip force. A novel design method was proposed by Chau et al. [13] to address the issue of structural optimisation for the soft rotary joint. The adaptive neuro-fuzzy inference system model, the FEM, and the water cycle moth-flame optimisation algorithm all contributed to the development of the suggested optimisation method. Taguchi approach was used to optimise the neuro-fuzzy inference system adaptively, which improves the precision of the models produced. However, all these methods were performed on 3D-printed soft grippers and robots without consideration of their 4D or stimuli-responsive properties in the optimization stage.</p>
<p>Recently, there has been a practical yet efficient 4D printing technique for developing soft grippers via prestrain induced during the fabrication mechanism. A 4D printing platform was developed by Zou et al. [14], which can apply strain during the printing process to fabricate the pre-strained structures with the aid of in situ the printing base. When printing a bilayer construction, one layer is pre-strained, while the other is not. Experiments and FEM demonstrated that the aspect ratio has little influence on the deformation of the bilayer structure; however, the pre-strain plays a crucial role in the deformation and significantly speeds up the actuation of the bilayer structure. Using this method, a 4D-printed pre-strained bilayer energy-free gripper was fabricated. In another work, a 4D printing method for fabricating multiscale shape-morphing structures was presented by Deng et al. [15], which can be precisely controlled by the applied strains. To create these prototypes, a two-nozzle 3D printer was used to print phase change wax microparticles (MPs) into the elastomer matrix. Because of the solid-liquid phase shift, the wax MPs are able to keep the residual strain after the pre-strained elastomer composite has been relaxed. The anisotropic stress field in the elastomer composite is achieved by the 3D-programmable spatial distribution of the wax MPs. These stresses result in out-of-plane deformations such as curling, folding, and buckling. Due to the reversible phase transition of the wax MPs, these deformations are multiscale and programmable. It was also reported that the characteristics of deformations, such as curvatures and folding angles, are linearly dependent on the applied strains, suggesting controllable features. Furthermore, the bi-stable mechanism was incorporated into the pre-strain 4D printing principle by Liu et al. [16] in a soft and bi-stable gripper. It was shown that the gripper deforms upon impact with other objects, absorbing their kinetic energy to provide instability and allowing for both rapid gripping and a degree of cushioning. Since this method does not need any additional energy input, it substantially simplifies the usual driving devices allowing for the miniaturised and lightweight gripping actuation to be achieved. By applying the right amount of pre-deformation to the gripper's bi-stable structure, the energy barrier for initiating the beginning of instability may be dynamically adjusted to provide the best possible grasp and buffering effect, as per the target's kinetic properties. As soon as it has completed its current gripping task, the bi-stable gripper may reset to its starting position and release the object using a cable-driven mechanism. Their experiment shows the suggested soft gripper could grab, transport, and release moving items, giving it considerable potential to carry out tricky activities on space missions.</p>
<p>All recent studies have demonstrated the feasibility and utility of 4D printing in the development of soft grippers with pre-strain and bi-stable mechanisms. However, there was little effort focused on the optimization of the parameters to accelerate the actuation of thermally responsive structures. In this research, we use the response surface method (RSM) optimization with the aid of numerical solutions to investigate effective parameters in the design of a bi-stable, 4D-printed soft robotic gripper. The bi-stability is induced based on the pre-strain 4D printing mechanism in the soft gripper. This approach is proposed to accelerate the actuation of thermally responsive shape-morphing structures that can be controlled by the applied strains during the manufacturing and post-manufacturing heat stimuli as variable parameters.</p>
<p>In this research, a pre-strained bilayer thermal actuator is evaluated according to the recent development in [14,16], as shown in Fig. 1, due to its fast actuation mechanism. The 4D printing procedure is the same as earlier work of authors [14,17]. Based on this characteristic, these actuators can be effectively used in soft robotic grippers, as the variation in curvature of the structure can be considered an appropriate parameter for the effective deformation calculation of pre-strained bilayer structures. Liu et al. [16] also presented a designation for the bi-stable soft robotic grippers used for the dynamic capture of objects in space. As shown in Fig. 1b, they used a particular design consisting of a normal soft gripper and a ring, which causes the structure to be bistable. Based on the research background, one of the criteria to evaluate the stability of bi-stable soft robotic grippers is the amount of strain energy created in the gripper [18]. It should be noted that in most studies, the silicone elastomer processed by 3D printing is used to fabricate gripper samples [14,16].</p>
<p>For this purpose, the bi-stable gripper sample was designed similarly to that of the gripper in [16], as shown in Fig. 2. The structure of the bi-stable soft robotic gripper was considered a two-layer structure with specified prestrain values and thickness ratios, consisting of one layer of silicone-ethanol composite and one layer of silicone elastomer. The thermomechanical properties of silicon-ethanol and silicone elastomer are reported in Table 1. It should be noted that silicone-ethanol composite is a relatively soft and flexible material that could be isotopically deformed under thermal stimulation, but silicone elastomer demonstrates almost no expansion under thermal stimulation and it has a high Young's modulus compared to silicone-ethanol composite [19].</p>
<p>The RSM is a collection of mathematical and statistical inference approaches used to model and analyse issues where the system's output (solution) is controlled by a large number of variables and the goal is to maximise the given solutions. In the RSM, a series of data obtained via performing experimental and/or numerical tests are used to solve the multivariate equations simultaneously. One of the initial steps in RSM-based optimisation design is settling on an optimisation model. To do this, the functions that need to be optimised as well as the variables that have the most influence on the functions must be determined.</p>
<p>In the statistical technique of RSM, the model adaptation is carried out through regression analysis. In fact, the RSM is an approximate one which fits the data obtained from the experiments. Assume that the output y (response) is a function of the variables [x 1 , x 2 , x 3 , …, x k ]. The relationship between the system's outputs and variables can be expressed as [20]:</p>
<p>Here ' e' stands for the error term in the response deter- mination. Now, if the expected response of the system is expressed as, then the level defined as follows is called the response surface.</p>
<p>The relation between the problem's independent variables and the consequent responses is often not known in RSM issues. Therefore, the first step in finding a RSM is to find an appropriate approximation between the response (y) and the set of independent variables. If the RSM is appropriately modelled with a linear equation of the problem variables, the approximate function will be a first-order model, while for the curvature, polynomials with higher degrees are used. Generally, the polynomial RSM can be given in a matrix form as in Eq. ( 3).</p>
<p>(1)</p>
<p>Fig. 2 The design process of and analysis procedure in this study where 'x' is the input matrix and 'b' stands for the vector of coefficients. To estimate the unknown coefficients, a set of variable data and their corresponding set of responses, 'y', are determined. If 'Y' and 'X' represent the set of responses and matrix of variables, respectively, the vector of coefficients is obtained according to Eq. ( 4).</p>
<p>The least-squares method is used in order to estimate the unknown coefficients in the approximate polynomial. To use this method, the number of test specimens must be greater than the unknown coefficients so that the X T X matrix is not singular [20].</p>
<p>After determining the unknown coefficients, the system response is approximately modelled by the surface fitting to the obtained data. If the surface provides a good approximation of the response function, the analysis of the fitted surface will be equivalent to the real-system analysis considering an acceptable value of error. Given an appropriate design of experiments for the data collection, the coefficients will be determined with higher accuracy and the fitting model's error will be reduced. The designs used for this purpose are called the RSM experiment designs.</p>
<p>According to [14], the control parameters were set at three levels, as shown in Table 2. Therefore, an overall number of (3)</p>
<p>54 cases were examined. The input parameters include the pre-strain, the thickness ratio of the inner layer to the outer layer, and the temperature applied to the soft gripper. Six various geometries of the bi-stable soft robotic gripper were evaluated since each of the pre-strain and thickness ratio parameters has three levels. Figure 3 shows three grippers with different pre-strain values at a thickness ratio equal to 1. Besides, to examine the amount of effective deformation in the bilayer pre-strain structure and the amount of stability of the structure, two output responses, including the average distance between the two clamps of the gripper and the maximum value of the strain energy, were considered.</p>
<p>A coupled temperature-displacement modelling algorithm was utilized as the simulation problem of the 4D-printed soft gripper is a combination of thermal and mechanical phenomena. Furthermore, to simulate the effects of thermal loading, the time needed for the deformation completion of the soft gripper due to thermal loading was set to be equal to 1 min (60 s). Thermal load was applied to the soft gripper as a constant temperature according to the values specified in Table 2, and the initial temperature of the gripper was set to be equal to 20 degrees Celsius (ambient temperature). Besides, the upper surface of the clamp is fixed at the reference point (RP) in all directions. As shown in Fig. 4, a total of 18,673 triangular 4-node coupled temperature-displacement elements (C3D4T) were used in the present modelling. The size of the elements was chosen so that at least one element is created in the thickness of each structure, and on the other hand, the results are independent of the mesh size. Fig. 3 The bi-stable soft robotic gripper with three various pre-strain values for capturing different sizes of moving targets</p>
<p>The RSM methodology is applied for modelling and optimizing the bi-stable soft robotic gripper behaviour under various conditions. So, input parameters, including the values of pre-strain, thickness ratio, and temperature, along with output parameters, such as the maximum strain energy and the average distance between the clamps of the gripper are introduced in Table 2. Two opening and closing modes are also considered in the solution procedure. The output responses of the RSM solution method were extracted following the FEM simulation of the problem. All simulation conditions and their corresponding results are reported in Table 3, where t r , ε, T, α in , α out , E and L are the values of thickness ratio, pre-strain, applied temperature, thermal expansion coefficient of interior material, thermal expansion coefficient of exterior material, maximum strain energy and the average distance between the clamps, respectively. After extracting the results, it is possible to demonstrate the dependence of the output responses on the input parameters considered by the RSM methodology. Equations 5-8 demonstrate the dependence of the maximum strain energy and the average distance between clamps in two opening and closing modes. The RSM is able to determine the optimal values of several variables simultaneously with the least amount of data. In this method, the RSM curves are obtained by fitting the appropriate model to the output data. After modelling the responses of the experiments, the most optimal parameters are obtained using the RSM. Equations 5-8 represent the maximum strain energy and the average distance between the clamps for the two opening and closing modes are achieved. Model number 25 corresponds to the most optimal condition for 27 models in opening mode. In this case, the optimal values of maximum strain energy of 1.57341 mJ and the average distance between the clamps of 3.2812 mm have been obtained for Model CCC. Similarly, experiment number 46 corresponds to the most optimal condition for the second 27 experiment models in closing mode. Accordingly, the most optimal values for this condition are the maximum strain energy of 2.19955 mJ and the average distance between the clamps of 2.1654 mm which corresponds to Model C.</p>
<p>Figure 10 shows the strain energy diagram during the deformation process. This figure shows the changes in strain energy during the deformation of the gripper of soft grippers with a pre-strain of 0.1 and a thickness ratio of 1 at different temperatures in both closing and opening modes. Figure 10 also reveals the strain energy changes due to the thermal load applied to the soft grippers in an inadvertent manner. This behaviour of the graph is the same for all 54 models, and only its maximum values are different. Also, it can be seen that increasing the value of temperature applied to the soft gripper increases the strain energy in both the opening and closing modes. As per the results, the gripper in the opening mode does not have the ability to change its shape too much, and the reason is due to the constraint applied from the ring around the bilayer soft gripper. On the other hand, when the temperature rises, the value of deformation increases, and the ring stops the gripper from further deforming in a shorter time.</p>
<p>The responses of the maximum strain energy and the average distance of the gripper clamps in the RSM with three control levels of pre-strain, thickness ratio and applied temperature for 27 samples in the opening mode and 27 samples in the closing mode are reported in Table 3. This table shows that different gripper models have a significant effect on the control parameters and consequently the responses of the response level method. Using variance analysis, Fig. 11 shows the interaction effects of thickness ratio and applied temperature, respectively, on the maximum strain energy and the average distance of the gripper clamps for the opening modes. Figure 11 demonstrates that increasing the pre-strain and the thickness ratio or various applied temperatures does not have a significant effect on the maximum strain energy in the opening mode. According to Fig. 10, the average distance of the clamps of the gripper has a parabolic behaviour concerning the pre-strain and the thickness ratio or different applied temperatures: as the thickness ratio decreases, the distance of the clamps increases, and as the temperature increases, the distance between the clamps also increases.</p>
<p>Using variance analysis, Fig. 12 shows the interaction effects of thickness ratio and applied temperature, respectively, on the maximum strain energy and the average distance of the gripper clamps for the closing modes. It is observed that the maximum strain energy in the closing mode is not much affected by increasing the pre-strain and thickness ratio as well as different temperature values. According to Fig. 12, the average distance of the clamps of the gripper has a parabolic behaviour concerning the pre-strain and the thickness ratio or various applied temperatures. In other words, by increasing the temperature or decreasing the thickness ratio, the distance of the clamps increases. Figure 13 also shows the diagram of predicted values by the RSM for the average distance of the gripper clamps, as well as the maximum strain energy in the closing and opening modes. The red circles indicate some outlier results compared to the predicted values by RSM.</p>
<p>Page 4 of 14</p>
<p>Funding Open Access funding enabled and organized by CAUL and its Member Institutions.</p>
<p>The data that support the findings of this study are available from the corresponding author upon reasonable request.</p>
<p>Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.</p>
<p>Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f159507344"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:58+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Adaptive techniques have great potential for wide application in enhancing the precision of quantum parameter estimation. We present an adaptive quantum state tomography protocol for finite dimensional quantum systems and experimentally implement the adaptive tomography protocol on two-qubit systems. In this adaptive quantum state tomography protocol, an adaptive measurement strategy and a recursive linear regression estimation algorithm are performed. Numerical results show that our adaptive quantum state tomography protocol can outperform tomography protocols using mutually unbiased bases and the twostage mutually unbiased bases adaptive strategy, even with the simplest product measurements. When nonlocal measurements are available, our adaptive quantum state tomography can beat the Gill-Massar bound for a wide range of quantum states with a modest number of copies. We use only the simplest product measurements to implement two-qubit tomography experiments. In the experiments, we use error-compensation techniques to tackle systematic error due to misalignments and imperfection of wave plates, and achieve about a 100-fold reduction of the systematic error. The experimental results demonstrate that the improvement of adaptive quantum state tomography over nonadaptive tomography is significant for states with a high level of purity. Our results also show that this adaptive tomography method is particularly effective for the reconstruction of maximally entangled states, which are important resources in quantum information.</p>
<p>One of the central problems in quantum science and technology is the estimation of an unknown quantum state. 1 Quantum state tomography (QST) as the procedure of experimentally determining an unknown quantum state has become a standard technology for verification and benchmarking of quantum devices. [2][3][4][5][6][7] Two key tasks in QST are data acquisition and data analysis. The aim of data acquisition is to devise appropriate measurement strategies to acquire information for reconstructing the quantum state. Then, in the step of data analysis, the acquired data generates an estimate of the unknown quantum state by use of an estimation algorithm.</p>
<p>In order to enhance the efficiency in data acquisition, it is desired to develop optimal measurement strategies for collecting data. However, an optimal measurement strategy, which is only known for a few special cases, 2,8,9 depends on the unknown state. To circumvent this issue, many kinds of fixed sets of measurement bases have been designed to be optimal either in terms of the average over a certain quantum state space [10][11][12][13][14] or in terms of the worst case in the quantum state space. 6 For instance, improved state estimation can be achieved by taking advantage of mutually unbiased bases (MUB) 10,14 and symmetric informationally complete positive operator-valued measures (SIC-POVM). 15,16 For multi-partite quantum systems, MUB and SIC-POVM are difficult to experimentally realize since they involve nonlocal measurements. There are also other choices of optimal measurement bases in terms of robustness against errors. 17,18 The question of how to efficiently acquire information of an unknown quantum state using simple measurements that are easy to realize experimentally remains open.</p>
<p>For data analysis in tomography, although many methods, such as maximum-likelihood estimation, 4,19,20 Bayesian mean estimation, 21,22 and least-squared inversion, 23 have been used to reconstruct the quantum state, this task can be computationally intensive, and may take even more time than the experiments themselves. It has been reported in ref. 5 that using the maximumlikelihood method to reconstruct eight-qubit took weeks of computation. Therefore, the development of an efficient data analysis algorithm is also a critical issue in QST. 6,24 In ref. 6, a recursive linear regression estimation (LRE) algorithm was presented which is much more computationally efficient in the sense that it can greatly save the cost of computation as compared to the maximum-likelihood method with only a small amount of accuracy sacrificed. This method has even further optimized to fully reconstruct a 14-qubit state within four hours via parallel GPU programming. 25 For a given number of copies of the system, in order to improve the tomography accuracy by better tomographic measurements, a natural idea is to develop an adaptive tomography protocol where the measurement can be adaptively optimized based on data collected so far. Adaptive measurements have shown more powerful capability than nonadaptive measurements in quantum phase estimation, [26][27][28] phase tracking, 29 quantum state discrimination, 30,31 and Hamiltonian estimation. 32,33 Actually, adaptivity has been proposed for QST in various contexts. 2,21,24,[34][35][36][37][38][39] For example, the results on one qubit have demonstrated that adaptive QST can improve the accuracy quadratically considering the infidelity index. 24 However, when generalizing their results to n-qubit systems, the adaptive tomography protocol will involve nonlocal measurements which are hard to realize in experiments. Adaptive QST based on Bayesian estimation 21,38 has been presented and experimental results of factorized adaptive measurements have been demonstrated in two-qubit systems. 40 However, Bayesian algorithm estimation algorithm has usually a much higher computational complexity than LRE for QST.</p>
<p>In this paper, we combine the computational efficiency of the recursive technique of ref. 6 with a new adaptive protocol that does not necessarily require nonlocal measurement to obtain a new protocol: adaptive QST via LRE. In this paper, we call it recursively adaptive quantum state tomography (RAQST) because the parameter estimation is recursively updated 41 and adaptive measurements are used. In our RAQST protocol, no prior assumption is made on the state to be reconstructed. The state estimate is updated based on the current estimate and the new measurement data. Thus, we do not have to combine all the historical information with the new acquired data to update the estimate as the maximum-likelihood method. Thanks to the simple recursive estimation procedure, we can obtain the estimate state in a realtime way, and using the estimate we can adaptively optimize the measurement strategies to be performed in the following step. In our RAQST protocol, the measurement to be performed at each step is optimized upon the corresponding admissible measurement set determined by the experimental conditions.</p>
<p>It is first demonstrated numerically that our RAQST, even with the simplest product measurements, can outperform the tomography protocols using MUBs and the two-stage MUB adaptive strategy. For maximally entangled states (MESs), the infidelity can even be reduced to beat the Gill-Massar (GM) bound which is a type of quantum Cramér-Rao inequality. 2 This is possible because the GM bound assumes an unbiased estimator, whereas our experiments are biased because they are constrained to satisfy the positivity condition, which is particularly relevant in the case of high purity. Moreover, if nonlocal measurements are available, with our RAQST the infidelity can be further reduced. For a wide range of quantum states, the infidelity of our RAQST can be reduced to beat the Gill-Massar bound with a modest number of copies. We perform the two-qubit state tomography experiments using only the simplest product measurements, and the experimental results demonstrate that the improvement of our RAQST over nonadaptive tomography is significant for states with a high level of purity. This limit (very high purity) is the one relevant for most forms of quantum information processing.</p>
<p>A LRE method for QST was proposed in ref. 6, and the results have shown that the LRE approach has much lower computational complexity than the maximum-likelihood estimation method for quantum tomography. Here, we further develop this LRE method to present an adaptive QST protocol that can greatly improve the precision of tomography.</p>
<p>We first convert a QST problem into a parameter estimation problem of a linear regression model. Consider a d-dimensional quantum system with Hilbert space H. Let fΩ i g d 2 À1</p>
<p>i¼1 denote a set of Hermitian operators satisfying (i) Tr(Ω i ) = 0 and (ii) Tr(Ω i Ω j ) = δ ij , where δ ij is the Kronecker function. Using this set, the quantum state ρ to be reconstructed can be parameterized as</p>
<p>where I is the identity matrix and θ i = Tr(ρΩ i ). Let Θ ¼ ðθ 1 ; Á Á Á ; θ d 2 À1 Þ T , where T denotes the transpose operation.</p>
<p>A quantum measurement can be described by a positive operator-valued measure (POVM) fE i g M i¼1 , which is a set of positive semidefinite matrices that sum to the identity, i.e., E i ≥ 0 and P M i¼1 E i ¼ I. In QST, different sets of POVMs should be appropriately combined to efficiently acquire information of the unknown quantum state. Let M ¼ ∪ j¼1 M ðjÞ denote the admissible measurement set, which is a union of POVMs determined by the experimental conditions. Each POVM is denoted as</p>
<p>k¼1 , elements of the POVM can be parameterized as</p>
<p>where γ</p>
<p>When we perform the POVM M ðjÞ on copies of a system in state ρ, the probability that we observe the result m is given by</p>
<p>Assume that the total number of experiments is N, and we perform a measurement described by M ðjÞ ¼ fE may be considered as the observation noise. Hence, the problem of QST is converted into the estimation of the unknown vector Θ.</p>
<p>To give an estimate with a high level of accuracy, the basic idea of LRE is to find an estimate Θt such that</p>
<p>Here,</p>
<p>A recursive LRE algorithm 6 can be utilized to find the solution of Θt . For completeness, we present the recursive LRE algorithm in section A of the Supplementary Material. Its basic idea is that one only needs to store the best estimate state so far, and then update it using a bunch of new measurement results with a fixed setting. This is quite different from the maximum-likelihood estimation method since there one has to combine all the historical information with the new collected data to update the estimate, which is quite computationally intensive. It has been demonstrated in Fig. 1 of 6 that the LRE tomography algorithm can greatly reduce the total cost of computation with only a small amount of accuracy sacrificed in comparison with the maximum-likelihood estimation method.</p>
<p>As demonstrated in Section B of the Supplementary Material, when the number of copies N of the unknown quantum state becomes large, the only relevant measure of the quality of estimation becomes the mean squared error matrix Eð Θt À ΘÞð Θt À ΘÞ T . The mean squared error matrix depends upon the state ρ (i.e., Θ) to be reconstructed and the chosen POVMs. Thanks to the iterative algorithm, we can obtain the estimate of the state ρ recursively, and then adaptively optimize the POVM measurements that should be performed in order to minimize the mean squared error in the next step. By doing so, the accuracy of the tomography can be greatly improved. The details of how to adaptively choose POVMs are presented in Section C of the Supplementary Material.</p>
<p>Using the solution Θt in (4) and the relationship in (1), we can obtain a Hermitian matrix μ with Trμ ¼ 1. However, μ may have negative eigenvalues and be nonphysical due to the randomness of measurement results. In this work, the physical estimate ρ is chosen to be the closest density matrix to μ under the matrix 2norm. In standard state reconstruction algorithms, this task is computationally intensive 20 . However, we can employ the fast algorithm in ref. 20 with computational complexity O(d 3 ) to solve this problem since we have a Hermitian estimate μ with Trμ ¼ 1. It can be verified that pulling μ back to a physical state can further reduce the mean squared error. 7</p>
<p>In this section we present the numerical results. First of all, we would like to stress two advantages of the LRE method: (a) as we have demonstrated in ref. 6, the LRE method can greatly reduce the cost of computation in comparison with the maximumlikelihood method; (b) the recursive LRE algorithm is naturally suitable for optimizing measurements adaptively. The argument for the advantage (b) can be explained as follows. For state tomography the optimal measurements generally depend upon the state to be reconstructed. By utilizing the LRE algorithm, we can obtain the estimate of the real state in a computationally efficient way. Using the state estimate, the measurements to be performed can be adaptively optimized. In the following, we perform numerical simulations of two-qubit tomography using only the LRE method while with six different measurement strategies: (i) standard cube measurements 11 ; (ii) mutually unbiased bases (MUB) measurements; (iii) MUB half-half 24 ; (iv) "known basis" 24 ; (v) RAQST1, in which the admissible measurement set only contains the simplest product measurements; (vi) RAQST2, in which the admissible measurement set is not limited.</p>
<p>Each of the tomography protocols (iii)-(vi) consists of two stages. In the first stage, they all use the standard cube measurements. Standard cube measurements for multi-qubit systems are defined in 11 as product cube measurements on each qubit, such as the tensor product of three Pauli measurements. For the MUB half-half, we first perform standard cube measurements on N/2 copies and obtain a preliminary estimate ρ0 via LRE, and then measure the remaining half of copies so that one set of the bases is adaptively adjusted to diagonalize ρ0 and it together with another four sets of bases constitutes a complete set of MUB as proposed in ref. 24. In contrast to the MUB half-half, for the "known basis", 24 in the second stage, we perform a set of measurements so that one of the five bases of the MUB is the eigenbasis of the state to be reconstructed. Although it is impossible physically (since the state is not known), this is a useful comparison. For the RAQST, we first perform standard cube measurements on N 1 copies and obtain a preliminary estimate. Then we adaptively optimize the measurement to be performed at each iteration step upon the corresponding admissible measurement set (see Section D of the Supplementary Material). In RAQST1, the basic admissible measurement set is the standard cube measurement bases. At each iteration step, we add another set of product measurements obtained by solving a conditional extremum problem to the basic admissible measurement set (see Section E of the Supplementary Material). In RAQST2, at each iteration step, the set of the eigenbases of the current estimate state is also added into the admissible measurement set. Note that the admissible measurement set in RAQST2 will involve nonlocal measurements in general if there are more than one particle. The details can be found in Section D of the Supplementary Material.</p>
<p>For the RAQST, we need to specify N 1 , which is the number of copies measured in the first stage, and the number K of the iteration steps such that N = N 1 + K⋅N 2 , where N 2 is the number of with different tomography protocols. Each point is averaged over 100 realizations. Error bars are the standard deviation of the average. b Histogram of improvement proportion of infidelity (a value greater than one means beating the Gill-Massar bound; see text for details.) for 200 randomly selected MESs and 200 pure states when the total number of copies is N = 10 4 for each random state. Each generated state is repeated through the RAQST protocol for 200 times copies for each POVM in the second stage. In principle, the number K of the iteration steps in the second stage may depend on the preliminary estimate in the first stage. For simplicity, in this work, we give empirical formulas depending only upon the total number N of the copies. Note that in RAQST1 and RAQST2, the admissible measurement sets are different, and so are their empirical formulas. For RAQST1, N ð1Þ 1 ¼ N=ð1:3 þ 0:1log 10 NÞ, K ð1Þ ¼ blog 10 N À 1c, and for RAQST2, N ð2Þ 1 ¼ Nð0:8 À 0:01 log 10 NÞ, K ð2Þ ¼ b1:5 log 10 N À 2c where bxc returns the maximum integer that is less than or equal to x. Obviously the formula for the resource distribution for RAQST2 applies only when N is not too large.</p>
<p>We use Monte Carlo simulations to demonstrate the results. The figure of merit is the particularly well-motivated quantum infidelity, 24 , where |H〉 and |V〉 correspond to the horizontal and vertical photon polarization states, respectively. It can be seen that the average infidelity of the static tomography protocols (i.e., (i) and (ii)) vs. N is in the order of Oð1= ffiffiffi ffi N p Þ. However, the Gill-Massar bound 2 for the infidelity in two-qubit state tomography is 75=4N. This can be obtained by combining the equations (5.29) and (A.8) in ref. 9 (see Supplementary Material). It is clearly seen that, as compared to the static tomography protocols and the adaptive MUB half-half, the average infidelity using our RAQST protocol can be reduced to beat the Gill-Massar bound even only with the simplest product measurements. Furthermore, if there is no limitation on the admissible measurement set, the RAQST2 can outperform the "known basis" tomography. It can be seen that the average infidelity of RAQST1 and RAQST2 vs. N can be significantly reduced to the order of the Gill-Massar bound, i.e., O(1/N).</p>
<p>Fig. 1b shows the histogram for RAQST over 200 randomly selected pure states and 200 MESs when the total number of copies is N = 10 4 for each random state. Random pure states are created using the algorithm in ref. 42. Since all the MESs are equivalent under local unitary operations, they are randomly selected by applying randomly generated local unitary operators 43 on the same MESs. We adopt the index Υ = (C-A)/(C-G) to evaluate the performance of our RAQST protocol. Here, C and A represent the log 10 of the average infidelity between the corresponding estimate and the true state when the standard cube measurement bases and the RAQST are utilized, respectively, while G is the Gill-Massar bound. Note that if ϒ &gt; 0, our adaptive protocol surpasses the standard measurement strategy, while if ϒ &gt; 1, our adaptive protocol beats the Gill-Massar bound. From Fig. 1b we can see that our RAQST protocol is particularly effective for the class of MESs which are important resources in quantum information.</p>
<p>Fig. 2a depicts average infidelity vs. N for the Werner states in the form of</p>
<p>In this case we produce a state with p = 0.997, which has purity Tr(ρ 2 ) = 0.9955. Note that there are kinks in the four curves corresponding to the four different adaptive protocols (iii)-(vi). We can see that each of the four curves can be divided into three segments from left to right. In the first segment, the infidelity decreases quickly as N increases until the infidelity is reduced to the order of the small eigenvalues of the state to be reconstructed, then the curves go into the second segment where the infidelity decreases slowly. After the infidelity is smaller than the smallest eigenvalues, the infidelity decreases quickly again as N increases. This is because infidelity is hypersensitive to misestimation of small eigenvalues, as pointed out in ref. 24. Hence, we must accurately estimate the eigenvalues that appear to be zero. When the infidelity is of the order of the smallest eigenvalues, it will be hard to estimate them accurately, so the decay rate of the infidelity will become slow. Once the infidelity decreases to be smaller than the smallest eigenvalues, we can estimate them more accurately as N increases, and then the infidelity decreases quickly. It can be seen that our RAQST1 can beat the static tomography protocols and the adaptive MUB half-half protocol even with the simplest product measurements. The infidelity can be further reduced by using RAQST2, and when the total copies N ≥ 10 4.5 , the infidelity can be reduced to O(1/N).</p>
<p>Fig. 2b shows average infidelity vs. different purity when the total number of the copies for each state is N = 10 4 . The quantum states are chosen as Werner states in Eq. 5 with different p. The occurrence of the peak at the purity value around 0.95 is due to the issue of misestimation of small eigenvalues, similar to that in Fig. 2a. The results show that when the states have a high level of purity, our RAQST1 with the simplest product measurements can beat the MUB protocol. However, as the state becomes more mixed (Tr(ρ 2 ) decreases), using MUB measurements for state tomography can do better than using the adaptive product (5). The total number of copies for each state is N = 10 4 . Each point is averaged over 1000 realizations measurements. This fact is due to the essential limit of product measurements on mixed states. As pointed out in ref. 2, nonlocal measurements on a mixed state can extract more information. Thus, to reconstruct mixed states, it is better to use nonlocal measurements, e.g., MUB measurements. It is also clear that the infidelity achieved by using RAQST2 is much lower than that using MUB, and can beat the Gill-Massar bound for a wide range of quantum states.</p>
<p>In this section, we report the experimental results using our RAQST protocol for two-qubit QST. Since it is hard to perform nonlocal measurements in real experiments, we only experimentally implement tomography protocols using (i) standard cube measurements and (v) RAQST1.As shown in Fig. 3, the experimental setup includes two modules: state preparation (gray) and adaptive measurement (light blue). In the state preparation module, an arbitrary Werner state ρ W (p) in Eq. 5 can be generated.</p>
<p>In the adaptive measurement module, the two-photon product measurements can be adaptively adjusted according to the analysis of the collected coincidence data.</p>
<p>In the first experiment, as shown in Fig. 4a, we realize RAQST1 and standard cube measurements tomography protocols for entangled states with a high level of purity with respect to different number of resources N ranging from 251 to 251,189. First, we calibrate the true state ρ using RAQST1 with N = 10 7 copies so that the infidelity of the calibrated true state is 10 times smaller even than the estimate accuracy achieved at N = 251,189 with RAQST1. The purity of the calibrated state is 0.983. Systematic error is crucial in the experiments. Beam displacers, which separate extraordinary and ordinary light, act as PBSs and have an extinction ratio of about 10,000:1. As the precision of rotation stages of QWPs and Half-wave plates (HWPs) are 0.01°, the rotation error is determined by the calibration error of optic axes, which is 0.1°in our experiment. Phase errors of the currently used true zero-order QWPs and HWPs are 1.2°, which dominate the systematic error of practically realized measurements. These error sources induce a systematic error to the estimate state, which can be characterized by its infidelity from the true state. The systematic error is in the order of 10 -3 when the error sources take the above values. For resource number N ≥ 10 3 , the systematic error is of the same scale as or even larger than the statistical error due to finite resources (N copies). To deal with this problem, we employ error-compensation measurements 44 to reduce the systematic error to the order of 10 -5 . In errorcompensation measurement technique, multiple nominally equivalent measurement settings are applied to sub-ensembles such that the systematic errors can cancel out in first order. Tomography experiments using both RAQST1 and standard cube measurements are repeated 10 times for each number of photon resources.</p>
<p>In the second experiment, as shown in Fig. 4b, we realize tomography protocols using RAQST1 and standard cube measurements for Werner states with purities ranging from 0.25 to 0.98. The purities are changed by adjusting the apertures. Since the photon resource for each run of tomography protocols is 10 4 , we use 10 6 copies to calibrate the true state. There are 40 experimental runs and 1000 simulation runs for each of nine Werner states. In each RAQST experiment, four adaptive steps are used to optimize the measurements. To ensure measurement accuracy, error-compensation measurements are also employed.</p>
<p>In both of these two experiments, our experimental results agree well with simulation results. The improvement of RAQST1 protocol over the standard cube measurements strategy is significant. According to the simulation results of MUB protocol and the experimental results of RAQST1, even with only the simplest product measurements, our RAQST1 can outperform the tomography protocols using MUB for states with a high level of purity. Taking into account the trade-off between accuracy and implementation challenge, from Figs 2 and4, RAQST using the simplest product measurement seems to be the best choice for reconstructing entangled states with a high level of purity.</p>
<p>It is worth stressing that our RAQST protocol is flexible and extensible. For any finite dimensional quantum systems, once the admissible measurement set is given, we can utilize the adaptive measurement strategy to estimate an unknown quantum state. As demonstrated by numerical results, if nonlocal measurements can be experimentally realized through some breakthrough in technology, the admissible measurement set M can be enlarged, and our RAQST protocol can be better utilized accordingly. How to give a more effective empirical formula for the parameters defining the second stage is worthy of further exploration, in particular allowing the parameters to depend upon the estimate state of the first stage. This is actually related to the tomography problem wherein some prior information is already known, e.g., pure entangled states, matrix-product states, low-rank states. By taking full advantage of the prior information, an even more efficient RAQST protocol may be designed. Thus, our RAQST protocol may have wide applications in practical quantum tomography experiments.</p>
<p>Note added After we completed the experiments, we became aware of a highly relevant work 40 taking a Bayesian estimation approach to realize two-qubit adaptive QST using factorized measurements. The updated optimal measurements are determined in terms of maximum information gain in ref. 40. Since Bayesian estimation yields posterior distribution of quantum states, it always gives a physical point estimate and can easily generate reliable regions. Compared with the adaptive algorithm based on Bayesian approach, our method via LRE is typically much more computationally efficient.</p>
<p>As shown in Fig. 3, the experimental setup includes two modules: state preparation (gray) and adaptive measurement (light blue). In the state preparation module, a pair of polarization-entangled photons with a central wavelength at λ = 702.2 nm is first generated after the continuous Ar + laser at 351.1 nm with diagonal polarization pumps a pair of type I phase-matched β-barium borate crystals whose optic axes are normal to each other. 45 The generation rate is about 3000 two-photon coincidence counts per second at a pump power of 60 mW. HWPs at both ends of the two single mode fibers are used to control polarization. Then, one photon is either reflected by or transmits through a 50/50 beam splitter (BS). In the transmission path, a QWP is tilted to compensate the phase of the two-photon state for the generation of HV j iÀ VH j i= ffiffi ffi 2 p . In the reflected path, three 446 λ quartz crystals and a half wave plate with 22.5°are used to dephase the two-photon state into a completely mixed state I/4. The ratio of the two states mixed at the output port of the second BS can be changed by the two adjustable apertures for the generation of an arbitrary Werner state ρ W (p) in Eq. 5. Since the coherence length of the photon is only 176 λ (due to the 4 nm bandwidth of the interference filter (IF)), much smaller than the optical path difference of 0.5 m, two states from the reflected and transmission paths only mix at the second BS rather than coherently superpose. In the adaptive measurement module, the twophoton product measurements are realized by the combinations of quarter-wave plates (QWPs), HWPs, polarizing beam splitter (PBS), single photon detector (SPDs) and a coincidence circuit. The rotation angles of QWPs and HWPs can be adaptively adjusted by a controller according to the analysis of the collected coincidence data on a computer.</p>
<p>npj Quantum Information (2017)19 Published in partnership with The University of New South Wales</p>
<p>Published in partnership with The University of New South Wales npj Quantum Information (2017) 19</p>
<p>The authors would like to thank Huangjun Zhu for helpful discussions about the Gill-Massar bound for infidelity. The work was supported by the National Natural Science Foundation of China under Grants (Nos. 61222504, 11574291, 61374092, and 61227902) and the Australian Research Council's Discovery Projects funding scheme under Project DP130101658 and Center of Excellence CE110001027.</p>
<p>The authors declare that they have no competing interests. Supplementary Information accompanies the paper on the npj Quantum Information website (doi:10.1038/s41534-017-0016-4).</p>
</text>
</tei>
  <tei>
    <teiHeader>
        <fileDesc id="f159617369"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:23+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text lang="en">
        <p>Objective The aim of this study was to provide an overview of the recommendations regarding the diagnosis and treatment contained in current clinical practice guidelines for patients with non-specific low back pain in primary care. We also aimed to examine how recommendations have changed since our last overview in 2010. Method The searches for clinical practice guidelines were performed for the period from 2008 to 2017 in electronic databases. Guidelines including information regarding either the diagnosis or treatment of non-specific low back pain, and targeted at a multidisciplinary audience in the primary care setting, were considered eligible. We extracted data regarding recommendations for diagnosis and treatment, and methods for development of guidelines.</p>
        <p>We identified 15 clinical practice guidelines for the management of low back pain in primary care. For diagnosis of patients with non-specific low back pain, the clinical practice guidelines recommend history taking and physical examination to identify red flags, neurological testing to identify radicular syndrome, use of imaging if serious pathology is suspected (but discourage routine use), and assessment of psychosocial factors. For treatment of patients with acute low back pain, the guidelines recommend reassurance on the favourable prognosis and advice on returning to normal activities, avoiding bed rest, the use of nonsteroidal anti-inflammatory drugs (NSAIDs) and weak opioids for short periods. For treatment of patients with chronic low back pain, the guidelines recommend the use of NSAIDs and antidepressants, exercise therapy, and psychosocial interventions. In addition, referral to a specialist is recommended in case of suspicion of specific pathologies or radiculopathy or if there is no improvement after 4 weeks. While there were a few discrepancies across the current clinical practice guidelines, a substantial proportion of recommendations was consistently endorsed. In the current review, we identified some differences compared to the previous overview regarding the recommendations for assessment of psychosocial factors, the use of some medications (e.g., paracetamol) as well as an increasing amount of information regarding the types of exercise, mode of delivery, acupuncture, herbal medicines, and invasive treatments.</p>
        <p>Low back pain (LBP) is the leading contributor to years lived with disability [14]. Non-specific LBP is defined as low back pain not attributable to a known cause [21] and represents 90-95% of the cases of LBP [4]. The estimated point prevalence of non-specific LBP is 18% [13]. Annually, total costs of LBP are estimated to be US $100 billion in the USA [8], €3.5 billion in the Netherlands [19], €6.6 billion in Switzerland [35], €17.4 billion in Germany [5], and AUD $9.17 billion in Australia [34]. Although LBP imposes an enormous economic burden on healthcare systems, this condition is responsible to affect individuals' daily lives. Hence, effective strategies play an important role to minimize the impact of LBP.</p>
        <p>Clinical practice guidelines provide evidence-based recommendations to assist decision making about health interventions. These documents, developed by expert panels, are normally updated every 3 to 5 years or if the available evidence suggests a reformulation of the previous document is necessary [33]. A brief search of the Central Register of Controlled Trials (CENTRAL) reveals that the number of randomized controlled trials in LBP has nearly doubled since 2010. This finding suggests that some recommendations of clinical practice guidelines for the management of LBP may have changed in recent years.</p>
        <p>Since 2001, we have been conducting overviews of clinical practice guidelines for the management of patients with non-specific LBP in primary care settings [17,18]. These overviews have summarized the overall consensus messages, any differences between clinical practice guidelines, the scientific support for the recommendations, and changes in recommendations over time. The importance of these publications is evidenced by the number of citations received; Web of Science citation index notes that the 2001 review [18] was cited 377 times and the 2010 review [17] 316 times. It has been 8 years since our last review and some of the recommendations for the management of low back pain have likely changed. Therefore, the primary aim of this study was to provide an overview of the recommendations regarding the diagnosis and treatment of patients with non-specific LBP in primary care in current international clinical practice guidelines. We also aimed to examine if recommendations have changed since our last overview.</p>
        <p>The searches for clinical guidelines were performed for the period from 2008 to 2017 in the following databases: MEDLINE via OVID (key words: combination of search terms regarding low back pain AND clinical guidelines), PEDro (key words: low back pain AND practice guidelines), National Guideline Clearinghouse (www.guide line.gov; key word: low back pain), and National Institute for Health and Clinical Excellence (NICE) (www.nice.org.uk; key word: low back pain). We also checked the guidelines included in our previous review for updates. Furthermore, we conducted citation tracking in the content and reference lists of relevant reviews on guidelines, completed a search of Web of Science citation index for articles citing the previous reviews, and asked experts in the field. Two authors (C.B.O. and C.G M.) independently screened titles and abstracts of the search results. In case of disagreement, a third author (B.W.K.) arbitrated.</p>
        <p>Guidelines including information regarding either the diagnosis or treatment of non-specific LBP, and targeted at a multidisciplinary audience in the primary care setting, were considered eligible. Only guidelines available in English, French, German, Portuguese, Spanish, Chinese, or Dutch were included because the authors can read these languages. For languages beyond these, we included English language summaries of the guideline if they contained sufficient information. We included one guideline per country unless there were separate guidelines for acute and chronic LBP. We also included guidelines issued by a multinational committee (e.g., Africa, Europe). If more than one guideline was considered eligible, we included the most recent issued by a national body (e.g., national pain society, or national health body).</p>
        <p>Two independent authors extracted the following data using a standardised form: recommendations regarding diagnosis and treatment, target population, committee membership, the evidence base of the recommendations (e.g., literature search, grade of evidence), consensus methods (e.g., committee meetings, discussion groups), and dissemination of guidelines (e.g., publication in website or scientific journals). To examine changes in recommendations over time, we compared results of the previous overviews with the current review. We presented the recommendations from the included guidelines in tables.</p>
        <p>Electronic searches conducted on June 16, 2017 retrieved 1611 records after removing duplicates. After the screening of titles and abstracts, we assessed 61 full texts against our inclusion criteria. Of these, we excluded 46 full texts because they were: not the most recent guideline issued (n = 19), not guidelines (n = 15), not targeted at a multidisciplinary audience (n = 10), and not in a language where we could obtain a translation (n = 2). Finally, 15 clinical practice guidelines [1, 3, 7, 9-11, 15, 20, 24, 27, 30-32] for the management of LBP were included from the following countries: Africa (multinational), Australia, Brazil, Belgium, Canada, Denmark, Finland, Germany, Malaysia, Mexico, the Netherlands, Philippine, Spain, the USA, and the UK.</p>
        <p>Six guidelines [1,7,11,20,26,28] (40%) provided recommendations for patients with acute, subacute, and chronic LBP (i.e., Canada, Finland, Mexico, Philippine, Spain, and the USA), two guidelines [15,31] (13%) focussed on acute and chronic LBP (i.e., Malaysia and the Netherlands), three guidelines [9,25,30] (20%) focussed on acute LBP (i.e., Australia, and Denmark), and one guideline [3] (7%) focussed on chronic LBP (i.e., Brazil). In addition, three guidelines [10,24,32] (20%) provided recommendations regardless of the duration of symptoms (i.e., Africa, Belgium, Germany and the UK). Therefore, ten guidelines contained recommendations for patients with acute LBP, six guidelines contained recommendations for patients with subacute LBP, and nine guidelines contained recommendations for patients with chronic LBP.</p>
        <p>Three guidelines [1,11,28] defined acute LBP as less than 4 weeks duration, two guidelines [6,26] specified less than 6 weeks duration and four guidelines [15,25,30,31] defined acute LBP as less than 12 weeks duration. The Canadian guideline [7] defined acute and subacute LBP as less than 12 weeks duration but without specifying the cutoffs for each one. All guidelines defined chronic LBP as more than 12 weeks' duration.</p>
        <p>Table 1 describes the recommendations regarding diagnosis endorsed by each clinical practice guideline, and "supplementary material: Appendix 1" details these recommendations. Fourteen guidelines provided at least one recommendation regarding diagnosis of patients with LBP. The American guideline [28] did not provide any recommendation regarding diagnosis because the committee group was instructed to make only recommendations for treatment of LBP.</p>
        <p>Recommendations for diagnostic triage were found in 13 guidelines. Over half of guidelines [1, 7, 24-26, 31, 32] (7 out of 13; 54%) recommend diagnostic triage to classify patients into one of three categories: non-specific LBP, radiculopathy/sciatica or specific LBP. Almost half of the guidelines [3, 9-11, 15, 20] (46%) recommend the classifications of non-specific LBP and specific LBP without distinguishing the group of patients with radicular pain/radiculopathy. Most guidelines [1, 7, 11, 15, 20, 24-26, 31, 32] (10 out of 12; 83%) recommend history taking and physical examination to identify patients with specific conditions as the cause of the LBP. Box 1 describes the red flags endorsed by most clinical practice guidelines to identify serious conditions in the assessment. In addition, most guidelines [1,7,11,15,25,26,31] (7 out of 9; 78%) recommend neurologic examination to identify radicular pain/radiculopathy including straight leg raise test [1,7,15,26,32] and assessment of strength, reflexes, and sensation [1,11,15]. Only three guidelines [11,15,26] (3 out of 12; 25%) recommend an assessment that also includes palpation, posture assessment, and spinal range of movement testing.</p>
        <p>All guidelines recommend against the use of routine imaging for patients with non-specific LBP. Most guidelines [1, 7, 9-11, 25, 30] (7 out of 12; 58%) recommend that imaging should only be considered if red flags are present. In addition, five guidelines [1,7,10,24,32] (42%) suggest imaging when the results are likely to change or direct the treatment (e.g., invasive treatments), and two guidelines (17%) recommend imaging if pain persists beyond 4 to 6 weeks [7,26].</p>
        <p>Twelve guidelines contain recommendations for assessment of psychosocial factors, or yellow flags, to identify patients with poor prognosis and guide treatment. Most guidelines [1,7,9,11,15,20,26,31] (8 out of 12; 67%) recommend the assessment based on a list of yellow flags reported in the guideline. Box 2 provides these yellow flags endorsed by most clinical practice guidelines. Four guidelines [10,24,25,32] (33%) recommend assessment using validated prognostic screening tools (e.g., STarT Back and Orebro) which combine a number of yellow flags. The Danish guideline [30] recommends against targeted treatment for a subgroup of patients with specific prognostic factors. Regarding the optimal timing to assess yellow flags, most guidelines [7,10,11,15,24,25,32] (7 out of 12; 58%) recommend assessment during the first or second consultation. "-" = The guideline did not provide any recommendation regarding the approach.</p>
        <p>"X" = The guideline endorsed the recommendation regarding the approach.</p>
        <p>" " = The guideline did not endorse the recommendation regarding the approach.</p>
        <p>Table 2 provides the recommendations regarding treatment endorsed by each clinical practice guideline, and "supplementary material: Appendix 2" details these recommendations. All guidelines provided at least one recommendation regarding the treatment of LBP.</p>
        <p>Recommendations regarding bed rest were provided in 12 guidelines. Most guidelines [7,9,11,15,25,30,31] (7 out of 11; 64%) recommend avoiding bed rest for patients with acute LBP, and four guidelines [1,10,20,26] (36%) recommend for any duration of symptoms. The only exception was the Belgian guideline [32] (8%) which notes an absence of evidence on the benefits or harms of bed rest when used in the short term.</p>
        <p>Recommendations on reassurance or advice for patients with non-specific LBP were identified in 14 guidelines. Most guidelines (7 out of 12; 58%) recommend advice to maintain normal activities for patients with acute LBP [1,7,10,15,25,30,32], and some guidelines (42%) recommend the same advice for patients with any duration of symptoms [20,24,26,31,32]. In addition, most guidelines (10 out of 14; 71%) recommend reassuring the patient that LBP is not a serious illness regardless of the duration of symptoms or reassuring patients with acute LBP of the favorable prognosis [7, 15, 20, 24-26, 28, 30-32].</p>
        <p>The recommendations for the prescription of medication vary depending on the class of medication and symptom duration. Most guidelines (14 out of 15; 93%) recommend the use of nonsteroidal anti-inflammatory drugs (NSAIDs) for patients with acute and chronic LBP considering the risk of adverse events (e.g., renal, cardiovascular, and gastrointestinal) [1, 3, 7, 15, 24-26, 28, 32]. For paracetamol/ acetaminophen, while most guidelines recommend in favor of this medication [1,3,7,11,15,20,26,31] (8 out of 14; 57%), five guidelines [10,24,27,30,32] (36%) advise against the use of paracetamol. The Australian guideline [25] recommends the use of paracetamol but advises that clinicians and patients should be made aware that the medicine might not be effective. Most guidelines (13 out of 15; 87%) recommend weak opioids [1,15,24,26,31,32] for short periods [3,7,10,20,31,32], if there is no improvement with NSAIDs or other treatments. The guidelines recommend opioids for acute LBP [1, 7, 9-11, 24, 26, 32] (8 out of 13; 61%), chronic LBP [1,3,10,27,31] (38%), and for any symptom duration [15,20] (23%). For antidepressants, most guidelines (6 out of 8; 75%) recommend its use for patients with chronic LBP where necessary [1,3,7,11,26,28]. For muscle relaxants, most guidelines [1,7,11,20,26,28] (6 out of 11; 54%) recommend this medication for acute LBP [1,26,28] (3 out of 6; 50%), chronic LBP [1,7] (33%), and for any symptom duration [11,20] (33%). In contrast, five guidelines (5 out of 11; 45%) recommend against muscle relaxants [3,9,10,31,32]. Two guidelines mentioned the use of herbal medicine for LBP (2 out of 15; 13%); one recommends its use for patients with chronic LBP [7], but the other recommends against it for any type of LBP [10].</p>
        <p>Recommendations for referral to a specialist were found in 13 guidelines. Most guidelines [1,7,15,20,24,26,30,32] (9 out of 13; 69%) recommend referral to a specialist in cases where there is suspicion of serious pathologies or radiculopathy. In addition, most guidelines [7,9,10,20,25,30,31] (7 out of 13; 54%) recommend referral to a specialist if there is no improvement after a time period that ranges from 4 weeks to 2 years.</p>
        <p>Recommendations on invasive treatments (e.g., injections, surgery, and radiofrequency denervation) for nonspecific LBP were identified in 8 guidelines. Of these, five guidelines (5 out of 8; 62%) recommended against the use of injections for non-specific LBP [7,10,24,25,31]. In addition, four guidelines [7,10,24,25] (50%) recommend against surgery or radiofrequency denervation [7,10,25,31] (50%) for non-specific LBP. In contrast, three guidelines [1, 24, 32] (37%) recommend radiofrequency denervation for chronic LBP; however, two guidelines [24, 32] (25%) recommended only in strict circumstances such as lack of improvement after conservative treatment, a positive response to a medial branch nerve block, and moderate to severe back pain. Some guidelines recommend surgery for chronic LBP due to disk herniation or spinal instability [1,15] and common degenerative disorders [1].</p>
        <p>Recommendations for multidisciplinary rehabilitation were identified in nine guidelines. Most guidelines (9 out 11; 90%) recommend multidisciplinary rehabilitation for patients with chronic LBP [7, 10, 11, 15, 24-26, 28, 32]. One guideline [20] [1,7,9,11,15,20,25,26] for any duration of symptoms, and one guideline [31] recommends if there is no improvement after monodisciplinary approach.</p>
        <p>Recommendations for psychosocial strategies were found across eleven guidelines. Most guidelines (10 out of 11; 91%) endorse the use of a cognitive behavior approach [7, 10, 11, 20, 24-26, 28, 31, 32]. In addition, most guidelines (9 out of 11; 82%) recommend these therapies for patients with chronic LBP [7,10,15,20,24,26,28,31,32] with some of them recommending only if psychosocial factors are identified [15,24,31,32].</p>
        <p>All clinical practice guidelines provided recommendations for exercise therapy. Most guidelines (10 out of 14; 71%) recommend exercise therapy for patients with chronic LBP [1,3,7,11,15,20,26,28,31]. Noteworthy, we identified great discrepancy in the type of exercise program (e.g., acute LBP, but there are some discrepancies on the indications. The guidelines recommend spinal manipulation in addition to usual care [30], if there is no improvement after other treatments [7,31], or in any circumstance [10,28]. Three guidelines [15,24,32] (33%) recommend spinal manipulation as a component of a multimodal or active treatment program for patients with any symptom duration. Three guidelines (33%) recommend spinal manipulation as a component of a multimodal treatment program [10] or in any circumstance for chronic LBP [28]. In contrast, two guidelines recommend against spinal manipulation for acute LBP [9] or chronic LBP [31].</p>
        <p>Similarly, the recommendations for acupuncture were inconsistent. Four guidelines [1,7,10,28] recommend the use of acupuncture. Of these, three guidelines recommend acupuncture for patients with acute and chronic LBP [1,28]. One guideline [7,10] recommends acupuncture as an adjunct of an active rehabilitation program for patients with chronic LBP. Four out of eight guidelines do not recommend acupuncture [9,24,30] (37%) or state that acupuncture should be avoided [25] (13%).</p>
        <p>Table 3 provides the methods of development and implementation reported by each clinical practice guideline, and "supplementary material: Appendix 3" details these methods. Most guidelines [1, 7, 10, 11, 15, 20, 24-26, 28, 30-32] were issued by a multidisciplinary group including healthcare professionals such as primary care physicians, physical and manual therapists, chiropractors, psychologists, orthopaedic surgeons, rheumatologists, and radiologists. The African guideline [9] was developed by a medical group, and the Brazilian guideline [3] was developed by an association comprised of physiatrists.</p>
        <p>Most guidelines based their recommendations on systematic literature searches of electronic databases and previous version of guidelines (14 out of 15; 93%) [1, 3, 7, 10, 11, 15, 20, 24-26, 28, 30-32], evaluated the strength of the evidence (10 out of 15; 67%) [1, 3, 10, 11, 20, 24-28, 30, 32], and used consensus in the working group when necessary (11 out of 15; 73%) [1, 9-11, 20, 24-26, 30-32]. In addition, most guidelines gave direct links between the recommendations and the evidence (9 out of 15; 60%) [1, 3, 7, 9-11, 25, 30] and provided clear and specific recommendations (11 out of 15; 73%) [1, 7, 10, 20, 24-26, 28, 30-32]. In contrast, few guidelines provided sufficient information regarding their external review process (5 out of 15; 33%) [20,24,28,30,32] and the time frame for updates (4 out of 15; 27%) [10,24,26,30]. Where it was reported, this ranged from 2 to 5 years.</p>
        <p>Most guidelines were available on the website of the participating organization, and some guidelines [3,10,11,28,30] were published in scientific journals. Most guidelines (9 out of 15; 60%) were accompanied by additional materials for dissemination [1, 7, 10, 20, 24-26, 31, 32] such as different versions for patients and clinicians, a care pathway, a summary version, an interactive flowchart, or videos. A few guidelines (6 out of 15; 40%) reported strategies or the barriers and facilitators for implementation [1,20,24,26,32].</p>
        <p>Few changes were identified in the recommendations on diagnosis of non-specific LBP compared to the previous guidelines. Currently, most guidelines still recommend the assessment of psychosocial factors based on yellow flags at the first or second consultation. Of note, an increasing proportion (33%) of guidelines are recommending the use of validated prognostic screening tools (e.g., STarT Back screening tool or Örebro). Some recommendations changed compared to the previous guidelines for the use of medications for non-specific LBP. Our 2010 overview found a hierarchical order including paracetamol as the first choice and NSAIDs as the second choice. In this review, we identified that most guidelines recommend only the use of NSAIDs as the first choice for any duration of symptoms. Of note, most current guidelines recommend antidepressants, where necessary, for chronic LBP which was not endorsed by the previous guidelines. The recommendations regarding the NSAIDs and antidepressants were consistent across guidelines included in this review.</p>
        <p>We also identified more details on the recommendations regarding some approaches compared to the past guidelines. The current clinical practice guidelines suggest some types of exercise and modes of delivery for patients with chronic LBP compared to the previous guidelines which only noted the preference for using intensive training. We also found recommendations regarding some approaches in this review which were not previously cited in past guidelines such as the use of herbal medicines, acupuncture, and invasive treatments. However, the recommendations regarding these approaches were inconsistent or cited in a small proportion of guidelines (i.e., less than 50% of the guidelines).</p>
        <p>Fifteen clinical practice guidelines containing recommendations for non-specific LBP have been issued or updated since our last overview in 2010. For the diagnostic recommendations, guidelines recommend diagnostic triage (i.e., classification in non-specific LBP, radiculopathy/sciatica, and specific LBP), history taking and physical examination to identify red flags, neurological testing to identify radicular pain/radiculopathy, no routine imaging unless serious pathology is suspected, and assessment of yellow flags based on psychosocial factors cited in the guidelines in the first or second evaluation. For treatment of patients with acute LBP, most guidelines endorse recommendations for patient education, reassurance about a favourable prognosis and advice on returning to normal activities, avoiding bed rest, the use of NSAIDs and weak opioids for short periods when there is contraindication or lack of improvement with NSAIDs. For treatment of patients with chronic LBP, most guidelines recommend the use of NSAIDs and antidepressants where necessary, prescription of exercise therapy, and psychosocial interventions. In addition, considering referring to a specialist is recommended in case of serious pathologies or radiculopathy, or if there is no improvement after 4 weeks to 2 years.</p>
        <p>We identified discrepancies in the recommendations for the use of paracetamol, muscle relaxants, and herbal medicines. For paracetamol, the most recent guidelines [10,24,28,30,32] do not recommend this medication. This change might be attributable to recent studies demonstrating the lack of efficacy of paracetamol for non-specific LBP [29,36]. In addition, the inconsistent recommendations for the use of muscle relaxants, and herbal medicines might be attributable to different care settings and cultural context across the countries.</p>
        <p>Most guidelines recommend the use of weak opioids for short periods if NSAIDs are contraindicated or not effective for patients with acute LBP, despite an absence of relevant clinical trials as demonstrated by a recent systematic review [2]. Considering the rising prescription of opioids [22], the use of this pain medication has been discouraged due to the small benefit on pain intensity in chronic LBP as well as potential side effects (e.g., misuse or physical dependence) [2,23]. Although the current review found that most guidelines recommend opioids for acute LBP, this recommendation is not supported by the evidence and may result in increased harms for patients with non-specific LBP.</p>
        <p>The recommendations on spinal manipulation and acupuncture are inconsistent but in different aspects. The recommendations on spinal manipulation vary mainly regarding the circumstances in which the intervention should be administered (e.g., any circumstance, in addition to usual care, after lack of improvement). The recommendations on acupuncture have discrepancies related to its use in patients with non-specific LBP. In addition, four guidelines [1,7,10,28] recommend acupuncture, but disagree regarding duration of symptoms. These discrepancies might be attributable to the lack of high-quality evidence which may result in recommendations based on group consensus considering different aspects. Future studies should be conducted to clarify these recommendations.</p>
        <p>Although the number of randomised controlled trials has nearly doubled since 2010, the recommendations regarding management remain similar compared to the previous review. We identified an increasing proportion (33%) of guidelines recommending the assessment of yellow flags using prognostic screening tools [10,24,25,32]. This might be attributable to a recent randomised clinical trial that showed small improvements from targeting treatment based on responses to a validated prognostic screening tool [12]. However, this was based on one study only, and a recent review [16] found that screening tools poorly identify patients who will develop chronic pain and worse outcomes in patients with LBP. Future studies should be conducted before any definitive conclusion can be made regarding the use of prognostic models.</p>
        <p>The guidelines still uniformly recommend exercise for chronic LBP. However, the clinical practice guidelines are now suggesting a greater variety of types of exercise. For example, guidelines include options such as sports rehabilitation, physical activity as tolerated, aquatic exercises, stretching, aerobic, strength training, endurance, motor control exercise, yoga, and tai-chi. Although the guidelines endorsing some types of exercise increased [1,7,20,24,26,28], there is no consistency in the recommendations favouring one particular modality. Hence, we would argue that the choice may rely on patients' preferences and therapists' experience.</p>
        <p>Our overview included clinical practice guidelines that issued recommendations for patients with nonspecific LBP. Although some guidelines also include recommendations for different types of LBP, future studies should investigate the recommendations for radicular pain/radiculopathy and specific LBP. Another limitation of this review is the absence of quality assessment of the guidelines using a validated tool (e.g., AGREE). Nevertheless, we provided an overview of the methods of the clinical practice guidelines included in the current review.</p>
        <p>Based on the recommendations for the development of guidelines for LBP provided by the previous review, the methods for developing the guidelines seem to have improved over the years (Box 3). Most guidelines provided a description for obtaining the evidence to be used in the recommendations, with some describing the method for assessing the strength of the evidence (Recommendation 1). However, only two guidelines [20,30] (13%) included non-English publications (Recommendation 2). The target group and the committee of the guideline were well described (Recommendations 3 and 4). A substantial proportion (53%) of guidelines provided a direct link between the evidence and recommendations (Recommendation 5). Although an increasing number of guidelines reported details regarding the consensus methods, this topic was still not appropriately described by the guidelines (Recommendation 6). One issue that remained over the years was that the clinical practice guidelines did not often incorporate information regarding effectiveness and health benefits as well as the cost-effectiveness (Recommendation 7). As mentioned earlier, the strategies for dissemination of the guidelines have improved substantially with several types of materials available for patients and clinicians. However, although the details regarding implementation also improved, most guidelines did not specify the strategies as well as the barriers and facilitators for implementation in the clinical practice (Recommendation 8). In addition, few guidelines [10,24,26,30] provided the methods and time frame for updating (Recommendation 9).</p>
        <p>The current clinical practice guidelines recommend diagnostic triage using history taking and physical examination to identify red flags and neurological testing to identify radicular pain/radiculopathy, against routine imaging unless serious pathology is suspected, and assessment of yellow flags based on psychosocial factors cited in the guidelines in the first or second evaluation. For acute LBP, most guidelines endorsed recommendations for patient education, reassurance about the favourable prognosis and advice on returning to normal activities, avoiding bed rest, the use of NSAIDs and weak opioids for short periods where necessary. For chronic LBP, most guidelines recommended the use of NSAIDs and antidepressants where necessary, prescription of exercise therapy, and psychosocial interventions. In addition, referring to a specialist is recommended in cases where there is suspicion of serious pathologies or radiculopathy or if there is no improvement after 4 weeks to 2 years.</p>
        <p>aquatic exercises, stretching, back schools, McKenzie exercise approach, yoga, and tai-chi) and mode of delivery (e.g., individually designed programs, supervised home exercise, and group exercise). Guidelines provided inconsistent recommendations on exercise therapy for acute LBP.</p>
        <p>The recommendations for spinal manipulation and acupuncture vary across clinical practice guidelines. Eleven guidelines provided recommendations for spinal manipulation, and nine guidelines recommended its use. Most guidelines (6 out of 9; 66%) recommend spinal manipulation for</p>
        <p>case of suspicion of specific pathologies or radiculopathy (69%)</p>
        <p>Referral to specialist if there is no improvement after four weeks to two years</p>
        <p>Using radiofrequency denervation for chronic LBP.</p>
        <p>-</p>
        <p>"-" = The guideline did not provide any recommendation regarding the approach.</p>
        <p>"X" = The guideline endorsed the recommendation regarding the approach.</p>
        <p>" " = The guideline did not endorse the recommendation regarding the approach.</p>
        <p>Description of the methods for development of clinical guidelines for low back pain "-" The guideline did not provide any information regarding the topic "X" The guideline provided information regarding the topic " " The guideline did not met this topic Methods Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creat iveco mmons .org/licen ses/by/4.0 /), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
    </text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f573846896"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:30+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Background: With restrictions on movement and stay-at-home orders in place due to the COVID-19 pandemic, social media platforms such as Twitter have become an outlet for users to express their concerns, opinions, and feelings about the pandemic. Individuals, health agencies, and governments are using Twitter to communicate about COVID-19.</p>
<p>The aims of this study were to examine key themes and topics of English-language COVID-19-related tweets posted by individuals and to explore the trends and variations in how the COVID-19-related tweets, key topics, and associated sentiments changed over a period of time from before to after the disease was declared a pandemic.</p>
<p>Results: Topic modeling yielded 26 topics, which were grouped into 10 broader themes underlying the COVID-19-related tweets. Of the 13,937,906 examined tweets, 2,858,316 (20.51%) were about the impact of COVID-19 on the economy and markets, followed by spread and growth in cases (2,154,065, 15.45%), treatment and recovery (1,831,339, 13.14%), impact on the health care sector (1,588,499, 11.40%), and governments response (1,559,591, 11.19%). Average compound sentiment scores were found to be negative throughout the examined time period for the topics of spread and growth of cases, symptoms, racism, source of the outbreak, and political impact of COVID-19. In contrast, we saw a reversal of sentiments from negative to positive for prevention, impact on the economy and markets, government response, impact on the health care industry, and treatment and recovery.</p>
<p>Conclusions: Identification of dominant themes, topics, sentiments, and changing trends in tweets about the COVID-19 pandemic can help governments, health care agencies, and policy makers frame appropriate responses to prevent and control the spread of the pandemic.</p>
<p>As the effects of the COVID-19 pandemic are felt worldwide, social media platforms are becoming inundated with content associated with the disease. Since its initial identification and reporting in Wuhan, China, the novel disease COVID-19 has spread to multiple countries across all continents and has become a global pandemic. The World Health Organization (WHO) declared the outbreak to be a pandemic on March 11, 2020, and the US government declared it to be a national emergency on March 13, 2020. As of June 30, 2020, the virus has infected over 10 million individuals and has caused approximately 503,000 deaths worldwide [1]. To contain the spread of the virus, several countries have implemented lockdown and quarantine measures and imposed travel bans, restricting people's movement. Schools have been closed, many workers have become unemployed, and numerous individuals are locked down in their homes. With millions of lives affected by the COVID-19 pandemic, social media platforms such as Twitter have become an outlet for users to express their concerns, opinions, and feelings about the pandemic.</p>
<p>Social media has emerged as a significant conduit for health-related information; the majority of people across multiple countries use some form of social media [1,2]. Pew Research surveys examining multiple countries have identified social media as an important source of health information [3]. In recent years, sharing and consuming health information via social media has become prevalent. It is unsurprising that social media has become a prominent platform for people to share information and feelings about COVID-19.</p>
<p>The science of understanding health-related information that is distributed via a digital medium such as the internet or social media with the aim to inform public health and public policy is known as infodemiology. A related term, infoveillance, refers to syndromic surveillance of public health-related concerns that is expressed and diffused on the internet through digital channels. Infoveillance has been particularly useful to identify outbreak patterns and to study public perceptions of several diseases, including H1N1 influenza ("swine flu") [4], Ebola virus [5,6], and Zika virus [7][8][9]. Analysis of health event data posted on social media platforms not only provides firsthand evidence of health event occurrences but also enables faster access to real-time information that can help health professionals and policy makers frame appropriate responses to health-related events.</p>
<p>Our research goals were to examine key themes and topics in COVID-19-related English-language tweets posted by individuals and to explore the trends and variations in how COVID-19-related tweets, key topics, and associated sentiments changed over a period of time from before to after the disease was declared a pandemic.</p>
<p>Identified 12 topics that were grouped into four themes, viz the origin of the virus; its sources; its impact on people, countries, and the economy; and ways of mitigating infection.</p>
<p>Tweets from February 2 to March 15, 2020 167,073 tweets Twitter Abd-Alrazaq et al, 2020 [10] Positive correlation between the number of Weibo posts and number of reported cases in Wuhan. Qualitative analysis of 11,893 posts revealed main themes of disease causes, changing epidemiological characteristics, and public reaction to outbreak control and response measures.</p>
<p>Posts from December 23, 2019, to January 30, 2020 115,299 posts Weibo Li et al, 2020 [11] Developed a classifier to identify "sick posts" pertaining to COVID-19. The number of sick posts positively predicted the officially reported COVID-19 cases up to 14 days ahead of official statistics.</p>
<p>Posts from November 1, 2019, to March 31, 2020 15 million posts Weibo Shen et al, 2020 [12] 203 users who tested positive for COVID-19 reported their symptoms: fever/pyrexia, cough, body ache/pain, fatigue, headache, dyspnea, anosmia and ageusia.</p>
<p>N/A a 499,601 tweets from 305 users who selfdisclosed their COVID-19 test results Twitter Sarker et al, 2020 [13] Analysis of oral health-related information posted on Weibo revealed home oral care and dental services to be the most common tweet topics.</p>
<p>December 31, 2019, to March 16, 2020 15,900 posts Weibo Tao et al, 2020 [14] Identified eight themes: actions and recommendations, fighting misinformation, information and knowledge, the health care system, symptoms and illness, immunity, testing, and infection and transmission.</p>
<p>Rufai and Bunce, 2020 [17] Assessed speed of information transmission in networks and found that news containing the word "coronavirus" spread faster.</p>
<p>Few weeks before February 29, 2020 43,832 users and 78,233 relationships Twitter Park et al, 2020 [18] An examination of four emotions (fear, anger, sadness, and joy) revealed that emotions shifted from fear to anger, while sadness and joy also surfaced.</p>
<p>January 28 to April 9, 2020 20,325,929 tweets from 7,033,158 users Twitter Lwin et al, 2020 [19] Examined temporal and geographical variations of COVID-19-related tweets, focusing on Europe, and the categories and origins of shared external resources.</p>
<p>Topic modeling is an unsupervised machine learning approach that is useful for discovering abstract topics that occur in a collection of textual documents. It helps uncover hidden semantic structures in a body of documents. Most topic modeling algorithms are based on probabilistic generative models that specify mechanisms for how documents are written in order to infer abstract topics. One popular topic modeling algorithm, latent Dirichlet allocation (LDA), is an unsupervised generative probabilistic method for modeling a corpus of words [31]. A key advantage of LDA is that no prior knowledge of topics is needed. By tuning the LDA parameters, one can explore the formation of different topics and the resultant document clusters. Despite the usefulness of LDA, its outcomes can be difficult to interpret and can drastically vary based on the choice of parameters. With a large corpus of texts, the unsupervised nature of LDA can result in the generation of topics that are neither meaningful nor effective, requiring human intervention and multiple iterations [10]. An improvised variant to traditional LDA, the guided LDA algorithm [32], enables the provision of a set of seed words that are representative of the underlying topics so that the topic models are guided to learn topics that are of specific interest.</p>
<p>We obtained a total of 13,937,906 tweets from 10,868,921 unique users after eliminating 4,085,264 tweets posted by organizations and institutions. Our primary goal was to understand public perceptions and sentiments pertaining to COVID-19; hence, only tweets posted by individuals were retained for analysis.</p>
<p>Our analysis of tweets yielded 26 subtopics, which we framed into 10 broad themes (Table 2). Of the 13,937,906 tweets we examined, 2,858,316 (20.51%) pertained to the theme of the impact of COVID-19 on the economy and markets, followed by spread and growth in cases (2,154,065, 15.45%), treatment and recovery (1,831,339, 13.14%), impact on the health care sector (1,588,499, 11.40%), and government response to the pandemic (1,559,591, 11.19%). Although tweets related to the theme of racism formed only 4.14% (577,066/13,937,906) of the data, over 500,000 tweets were found to contain racist content. It should be noted that all the tweets we assessed were public discourses pertaining to broader themes, as our data set consisted of tweets posted by individuals about various issues pertaining to the COVID-19 pandemic.</p>
<p>For each theme pertaining to COVID-19, we examined the trends in the proportions of positive, negative, and neutral tweets over time (Figure S1 in Multimedia Appendix 3). Of the total tweets concerning the source of the COVID-19 outbreak, the proportions of neutral and negative tweets remained fairly high (approximately 35% to 45%) in the weeks before the WHO announced that COVID-19 was a pandemic. The proportion of positive tweets exceeded those of negative and neutral tweets in the week of the WHO declaration. In the subsequent weeks, the proportion of positive tweets dropped to approximately 25%, whereas the proportions of neutral and negative tweets were approximately 30% to 45%. When we examined tweets pertaining to the prevention of COVID-19, the proportion of positive tweets exceeded those of neutral and negative tweets in almost all the weeks from February 2020, reaching approximately 40% in the beginning of May 2020.</p>
<p>The proportion of negative tweets was considerably higher than those of the positive and neutral tweets for the themes of symptoms (approximately 60%) and of spread and growth in cases (approximately 45%). This pattern was observed for almost all the weeks we examined. In February 2020, over 90% of tweets on the theme of symptoms were negative. Although this trend gradually declined over the next few weeks, it still formed over 50% in the last week of our examination. Similarly, negative tweets about the spread and increase in COVID-19 cases constituted between 40% and 50% from February 2020 until the beginning of May 2020. For the theme of treatment and recovery, the proportion of positive tweets (20%) gradually increased to over 40% over the 17-week period. The negative tweets in the initial weeks (30% to 35%) declined to 25% in April and early May 2020.</p>
<p>We noted a gradual increase in the proportion of positive tweets pertaining to the impact of COVID-19 on the economy and markets over time. Proportions of negative tweets were higher in the months of February and March 2020 but gradually declined to approximately 30% toward the beginning of May 2020.</p>
<p>An increase in the proportion of positive tweets over time was seen for the themes of government response and impact on the health care industry. The theme pertaining to government response captured the Twitter discourse by users concerning various measures taken by different governments to address COVID-19. The proportion of negative tweets about government response was approximately 45% up to mid-March 2020 and then declined to approximately 30% by the first week of May. The proportion of negative tweets on the theme of the political impacts of COVID-19 was considerably higher (&gt;50%) from March 2020. We also noted a substantial proportion of negative tweets on the theme of racism.</p>
<p>We examined the trends pertaining to the changes in the sentiment scores of each of our themes and topics over the time period of examination. To plot the trends, we used the average compound scores by topic and week. Our results are presented in Figure S2 (Multimedia Appendix 3).</p>
<p>Average compound sentiment scores were found to be negative throughout the time period of our examination for the themes of spread and growth of cases, symptoms, racism, source of the outbreak, and political impacts of COVID-19. In contrast, we saw a reversal of sentiments from negative to positive for the themes of prevention, impact on the economy and markets, government response, impact on the health care industry, and treatment and recovery; the negative sentiment scores in the initial weeks of the COVID-19 outbreak for the aforementioned themes changed to positive scores in the final few weeks of our examination. This reversal of sentiments is noteworthy, as it reflects a collective opinion of a fairly larger set of Twitter users on how the pandemic is being managed by key stakeholders.</p>
<p>Our analysis revealed a consistently negative average compound score for the topic of the outbreak in Wuhan, China, for all the weeks that we examined. We found that Twitter users frequently referred to the geographical origin of the disease even in the later weeks of our examination. When we examined the topic of alternative causes of the outbreak, we found several tweets about hypothetical causes and conspiracy theories pertaining to COVID-19 (eg, use of SARS-CoV-2 as a bioweapon and origin of the virus in a lab in Wuhan). The average sentiment scores remained negative for weeks until the week of March 22 to 28, then showed a spike to positive values and continued to remain positive until the beginning of May 2020. This positive trend in later weeks is due to tweets dismissing the conspiracy theories that were circulated during the early weeks. Further, the spike in the positive score in the week of March 22 to 28 is partly due to a large number of tweets that contained references to "coronavirus as an act of God" and prayers to end the pandemic, as well as tweets that viewed COVID-19 as "nature's way to heal the planet." These types of tweets provide qualitative evidence for the positive sentiment scores we observed in the analysis, such as:</p>
<p>This virus is certainly God's call to humanity to wake up and recognise him before it is too late.</p>
<p>We're the virus.</p>
<p>The average compound score for social distancing remained negative until the first week of March. During this time period, COVID- 19 had not yet spread worldwide. However, from the second week of March 2020, the average sentiment score was positive for all the weeks we examined, reflecting that the general public supported and had a favorable disposition toward social distancing as a mechanism to combat the spread of the virus. We observed that several Twitter appealed to others and advocated social distancing measures, such as: Kindly stay at home. Wash your hands. Practice social distancing.</p>
<p>The topic of disinfecting and cleanliness showed average positive sentiment scores for all weeks from the third week of January 2020. We found that Twitter users used gaming strategies such as challenges (eg, #SafeHandsChallenge) involving a chain of users to advocate cleanliness and create broader awareness about the importance of disinfecting and cleanliness. We found that many Twitter users shared tips about disinfecting groceries and products after shopping. We also found that some Twitter users condemned people who did not wear face masks or follow recommended safety protocols in public.</p>
<p>Three of the four topics under the theme of spread and growth exhibited negative average compound sentiment scores. The average compound scores for the topic of death reports were negative for all the weeks, with values ranging between -0.2 and -0.5. The topic pertaining to spread of cases exhibited negative trends throughout, with average compound scores ranging between -0.1 and -0.3. The topic of modes of transmission of COVID-19 also showed negative scores across all the weeks, with values between 0 and -0.2. The topic of hotspots and locations for COVID-19 transmission exhibited negative scores until February 2020 but showed positive scores thereafter. Tweets mentioning hotspots of COVID-19 transmission often included mentions of places such as churches, places of religious worship, beaches, events, and festive occasions with mass gatherings; these mentions primarily contributed to the positive values.</p>
<p>All four topics under the theme of treatment and recovery showed negative scores in the initial weeks, which changed to positive average compound scores from April 2020. For the topic of testing, Twitter users reacted negatively to the lack of availability of test kits and testing methods in the initial weeks of the pandemic (eg, tweets containing phrases such as "not all in the hospitals can be tested as they are often short with test kits" or "Many places are not testing people for coronavirus due to test shortage. Its annoying"); however, with the improvement in availability of COVID-19 test kits and test centers worldwide, the sentiment became positive:</p>
<p>We got tested today. Easy as could be, no waiting, felt really safe, cheek swabs.</p>
<p>As more information on the efficacies of drugs such as remdesivir became available, Twitter users' sentiments regarding drugs and medicines for COVID-19 became positive by the end of March 2020. Twitter users reacted to news about drugs, as can been seen in these example tweets:</p>
<p>Remdesivir is effective in mitigating COVID-19 symptoms if taken early, ideally pre-hospitalization.</p>
<p>We also noted a small increase in the average positive compound score for the topic of drugs and medicines in the last week of April; this can be attributed to the US Food and Drug Administration's authorization of emergency use of the antimalarial drug chloroquine to treat COVID-19 on April 27, 2020. Tweets such as these contributed to this positive compound score:</p>
<p>Hydroxychloroquine protocol: effective, cheap and can be produced in many laboratories. HCQ functions as both a cure and a vaccine.</p>
<p>However, it should be noted that this authorization was later revoked on June 15, 2020, a date outside the time period covered by our study. The negative sentiments about various therapies in the initial weeks of the pandemic also started to become positive in the third week of March. Twitter users positively reacted and shared information on plasma therapy and associated trials that were being conducted on patients with COVID-19. For instance, some tweets provided examples of positive sentiments from Twitter users:</p>
<p>We desperately need a treatment for those severely suffering with Coronavirus. Blood plasma could be the answer.</p>
<p>The topic of alternative methods of treatment for COVID-19 (traditional Chinese medicine, Indian Ayurveda, etc.) had mildly positive sentiment scores for most of the time period in our examination.</p>
<p>Among the topics that comprise the theme of impact on the economy and markets, Twitter users' average compound scores for sentiments about the topic of employment remained negative for all the weeks we examined. Many Twitter users posted information about their job loss and unemployment:</p>
<p>Lost my job a couple weeks ago due to Coronavirus and now it's impossible to find a new job.</p>
<p>Moreover, other users organized crowdfunding campaigns to help people who lost their jobs. Similar negative scores were seen across all the weeks for the topic pertaining to stock markets. Tweets pertaining to the topic of panic buying by consumers showed negative sentiment scores for all the weeks until mid-April, after which the scores began to be positive. Many users shared tweets about long queues and panic buying, as can be seen in these tweets:</p>
<p>No panic buying y'all hear that? So leave some damn bread and milk for me please. Tweets about the topic of shortages (of food and essential items) swung between positive and negative scores in the first few weeks of the pandemic but became positive from mid-March until early May. Twitter users reacted positively to measures adopted by supermarkets and grocery stores to practice safety measures, as can be seen in this illustrative tweet:</p>
<p>Yes! Longos Markets requires all customers to wear masks. Went there today, it was a good, safe shopping experience, better than any other store. Will definitely be shopping there again.</p>
<p>Twitter users' sentiments about the topic of businesses exhibited negative scores in the initial weeks of the pandemic, primarily fueled by news about closures and losses. However, this sentiment score changed to positive in the first week of March 2020. The positive score seen here reflects the adaptation of businesses to the new pandemic and their reopening and revival across different countries. Tweets such as the following provide indicators of positive sentiments of users about reopening of businesses:</p>
<p>Open for business. Trusting the people to take care of themselves. Freedom smells sweet.</p>
<p>Sentiment scores pertaining to the topic of hospitals and clinics largely remained negative throughout the time period of our examination. Tweets about lack of beds, facilities, NS ventilators, overcrowding of patients, and the struggles of health care institutions to cater to the influx of COVID-19 patients contributed to the negative sentiment scores. Illustrative tweets about these negative sentiments include:</p>
<p>Lack of safety gear for healthcare workers, shortage of beds and doctors, inadequate labs to conduct tests -our healthcare system is very fragile!! However, we noted a reversal in the trends of sentiment scores for the topic of frontline health care workers. Twitter users' negative sentiments until the end of March 2020, reflecting the lack of personal protective equipment and gear for health care professionals, health worker burnout, and increased workload for health care workers, became positive in April and early May 2020 as the situation improved. We saw tweets in the initial period of the pandemic with negative sentiments, such as "the knighted geniuses at the top of the NHS can't even organise protective equipment for our doctors and nurses". In the later weeks of our examination, hashtags such as #coronawarriors and tweets hailing the services of frontline workers (eg, "Deepest gratitude to the #CoronaWarriors who are working tirelessly in these difficult times") contributed to positive sentiment scores. The topic of health policy, which reflects the newer safety guidelines, protocols, and policies pertaining to patients with COVID-19 implemented by health care organizations, exhibited a negative trend in the early period, with tweets such as:</p>
<p>The ventilator situation is even more dire than we know. Not every hospital had an allocation policy in place.</p>
<p>Spain has begun a no ventilator policy for anyone over 65.</p>
<p>However, this topic showed a positive trend after the end of March 2020 as many agencies, governments, and health care institutions began to establish clear policies for treating patients with COVID-19. In the later weeks of our examination, many hospitals had framed clearer guidelines for use of masks, visitations, and restrictions pertaining to COVID-19. These illustrative tweets point to a possible rationale behind the positive sentiments pertaining to the topic of health policy in the later weeks of our examination:</p>
<p>The hospital has an understandable policy during this crisis of limiting visitation for the safety of all &amp; to reduce use of critical PPEs.</p>
<p>Twitter users' sentiments about the topic of travel restrictions imposed by governments worldwide were largely negative for most of the weeks we examined, except for the week of March 22 to 28, 2020. In this week, governments in populous countries such as India and Canada announced travel restrictions such as flight suspensions and isolation and quarantine measures for individuals entering these countries. Tweets indicated positive sentiments about travel restrictions: I believe it was a good move from India to have a complete travel restriction to all countries. When we don't have the health systems to treat huge populations, the best thing to do is to shut doors.</p>
<p>The fine for breaking self-quarantine / self-isolation in BC, Canada is $25,000 AND jail time. Canada is taking travel and quarantine very seriously. Great job.</p>
<p>Many Twitter users welcomed travel bans and restrictions and expressed positive sentiments about them.</p>
<p>Except for the first two weeks of April, the average compound sentiment scores about the topic of lockdown regulations remained negative in most of the weeks we examined. Twitter users' sentiments about stay-at-home orders, shutdowns, and lockdowns of complete cities were negative. This can be seen from these sample tweets:</p>
<p>This lockdown really does do bad things to good peoples mental health, trying to stay positive is a task in itself when this shite feels never ending.</p>
<p>Lockdown extended for another 3 weeks I hate it here.</p>
<p>However, the sentiment scores were positive in the weeks in which different governments announced financial measures such as stimulus payments to people affected by closures and lockdowns. In some tweets, users expressed positive sentiments about the financial relief measures to help individuals suffering due to the impact of COVID-19: I got my stimulus check today! Woohoo! Zoe and I finally received our stimulus/relief check from the federal government.</p>
<p>India is preparing a stimulus package that would put money directly into the accounts of more than 100 million poor people and support businesses hit the hardest by the 21-day lockdown.</p>
<p>This study joins the growing body of infoveillance studies on COVID-19 that examine social media data to uncover public opinions about the pandemic. We used a corpus of over 13 million tweets from January until the first week of May 2020 to uncover the trends in sentiments regarding various themes and topics. Our study is comprehensive, covering 26 different topics underlying COVID-19-related tweets under 10 broader themes. In response to a call made by Liu et al [34], we combined the topic modeling approach with sentiment analysis to observe the trends in sentiments for various themes and topics over time. By assimilating the collective opinions of several million users, we found interesting patterns in the trends pertaining to sentiments of themes and topics of COVID-19-related tweets.</p>
<p>We combined two publicly available sources with our own search to assemble a unique data set that contained English-language tweets about various topics associated with COVID-19. We further used a naïve Bayes classifier to segregate tweets made by individuals. We employed guided LDA to identify the underlying topics and associated themes, and we also examined the sentiments associated with the tweets and their changes over time.</p>
<p>Our key finding is that the impact of COVID-19 on the economy and markets was the most discussed issue by Twitter users. The number and proportions of tweets on this theme were remarkably higher than those of tweets on the other themes we uncovered. Further, users' sentiment was negative until the third week of March but gradually became positive in the final weeks we studied. Users' initial negative sentiments about shortages, panic buying, and businesses gradually turned positive from April 2020. Users started feeling positive about government responses to contain the pandemic, including financial measures to support and assist them in dealing with the disease outbreak.</p>
<p>Twitter users felt negative about continued spread and growth of the number of cases and the symptoms of COVID-19. However, we also found that Twitter users were more positive about treatment of and recovery from COVID-19 in later weeks than they were during the earlier stages of the pandemic. They expressed positive feelings by sharing information on testing, drugs, and newer therapies that show promise to contain the outbreak. Another notable finding is the Twitter users' gradual change in sentiment from negative to positive regarding COVID-19 prevention measures such as social distancing and cleanliness. Twitter users who initially expressed negative sentiments regarding COVID-19's impacts on the health care sector, comprising hospitals, clinics, and frontline workers, gradually became positive in the later weeks.</p>
<p>Another key finding of our study is the continued negative sentiments about political fallouts due to COVID-19. Although leaders worldwide are struggling to contain the pandemic, we noted that Twitter users felt negative about how COVID-19 was used for political purposes. Similarly, we noted strong negative sentiments about racist content in users' tweets.</p>
<p>Our study offers several insights for health policy makers, administrators, and officials who are managing the impact of the COVID-19 pandemic. Identification of topics and associated sentiment changes provide pointers to how the general public are reacting to specific measures taken to tackle the pandemic. Variations in sentiment scores serve as a feedback mechanism for assessing public perceptions of various measures taken with respect to social distancing, cleanliness and disinfecting, lockdowns, travel restrictions, and efforts to revive the economy. Public sentiments have also started to become positive about COVID-19 testing, treatment, and vaccines as well as health policies. Our study shows that observing aggregate sentiments and changes in trends via social media posts can offer a cost-effective, timely, and valuable mechanism to gauge public perceptions regarding policy decisions being made to address the pandemic.</p>
<p>This study has a few limitations that should be kept in mind while interpreting the results. We relied on a large data set that was partly compiled by us and included two other publicly available data sets. These data sources contained tweets from varying dates and used different search terms and search strategies to gather the tweets. Our analysis may have inadvertently omitted certain COVID-19-related tweets that were not captured by the data sources. In addition, COVID-19-related tweets from users who chose to make their accounts private were not included in our study. Further, we did not consider any geographical boundaries when examining the tweets. Studies focusing on tweets from specific countries can find different topics and sentiments that reflect country-specific opinions and concerns. We also restricted our study to tweets in the English language and to those posted by individuals. It should be noted that our naïve Bayes classifier with over 80% accuracy helped us identify tweets posted by individuals. It is possible that some individual users posted tweets on behalf of organizations, and these tweets may have been included in our data set. A more refined approach with deep learning techniques to identify individual tweets can aid in classifying and assembling a tweet data set with increased accuracy. As a future research extension, tweets posted by organizations could be another frame of reference to understand their concerns and sentiments. Another important limitation is that our findings are reflective of Twitter users, who are fairly familiar with social media and use of technology. The results may not generalize to the larger worldwide population of people who do not use Twitter.</p>
<p>As COVID-19 continues to affect millions of people worldwide, our study throws light on dominant themes, topics, sentiments and changing trends regarding this pandemic among Twitter users. By examining the changing sentiments and trends surrounding various themes and topics, government agencies, health care organizations, businesses, and leaders who are working to address the COVID-19 pandemic can be informed about the larger public opinion regarding the disease and the measures they have taken so that adaptations and corrective courses of action can be applied to prevent and control the spread of COVID-19.</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 2 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 3 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 4 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 5 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 6 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 7 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 8 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 9 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 10 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>J Med Internet Res 2020 | vol. 22 | iss. 10 | e22624 | p. 11 http://www.jmir.org/2020/10/e22624/ (page number not for citation purposes)</p>
<p>The authors would like to thank Navya Shiva, Karansinh Raj, Paul Davis and Ronald Omega Pukadiyil for their assistance in the data collection for the study</p>
<p>None declared.</p>
<p>The confusion matrix.</p>
<p>[DOCX File , 12 KB-Multimedia Appendix 1]</p>
</text>
</tei>
  <tei>
    <teiHeader>
        <fileDesc id="f81719149"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:18+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text lang="en">
        <p>Background: Recently, the potential role of gut microbiome in metabolic diseases has been revealed, especially in cardiovascular diseases. Hypertension is one of the most prevalent cardiovascular diseases worldwide, yet whether gut microbiota dysbiosis participates in the development of hypertension remains largely unknown. To investigate this issue, we carried out comprehensive metagenomic and metabolomic analyses in a cohort of 41 healthy controls, 56 subjects with pre-hypertension, 99 individuals with primary hypertension, and performed fecal microbiota transplantation from patients to germ-free mice. Results: Compared to the healthy controls, we found dramatically decreased microbial richness and diversity, Prevotelladominated gut enterotype, distinct metagenomic composition with reduced bacteria associated with healthy status and overgrowth of bacteria such as Prevotella and Klebsiella, and disease-linked microbial function in both pre-hypertensive and hypertensive populations. Unexpectedly, the microbiome characteristic in pre-hypertension group was quite similar to that in hypertension. The metabolism changes of host with pre-hypertension or hypertension were identified to be closely linked to gut microbiome dysbiosis. And a disease classifier based on microbiota and metabolites was constructed to discriminate pre-hypertensive and hypertensive individuals from controls accurately. Furthermore, by fecal transplantation from hypertensive human donors to germ-free mice, elevated blood pressure was observed to be transferrable through microbiota, and the direct influence of gut microbiota on blood pressure of the host was demonstrated. Conclusions: Overall, our results describe a novel causal role of aberrant gut microbiota in contributing to the pathogenesis of hypertension. And the significance of early intervention for pre-hypertension was emphasized.</p>
        <p>In recent decades, the potential role of the gut microbiome in altering health status of the hosts has drawn considerable attention. Emerging evidence suggests a link between gut microbiome and various diseases, including colorectal cancer, liver cirrhosis, arthritis, type 2 diabetes, and atherosclerosis [1][2][3][4][5]. A number of microbial biomarkers specific to these diseases have been discovered, and fecal microbiome-targeted strategies are recommended to be a powerful tool for early diagnosis and treatment of different diseases.</p>
        <p>More importantly, by fecal transfer experiment and gut microbiota (GM) remodeling, intestinal microbiome has been further indicated to conduce to the pathogenesis of multiple diseases such as obesity, depressive disorder, chronic ileal inflammation, liver diseases, and atherosclerosis [6][7][8][9][10][11][12]. Specific mechanisms underlying the causal function of GM have been revealed. For example, the metabolism by intestinal microbiota of dietary L-carnitine, a nutrient in red meat, was demonstrated to promote atherosclerosis and lead to cardiovascular disease risk via producing trimethylamine and trimethylamine-Noxide [12]. Targeting gut microbial production of trimethylamine specifically and non-lethal microbial inhibitors were confirmed to relieve diet-induced atherosclerotic lesion development [13]. Thus GM may serve as a potential therapeutic approach for the treatment of cardiovascular and metabolic diseases.</p>
        <p>Hypertension (HTN) has become a global public health concern and a major risk factor for cardiovascular, cerebrovascular, and kidney diseases [14,15]. It is believed that the etiology of HTN depends on the complex interplay of both genetic and environmental factors [16,17], and the precise cause of this morbidity has not been elucidated to date. It has been suggested that the germ-free (GF) mice, in which the intestinal bacteria is completely absent, present relatively lower blood pressure (BP) when compared to conventional mice [18]. And therefore we suspected that GM might have the potential to regulate BP.</p>
        <p>Most recently, many lines of seminal evidence, which for the first time demonstrate that aberrant gut microbial community are linked to BP changes of the host, support this hypothesis. For example, disordered GM as a result of decreased microbial richness, diversity, evenness, and increased Firmicutes/Bacteroidetes ratio was reported in hypertensive animals and seven HTN patients, as sequenced by 16S ribosomal RNA [19]. In Dahl rats, distinct metagenomic composition have been revealed between salt-sensitive and salt-resistant strains, and the GM of salt-sensitive rats was suggested to be in a symbiotic relationship with the host [20]. In addition, by rat models of HTN and meta-analyses in randomized human clinical trials, investigators have revealed that administration of probiotics can reduce BP [21,22]. This drove us to speculate that the alteration in GM by probiotic use may lead to BP changes. Furthermore, it has been proved that transplantation of cecal contents from hypertensive obstructive sleep apnea rats on high-fat diet into recipient rats on normal chow diet lead to higher BP levels, and a major contributor to the gut dysbiosis of obstructive sleep apnea-induced HTN is high-fat diet [23]. These studies have emphasized a strong correlation between gut dysbiosis and HTN, and further implied the significance of GM in BP regulation, yet animal models could not perfectly substitute human disease, and the sample size of human participants for microbial analysis was quite limited.</p>
        <p>In consideration of the BP levels being classified into optimal, pre-hypertension (pHTN), and HTN according to the most recent clinical guidelines [24], it remains obscure how exactly the composition of gut microbes and the products of microbial fermentation change in human patients with HTN, especially in pHTN populations. In addition, decisive evidence is still needed to determine whether gut dysbiosis is a consequence or an important causal factor for the pathogenesis of HTN. Fecal transplantation from human samples into GF mice is required to uncover the involvement of GM dysbiosis in pathophysiology of HTN. Collectively, these key issues are the major goal of the present study.</p>
        <p>To address the questions above, we performed deep metagenomic sequencing of stool samples from 196 participants of healthy control, pHTN, and HTN; took metabolomic analyses of their metabolic profiles, further constructed a disease classifier for pHTN and HTN based on GM and metabolites; and demonstrated the crucial role of disordered GM in triggering thigh BP by human fecal microbiota transplantation into GF mice.</p>
        <p>To identify whether gut microbial changes are associated with HTN, we performed shotgun metagenomic sequencing of fecal samples from a cohort of 196 Chinese individuals. The cohort consisted of 41 healthy controls, 56 subjects with pHTN, and 99 patients with primary HTN. All the participants were from a cohort study among employees of the Kailuan Group Corporation. The Kailuan study is a prospective cohort study focusing on the Kailuan community in Tangshan, a large modern city in northern China. All the subjects in the hypertension group were newly diagnosed hypertensive patients prior to antihypertensive treatment. Patients suffering from cancer, heart failure, renal failure, smoking, stroke, peripheral artery disease, and chronic inflammatory disease were all excluded. Drugs including statins, aspirin, insulin, metformin, nifedipine, and metoprolol were not used on the patients, and other drug consumption was not compared because the sample size was quite small. Individuals were also excluded if they had received antibiotics or probiotics within the last 8 weeks. Other than SBP and DBP, there was no significant difference in other clinical parameters among groups, except for fasting blood glucose level (FBG) (P = 0.026, C vs H; Kruskal-Wallis test, Additional file 1: Table S1). Bacterial DNA was extracted from stool samples, sequenced on the Illumina platform, and a total of 1211 Gb 125-bp paired-end reads were generated, with an average of 6.18 ± 1.43 (s.d.) million reads per sample (Additional file 2: Table S2). For each sample, a majority of high-quality sequencing reads (83.74-97.24%) were de novo assembled into long contigs or scaffolds, which were used for gene prediction, taxonomic classification, and functional annotation.</p>
        <p>To characterize the bacterial richness, rarefaction analysis was performed by randomly sampling 100 times with replacement and estimating the total number of genes that could be identified from these samples. The curve in each group was near saturation, which suggested the sequencing data were great enough with very few new genes undetected. The rate of acquisition of new genes in control samples rapidly outpaced new gene acquisition in disease samples, suggesting lower levels of gene richness in the pHTN and HTN groups (Fig. 1a). The number of genes in both pHTN and HTN groups were significantly decreased as compared to the controls (P = 0.024, C vs P; P = 0.04, C vs H; Kruskal-Wallis test, Fig. 1b). Shannon index based on the genera profile was calculated to estimate the within-sample (α) diversity. Consistently, the α diversity at the genus level was much lower in pHTN and HTN groups (P = 0.023, C vs P; P = 0.016, C vs H; Kruskal-Wallis test, Fig. 1c). The reduced richness of genes and genera in the GM of pHTN and HTN groups is consistent with previous findings [19], suggesting possible deficiency of healthy microflora in hypertensive patients.</p>
        <p>To explore the difference between the microbial communities at different stages of HTN, enterotypes were identified based on the abundance of genera using Partitioning Around Medoid (PAM) clustering method. The optimal number of enterotypes was two as indicated by Calinski-Harabasz (CH) index (Additional file 3: Figure S1). Then Principal Coordinate Analysis (PCoA) using Jensen-Shannon distance was performed to cluster the 196 samples into two distinct enterotypes (Fig. 1d). Prevotella was the most enriched genus in enterotype 1; Bacteroides was the most enriched genus in enterotype 2 (P = 6.31e-31 and P = 2.09e-15, respectively; Wilcoxon rank sum test, Fig. 1e). Both contributors in the two enterotypes have been reported in European and Chinese populations before [2,3]. There was a higher percentage of pre-hypertensive and hypertensive patients distributed in enterotype 1 (48.21% for pHTN, and 45.45% for HTN), while more healthy controls (73.17%) were found in enterotype 2 (P = 0.02, C vs P; P = 0.03, C vs H; Fisher's exact test; Fig. 1f). These findings suggest that enterotype 2 may represent a GM community structure associated with healthy control, while enterotype 1 may be associated with pHTN and HTN.</p>
        <p>Considering the higher percentage of HTN patients in enterotype 1, we clustered the genera in this enterotype and further explored the microbial co-occurrence network by Spearman's correlation. There was a positively interacted network constituted by 12 genera, which were negatively correlated with Prevotella, the core genus in this enterotype (Additional file 4: Figure S2a). All these genera were decreased in enterotype 1 as compared with enterotype 2 (Additional file 4: Figure S2b). Eight out of them were directly linked to Prevotella, while the other four, including Oscillibacter, Faecalibacterium, Butyrivibrio, and Roseburia, were indirectly linked to Prevotella. These findings highlighted the possibility of Prevotella as a key genus associated with pHTN and HTN. The difference in gut enterotype distribution revealed profound changes of the intestinal microbiome structure in both pHTN and HTN, implying the significance of gut microbes in the development of HTN.</p>
        <p>pHTN and HTN-associated genera in GM Genes were aligned to the NR database and annotated to taxonomic groups. The relative abundance of gut microbes was calculated by summing the abundance of genes as listed in Additional file 2: Table S3-S4. P values were tested by Wilcoxon rank sum test and corrected for multiple testing with Benjamin &amp; Hochberg method as others previously did [4,25]. It is worth mentioning that 44 genera were differentially enriched in control, pHTN, and HTN (P &lt; 0.1, Wilcoxon rank sum test, Fig. 2a and Additional file 2: Table S5). Fifteen of them were further shown in Fig. 2b. Genera such as Prevotella and Klebsiella were overrepresented in individuals with pHTN or HTN (Fig. 2b). Prevotella, originated from mouth and vagina, was abundant in the microbiome of our study cohort. The pathogenesis of periodontal diseases and rheumatoid arthritis are thought to be attributed to Prevotella [3,26]. A wide range of infectious diseases are known to be attributed to Klebsiella [27,28]. Porphyromonas and Actinomyces, which were also elevated in the HTN group, are morbific oral bacteria that cause infections and periodontal diseases [29].</p>
        <p>By contrast, Faecalibacterium, Oscillibacter, Roseburia, Bifidobacterium, Coprococcus, and Butyrivibrio, which were enriched in healthy controls, declined in pHTN and HTN patients (Fig. 2b). Our observations were consistent with the genera negatively correlated with Prevotella in the network of enterotype 1 (Additional file 4: Figure S2), and these bacteria are known to be essential for healthy status. For example, reduced levels of Faecalibacterium and Roseburia in the intestines are associated with Crohn's disease and ulcerative colitis [30,31]. Both bacteria are crucial for butyric acid production [30,32]. Moreover, Bifidobacterium is an important probiotic necessary to intestinal microbial homeostasis, gut barrier, and lipopolysaccharide (LPS) reduction [33].</p>
        <p>The divergence of GM composition in each sample was assessed to explore the correlation of microbial abundance with body mass index (BMI), age, and gender (Additional file 5: Figure S3). Although the gender ratio is discrepant among groups (Additional file 1: Table S1), we found no remarkable regularity of bacterial abundance based on BMI, age or gender.</p>
        <p>To further validate the bacterial alterations in HTN, an independent metagenomic analysis was performed using the sequencing data generated from a previous study of type 2 diabetes [2]. From a total of 174 nondiabetic controls in the study, normotensive controls with SBP ≤125 mmHg or DBP ≤80 mmHg were enrolled, and HTN were elected with the inclusion criteria of SBP ≥150 mmHg or DBP ≥100 mmHg. The FBG levels between normotensive controls and HTN were similar. Finally, six subjects (HTNs, n = 3; normotensive controls, n = 3) were included in our analysis (Additional file 2: Table S6). As expected, the microbial diversity was decreased in HTN (Additional file 6: Figure S4a), and there were at least 20 genera showing consistent trends with our findings, including decreased Butyrivibrio, Clostridium, Faecalibacterium, Enterococcus, Roseburia, Blautia, Oscillbacter, and elevated Klebsiella, Prevotella, and Desulfovibrio (Additional file 6: Figure S4b, Additional file 2: Table S7).</p>
        <p>Collectively, these results supported our hypothesis that bacteria associated with healthy status were reduced in patients with HTN. This phenomenon together with the overgrowth of bacteria such as Prevotella and Klebsiella may play important role in the pathology of HTN.</p>
        <p>Firstly, for each gene, an OR score was calculated according to the abundance of each gene. Then, for the comparative analysis between control and HTN samples, the HTN-associated genes were classified as HTNenriched (OR &gt;2) or HTN-depleted (OR &lt;0.5) as previously described [34]. When calculating HTN-associated ORs, samples of pHTN were excluded, and samples labeled as HTN were excluded as well when calculating pHTN-associated ORs. A total of 1,120,526 genes significantly different in relative abundance across groups were identified (Additional file 7: Table S8). Secondly, we clustered genes by a rather high threshold (Spearman's correlation coefficient ≥0.7) according to previous methods [4,35]. Spearman's correlation coefficient was analyzed by R. The cluster groups with at least 50 genes were defined as co-abundance groups (CAGs) [4], and used for further analysis [35]. One thousand ninety-nine distinct CAGs were obtained (Additional file 2: Table S9-S11 and Additional file 8: Figure S5a). Seven hundred fourteen CAGs were assigned to known bacterial genera based on the tracer genes, with at least 80% of the genes mapped to the reference genome at an identity higher than 85% (Additional file 8: Figure S5b).</p>
        <p>CAGs were further clustered by Spearman's correlation based on the abundance. Compared with the controls, there were 316 CAGs and 372 CAGs enriched in pHTN and HTN, respectively (Additional file 2: Table S12). In the control group, Firmicutes and Roseburia were more abundant (Fig. 3a,b). Most CAGs enriched in prehypertensive samples were originated from Enterobacter, a disease-causing bacteria linked to obesity. Klebsiella, causally implicated in various infections, was also overrepresented in pre-hypertensive and hypertensive patients [27]. Additionally, most recent studies revealed that Fusobacterium was enriched in the fecal samples of patients with liver cirrhosis, colorectal carcinoma, or ulcerative colitis [4,36,37]. We also detected several clusters of CAGs assigned to Fusobacterium enriched in pHTN and HTN groups. About 200 CAGs were different in pHTN and HTN. Most of them in pHTN were from Enterobacter and Klebsiella, while Prevotella and Fusobacterium were more abundant in HTN.</p>
        <p>To further examine the relationship between clinical indices and CAGs of GM, physiological parameters of SBP, DBP, BMI, FBG, total cholesterol (TC), triglyceride (TG), and low-density lipoprotein (LDL) were included in a Spearman's correlation analysis. We observed that SBP and DBP could negatively influence the CAGs enriched in the control group, such as Firmicutes and Roseburia, and positively interacted with Prevotella and Desulfovibrio, which were abundant in pHTN and HTN (Additional file 9: Figure S6). Whereas, both TC and TG were negatively correlated with Enterobacter, that was enriched in pHTN and HTN groups. Altogether, these results indicated that the bacterial communities in individuals with pHTN and HTN are similar, and the collective effect of these bacteria may account for intestinal dysbiosis in HTN.</p>
        <p>Using the Kyoto Encyclopedia of Genes and Genomes (KEGG) and Carbohydrate-Active EnZymes (CAZy) [38] database, we evaluated gut microbial functions across groups in our study cohort. All the genes were aligned to the KEGG database and CAZy database, and proteins were assigned to the KEGG orthology and CAZy families (Additional file 2: Table S13-S15). Principal component analysis (PCA) based on KEGG orthology revealed striking differences in microbial functions at the first principal component (PC1) between controls and patients (P &lt; 0.001, Wilcoxon rank sum test, Fig. 4a). Nearly all the KEGG modules and CAZy families displayed a similar discrepancy in pHTN and HTN when compared with the controls (Fig. 4b,c), illustrating the common functional features in pHTN and HTN. Sixty-five (n = 65) KEGG modules were differentially enriched among the three groups (adjusted P value &lt;0.05, Wilcoxon rank sum test, Additional file 2: Table S12). The thirty-nine (n = 39) modules decreased in pHTN and HTN groups were involved in branched-chain amino acid biosynthesis and transport, ketone body biosynthesis, two-component regulatory system, The network of CAGs enriched in HTN is compared to controls. CAGs are colored according to the taxonomic assignment as labeled, and the node size is scaled with the number of genes within the CAG. Edges between nodes denote Spearman correlation &gt;0.8 (red) or between 0.7 and 0.8 (gray) and degradation of methionine and purine (Fig. 4b). These metabolic functions are essential for the host and have been observed in healthy populations [4,5,39,40]. Although previous studies have found that iron, phosphate, and amino acid transport system, GABA biosynthesis, and methanogenesis were enriched in the patients subjected to colorectal cancer or liver cirrhosis [4,39], these metabolic functions were not enriched in our patient cohort. We observed seventeen (n = 17) modules elevated in pHTN and HTN, including LPS biosynthesis and export, phospholipid transport, phosphotransferase system (PTS), biosynthesis of phenylalanine and phosphatidylethanolamine, and secretion system (Fig. 4b). The capacity to synthesize and export LPS of the gut microbiome in patients with colorectal carcinoma has been suggested to represent an important mechanism whereby inflammation contributes to tumor progression [5,41,42]. PTS system, phosphatidylethanolamine biosynthesis, secretion system, and transport of phospholipid, which were overrepresented in pHTN and HTN, are also linked to diabetes, liver cirrhosis, and rheumatoid arthritis [2,4]. Additionally, the metagenome of patients were enriched in genes associated with cellulose-binding domains but depleted in host glycanutilizing enzymes (Fig. 4c). These gut microbial functions in hypertensive patients are commonly associated with other diseases. Although the functional annotation analyses are predictive, it indicated that impairment of GM may evoke a disease-linked state through interference of physiological metabolic functions.</p>
        <p>Considering the aberrant function profiles of gut microbes in disease subjects, we wondered the microbe-host interactions in HTN. As some end products of fermentation by the GM could enter the bloodstream and exert important influences on the physiology of the hosts, we explored the host metabolic profiling in fasting serum of a subset of 124 subjects by high-throughput liquid chromatographymass spectrometry (LC/MS) and examined the relationship between GM and metabolites in the circulation. Thirty healthy controls, 31 pHTNs, and 63 patients of HTN from our previous cohort were randomly enrolled. The serum samples were subjected to LC/MS analysis in both positive ion mode (ES+) and negative ion mode (ES-). After eliminating the impurity peaks and duplicate identifications, we identified a total of 1290 chromatographic peaks in ES+ and 2289 variables in ES-for further analyses. To discriminate the metabolic profiles across groups, we performed clustering analyses based on partial least-squares discriminant analysis (PLS-DA) and orthogonal partial least-squares discriminant analysis (OPLS-DA). The serum samples from distinct groups were largely separated according to the PLS-DA plots (Fig. 5a). The scatter plots in pHTN group were closer to those in HTN, suggesting a similar metabolic mode. Furthermore, individuals in either pHTN or HTN groups were separated from the controls as further evidenced by the OPLS-DA score scatter plots (Fig. 5b).</p>
        <p>The compositional changes in patients involved 167 analytes that were significantly different between pHTN and control, and 215 analytes altered in HTN (Fig. 5c). There were 26 metabolites which were obviously different in both pHTN and HTN groups as compared to the control (Additional file 2: Table S16). Notably, these metabolites exhibited statistically analogous profiles of alterations in pHTN and HTN, which was consistent with our findings based on gut microbiome (Fig. 5d). Endogenous compounds whose levels significantly decreased in pHTN and HTN include phosphatidylserine (PS), 3,4,5-trimethoxycinnamic acid, lysophosphatidylcholine (LysoPC), S-carboxymethyl-L-cysteine, and lysophosphatidylethanolamine (LysoPE). 3,4,5-Trimethoxycinnamic acid is capable to protect against inflammatory diseases through suppressing cell adhesion molecules in vascular endothelial cells [43]. Also S-Carboxymethyl-L-cysteine exerts anti-inflammatory properties [44]. These observed downregulations could promote the inflammatory environment associated with HTN. On the other hand, endogenous compounds whose levels significantly increased in pHTN and HTN include metabolites such as Nα-acetyl-L-arginine, stearic acid, phosphatidic acid (PA), and glucoside. Elevated levels of Nα-acetyl-L-arginine and stearic acid have been previously observed in uremia and spontaneously hypertensive rats [45,46]. These compounds may represent possible markers for the development of HTN and might be derived from gut microflora or their fermented products. To explore this idea, the relationship between 26 representative metabolites and the 44 most different genera was examined by correlation analysis (Fig. 5e). Control-enriched trichloroethanol glucuronide was positively correlated with Bifidobacterium and Akkermansia, but negatively linked to Prevotella. Conversely, there was a positive association between 9,10-dichloro-octadecanoic acid (stearic acid) and microflora including Klebsiella, Prevotella, and Enterbacter, which were all overrepresented in HTN. It was accordant that both Bifidobacterium and Roseburia negatively interacted with 9,10-dichloro-octadecanoic acid, which was hence considered as an important GM-influenced metabolic product in HTN. Thus the distinguished metabolic profiling in HTN was closely connected to intestinal microflora variation, although whether these metabolic products were directly metabolized by the intestinal microorganisms remained to be explored.</p>
        <p>To illustrate the microbial and metabolic signature of pHTN and HTN, and further exploit the potential of gut microbiome and metabolites in HTN identification, random forest disease classifier using explanatory variables of CAGs, metabolites, and species abundances were performed. Tenfold cross-validation was repeated for five times and the receiver operating characteristic (ROC) curves for classifying pHTN and HTN patients from controls were developed.</p>
        <p>We could detect HTN individuals accurately based on the gut CAGs + metabolites, as indicated by the area under the receiver operating curve (AUC) of up to 0.91, and 95% confidence interval (CI) of 0.75-1 (Fig. 6a). Similarly, comparing to the other variables, the variable of CAGs + metabolites was more effective to classify pHTN samples from controls, showing an AUC of 0.89, and 95% CI of 0.65-1 (Fig. 6b). Thus, we conducted a testing set consisted of 13 randomly chosen subjects based on CAGs + metabolites. In this assessment analysis, both pHTN and HTN patients possess remarkable features in gut microbiome and metabolites as compared to the controls (Fig. 6c). However, we observed poor performance on the test set when discriminating between pHTN and HTN by lower specificity and sensitivity (AUC, 0.57; 95% CI, 0.21-0.93; Fig. 6c). This further validated the similarity of pHTN and HTN in our previous findings. Among the most discriminatory CAGs to distinguish pHTN or HTN from control, there were some CAGs similarly enriched in both pHTN and HTN subjects, including CAG-172 (Prevotella), CAG-197 (Prevotella), CAG-759 (Faecalibacterium), CAG-765 (Faecalibacterium), and CAG-793 (Faecalibacterium) (Fig. 6d). These CAG markers were the common microbial characteristics of pHTN and HTN and contributed a lot to the identification of pHTN and HTN.</p>
        <p>We also investigated the utility of the classifier based on microbial CAGs + species. Consistently, the AUC for identifying pHTN and HTN from the controls was 0.67 (95% CI, 0.39-0.95) and 0.81 (95% CI, 0.53-1), respectively, and the performance on pHTN and HTN individuals was not as satisfactory (AUC, 0.47; 95% CI, 0.19-0.75; Additional file 10: Figure S7a). For HTN classification, CAGs and species taxonomic annotated to Prevotella, including Prevotella sp. CAG:5226.CAG-377, Prevotella bivia, and CAG-184 were typically important (Additional file 10: Figure S7b). Overall, the pHTN-and HTN-associated microbial and metabolic features captured by the classifier offered further evidence for dysbiotic gut microbiome and highlighted great potential ability for detection of pHTN and HTN populations by GM and metabolites. High BP is transferrable by fecal transplant Previous studies have revealed that antibiotics and probiotics are potential treatment modalities for BP in both animal models and clinical trials [19,21,22,47]. We speculated that the alterations in GM under pro/antibiotic use may be associated with BP changes. There is evidence that Dahl salt-sensitive rats transplanted with salt-resistant rat microbiota have further exacerbated BP, which indicate that the microbiota resident within the cecum of the Dahl salt-sensitive rat, but not the saltresistant rat, are in a symbiotic relationship with the host [20]. Thus the differences between Dahl saltsensitive rats and the salt-resistant rats are highlighted. Investigators have also proved that transplantation of cecal contents from hypertensive obstructive sleep apnea rats on high-fat diet into the same obstructive sleep apnea recipient rats on normal chow diet lead to higher BP similar to the donors [23]. In this study, it seems that a major contributor to the gut dysbiosis of HTN is a high-fat diet. Therefore, direct studies testing if microbial transplantation can transmit changes in BP from hypertensive donors to recipients are still lacking. To further demonstrate whether alterations of GM are a causal factor for the progression of HTN in vivo, fecal bacteria from hypertensive patients were transplanted to GF mice in the present work.</p>
        <p>The donors for microbiota transplantation consisted of two patients of HTN and one normotensive control (Additional file 11: Table S17). They were strictly selected, and fresh fecal samples from donors were inoculated to recipient mice as soon as possible. Male GF mice at 8-10 weeks were divided into groups and orally inoculated with stool samples two times at 1-day interval (Fig. 7a). The fecal samples of recipient mice posttransplantation were investigated by 16S V4 region amplicon sequencing (Additional file 2: Table S18). The sequences were de novo clustered at 97% sequence identity and annotated to genera. From HTN patients, 128 genera were successfully colonized in the intestine of HTN mice, and 110 genera were transferred to control-mice from the control donor (Fig. 7b). Shannon index based on the genera profile showed reduced bacterial diversity in HTN mice (P = 0.048; t test, Fig. 7c).</p>
        <p>As expected, PCoA at the genus level clustered HTN patients and mice colonized with hypertensive GM into one group, but control and control mice into a separated group (Fig. 7d). Moreover, at the genus level, Anaerotruncus, Coprococcus, Ruminococcus, Clostridium, Roseburia, Blautia, and Bifidobasterium were confirmed to be deficient, while Coprobacillus and Prevotella were shown to be more abundant in HTN mice, which was in agreement with our previous observations in the metagenomic analyses (Additional file 2: Table S19, Fig. 7e).</p>
        <p>At 10 weeks post-transplantation, BP of recipient mice in HTN and control group was measured by the tail-cuff method. Notably, the HTN mice exhibited significantly higher SBP, DBP, and mean blood pressure (MBP) as compared to controls (P &lt; 0.05), as well as elevated heart rate (P = 0.11) (Fig. 7f ). Early studies have shown that when compared to conventional controls, GF rats possess significantly lower cardiac output, relatively diminished regional blood flow, lower level of systemic BP response after blood loss, and hypotonic microvasculature [48], which might lead to a low systolic BP in the recipient mice. These findings provided novel and direct evidence that GM could influence the BP of host directly. Therefore, changes in the GM might be the mechanism underlying the effect of antibiotics and probiotics on BP control. As the number of donors for transplantation is limited, larger number of fecal transplants from hypertensive, pre-hypertensive, and normotensive control participants should be carried out in the future to further establish the magnitude of BP changes.</p>
        <p>To date, there are limited studies indicating a direct association between GM and HTN, especially in human disease. Several important gaps in knowledge of gut and BP remain unexplored, and critical issues should be addressed, such as the microbial profiles of HTN populations in clinical trials, the metabolites signature profiles, the microbial biomarkers for early detection of HTN, and fecal transplantation to make clear the causal relationship between gut dysbiosis and HTN. To make up for these blanks, we applied a strategy based on metagenomic and metabolomic analyses, coupled with GM transplantation. We sequenced the total bacteria DNA of stool samples from a cohort of 196 Chinese individuals and supplemented this analysis with an additional validation cohort. All the individuals in the present study are from a cohort study among employees of the Kailuan Group Corporation. The Kailuan study is a prospective cohort study focusing on the Kailuan community in Tangshan, a large modern city in northern China. As the subjects were from a relatively concentrated environment, the differences in the diets were relatively small. All the subjects in the hypertension group were newly diagnosed hypertensive patients prior to antihypertensive treatment. Patients suffering from cancer, heart failure, renal failure, smoking, stroke, peripheral artery disease, and chronic inflammatory disease were all excluded. Drugs including statins, aspirin, insulin, metformin, nifedipine, and metoprolol were not used on the patients, and other drug consumption was not compared because the sample size was quite small. Hence, it is not likely that the medication use directly influenced the gut metagenome and metabolites, as there was no significant difference in the drugs consumed by these subjects. Our results demonstrate that decreased diversity, altered enterotype distribution, and variation in bacteria populations were associated with both pHTN and HTN. The bacterial metabolic functions and GM-related metabolites in pre-hypertensive and hypertensive adults were closely linked to inflammatory state. Particularly, both pHTN and HTN individuals could be accurately distinguished from the controls by variables of CAGs and metabolites. And most importantly, the direct impact of GM composition on regulating BP was evaluated using an in vivo model of GF mice colonized with human intestinal microbiota. Bacteria such as Prevotella, Klebsiella, Enterobacter, and Fusobacterium are potential candidates for further bacteria transfer experiments to explore the precise mechanisms underlying the effect of GM in BP regulation. Our work provides the first direct evidence that highlights the pivotal role of dysbiotic gut microbiome as an important pathogenic factor for the high BP of the host. Thus GM modulation should be considered during antihypertensive treatment.</p>
        <p>Researchers previously suggested that the intestinal bacterium Prevotella copri thrives in a pro-inflammatory environment of rheumatoid arthritis [3,49]. The superoxide reductase and phosphoadenosine phosphosulphate reductase encoded by Prevotella copri may favor the development of inflammation. In their further demonstration, colonization with Prevotella copri enhances body weight loss and exacerbates epithelial inflammation in colitis mouse model [3]. Interestingly, as shown by our data, the enterotype dominated by Prevotella was enriched with pHTN and HTN populations. Moreover, Prevotella was overrepresented in individuals with pHTN and HTN. And stearic acid, an important metabolite in HTN, was positively linked to Prevotella. Furthermore, CAGs and species taxonomic annotated to Prevotella were the common microbial characteristics of pHTN and HTN, and contributed a lot to classification of HTN. Thus Prevotella may play an essential role in HTN, probably by triggering the inflammatory response.</p>
        <p>Our findings have consolidated the potential of Prevotella in the pathogenesis of diseases, and call for further exploring whether Prevotella is a causal conducer to inflammation and HTN.</p>
        <p>Concomitant with the alteration of gut microbial composition, we observed a dysbiosis in bacterial gene functions. The metagenome of HTN patients were depleted in genes associated with biosynthesis and transport of amino acid, such as lysine, histidine, leucine, and serine, which are essential for human health. Functional annotation also indicated a decline of modules for fatty acid utilization and saccharide transport, suggesting an impaired capacity of energy production. In agreement with previous studies showing a dearth of microbial functions for purine metabolism in arthritis [3], a significant decrease in purine-metabolizing enzymes was identified to be related to HTN. Indeed, these metabolic functions are quite necessary for healthy populations [3-5, 39, 40]. In contrast, the enrichment of the modules for LPS biosynthesis and export in patients hints at a potential role of GM in causing low-grade inflammation. Inflammation due to immune response triggered by LPS is the cardinal feature of the pathogenesis of gram-negative bacteria, such as Prevotella and Klebsiella [50,51], and has been identified as an important contributor to the pathogenesis of HTN. Our findings raise the possibility that the low-grade inflammation and increase of gram-negative bacteria, especially Prevotella and Klebsiella, are likely responsible for HTN pathology. Thus, our analysis of bacterial gene functions indicates that functional dysbiosis may contribute to the susceptibility to HTN, and overproduction of LPS by gut bacteria seems to be directly linked to HTN development, whereas amino acid biosynthesis, fatty acid utilization, and purine metabolism by bacteria might have a role in HTN prevention.</p>
        <p>Actually, in GF mice, the tail-cuff method has been used for assessment of BP in a recent report, suggesting the methodology is acceptable [52]. In our study, the tail-cuff measurement was performed as the others did previously, and indicated a tendency for higher BP in recipient mice inoculated with stool samples from hypertensive donors as compared to controls. As such results were not obtained by fecal microbiota transplantation in conventionally raised mice, we speculate that the immune inflammatory system might play a crucial role in the pathogenesis of HTN. Further mechanism research to make clear whether gut bacterial metabolites show a contribution to the immune inflammatory system during the development of HTN is being performed.</p>
        <p>In HTN studies, most work focused on patients with a clinical definition of HTN, who display a SBP higher than 140 mmHg or DBP ≥90 mmHg. However, population studies suggest that there is an intermediate stage of BP between control and HTN defined as pHTN, which should not be ignored. In our study, we considered subjects with pHTN as an independent group. Surprisingly, the bacterial diversity, enterotype, composition, and metabolic functions, as well as classified characteristics in pHTN highly coincided with those in HTN. As shown in Figs. 1,2, and 3, there was a little difference in the structure of gut microbiome between pHTN and HTN, indicating that pHTN is not simply a transition stage between normotensive and hypertensive status upon BP levels but rather a state in which gut dysbiosis has already occurred. Moreover, our findings revealed indiscriminate metabolic profilings between pHTN and HTN, consistent with a previous report that the serum spectral profiles of the hosts were similar at a stage of SBP ≥130 mmHg and at SBP ≥150 mmHg [53]. The close correlation of metabolic products and GM further strengthened and highlighted the importance of pHTN. Therefore, early treatment of pHTN has strong clinical value. In agreement with our notion, high BP has become one of the three leading risk factors for death according to the Global Burden of Disease Study [54]. Moreover, our findings fully support the updated conclusion by the Systolic Blood Pressure Intervention Trial (SPRINT) research group, that controlling one's SBP to an optimal level lower than 120 mmHg rather than a pHTN level below 140 mmHg leads to significantly decreased occurrence of cardiovascular events and death [55]. Thus, more attention should be given to the previously neglected populations in pHTN, and early intervention for pHTN is strongly appealed.</p>
        <p>Taken together, we have described clearly the disordered profiles of GM and microbial products in human patients with pHTN and HTN, established the relationship between gut dysbiosis and HTN, and provided important evidence for the novel role of GM dysbiosis as a key factor for BP changes. Our findings point towards a new strategy aimed at preventing the development of HTN and reducing cardiovascular risks through restoring the homeostasis of GM, by improving diet and lifestyle or early intervening with drugs or probiotics.</p>
        <p>All the individuals in the present study were from a cohort study among employees of the Kailuan Group Corporation. The Kailuan study is a prospective cohort study focusing on the Kailuan community in Tangshan, a large modern city in northern China, where 11 hospitals are responsible for the health care of the community, all of which participated in conducting physical examinations. All the subjects in the current work were strictly enrolled and none of them was under antihypertensive treatment. The participants were classified based on the Internal Guidelines for HTN as described in Additional file 1: Table S1. It was composed of 41 healthy controls (SBP ≤125 mmHg, or DBP ≤80 mmHg), 56 pHTNs (125 mmHg &lt; SBP ≤ 139 mmHg, or 80 mmHg &lt; DBP ≤ 89 mmHg), 99 patients of HTN (140 mmHg ≤ SBP, or 90 mmHg ≤ DBP). BP was measured in a sitting position by nurses or physicians. Three readings were recorded at 5-min intervals with a random-zero mercury column sphygmomanometer, and the average was taken as the final measurement.</p>
        <p>All clinical information was collected according to standard procedures. Patients suffering from cancer, heart failure, renal failure, smoking, stroke, and peripheral artery disease were excluded, and none of the patients was under antihypertensive treatment. Healthy volunteers had no history of diabetes mellitus or hypercholesterolemia. Individuals were also excluded if they had received antibiotics or probiotics within the last 8 weeks. The study was approved by local ethics committees (Kailuan General Hospital, Beijing Chaoyang Hospital, and Beijing Fuwai Hospital) and informed consent was obtained from all subjects.</p>
        <p>Stool samples freshly collected from each participant were immediately frozen at -20 °C and transported to the laboratory with ice pack. Bacterial DNA was extracted at Novogene Bioinformatics Technology Co., Ltd using TIANGEN kit according to the manufacturer's recommendations.</p>
        <p>All samples were paired-end sequenced on the Illumina platform (insert size 300 bp, read length 125 bp) at the Novogene Bioinformatics Technology Co., Ltd. After quality control, the reads aligned to the human genome (alignment with SOAP2 [56], Version 2.21, parameters: -s 135, -l 30, -v 7,-m 200,-x 400) were removed. The remaining high-quality reads were used for further analysis.</p>
        <p>To determine the abundance of genes, reads were realigned to the gene catalogue with SOAP2 using parameters: -m 200 -x 400 -s 119. Only genes with ≥2 mapped reads were deemed to be present in a sample [59]. The abundance of genes was calculated by counting the number of reads and normalizing by gene length.</p>
        <p>To estimate the genera richness of the sample, we calculated the within-sample (α) diversity using Shannon index based on the genera profiles. A high α diversity indicates a high richness of genera within the sample.</p>
        <p>The community types of each sample were analyzed by the PAM method using relative abundance of genera.</p>
        <p>All phenotype information of participants were listed in the supplementary tables of Qin J et. al [2]. Subjects with diabetes were excluded. Three HTN patients with SBP ≥150 mmHg or DBP ≥100 mmHg were enrolled, and three normotensive controls with SBP ≤125 mmHg and DBP ≤80 mmHg were included for the analysis.</p>
        <p>To identify the marker genes associated with pHTN and HTN, the abundance of each gene across groups was compared according to Greenblum S et al. [34]. As previously described [35], these marker genes were clustered into groups based on their abundance variation across groups. Clusters with more than 50 genes were defined as co-abundance gene groups (CAGs), and used for further analysis. CAG abundance profiles were calculated by the average gene depth signal and weighted by gene length.</p>
        <p>Taxonomic assignment of the CAGs was performed according to the taxonomy of tracer genes, as previously described [2]. Briefly, assignment to species requires 90% of the genes in a CAG to align with the species' genome with 95% identity and 70% overlap of query. Assigning CAG to a genus requires 80% of its genes to align to the genome with 85% identity in both DNA and protein sequences.</p>
        <p>Based on the clinical indices and enriched CAG profiles, we calculated Spearman's correlation in all samples. The P values were corrected for multiple testing with Holm method by R (Version 2.15.3, psychpackage). Only 162 samples were considered in the analysis because of the clinical data missing in 34 samples.</p>
        <p>One-hundred twenty-four (n = 124) individuals from our study cohort were subjected to metabonomics analysis based on the LC/MS method. This cohort was composed of 30 healthy controls, 31 pHTNs, and 63 patients of HTN. The whole blood samples were collected and separated into serum by centrifugation. Each serum samples at 100 μL were mixed with 400 μL methanol, and the mixtures were centrifuged at 12,000 rpm for 15 min at 4 °C. For LC/MS analysis, 200 μL of the supernatant was harvested.</p>
        <p>The serum metabolic profiles were performed on a Thermo Fisher Ultimate 3000 LC system. For chromatographic separation, C18 (2.1 mm × 100 mm × 1.9 μm) reversed-phase column (Thermo Scientific, USA) preheated at 40 °C was used. A prepared serum sample of 4 μL was injected and maintained at 4 °C for analysis. The gradient conditions for metabolite elution were at 5% B for 0-1 min, 5-40% B for 1-2 min of linear gradient, 40-80% B for 2-11 min of linear gradient, and 95% B for 11-15 min. The mobile phase for positive ion mode (ES+) and negative ion mode (ES-) was composed of water with 0.1% formic acid as solvent A, and acetonitrile with 0.1% formic acid as solvent B, and the flow rate was at 300 μL/min.</p>
        <p>For mass spectrometric assay, Orbitrap Elite mass spectrometer (Thermo Scientific, USA) equipped with ESI source was used to analyze the metabolite ions. The spray voltage was set to 3.8 kV in ES+ and 3.2 kV in ES-, the flow rate of sheath gas, aux gas, and sweep gas was 45, 15, and 1 arb, respectively. The ion source temperature was 300 °C, and the capillary temperature was 350 °C. Masses ranging from 50 to 1000 ion mass (m/z) were acquired, and the resolving power was set to 60,000.</p>
        <p>The raw ESI data of LC/MS was converted into m/z format and analyzed for non-linear retention time (RT) alignment, peak detection, and filtration. Maximal spectrum of continuous wavelet transform was used to correct baseline and detect peak positions. Impurity peaks and duplicate identifications were eliminated. Compounds significantly different between groups were obtained at a variable influence on projection (VIP) &gt;1.5, and P value of t test statistics &lt;0.05 based on the peak intensities. The m/z values of these compounds were used to identify the metabolites corresponding to the featured peak in the Metlin database.</p>
        <p>From the metabolite profile and 44 top differential genera abundance profile, Spearman's correlation was performed to eliminate multi-collinearity and only one factor will be randomly selected from high correlated clusters (|r| ≥ 0.9) for further analysis. A stepwise regression of linear models was used for modeling the relationship between metabolites and related genera, from the fitting value of individual metabolites, and Spearman's correlation between metabolic and associated genera was calculated and scaled by coefficients of each respective linear model.</p>
        <p>GF C57BL/6L mice were obtained from Shanghai Institutes for Biological Sciences (SLAC Inc., Shanghai, China) and housed under a 12-h light-dark cycle in the gnotobiotic facilities. All mice were fed with sterile food and water ad libitum, and bacterial contamination was monitored by periodic examination of stools. For microbiota transplantation, the fresh fecal samples were collected from donors (Additional file 11: Table S17), resuspended with sterile saline, and centrifuged for supernatant. Male GF mice aged 8-10 weeks were randomly distributed into two groups and orally inoculated (200 μL for each mouse) twice at 1-day interval with prepared fecal contents from control or patients. Recipient mice transferred with microbiota were kept in different Trexler-type flexible film isolators, fed with sterile food and water, and bacterial contamination was strictly controlled. The gut microbial profiles of recipient mice were analyzed by 16S sequencing after 7 days. We chose a time point of 10 weeks post-transplantation for BP measurement. An assessment of BP was performed within 60 min after exporting the mice out of their gnotobiotic facilities, and we could not ensure prevention from bacterial contamination after the measurement; the BP at other time points during 10 weeks was not further examined. The BP was measured by the tailcuff method and the BP-98A system (Softron, Tokyo, Japan), which was noninvasive and did not require surgery, since using direct invasive methods such as radiotelemetry techniques will immediately expose the mice to a non-sterile condition, which might impact the results. To acclimatize the mice undergoing the measurement procedures and improve measurement reliability, a heat-sterilized dark cover was transported into the germ-free mice isolator, where it was sterilized by spraying with a chlorine dioxide-based disinfectant in the isolator port. Before BP measurement, we have trained the mice by placing them in the dark cover in their sterile flexible film isolators without exporting them out at the same time for 14 days. To minimize contamination, the measurement was performed with UV-sterilized instruments under a sterile hood within 60 min after exporting the mice out of their sterile environment. All animal care and experiments were performed in accordance with the guidelines of Institutional Animal Care and Use Committee of SLAC Inc.</p>
        <p>Not applicable.</p>
        <p>Funding This work was supported by National Basic Research Program of China (973 Program,2014CB542302), CAMS Innovation Fund for Medical Science (CIFMS, 2016-I2M-1-006), National Natural Science Foundation of China (81470541, 81630014, 91531306, 81500383), National Basic Research Program of China (973 Program,2015CB554200), Beijing Municipal Science and Technology Commission (Z151100002115050, Z151100004015176), Beijing Municipal Commission of Education (KZ201610025028), the International S&amp;T Cooperation Program of China (2013DFB30310), and the AHA Scientist Development Grant (L.C., 12SDG11680011).</p>
        <p>The data set supporting the results of this article has been deposited in the EMBL European Nucleotide Archive (ENA) under BioProject accession code PRJEB13870 [http://www.ebi.ac.uk/ena/data/view/PRJEB13870].</p>
        <p>Additional file 1: Table S1. Characteristics of the study cohort. A total of 196 participants consisted of 41 healthy controls, 56 subjects of pHTN, and 99 patients with HTN were enrolled. (DOC 42 kb)</p>
        <p>Additional file 2: Table S2. Data production of 196 samples in control, pHTN and HTN. Table S3. Relative abundance profile at the phylum level. Table S4. Relative abundance profile at the genus level. Table S5. Detailed information of differential genera. Table S6. Information of 6 samples in the verification phase. Table S7. Relative abundance profile at the genus level of 6 samples in the verification phase. Table S9. Reference genomes for CAG's taxonomy assignment. Table S10. Detailed information of enriched CAGs in different groups. Table S11. Detailed information of 1099 CAGs. Table S12. Spearman's correlation between enriched CAGs. Table S13. Detailed information of differential KEGG modules. Table S14. Detailed information of differential KEGG orthologys. Table S15. Detailed information of differential CAZy family. Table S16. Detailed information of 26 metabolites differently enriched across groups. Table S18. Data production for donors and recipient mice in microbiota transplantation. Table S19. Relative abundance profile at the genus level of donors and recipient mice. Authors' contributions JC, XCY, BLZ, JL, and FQZ conceived the study, directed the project, designed the experiments, interpreted the results, and wrote the manuscript; JT, WLZ, TG, SLW, LY, and XYL obtained the samples and clinical details; YDW assisted with microbiome sample processing; JRC, WBL, and QHC performed the computational and metagenomic microbiota analysis; JL and JRC performed the metabonomics analysis; JL, JRC, YDW, and BG supervised the fecal microbiota transplantation and analyzed the data of animal experiments; WR, AK, and CL revised the manuscript. All authors read and approved the final manuscript.</p>
        <p>The authors declare that they have no competing interests.</p>
        <p>Not applicable.</p>
        <p>The study was approved by local ethics committees (Kailuan General Hospital, Beijing Chaoyang Hospital, and Beijing Fuwai Hospital) and informed consent was obtained from all subjects. All animal care and experiments were performed in accordance with the guidelines of Institutional Animal Care and Use Committee of SLAC Inc.</p>
    </text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f347566724"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:22+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Robots are being implemented in many frontline services, from waiter robots in restaurants to robotic concierges in hotels. A growing number of firms in hospitality and tourism industries introduce service robots to reduce their operational costs and to provide customers with enhanced services (e.g. greater convenience). In turn, customers may consider that such a disruptive innovation is altering the established conditions of the service-provider relationship. Based on attribution theory, this research explores how customers' attributions about the firm motivations to implement service robots (i.e. cost reduction and service enhancement) are affecting customers' intentions to use and recommend this innovation. Following previous research on robot's acceptance, our research framework analyzes how these attributions may be shaped by customers' perceptions of robot's humanlikeness and their affinity with the robot. Structural equation modelling is used to analyze data collected from 517 customers evaluating service robots in the hospitality industry; results show that attributions mediate the relationships between affinity toward the robot and customer behavioral intentions to use and recommend service robots. Specifically, customer's affinity toward the service robot positively affects service improvement attribution, which in turn has a positive influence on customer behavioral intentions. In contrast, affinity negatively affects cost reduction attribution, which in turn has a negative effect on behavioral intentions. Finally, human-likeness has a positive influence on affinity. This research provides practitioners with empirical evidence and guidance about the introduction of service robots and its relational implications in hospitality and tourism industries. Theoretical advances and future research avenues are also discussed.</p>
<p>Robots are replacing employees in many tasks (Huang and Rust 2018;Hofmann et al. 2020). Indeed, sales of service robots for professional and personal use are growing at annual rates greater than 30% (International Federation of Robotics 2018). Robotic applications are widely employed in manufacturing, military forces, medicine, home-care services and are increasingly common in hospitality and tourism (Murphy et al. 2017). Although some of these robots perform basic and routine tasks in hotels and restaurants (e.g. robotic floor cleaners [Murphy et al. 2017]), a growing number of them are performing more advanced frontline tasks that involve engaging customers at the social level (e.g. talking, serving food [Belanche et al. 2020a]). SoftBank Robotics, a leading service robot manufacturer, have sold more than 25,000 robots like Pepper or its little brother Nao all over the world. From India to the US, automated agents as Pepper or Relay are already performing concierge and waiter tasks in hotels and restaurants (Mende et al. 2019). As one of the latest advances in smart technologies with a disruptive nature, these robots are reshaping frontline services and the way they are managed (Gretzel et al. 2015;van Doorn et al. 2017).</p>
<p>Due to the rise of service robots, scholars have started to delve into this emerging field. However, most of the existing research about frontline robots is theoretical (e.g. Huang and Rust 2018;van Doorn et al. 2017;Wirtz et al. 2018;Belanche et al. 2020b), also in hospitality and tourism industries (e.g. Murphy et al. 2019;Tung and Au 2018), which provides little guidance for decision management. Indeed, a recent literature review by Ivanov et al. (2019) revealed that most of the publications on robot's implementation in hospitality and tourism had a conceptual or descriptive nature. Interestingly, they also found that most of the analyzed papers adopted a supply-side, with only one fifth of the studies focusing on the customer side (Ivanov et al. 2019). Therefore, there is little evidence about the impact of robotics introduction on the customer-provider relationship.</p>
<p>One of the principal reasons for these companies to introduce service robots is to reduce their costs and increase their efficiency (Ivanov and Webster 2018). This is the case of waiter robots implemented in Asian and Western countries, which have an average price around 6000 USD, below the average yearly salary of hospitality workers in China, and that deliver between 50% and 100% more meals per day than a human employee (Hospitality and Marketing News 2019). Another frequent reason for implementing service robots in to enhance customers' hospitality experience, that is providing extra benefits such as welcoming customers, improving service consistency or reducing waiting times (Lu et al. 2019;Qiu et al. 2020). Indeed, to achieve a successful introduction, not only companies but also customers need to be ready and willing to accept such innovation (Ivanov and Webster 2018). In this regard, previous research identified that the levels of robot human-likeness and user-robot affinity play a crucial role for their acceptance among customers of hospitality and tourism services (Murphy et al. 2019;Qiu et al. 2020). In addition, as far as service robots represent a disrupting innovation (Belanche et al. 2020a), customers may perceive that the firm is altering the established conditions of the service provision, thus leading to customers' psychological attributions (i.e. inferring the service provider reasons for introducing the innovation) and affecting the customer-provider relationship (Choi and Cai 2016;Nijssen et al. 2016).</p>
<p>To shed some light on this emerging but underdeveloped field of research, we propose a research framework that help better understand customers' decision to use and recommend service robots. We integrate literatures on customers' perceptions about robots and customers' reactions toward the introduction of service innovations. Based on attribution theory (Heider 1958;Kelley 1973), we propose that facing a disrupting technology such as a service robot increases customers' inferences about the reasons motivating its introduction by the firm. Following previous research on customers' attributions toward self-service technology introduction (Nijssen et al. 2016), we propose that customers attribute service enhancement or cost reduction as the principal firm motivations to introduce service robots. From a customerprovider relational perspective, service enhancement attributions increase customer's intention to use and recommend the service robots, whereas cost reduction attributions diminish these customer's behavioral intentions. Thus, our research does not focus on the actual motivations of the firm to introduce service robots, but on customers' inferences (i.e. dispositional attributions) about the firm motivations, since these customers' attributions have been proved to be affecting the customer-provider relationship in other settings (Nijssen et al. 2016). In addition, considering the existing knowledge on customers' perceptions about service robots, our research model argues that robot human-likeness increases customers' affinity with the automated agent (Mourey et al. 2017;Qiu et al. 2020), and that both factors increase customers' service enhancement attributions and reduce cost cutting attributions, as explained in our literature review section.</p>
<p>Based on responses collected from an international sample of 517 customers of hospitality and tourism services, our study contributes to expand the scarce knowledge about the impact of robot introduction on the customerprovider relationship. Due to the scarce empirical research on this topic, we aim to better understand customers' responses toward service robots implemented in these industries. We also contribute to the literature on customer's attributions in relation to firms' motivations for the introduction of service robots. This is a particularly suitable framework to be applied when dealing with customers' perceptions and thoughts about a newly launched service innovation, as it is the case of service robots. In this regard, our article combines two complementary fields or research: perceptions toward robots (i.e. human-likeness, affinity), and customer attributions about the firm (i.e. service enhancement and cost reduction motivations). In addition, considering the relevance of customers' recommendations for hospitality and tourism industries (Stienmetz et al. 2020;Casaló et al. 2010) and advancing from research focused exclusively on acceptance (Rosenthal-von der Püthen and Krämer, 2014;Lu et al. 2019), we analyze the relational impact of service robot introduction in terms of both customers' intentions to use and intentions to recommend the service robot to other potential customers. Finally, our research discusses the principal conclusions and findings derived from the results of our study. Implications for managers and customers are also provided with the aim of guiding future decisions about robot introduction in hospitality and tourism services.</p>
<p>Technology-based initiatives are routinely incorporated in most companies' marketing strategies, but sometimes customers perceive them as unacceptable or harmful (Fullerton et al. 2017). This kind of innovations may alter the implicit psychological contract established by customers and service providers (Baeshen 2018), that is, the "individual's relational schema regarding the rules and conditions of the resource exchange between the organization and the person" (Guo et al. 2015, p. 4). From the standpoint of customers, their experience with a service robot may be different from those traditionally experienced with frontline employees, altering their psychological contract and increasing their awareness and thinking about the innovation (Qiu et al. 2020).</p>
<p>In this vein, attribution theory (Heider 1958;Kelley 1973) contributes to explain how individuals infer causal explanations in a social context, that is, identifying why someone did that (Nijssen et al. 2016). Differing form internal attributions (self-motivations), dispositional attributions focus on determining others' reason motivating their actions. Dispositional attributions have been successfully employed to comprehend how individuals infer firms' motivations to introduce service innovations. According to the multiple inference model (MIM) of attribution (Reeder et al. 2004), observers draw various inferences and attempt to integrate them into a coherent cognitive response. It is important to note that customer's dispositional attributions may be different from the actual reasons that are motivating the service provider to introduce the innovation (e.g. they may be exaggerated or based on heuristic cues [Allen and Leary 2010]). For instance, the introduction of a new distribution system is often perceived as motivated by increased convenience but also as an opportunistic and unfair allocation of gains by the service provider (Selviaridis 2016). In relation to self-service technology, which could be considered a precursor of service robots, customers attribute that firms may introduce this innovation to enhance the service offering, but they may also consider that this change could be motivated by cost cutting reasons (Nijssen et al. 2016). Therefore, depending on whether customers think that the implicit contract is fulfilled or violated by the service provider they would behave accordingly (e.g. psychological contract breach leads to greater dissatisfaction and lower loyalty [Baeshen 2018]).</p>
<p>Dispositional attributions may vary between customers and highly depends on individual's perceptions about the particular features of the innovation (Heywood and Norman 1988). In other words, the features of the technology being employed by the marketer to serve customers becomes the dominant attribute of the offering being judged (Fullerton et al. 2017). In this line, the uncanny valley theory (Mori 1970) proposes that individuals assess a robotic entity by focusing on two key features: their perception of robot's human-likeness and their feelings of affinity with the robot. Human-likeness could be defined as the extent to which the robot's physical appearance is similar to a human being (Seyama and Nagayama 2007). This term has been widely employed in literature about robot design and human-robot interaction (Walters et al. 2008). Human-likeness is also known as anthropomorphism or embodiment (Tung and Au 2018), considering that robots -as well as products or any kind or interfaces-may have certain anthropomorphic appearance, which usually leads to favorable evaluations by customers (Mourey et al. 2017).</p>
<p>In turn, according to previous research on human-robot interaction, affinity refers to a kind of human description of the robot as a "friendly" or "good feeling" entity (Maehara and Fujinami 2018). Rincon et al. (2016) describe affinity as the level of robot agreeableness perceived by a human; that is, the individual assumption that the other entity is being likeable, pleasant, and harmonious in relations with others (Graziano and Tobin, 2009). The original term in Japanese "shinwakan" was initially translated as familiarity (Mori 1970), but latter research concluded that the terms affinity or likeability are more appropriate than familiarity to describe this concept (Rosenthal-von der Püthen and Krämer, 2014).</p>
<p>Linking previous literature on robot acceptance and attribution theory towards service innovations, we propose an integrative research framework as detailed henceforth.</p>
<p>The relationship between human-likeness and perceived affinity According to Mori (1970), as robots appear more humanlike, our sense of their affinity increases. For instance, industrial robots in factories without faces or legs lack of resemblance to human begins, such as people hardly feel any affinity with them. In contrast, if robots start to have human-looking external form and features, people may start to feel attached to them (Mori et al. 2012). This effect could be explained by Simulation Theory (Gordon 1986), which assumes that individuals are able to understand other's mind by "simulating" another's situation in order to comprehend their mental state or emotion (Gordon 1986;Riek et al. 2009). As far as it is easier for people to empathize with the emotions and mental states of agents that appears similar to them or belong to the same group (Turner 1978), the human-like appearance of a robot would facilitate this process (Riek et al. 2009). This is based on the notion that, as robots resemble human, the positive feeling toward them increases due to the perceived similarity and empathetic connection with the robot (Sone 2017). In this sense, Lee et al. (2017) found that children develop high social affinity towards robots imitating children expression and appearance, suggesting an affective link between them. Another study found that people empathized more strongly with more human-like robots and less with mechanical-looking robots (Riek et al. 2009).</p>
<p>Previous research confirmed that a greater human-like appearance increases users' expectations about the cognitive capabilities of robots as if they could think, feel and behave as "humans" to certain extent (Gray and Wegner 2012;Hegel et al. 2008). In this line, customers' start to perceive robots as social entities depending on their level of human-likeness (Kim et al. 2013). Indeed, automated social presence (i.e. customer's perception of the robot as a social entity performing the service) is becoming a topic of increasing interest in service research, which assumes that the level of anthropomorphization determines the receptiveness and attractiveness of the service robot (van Doorn et al. 2017), also in hospitality and tourism industries (Murphy et al. 2019). For instance, customers' acceptance of a hotel service robot is higher and leads to more positive emotions when it has a more anthropomorphized appearance (Tussyadiah and Park 2018). In sum, human-likeness leads to a stronger sense of social inclusion and likeability (Mourey et al. 2017;Qiu et al. 2020), thus, increasing customer's affinity with the service robot. Consequently, we propose our first hypothesis: H1: Perceived human-likeness of robots in hospitality services has a positive effect on their perceived affinity.</p>
<p>For service robots, human-likeness could be treated as an analogous factor to physical appearance (e.g. clothing) in frontline employees. Classical research on services marketing found that an appropriate physical appearance enhances customer perceptions of service quality (Gronroos 1984), firms' capabilities and control of the service encounter (Bitner 1990), process consistency (e.g. uniform clothing [Rafaeli 1993]) and overall satisfaction (Mayer et al. 2003). In addition, these physical features are interpreted by customers as a sign of the firm's dispositional attributions, that is to infer companies' motivations and procedures (Bitner 1990). Transferring these insights to a frontline robot context, human-likeness should lead to favorable attributions towards the company motivations to introduce such innovation. In this line, recent research on tourism and hospitality found that, compared to mechanic like alternatives, more anthropomorphic self-service technology reduces customers' blame attributions toward the firm's technology in case of service failure (Fan et al. 2019).</p>
<p>In addition, a higher level of robot human-likeness could be perceived as a greater investment by the company in "hightech" robotic agents with greater human qualities (Aggarwal and McGill 2007). Indeed, robots with increased human appearance are perceived as more sophisticated and impressive, incorporating the latest developments in the technological field (Roy and Sarkar 2016). Robots with human features tend to interact with customers following the same rules than human-to-human interactions, that is, performing tasks more closely to the traditional (and costly) service encounter (Tussyadiah and Park 2018). In contrast, low human-like robots may induce to cost reduction attribution because they resemble self-service technologies that highly depends on customer's effort and task making, altering the service provision (Meuter et al. 2005) and increasing the perceptions of the company shifting costs to the customer (Cunningham et al. 2009;Broadbent et al. 2009). Consequently: H2: Perceived human-likeness of robots in hospitality services has a positive effect on service enhancement attribution. H3: Perceived human-likeness of robots in hospitality services has a negative effect on cost reduction attribution.</p>
<p>Literature describing service encounters have found that employees' attractiveness and likeability increases customers' favorable perceptions in terms of aspects such as expertise and trustworthiness (Ahearne et al. 1999). Customers perceiving employees as attractive and likeable tend to attribute a higher service value and are more willing to tip them, spend more money and purchasing more expensive products (Jacob and Guéguen 2014;Otterbring et al. 2018). Customers affinity to a salesperson is also related to the employee cognitive and affective listening behaviors, as a kind of mutual recognition between both agents of the service encounter (Carlson 2016). Indeed, literature on sales management has widely covered how empathy and communication help building affinity between the salesperson and the customer (Smith 1998). In this sense, previous research found that more empathetic employees lead to customers' higher perceptions of service quality (Bitner et al. 1990). Thus, while a low level of affinity represents an impersonal technology driven interaction (Carlson 2016), a higher level of perceived affinity is linked to customers' expectations about the "knowledge, speed of response, breadth and depth of communication, and customization of the service offering" (Jones et al. 2005, p. 106). In the hospitality industry, advanced robots are able to recognize and process human feelings; designers also program them with facial expressions to actively respond to customers' affections, improving the communication and the perception of a human-orientation of the technology (Tung and Au 2018). Thus, especially in the case of a technology disruption, increased levels of affinity are positively evaluated by customers as a sign of firms' investment to keep the service standards instead of just reducing costs through technology (Carlson 2016). Therefore, we propose that: H4: Perceived affinity of robots in hospitality services has a positive effect on service enhancement attribution. H5: Perceived affinity of robots in hospitality services has a negative effect on cost reduction attribution.</p>
<p>Prior literature on service innovation identified that companies introduce technology mainly as an instrument to improve the service or to reduce the cost of the service provision (Bitner et al. 2002;Nijssen et al. 2016). These motivations have been also found to be the reasons for service robot introduction by firms in the hospitality industry (Qiu et al. 2020), which are focusing on the costs and benefits launching such innovation (Ivanov and Webster 2018;Ivanov et al. 2019).</p>
<p>Like self-service technology and chatbots, the introduction of service robots may result in a service enhancement in terms of increased convenience, reduction of the transaction times and quicker assistance to customer decision-making (Meuter et al. 2000;Ukpabi et al. 2019). When employed in hospitality, they also increase the service performance by improving the service consistency, providing more reliable information and minimizing errors in the service provision (Lu et al. 2019). Automation can also contribute to increase customer relationship management (CRM) by assisting employees and managers with information and resources to better serve the customer and to plan and organize accordingly (Kumar et al. 2019). For instance, some robot waiters greet customers when entering the restaurant and are able to call the customer by name or lead him or her to they preferred table based on the CRM information (Kabadayi et al. 2019).</p>
<p>Complementarily, firms introduce automated agents to reduce their costs (Kumar et al. 2019). Cost reduction is frequently associated to increased efficiency and job elimination (Meuter et al. 2000;Nijssen et al. 2016). Most of the service robots are designed to replace a human equivalent job (Belanche et al. 2020a). In particular, the hospitality sector introduces these kind of smart technological innovations to lower their cost and increase its efficiency (Gretzel et al. 2015;Ivanov and Webster 2018). For instance, robots and other smart devices are introduced in hotels to substitute guest-employees' interactions frequently described as costly, fallible and time-consuming (Kabadayi et al. 2019).</p>
<p>According to Nijssen et al. (2016), customers' dispositional attributions about the service provider motivations to introduce a technology focuses on service enhancement and cost reduction reasons, having positive and negative consequences for the customer-provider relationship respectively. Previous research on hospitality an tourism also indicate that customers own psychological processes (especially when making inferences about the positive and negative aspects of a service) play a central role in the customer-provider relationship (Choi and Cai 2016). Thus, as far as the introduction of a robot represent a disruptive innovation that could be perceived as fulfilling or violating the customer-provider psychological contract, we propose that these attributions lead to customer's behavioral intentions towards the company (Baeshen 2018). In particular, we hypothesize that customers' attributions of service enhancement motivation by the firm are interpreted as a relational investment (Nijssen et al. 2016) and increases customers' intentions to use and recommend the use of service robots. In turn, when customers attribute that a company implements robots in hospitality as a way to reduce costs, they would attribute a relational disinvestment (e.g. dismissing employees to maximize profit), which would reduce customers' intention to use and recommend such innovation. As a result, we propose the following hypotheses: H6: Service enhancement attribution has a positive effect on customers' intention to use robots in hospitality services H7: Service enhancement attribution has a positive effect on customers' intention to recommend robots in hospitality services H8: Cost reduction attribution has a negative effect on customers' intention to use robots in hospitality services H9: Cost reduction attribution has a negative effect on customers' intention to recommend robots in hospitality services</p>
<p>The use of a recently introduced technology by a critical mass of users is crucial to ensure its success on the medium and long terms (Belanche et al. 2012). In turn, customer recommendations are critical in hospitality and tourism (Alves et al. 2019), as far as customers' interpretation and sharing of their experiences in social media often become a stimuli influencing other customers and their journey mapping (Stienmetz et al. 2020). Customers with a higher intention to use a technology are more likely to recommend the technology to others (Oliveira et al. 2016). This loyalty based relationship occurs because behavioral intentions toward a recently introduced innovation in hospitality are based on users' positive perceptions about it, such that they tend to share this information with other people in order to spread its advantages and be seen in a positive light (Yang 2016). We thus propose our last hypothesis:</p>
<p>H10: Customers' intention to use robots in hospitality services has a positive effect on the intention to recommend them.</p>
<p>In sum, the proposed model is summarized in Fig. 1.</p>
<p>A survey was used to collect the data for this study; specifically, participants comprised 517 international customers recruited via a market research company, which enabled us to obtain a diverse sample in terms of demographic characteristics such as gender (54.15% of participants are male), age (&lt;25 years 6.96%, 25-34 years 38.68%, 35-44 years 27.27%, 45-54 years 15.09%, 55 or more 11.99%), education level (university studies 76.98%, secondary school 21.28%, primary school 1,74%), employment situation (full-time job 58.03%, part-time job 14.89%, student 5.42%, unemployed 7.35%, retired or other 14.31%) and country of origin (68.47% of participants come from US, 22.63% from the UK and 8.90% from other countries). To develop the Web survey and make the most of this method, the study followed recommendations by Illum et al. (2010), such as keeping it short and guaranteeing the anonymity of participants. Following recent methodology employed in service robots research (Belanche et al. 2020a;Mende et al. 2019), all participants were asked to read a general description of the context accompanied by a picture of the robotic agent. We focus on waiter robots operating in restaurants as a prototypical frontline service innovation in hospitality that is taking off in China and other countries around the world (Nguyen 2016;Hospitality and Marketing News 2019). The text reads "Imagine that you decide to go to a real well-known mid-class restaurant in your city that you have visited at least once. When you are at the restaurant, you notice that you are going to be served by a robot waiter. It has been recently introduced by the restaurant to perform waiter tasks such as greeting customers, taking orders and delivering orders to the tables".</p>
<p>To increase the variability in the human-likeness perceptions (M = 3.148, SD = 1.798, in a 7-point scale), participants viewed, by random assignation, one of the twelve humanoid robots selected in a pretest with other group of 116 participants (from Savioke Relay as less human-like [M = 1.703; SD = 1.000] to GeminoidDK as more human-like [M = 5.430; SD = 1.218]). The use of pictures of waiter robots accompanied by a general description of the context in a hypothetic restaurant scenario is a standard practice in current research in the field (Belanche et al. 2020a;Mende et al. 2019). A similar procedure is employed in experimental and survey based studies for introducing hospitality service encounters where robots perform check-in tasks in hotels (Park 2020;Yu and Ngan 2019), especially when customers have to evaluate robots' human-likeness (Mende et al. 2019;Fan et al. 2019). In order to avoid bias due to brand reputation (MacKenzie et al. 1986), the restaurant and the robot were not linked to any specific firm. Next, respondents answered the questionnaire, including variables measuring their perceptions about and affinity with the robot, their dispositional attributions and behavioral intentions, as well as some basic demographic information. The scenario realism was checked with two questions borrowed from Belanche et al. (2020a) and Fan et al. (2019), "How realistic is the scenario?" (from 1-not at all realistic, to 7very realistic) and "To what extent do you consider that the scenario is believable? (from 1-not at all believable, to 7very believable). The results indicated the suitability of the scenario since the scale (Pearson ρ = 0.850) provided a mean of 5.018 (SD= 1.386), a value that indicates that participants perceive the restaurant scenario as realistic and believable (Belanche 4) were based on self-reported measures and used seven-point Likert-type response formats, from 1 ("completely disagree") to 7 ("completely agree").</p>
<p>The initial set of items proposed to measure the latent constructs came from an in-depth review of relevant literature pertaining to robot acceptance and customers' reactions towards technological innovations such as e-commerce and smart services. The measures were adapted from previous scales assessing perceived human-likeness and affinity (e.g. Rosenthal-von der Pütten and Krämer 2014; Gong and Nass, 2007), service enhancement and cost reduction perceptions (e.g. Nijssen et al. 2016), intention to use (e.g. Belanche et al. 2012;Yang and Jolly 2009) and intention to recommend (e.g. Ryu et al. 2012). The extensive review helped to ensure the content validity of the scales. Following Zaichkowsky (1985), the authors also asked a panel of experts about the degree to which they judged that the items were clearly representative of the targeted construct, in order to test for face validity. Items that prompted a high level of consensus among the experts were retained (Lichtenstein et al. 1990). Final measures can be seen in appendix Table 4.</p>
<p>The proposed hypotheses are tested using structural equation modeling, which basically "consists of a set of linear equations that simultaneously test two or more relationships among directly observable and/or unmeasured latent variables" (Shook et al. 2004, p. 397). This technique is selected as it enables to: (1) include the measurement error on the structural coefficients, which should not be ignored as any measure of a latent variable reflects not only a theoretical concept but also measurement error (Bagozzi et al. 1991), and (2) evaluate and interpret complex interrelated dependence relationships (e.g., Davcik 2014;Hair et al. 2010;MacKenzie 2001). In this respect, structural equation modeling is able to analyze simultaneously a series of relationships in which a dependent variable becomes an independent variable in subsequent relationships (for example, service enhancement and cost reduction perceptions in our case), while examining multiple dependent variables at the same time too (Jöreskog et al. 1999). More precisely, covariance-based structural equation modeling is employed because it is a confirmatory method that tends to replicate the existing covariation among measures (e.g., Fornell and Bookstein 1982;Hair et al. 2010). Therefore, a structural equation model was developed (results are summarized in Fig. 2). The fit showed acceptable values (χ 2 = 442.294, 125 df, p &lt; 0.000; Satorra-Bentler scaled χ 2 = 351.646, 125 df, p &lt; 0.000; NFI = 0.963; NNFI = 0.970; CFI = 0.976; IFI = 0.976; RMSEA = 0.059; 90% confidence interval [0.052, 0.067]).</p>
<p>First, regarding the relationship between the two variables considered in the uncanny valley theory, we observe that human-likeness of service robots has a positive influence on perceived affinity (γ = 0.300, p &lt; 0.01), which supports H1. Second, regarding the influence of these two variables on customers' attributions of service enhancement (γ = 0,038, p &gt; 0.1) and cost reduction (γ = -0,038, p &gt; 0.1) are not affected by human-likeness. In turn, perceived affinity positively affects service enhancement (β = 0.473, p &lt; 0.01) and reduce cost reduction perceptions (β = -0.113, p &lt; 0.05). Therefore, while H2 and H3 are not supported, H4 and H5 are confirmed. Third, regarding the influence customers' attributions on intentions, we first observe that service enhancement has a positive effect on both customers' intention to use robots in hospitality services (β = 0,609, p &lt; 0.01) and to recommend them (β = 0,108, p &lt; 0.01), confirming H6 and H7. However, cost reduction attributions has a negative effect on customers' intention to use waiter robots in hospitality services (β = -0,116, p &lt; 0.01), and its influence on intention to recommend them is non-significant (β = 0,024, p &gt; 0.1), so that while H8 is confirmed, H9 is not supported. Finally, consumers' intentions are also related, as intention to use robots in hospitality services positively affects the intention to recommend them (β = 0.786, p &lt; 0.01), supporting H10.</p>
<p>In addition, the proposed framework implies some indirect effects of human-likeness and perceived affinity on customers' intentions (i.e., to use robots in hospitality services and to recommend them) via customers' attributions (i.e., service enhancements and cost reduction). Similarly, human-likeness indirectly affects customers' attributions (i.e., service enhancement and cost reduction perceptions) via perceived affinity. In this way, human-likeness exerts significant indirect effects on (1) service enhancement (0.142, p &lt; 0.01), (2) cost reduction (-0.034, p &lt; 0.05), (3) intention to use (0.118, p &lt; 0.01) and ( 4) intention to recommend (0.111, p &lt; 0.01). Similarly, perceived affinity exerts significant indirect effects on (1) intention to use (0.301, p &lt; 0.01) and ( 2) intention to recommend (0.285, p &lt; 0.01). Finally, both customer's attributions, service enhancement (0.479, p &lt; 0.01) and cost reduction (-0.091, p &lt; 0.01), exert a significant indirect effect on intention to recommend through intention to use. Table 2 summarizes direct, indirect and total effects implied in the model.</p>
<p>All these relationships can largely explain our key dependent variables, customers' intention to use robots in hospitality services (R 2 = 0.393) and to recommend them (R 2 = 0.728).</p>
<p>For the shake of completeness, we conducted formal tests of mediation (Bagozzi and Dholakia 2006) to additionally check whether the direct effects of both perceived human-likeness and affinity of frontline robots Standardized solution. Notes: *** coefficients are significant at the 01 level; ** coefficients are significant at the .05 level; n.s. coefficients are non-significant 3 shows a summary of results.</p>
<p>The first row of Table 3 shows the goodness-of-fit for the proposed model (M1), which provides the baseline for χ 2 difference tests of direct effects from perceived humanlikeness or affinity to intentions (Bagozzi and Dholakia 2006). The second row in Table 3 (M2) adds to the proposed model a direct effect of perceived human-likeness on intention to use robots in hospitality services. Then, because M2 is nested in M1, we performed a χ 2 difference test with one degree of freedom to determine whether this additional direct effect exists. Neither the additional effect in M2 is significant (0.070; p &gt; 0.1) nor the χ 2 difference (χ 2</p>
<p>(1) = 3.583; p &gt; 0.1). We therefore conclude that the influence of perceived humanlikeness on intention to use is fully mediated by the relationships proposed in the research model (Kulviwat et al. 2009).</p>
<p>In M3, the effect of perceived human-likeness on customer intention to recommend is added. In this case, the additional effect, even small, is significant (0.077; p &lt; 0.01) as well as the χ 2 difference (χ 2</p>
<p>(1) = 9.451; p &lt; 0.01). Therefore, the relationships proposed in the research model partially mediate the effect of perceived human-likeness on customer intention to recommend.</p>
<p>In turn, M4 includes the effect of perceived affinity on customer intention to use. In this case, both the additional effect (0.301; p &lt; 0.01) and the χ 2 difference (χ 2</p>
<p>(1) = 49.783; p &lt; 0.01) are significant. Similarly, M5 adds the effect of perceived affinity on customer intention to recommend, which is significant (0.131; p &lt; 0.01) as well as the χ 2 difference (χ 2</p>
<p>(1) = 17.289; p &lt; 0.01). Therefore, the relationships proposed in the research model partially mediate the effects of perceived affinity of the frontline robot on both customers' intention to use robots in hospitality services and to recommend them.</p>
<p>Following work intense industries such manufacturing, military or home-care services, robotic agents have also arrived to hospitality and tourism services (Fan et al. 2019;Murphy et al. 2017). These frontline robots are performing concierge and waiter tasks requiring certain level of interaction with customers and that had been traditionally carried out by frontline employees (Huang and Rust 2018;Belanche et al. 2020a). Nevertheless, most of the scientific knowledge about this new research topic is purely theoretical or descriptive, with a scarce number or studies providing empirical evidence from the customer approach (Ivanov et al. 2019). In this emerging research field, our study contributes to shed some light on the impact of robot introduction on the customer-provider relationship. Based on previous insights from literatures on robot acceptance and customers' attributions about service innovations (Nijssen et al. 2016), we have analyzed to what extent customers' perceptions and thoughts about this innovation are affecting their decisions to use and recommend service robots being employed in hospitality and tourism industries.</p>
<p>The results of our study revealed that human-likeness, as a frequently researched feature of robot design, is less relevant than expected, and that customers' affinity with the robot is a greater predictor of robot introduction success in hospitality services. Particularly, human-likeness have a positive influence on affinity, which in turn plays a crucial role as a determinant of the rest of dependent variables in our model. This finding suggests that humanlikeness should be considered an instrumental variable to increase customers' perceptions of affinity (as a kind of familiarity and closer connection) with the service robot. This result is in line with previous research, which suggest that individuals tend to accept to a greater extent robots and other technological objects incorporating anthropomorphic features and that a more mechanical look leads to feelings of social exclusion (Mourey et al. 2017;Rosenthal-von der Pütten and Krämer 2014;Tussyadiah and Park 2018).</p>
<p>On the other hand, customers' affinity with the service robot plays a crucial role in determining their reactions toward the firm introducing such innovation. In particular, users perceiving greater levels of affinity with the robotic agents tend to think that the service provider introduced this technology to enhance the service provision, that is, taking a customer orientation or aiming to benefit the customer. In addition, customers increased affinity with the service robot also reduces their cost attributions, dissipating negative thoughts of robot introduction as a disinvestment (e.g. human unemployment [Huang and Rust 2018]) or as a strategy to shift the cost to the customer (like it sometimes happens with self-service technology [Cunningham et al. 2009;Broadbent et al. 2009]). In this regard, our research extends previous findings on customers' attributions about service technologies (Nijssen et al. 2016;Selviaridis 2016) and suggests that, contrary to previous technology lacking social features, service robots have the possibility of engaging customers at the social level (van Doorn et al. 2017), being customer's affinity with the robot the key factor to shape their psychological reactions towards this innovation.</p>
<p>Complementary, we found that service enhancement attributions are found to be an essential factor determining customers' intention to use and recommend robots in hospitality and tourism services. Following previous research analyzing the benefits of service technologies from the customer side (Meuter et al. 2000;Ukpabi et al. 2019), our study confirmed that customers considering that the firm introduces the innovation to improve the service provision to its customers (e.g. reducing transaction times) generate positive behavioral intentions toward the innovation. Indeed, service enhancement attributions by customers not only influence their intention to use service robots but also to recommend using it to other customers. This finding is particularly relevant in the context of our study, since customers recommendations (e.g. sharing the experience on social media platforms [Stienmetz et al. 2020]) are particularly helpful to gain customers in the hospitality and tourism industries (Casaló et al. 2010). Focusing on cost reduction attributions, our findings reveal that these thoughts are not particularly detrimental but that they reduce customers' intention to use service robots to some extent. This finding agrees with those of previous research on customers' attributions' about selfservice technology, indicating that the positive influence of service enhancement on loyalty surpass any detrimental perception of cost reduction (Nijssen et al. 2016).</p>
<p>A post-hoc analysis assessed the direct influence of humanlikeness and perceived affinity on customers' intentions to use robots in hospitality services and to recommend them. Results of this post-hoc analysis revealed that these direct influences are not very relevant. In particular, the influence of humanlikeness on intention to use is fully mediated by the variables in the model, whereas the remaining influence of human-likeness and of affinity on both use and recommendation intentions are partially mediated by the variables of the model. Thus, the post-hoc analysis contributed to understand the effects of customers' perceptions (i.e. robot's human-likeness, affinity) on customers' loyalty intentions (i.e. use and recommendation), by corroborating that customers' attributions fully or partially mediate these influences.</p>
<p>Due to its efficiency and expansion in many service sectors, managers in hospitality and tourism industries are starting to consider the possibility of introducing service robots in their establishments. As far as these robotic entities perform more sophisticated frontline tasks at a lower cost than their human counterparts, service robots would become increasingly popular (Huang and Rust 2018). Nevertheless, customers support for this innovation is crucial to guarantee their success in the medium and long terms. The findings of our research suggest that the introduction of service robots should not only benefit the firm but it should have a clear benefit for customers in terms of service enhancement. According to the RAISA model (Ivanov and Webster 2019) the most direct way to incentive customer's adoption of robots in the hospitality and tourism industry is showing them that this innovation is beneficial for both companies (that can save costs) and customers (avoiding poor service quality). Thus, the introduction of service robots should not have negative impact upon service quality but should be implemented to enhance the overall service experience by adding customers' benefits to those traditionally established by frontline employees. In this regard, our research shows that customers intention to use and recommend the service is highly based on their attributions of the firm's motivations of service enhancement. That is, companies in the hospitality and tourism industries should make an effort to show that the introduction of service robots is not detrimental but positive for the customer experience.</p>
<p>In this line, our research found that focusing on customers' affinity with the robot is a crucial factor to increase service enhancement attributions. Previous literature on robot acceptance considered that humanlikeness is a cornerstone in the design of service robots (Fan et al. 2019. Rosenthal-von der Pütten andKrämer 2014). Nevertheless, our findings suggest that humanlikeness is just an instrumental variable, but that managers should focus on reaching high levels of customers' affinity with the robot. Like it happens with pets or toys, service robots should be able to engage customers at a social level (van Doorn et al. 2017). Customers curiosity and fun seeking may help them to start interacting and creating affinity with robot agents. Promoting robots as part of an attractive and enjoyable experience could be really useful to make customers interact with service robots (e.g. talk to them, use them to take orders). This finding also suggest that robot introduction could be particularly suitable in leisure and entertaining business where customers' amusement is paramount or in restaurants and hotels linked to such activities. Indeed, introducing the robots in such contexts and with a service enhancement orientation would be very helpful to increase its use but also to boost customers' recommendations in social media (e.g. taking and sharing photos).</p>
<p>In spite of these interesting contributions, this work has some limitations that suggest avenues for further research. First of all, in this study an international sample evaluated twelve humanoid robots in order to explain behavioral intentions as the main dependent variables. Even though previous research (Venkatesh and Davis, 2000) has confirmed that intention to use and actual use are habitually highly correlated in the case of volitional behaviors -as it is the case in the current study-and the fact that intentions help understand initial stages of the adoption process (e.g. Bhattacherjee, 2001), future research should develop a longitudinal field study that collects data about customers reactions towards frontline robots in the hospitality and tourism industries. In this regard, although the use of hypothetical scenarios is a common practice in literature on service robots (Park, 2020;Fan et al. 2019), it could be considered a limitation of the study. Thus, to increase the generalization of the findings, the research should be replicated as a field study in a restaurant that has already introduced service robots. Second, since individual factors are crucial to understand the application of theoretical models to specific situations (Sun and Zhang 2006), future studies could analyze the moderating role of individual characteristics, such as demographics (e.g., age, sex, etc.) or personality traits (e.g., technology readiness, need for social interaction, etc.). This way, it would be possible to evaluate how the proposed relationships might vary across customers. Third, the explained variance of affinity and cost reduction is low, suggesting that these variables could be affected by additional factors. In this regard, previous studies on service robots found that robot performance (Nijssen et al. 2016;Belanche et al. 2020a) and social influences (e.g. other customers' opinion, Belanche et al. 2019) may be also affecting customers' reactions towards robots. Finally, most participants in this research come from the UK and the US; therefore, future studies could replicate this study by incorporating other cultures (e.g. Asian, Latin-American, Jewish, etc.) to obtain a global understanding of how customers' attributions together with perceptions about service robots influence customer behavioral intentions in the hospitality industry.</p>
<p>Notes: Bold numbers on the diagonal show the square root of the average variance extracted; numbers below the diagonal represent construct correlations. *** Correlations are significant at the .01 level; ** correlations are significant at the .05 level; n.s. correlations are non-significant</p>
<p>Frontline robots in tourism and hospitality: service enhancement or cost reduction?</p>
<p>Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f480604593"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:58+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>We present the precision measurement from May 2011 to May 2017 (79 Bartels rotations) of the proton fluxes at rigidities from 1 to 60 GV and the helium fluxes from 1.9 to 60 GV based on a total of 1 × 10 9 events collected with the Alpha Magnetic Spectrometer aboard the International Space Station. This measurement is in solar cycle 24, which has the solar maximum in April 2014. We observed that, below 40 GV, the proton flux and the helium flux show nearly identical fine structures in both time and relative amplitude. The amplitudes of the flux structures decrease with increasing rigidity and vanish above 40 GV. The amplitudes of the structures are reduced during the time period, which started one year after solar maximum, when the proton and helium fluxes steadily increase. Above ∼3 GV the p=He flux ratio is time independent. We observed that below ∼3 GV the ratio has a long-term decrease coinciding with the period during which the fluxes start to rise. DOI: 10.1103/PhysRevLett.121.051101 Cosmic rays entering the heliosphere are subject to diffusion, convection, adiabatic energy losses, and magnetic drift [1]. The temporal evolution of these processes leads to cosmic ray intensity variation at Earth's orbit around the Sun. These variations correlate with solar activity, which has several cycles [2]. The most significant is the 11-year solar cycle during which the number of sunspots changes from minimum to maximum and then back to a minimum. Another is the 22-year cycle of the Sun's magnetic field polarity, which reverses every 11 years during the maxima of the solar cycle [3]. Cosmic ray spectra may also have temporary reductions due to the Published by the American Physical Society under the terms of the Creative Commons Attribution 4.0 International license. Further distribution of this work must maintain attribution to the author(s) and the published article's title, journal citation, and DOI.</p>
<p>interactions of cosmic rays with strong disturbances in the magnetic field, especially during solar maxima, that can last from days to months [4][5][6][7]. Time correlations at low rigidity among different particle spectra (p, He) due to solar modulation are expected by models of cosmic ray transport based on the Parker equation [1]. This is because the timedependent cosmic ray transport in the heliosphere is rigidity dependent and related to changes in solar activity. Numerous models of the propagation of charged particles in the heliosphere exist that predict different flux variations with time [8][9][10][11][12][13]. The large acceptance and high precision of the Alpha Magnetic Spectrometer (AMS) allow us to perform accurate measurements of the fluxes as functions of time and energy. This provides unique information to probe the dynamics of solar modulation, to allow the improvement of constraints for dark matter search [14][15][16][17], to investigate the processes of galactic cosmic ray propagation [18,19], and to reduce the uncertainties in radiation dose predictions for deep space human exploration [20,21].</p>
<p>The precision, high-energy measurements of the proton and helium fluxes by the AMS have been reported [22,23]. In this Letter, the time evolution of the proton flux from 1 to 60 GV based on 846 × 10 6 events and the helium flux from 1.9 to 60 GV based on 112 × 10 6 events are presented. The proton flux and the helium flux are measured for the 79 Bartels rotations from May 2011 to May 2017. For the first time, proton and helium fluxes are simultaneously measured with the same precision instrument for an extended period of time.</p>
<p>Event selection.-The collection time used in this analysis includes only those seconds during which the detector was in normal operating conditions, the AMS was pointing within 40°of the local zenith, and the International Space Station (ISS) was outside of the South Atlantic Anomaly. In addition, those seconds when the AMS detects solar energetic particles accelerated by the Sun are excluded. Because of the geomagnetic field, the collection time increases with rigidity; it is 1.0-1.4 × 10 5 s at 2 GV, 4.2-4.7 × 10 5 s at 5 GV, 8.8-9.4 × 10 5 s at 10 GV, 1.4-1.6 × 10 6 s at 20 GV, and, above 30 GV, reaches 1.7-1.9 × 10 6 s per Bartels rotation. Proton and helium events were selected as described in Refs. [22,23]. The measured rigidity is required to be greater than a factor of 1.2 times the maximum geomagnetic cutoff within the AMS field of view. The cutoff was calculated by backtracing particles from the top of the AMS out to 50 Earth's radii [30] using the most recent IGRF model [31]. After selection the event samples contain 846 × 10 6 Z ¼ þ1 and 112 × 10 6 Z ¼ þ2 nuclei each with a purity &gt; 99.8%. The Z ¼ þ1 sample includes protons and deuterons with rigidity larger than 1.00 GV and Z ¼ þ2 sample includes 3 He and 4 He isotopes with rigidity larger than 1.92 GV.</p>
<p>Data analysis.-The isotropic flux Φ i during a Bartels rotation in the ith rigidity bin (R i ; R i þ ΔR i ) is given by</p>
<p>where, for that Bartels rotation, N i is the number of events corrected for bin-to-bin migration, A i is the effective acceptance, ϵ i is the trigger efficiency, and T i is the collection time. In this Letter, the proton flux was measured in 45 bins from 1 to 60 GV and the helium flux in 40 bins from 1.9 to 60 GV. Above 1.9 GV, proton and helium have 40 common rigidity bins with identical bin widths. Bin-tobin migration of events was corrected using the unfolding procedures described in Refs. [22,23] independently for each Bartels rotation for the proton samples and for the helium samples. Extensive studies were made of the systematic errors for each Bartels rotation as described in Refs. [22,23,28]. These errors include the uncertainties in the acceptance, due to event reconstruction, selection, and nuclear cross sections, the background contamination, the geomagnetic cutoff factor, the event selection, the unfolding, the rigidity resolution function, and the absolute rigidity scale. These systematic errors are time independent. As an example, to estimate the systematic errors due to uncertainty on the cutoff determination, the nominal geomagnetic cutoff factor of 1.2 was varied from 1.0 to 1.4 and the difference in the resulting fluxes was included in the total systematic errors. The corresponding systematic uncertainties were found to be 2% at 1 GV for protons and negligible above 2 GV for both protons and helium.</p>
<p>As described in Ref. [22], we have also verified that the IGRF model with external nonsymmetric magnetic fields does not introduce observable changes in the flux values.</p>
<p>In addition, a time dependent systematic error due to the variations of trigger and reconstruction efficiency for different Bartels rotations was estimated to be 1.5% for protons at 1 GV and &lt; 1% at 2 GV, &lt; 0.6% at 10 GV, and &lt; 1.2% at 60 GV for both protons and helium. The total systematic error is obtained by adding in quadrature the PHYSICAL REVIEW LETTERS 121, 051101 (2018)</p>
<p>individual contributions of the time independent systematic and the time dependent systematic errors. At 1 GV it is 4.8% for protons, and it is &lt; 2.5% above 2 GV for both protons and helium. Most importantly, several independent analyses were performed on the same data sample. The results of those analyses are consistent with those presented in this Letter.</p>
<p>Results.-The measured proton fluxes, helium fluxes, and the p=He flux ratios for Bartels rotations 2426 to 2506 including statistical errors, time dependent systematic errors, and total systematic errors are tabulated in the Supplemental Material [32], as functions of the rigidity at the top of the AMS detector. Because of the very high statistics, the small time dependent systematic error from trigger and reconstruction efficiency variations for protons and differently for helium are noticeable. As in Ref. [28], contributions to the total systematic error are from the acceptance, the background contamination, the geomagnetic cutoff factor, the event selection, the unfolding, the rigidity resolution function, the absolute rigidity scale, and the time dependent systematic errors. The statistical errors for the ratio are the sum in quadrature of the relative statistical errors of the fluxes multiplied by the ratio. The time dependent systematic errors for the ratio are the sum in quadrature of the relative time dependent systematic errors of the fluxes multiplied by the ratio. The systematic errors from the acceptance for the ratio are added in quadrature. The correlations in the systematic errors from the unfolding and the absolute rigidity scale between the fluxes have been accounted for in calculating the corresponding systematic errors of the ratio. The contributions of the individual sources to the systematic error are added in quadrature to arrive at the total systematic uncertainty on the ratio.</p>
<p>Figure 1 shows the detailed behavior of (a) the proton flux and (b) the helium flux as functions of time and of rigidity from 1 to 10 GV and from 1.9 to 10 GV, respectively. Figure SM 1 in the Supplemental Material [32] shows the data over the entire rigidity range up to 60 GV. As seen, both the proton and helium spectra exhibit large variations with time at low rigidities which decrease with increasing rigidity. During the period of observation, both fluxes have a minimum in February 2014 and a maximum in February 2017.</p>
<p>The time dependence of the proton and helium fluxes are shown in Fig. 2 for 8 characteristic rigidity bins. As seen, both the proton and helium fluxes have fine time structures each with maxima and minima with boundaries marked by the vertical dashed lines from I to X. The structures in the proton flux and the helium flux are nearly identical in both time and relative amplitude.</p>
<p>In general, the amplitudes of the structures (indicated by the shading) decrease progressively with rigidity. The precision of AMS enables us to observe these structures up to 40 GV. The data presented in this Letter provide information for detailed studies on time-dependent phenomena like those described in Refs. [34,35].</p>
<p>It is important to note that five of the structures, boundaries I (September 27, 2011), II (March 7, 2012), III (July 20, 2012), IV (May 13, 2013), and VII (March 19,2015), marked by the red vertical dashed lines in the figure, have also been observed by AMS in the electron flux and the positron flux [33]. As seen, after boundary VII, which is one year after solar maximum (April 2014 for solar cycle 24), the amplitudes of the structures are considerably reduced and the proton and helium fluxes steadily increase at rigidities less than 40 GV. In addition, the change in long term behavior visible at boundary VII was also observed by AMS in the electron flux and the positron flux.</p>
<p>Figure 3(a) shows the comparison of the proton flux in the kinetic energy per nucleon range 1.19 to 1.40 GeV measured by AMS versus time together with the EPHIN/ SOHO measurement [36]. Figure 3(b) shows the AMS helium flux in the kinetic energy per nucleon range 1.11 to 1.28 GeV=n. Figure 3(c) shows the relative variation of the AMS proton flux integrated over R ≥ 6.47 GV as a function of time together with the relative variation of the rate reported by the Oulu, Finland neutron monitor [37]. Figure 3(d) shows the monthly averaged sunspot number during solar cycle 24 with the period of solar magnetic field polarity (A) reversal [38,39]. As seen, the data greatly improve the accuracy and the sensitivity of the time dependent proton and helium measurements this provides information for detailed studies of the correlation between sunspot number and the fluxes of protons and helium.</p>
<p>For illustration, Fig. SM 2 in the Supplemental Material [32] shows the relative variation of the AMS proton flux integrated with different minimum rigidities as a function of time together with the relative variation of the rate reported by the Oulu, Finland neutron monitor. As seen, the relative variation of this neutron monitor rate matches the AMS proton flux only when the flux is integrated over R ≥ 6.47 GV.</p>
<p>Figure 4 shows the AMS p=He flux ratio, see Supplemental Material [32], as a function of time for 9 rigidity bins. As seen, depending on the rigidity range, the p=He flux ratio shows two different behaviors in time. Above ∼3 GV the ratio is time independent. Below ∼3 GV the ratio has a long-term time dependence. To assess the transition between these two behaviors, we performed a fit of the p=He flux ratio r i for each rigidity bin i as a function of time t, with</p>
<p>where a i is the average p=He flux ratio from May 2011 to t i , t i is the time when the p=He flux ratio deviates from the average a i , and b i is the slope of the time variation. Above 19-1.40] GeV together with the measurement by EPHIN aboard SOHO for [1.12-1.29] GeV [36], (b) the AMS helium flux for ½1.11-1.28 GeV=n, (c) the relative variation of the AMS proton flux integrated over R ≥ 6.47 GV as a function of time together with the relative variation of the rate reported by the Oulu, Finland neutron monitor [37], and (d) the monthly averaged sunspot number [38] with the period of solar magnetic field polarity (A) reversal (vertical dashed lines) from A &lt; 0 to A &gt; 0, November 2012 to March 2014, of solar cycle 24 [39]. One year after solar maximum, both the p and He fluxes start to rise and, as seen, there is a negative correlation with the sunspot number. AMS data are converted from rigidity R to kinetic energy per nucleon</p>
<p>-MÞ=A, where M is the proton or the 4 He mass. The AMS error bars are the quadratic sum of the statistical and total systematic errors.</p>
<p>3.29 GV, the p=He flux ratio is consistent with a constant value at the 95% confidence level. This shows the universality of the solar modulation of cosmic ray nuclei at rigidities. Below 3.29 GV, the observed p=He flux ratio is steadily decreasing with time after t i . In the first five rigidity bins, the best fit values of t i are in agreement within each other. Their average value is equal to February 28, 2015 AE 42 days, consistent with boundary VII of Fig. 2, after which the proton and helium fluxes start to increase. This last observation shows a new and important feature regarding the propagation of lower energy cosmic rays in the heliosphere. Before this Letter, several effects had been proposed that lead to a time dependence of the p=He flux ratio at low rigidities, such as velocity dependence of the diffusion tensor, differences in the interstellar spectra of p and He, and the 3 He and 4 He isotopic composition [8][9][10][11][12][13]28,40,41]. The precision of the AMS data provides information for the development of refined solar modulation models.</p>
<p>In conclusion, the precision proton flux and the helium flux observed by AMS have fine time structures nearly identical in both time and relative amplitude. The amplitudes of the flux structures decrease with increasing rigidity and vanish above 40 GV. The amplitudes of the structures are reduced during the time period, which started one year after solar maximum, when the proton and helium fluxes steadily increase. In addition, above ∼3 GV the p=He flux ratio is time independent. Below ∼3 GV the ratio has a long-term decrease coinciding with the period during which the fluxes start to rise.</p>
<p>We thank former NASA Administrator Daniel S. Goldin for his dedication to the legacy of the ISS as a scientific laboratory and his decision for NASA to fly the AMS as a DOE payload. We also acknowledge the continuous support of the NASA leadership including Charles Bolden and William H. Gerstenmaier and of the JSC and MSFC flight control teams which has allowed AMS to operate optimally on the ISS for over six years. We are grateful for the support of Jim Siegrist and his staff of the DOE including resources from the National Energy Research Scientific Computing Center under Contract No. DE-AC02-05CH11231 and the Argonne Leadership Computing Facility under Contract No. DE-AC02-06CH11357. We also acknowledge the continuous support from MIT and its School of Science, Michael Sipser, Marc Kastner, Ernest Moniz, Richard Milner, and Boleslaw Wyslouch. We are grateful for the support of Edward Semones and his staff of the NASA Johnson Space Center including resources from Wyle Laboratories Grant No. 2014/T72497. Research supported by São Paulo Research Foundation (FAPESP) Grants No. 2014/19149-7, No. 2015/50378-5, and No. 2016/ 10222-9, Brazil; CAS, NSFC, MOST, the provincial governments of Shandong, Jiangsu, Guangdong, and the China Scholarship Council, China; Action H2020 MSCA-IF-2015 under Grant No. 707543-MAtISSE, European Union; the Finnish Funding Agency for Innovation (Tekes) Grants No. 40361/01 and No. 40518/03 and the Academy of Finland Grant No. 258963, Finland; CNRS/ IN2P3, CNES, Enigmass, and the ANR,</p>
<p>France; Pascale Ehrenfreund, DLR under Grant No. 50OO1403 and JARA-HPC under Project No. JARA0052, Germany; INFN and ASI under ASI-INFN Agreements No. 2013-002-R.0 and No. 2014-037-R.0, Italy; CHEP and NRF under Grants No. NRF-2009-0080142 and No. NRF-2012-010226 at Kyungpook National University and No. NRF-2013-004883 at Ewha Womans University, Korea; the Consejo Nacional de Ciencia y Tecnología and UNAM, Mexico; FCT under Grant No. PTDC/FIS/122567/2010, Portugal; CIEMAT, IAC, CDTI, and SEIDI-MINECO under Grants No. ESP2015-71662-C2-(1-P/2-P), No. SEV-2015-0548, No. MDM-2015-0509, and No. RyC-2013-14660, Spain; the Swiss National Science Foundation (SNSF), federal and cantonal authorities, Switzerland; Academia Sinica and the Ministry of Science and Technology (MOST) under Grants No. 103-2112-M-006-018-MY3, No. 105-2112-M-001-003, and No. CDA-105-M06, former Presidents of Academia Sinica Yuan-Tseh Lee and Chi-Huey Wong and former Ministers of MOST Maw-Kuen Wu and Luo-Chuan Lee, Taiwan; the Turkish Atomic Energy Authority under Grant No. 2017TEAK(CERN)A5.H6.F2-15, Turkey; and NSF Grants No. 14255202 and No. 1551980, and NASA NESSF Grant No. HELIO15F-0005, USA. We gratefully acknowledge the strong support from CERN including Rolf-Dieter Heuer and Fabiola Gianotti, from the CERN IT department and Bernd Panzer-Steindel, and from the European Space Agency including Johann-Dietrich Wörner and Simonetta Di Pippo. We are grateful for</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f589951298"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T08:14+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Words play a central role in language and thought. Factor analysis studies have shown that the primary dimensions of meaning are valence, arousal, and dominance (VAD). We present the NRC VAD Lexicon, which has human ratings of valence, arousal, and dominance for more than 20,000 English words. We use Best-Worst Scaling to obtain fine-grained scores and address issues of annotation consistency that plague traditional rating scale methods of annotation. We show that the ratings obtained are vastly more reliable than those in existing lexicons. We also show that there exist statistically significant differences in the shared understanding of valence, arousal, and dominance across demographic variables such as age, gender, and personality.</p>
<p>Words are the smallest meaningful utterances in language. They play a central role in our understanding and descriptions of the world around us. Some believe that the structure of a language even affects how we think (principle of linguistic relativity aka the SapirWhorf hypothesis). Several influential factor analysis studies have shown that the three most important, largely independent, dimensions of word meaning are valence (positiveness-negativeness/pleasuredispleasure), arousal (active-passive), and dominance (dominant-submissive) (Osgood et al., 1957;Russell, 1980Russell, , 2003)).1 Thus, when comparing the meanings of two words, we can compare their degrees of valence, arousal, or domi-nance. For example, the word banquet indicates more positiveness than the word funeral; nervous indicates more arousal than lazy; and fight indicates more dominance than delicate.</p>
<p>Access to these degrees of valence, arousal, and dominance of words is beneficial for a number of applications, including those in natural language processing (e.g., automatic sentiment and emotion analysis of text), in cognitive science (e.g., for understanding how humans represent and use language), in psychology (e.g., for understanding how people view the world around them), in social sciences (e.g., for understanding relationships between people), and even in evolutionary linguistics (e.g., for understanding how language and behaviour inter-relate to give us an advantage).</p>
<p>Existing VAD lexicons (Bradley and Lang, 1999; Warriner et al., 2013) were created using rating scales and thus suffer from limitations associated with the method (Presser and Schuman, 1996;Baumgartner and Steenkamp, 2001). These include: inconsistencies in annotations by different annotators, inconsistencies in annotations by the same annotator, scale region bias (annotators often have a bias towards a portion of the scale), and problems associated with a fixed granularity.</p>
<p>In this paper, we describe how we obtained human ratings of valence, arousal, and dominance for more than 20,000 commonly used English words by crowdsourcing. Notably, we use a comparative annotation technique called Best-Worst Scaling (BWS) that addresses the limitations of traditional rating scales (Louviere, 1991;Cohen, 2003;Louviere et al., 2015). The scores are finegrained real-valued numbers in the interval from 0 (lowest V, A, or D) to 1 (highest V, A, or D). We will refer to this new lexicon as the NRC Valence, Arousal, and Dominance (VAD) Lexicon. 2 Correlations (r) between repeated annotations, through metrics such as split-half reliability (SHR), are a common way to evaluate the reliabilities of ordinal and rank annotations. We show that our annotations have SHR scores of r = 0.95 for valence, r = 0.90 for arousal, and r = 0.91 for dominance. These scores are well above the SHR scores obtained by Warriner et al. (2013), and indicate high reliability.</p>
<p>Respondents who provided valence, arousal, and dominance annotations, were given the option of additionally filling out a brief demographic questionnaire to provide details of their age, gender, and personality traits. This demographic information along with the VAD annotations allows us to determine whether attributes such as age, gender, and personality impact our understanding of the valence, arousal, and dominance of words. We show that even though overall the annotations are consistent (as seen from the high SHR scores), people aged over 35 are significantly more consistent in their annotations than people aged 35 or less. We show for the first time that men have a significantly higher shared understanding of dominance and valence of words, whereas women have a higher shared understanding of the degree of arousal of words. We find that some personality traits significantly impact a person's annotations of one or more of valence, arousal, and dominance. We hope that these and other findings described in the paper foster further research into how we use language, how we represent concepts in our minds, and how certain aspects of the world are more important to certain demographic groups leading to higher degrees of shared representations of those concepts within those groups.</p>
<p>All of the annotation tasks described in this paper were approved by our institution's review board, which examined the methods to ensure that they were ethical. Special attention was paid to obtaining informed consent and protecting participant anonymity. The NRC VAD Lexicon is made freely available for research and non-commercial use through our project webpage. 3</p>
<p>Primary Dimensions of Meaning: Osgood et al. (1957) asked human participants to rate words along dimensions of opposites such as heavylight, good-bad, strong-weak, etc. Factor analysis 3 http://saifmohammad.com/WebPages/nrc-vad.html of these judgments revealed that the three most prominent dimensions of meaning are evaluation (good-bad), potency (strong-weak), and activity (active-passive). Russell (1980Russell ( , 2003) ) showed through similar analyses of emotion words that the three primary independent dimensions of emotions are valence or pleasure (positivenessnegativeness/pleasure-displeasure), arousal (active-passive), and dominance (dominantsubmissive). He argues that individual emotions such as joy, anger, and fear are points in a three-dimensional space of valence, arousal, and dominance. It is worth noting that even though the names given by Osgood et al. (1957) and Russell (1980) are different, they describe similar dimensions (Bakker et al., 2014).</p>
<p>Existing Affect Lexicons: Bradley and Lang (1999) asked annotators to rate valence, arousal, and dominance-for more than 1,000 words-on a 9-point rating scale. The ratings from multiple annotators were averaged to obtain a score between 1 (lowest V, A, or D) to 9 (highest V, A, or D). Their lexicon, called the Affective Norms of English Words (ANEW), has since been widely used across many different fields of study. More than a decade later, Warriner et al. (2013) created a similar lexicon for more than 13,000 words, using a similar annotation method. There exist a small number of VAD lexicons in non-English languages as well, such as the ones created by Moors et al. (2013) for Dutch, by Võ et al. (2009) for German, and by Redondo et al. (2007) for Spanish. The NRC VAD lexicon is the largest manually created VAD lexicon (in any language), and the only one that was created via comparative annotations (instead of rating scales).</p>
<p>Best-Worst Scaling: Best-Worst Scaling (BWS) was developed by (Louviere, 1991), building on work in the 1960's in mathematical psychology and psychophysics. Annotators are given n items (an n-tuple, where n &gt; 1 and commonly n = 4). 4They are asked which item is the best (highest in terms of the property of interest) and which is the worst (least in terms of the property of interest). When working on 4-tuples, best-worst annotations are particularly efficient because each best and worst annotation will reveal the order of five of the six item pairs (e.g., for a 4-tuple with items A, B, C, and D, if A is the best, and D is the worst, then A &gt; B, A &gt; C, A &gt; D, B &gt; D, and C &gt; D). Real-valued scores of association between the items and the property of interest can be determined using simple arithmetic on the number of times an item was chosen best and number of times it was chosen worst (as described in Section 3) (Orme, 2009;Flynn and Marley, 2014).</p>
<p>It has been empirically shown that three annotations each for 2N 4-tuples is sufficient for obtaining reliable scores (where N is the number of items) (Louviere, 1991;Kiritchenko and Mohammad, 2016). Kiritchenko and Mohammad (2017) showed through empirical experiments that BWS produces more reliable and more discriminating scores than those obtained using rating scales. (See Kiritchenko andMohammad (2016, 2017) for further details on BWS.)</p>
<p>Within the NLP community, BWS has been used for creating datasets for relational similarity (Jurgens et al., 2012), word-sense disambiguation (Jurgens, 2013), word-sentiment intensity (Kiritchenko and Mohammad, 2016), word-emotion intensity (Mohammad, 2018), and tweet-emotion intensity (Mohammad and Bravo-Marquez, 2017;Mohammad et al., 2018;Mohammad and Kiritchenko, 2018). Automatically Creating Affect Lexicons: There is growing work on automatically determining word-sentiment and word-emotion associations (Yang et al., 2007;Mohammad and Kiritchenko, 2015;Yu et al., 2015;Staiano and Guerini, 2014). The VAD Lexicon can be used to evaluate how accurately the automatic methods capture valence, arousal, and dominance.</p>
<p>We now describe how we selected the terms to be annotated and how we crowdsourced the annotation of the terms using best-worst scaling.</p>
<p>We chose to annotate commonly used English terms. We especially wanted to include terms that denotate or connotate emotions. We also include terms common in tweets.5 Specifically, we include terms from the following sources:</p>
<p>• All terms in the NRC Emotion Lexicon (Mohammad and Turney, 2013). It has about 14,000 words with labels indicating whether they are associated with any of the eight basic emotions: anger, anticipation, disgust, fear, joy, sadness, surprise, and trust (Plutchik, 1980).</p>
<p>• All 4,206 terms in the positive and negative lists of the General Inquirer (Stone et al., 1966).</p>
<p>• All 1,061 terms listed in ANEW (Bradley and Lang, 1999).</p>
<p>• All 13,915 terms listed in the Warriner et al. (2013) lexicon.</p>
<p>• 520 words from the Roget's Thesaurus categories corresponding to the eight basic Plutchik emotions.6</p>
<p>• About 1000 high-frequency content terms, including emoticons, from the Hashtag Emotion Corpus (HEC) (Mohammad, 2012).7</p>
<p>The union of the above sets resulted in 20,007 terms that were then annotated for valence, arousal, and dominance.</p>
<p>We describe below how we annotated words for valence. The same approach is followed for arousal and dominance. The annotators were presented with four words at a time (4-tuples) and asked to select the word with the highest valence and the word with the lowest valence. The questionnaire uses a set of paradigm words that signify the two ends of the valence dimension. The paradigm words were taken from past literature on VAD (Bradley and Lang, 1999;Osgood et al., 1957;Russell, 1980). The questions used for valence are shown below. Questions for arousal and dominance are similar.8 Detailed directions and example questions (with suitable responses) were provided in advance. 2 × N distinct 4-tuples were randomly generated in such a manner that each word is seen in eight different 4-tuples and no two 4-tuples have more than two items in common (where N is the number of words to be annotated).9</p>
<p>Crowdsourcing: We setup three separate crowdsourcing tasks corresponding to valence, arousal, and dominance. The 4-tuples of words were uploaded for annotation on the crowdsourcing platform, CrowdFlower. 10 We obtained annotations from native speakers of English residing around the world. Annotators were free to provide responses to as many 4-tuples as they wished. The annotation tasks were approved by our institution's review board.</p>
<p>About 2% of the data was annotated beforehand by the authors. These questions are referred to as gold questions. CrowdFlower interspersed the gold questions with the other questions. If a crowd worker answered a gold question incorrectly, then they were immediately notified, the annotation was discarded, and an additional annotation was requested from a different annotator. If an annotator's accuracy on the gold questions fell below 80%, then they were refused further annotation, and all of their annotations were discarded. This served as a mechanism to avoid malicious and random annotations. The gold questions also served as examples to guide the annotators. In the task settings for CrowdFlower, we specified that we needed annotations from six people for each word.11 However, because of the way the gold questions work in CrowdFlower, they were annotated by more than six people. Both the minimum and the median number of annotations per item was six. See Table 1 for summary statistics on the annotations. 12Annotation Aggregation: The final VAD scores were calculated from the BWS responses using a simple counting procedure (Orme, 2009;Flynn and Marley, 2014): For each item, the score is the proportion of times the item was chosen as the best (highest V/A/D) minus the proportion of times the item was chosen as the worst (lowest V/A/D). The scores were linearly transformed to the interval: 0 (lowest V/A/D) to 1 (the highest V/A/D). We refer to the list of words along with their scores for valence, arousal, and dominance as the NRC Valence, Arousal, and Dominance Lexicon, or the NRC VAD Lexicon for short.</p>
<p>Respondents who annotated our VAD questionnaires were given a special code through which they could then optionally respond to a separate CrowdFlower survey asking for their demographic information: age, gender, country they live in, and personality traits. For the latter, we asked how they viewed themselves across the big five (Barrick and Mount, 1991) personality traits:</p>
<p>• Agreeableness (Ag) -Disagreeableness (Di): friendly and compassionate or careful in whom to trust, argumentative</p>
<p>• Conscientiousness (Co) -Easygoing (Ea): efficient and organized (prefer planned and self-disciplined behaviour) or easy-going and carefree (prefer flexibility and spontaneity)</p>
<p>• Extrovert (Ex) -Introvert (In): outgoing, energetic, seek the company of others or solitary, reserved, meeting many people causes anxiety</p>
<p>• Neurotic (Ne) -Secure (Se): sensitive and nervous (often feel anger, anxiety, depression, and vulnerability) or secure and confident (rarely feel anger, anxiety, depression, and vulnerability)</p>
<p>• Open to experiences (Op) -Closed to experiences (Cl): inventive and curious (seek out new experiences) or consistent and cautious (anxious about new experiences)</p>
<p>The questionnaire described the two sides of the dimension using only the texts after the colons above. 13 The questionnaire did not ask for identifying information such as name or date of birth. In total, 991 people (55% of the VAD annotators) chose to provide their demographic information. Table 3 shows the details. 4 shows the results. (These numbers were calculated for the 13,915 common terms across the two lexicons.) Observe that the especially low correlations for dominance and arousal indicate that our lexicon has substantially different scores and rankings of terms by these dimensions. Even for valence, a correlation of 0.81 indicates a marked amount of differences in scores.</p>
<p>Russell (1980) found through his factor analysis work that valence, arousal, and dominance are nearly independent dimensions. However, Warriner et al. ( 2013) report that their scores for valence and dominance have substantial correlation (r = 0.717). Given that the split-half reliability score for their dominance annotations is only 0.77, the high V-D correlations raises the suspicion whether annotators sufficiently understood the difference between dominance and valence.</p>
<p>Table 5 shows the correlations between various pair-wise combinations of valence, arousal, and dominance for both our lexicon and the Warriner lexicon. Observe that unlike the Warriner annotations where V and D are highly correlated, our annotations show that V and D are only slightly correlated. The correlations for V-A and A-D are low in both our and Warriner annotations, albeit slightly higher in magnitude in our annotations.</p>
<p>Annotations #Terms #Annotations V A D a. Ours (on all terms) 20,007 6 per tuple 0.950 0.899 0.902 b. Ours (on only those terms also in Warriner) 13,915 6 per tuple 0.952 0.905 0.906 c. Warriner et al. (2013) 13,915 20 per term 0.914 0.689 0.770</p>
<p>A useful measure of quality is reproducibility of the end result-repeated independent manual annotations from multiple respondents should result in similar scores. To assess this reproducibility, we calculate average split-half reliability (SHR) over 100 trials. All annotations for an item (in our case, 4-tuples) are randomly split into two halves. Two sets of scores are produced independently from the two halves. Then the correlation between the two sets of scores is calculated.</p>
<p>If the annotations are of good quality, then the correlation between the two halves will be high.</p>
<p>Table 6 shows the split-half reliabilities (SHR) for valence, arousal, and dominance annotations. Row a. shows the SHR on the full set of terms in the VAD lexicon. Row b. shows the SHR on just the Warriner subset of terms in the VAD lexicon. Row c. shows the SHR reported by Warriner et al. (2013) on their annotations. Observe that the SHR scores for our annotations are markedly higher than those reported by Warriner et al. (2013), especially for arousal and dominance. All differences in SHR scores between rows b and c are statistically significant.</p>
<p>The low correlations between the scores in our lexicon and the Warriner lexicon (especially for D and A) show that the scores in the two lexicons are substantially different. The scores for correlations across all pairs of dimensions in our lexicon are low (r &lt; 0.5). SHR scores of 0.95 for valence, 0.9 for arousal, and 0.9 for dominance show for the first time that highly reliable fine-grained ratings can be obtained for valence, arousal, and dominance.</p>
<p>Human cognition and behaviour is impacted by evolutionary and socio-cultural factors. These factors are known to impact different groups of people differently (men vs. women, young vs. old, etc.). Thus it is not surprising that our understanding of the world may be slightly different de-pending on our demographic attributes. Consider gender-a key demographic attribute. 14 Men, women, and other genders are substantially more alike than they are different. However, they have encountered different socio-cultural influences for thousands of years. Often these disparities have been a means to exert unequal status and asymmetric power relations. Thus a crucial area in gender studies is to examine both the overt and subtle impacts of these socio-cultural influences, as well as ways to mitigate the inequity. Understanding how different genders perceive and use language is an important component of that research. Language use is also relevant to the understanding and treatment of neuropsychiatric disorders, such as sleep, mood, and anxiety disorders, which have been shown to occur more frequently in women than men (Bao and Swaab, 2011;Lewinsohn et al., 1998;McLean et al., 2011;Johnson et al., 2006;Chmielewski et al., 1995).</p>
<p>In addition to the VAD Lexicon (created by aggregating human judgments), we also make available the demographic information of the annotators. This demographic information along with the individual judgments on the best-worst tuples forms a significant resource in the study of how demographic attributes are correlated with our understanding of language. The data can be used to shed light on research questions such as: 'are there significant differences in the shared understanding of word meanings in men and women?', 'how is the social construct of gender reflected in language, especially in socio-political interactions?', 'does age impact our view of the valence, arousal, and dominance of concepts?', 'do people that view themselves as conscientious have slightly different judgments of valence, arousal, and dominance, than people who view themselves as easy going?', and so on. Table 8: Gender: Significance of difference in average agreement scores (p = 0.05). 'y' = yes significant. '-' = not significant.</p>
<p>We now describe experiments we conducted to determine whether demographic attributes impact how we judge words for valence, arousal, and dominance. For each demographic attribute, we partitioned the annotators into two groups: male (m) and female (f), ages 18 to 35 (≤35) and ages over 35 (&gt;35), and so on. 15 For each of the five personality traits, annotators are partitioned into the two groups shown in the bullet list of Section 4. We then calculated the extent to which people within the same group agreed with each other, and the extent to which people across groups agreed with each other on the VAD annotations (as described in the paragraph below). We also determined if the differences in agreement were statistically significant.</p>
<p>For each dimension (V, A, and D), we first collected only those 4-tuples where at least two female and at least two male responses were available. We will refer to this set as the base set. For each of the base set 4-tuples, we calculated three agreement percentages: 1. the percentage of all female-female best-worst responses where the two agreed with each other, 2. the percentage of all male-male responses where the two agreed with each other, and 3. the percentage of all female-male responses where the two agreed with each other. We then calculated the averages of the agreement percentages across all the 4-tuples in the base set. We conducted similar experiments for age groups and personality traits. Table 10: Age: Significance of difference in average agreement scores (p = 0.05).</p>
<p>Table 7 shows the results for gender. Note that the average agreement numbers are not expected to be high because often a 4-tuple may include two words that are close to each other in terms of the property of interest (V/A/D). 16 However, the relative values of the agreement percentages indicate the relative levels of agreements within groups and across groups.</p>
<p>Table 7 numbers indicate that women have a higher shared understanding of the degree of arousal of words (higher f-f average agreement scores on A), whereas men have a higher shared understanding of dominance and valence of words (higher m-m average agreement scores on V and D). The table also shows the cross-group (f-m) average agreements are the lowest for valence and arousal, but higher than f-f pairs for dominance. (Each of these agreements was determined from 1 to 1.5 million judgment pairs.)</p>
<p>Table 8 shows which of the Table 7 average agreements are statistically significantly different (shown with a 'y'). Significance values were calculated using the chi-square test for independence and significance level of 0.05. Observe that all score differences are statistically significant except for between f-f and f-m scores for V and mm and f-m scores for A.</p>
<p>Tables 9 through 12 are similar to Tables 7 and8, but for age groups and personality traits. Tables 9 and10 show that respondents over the age of 35 obtain significantly higher agreements with each other on valence and arousal and lower agreements on dominance, than respondents aged 35 and under (with each other). Tables 11 and12 show that Table 12: Personality Trait: Significance of difference in average agreement scores (p = 0.05). people that share certain demographic attributes show a higher shared understanding of the relative rankings of words by (one or more of) V, A, or D than others. However, this raises new questions: why do certain demographic attributes impact our judgments of V, A, and D? Are there evolutionary forces that caused some groups such as women to develop a higher shared understanding or the arousal, whereas different evolutionary forces caused some groups, such as men, to have a higher shared understanding of dominance? We hope that the data collected as part of this project will spur further inquiry into these and other questions.</p>
<p>The large number of entries in the VAD Lexicon and the high reliability of the scores make it useful for a number of research projects and applications. We list a few below:</p>
<p>• To provide features for sentiment or emotion detection systems. They can also be used to obtain sentiment-aware word embeddings and sentiment-aware sentence representations.</p>
<p>• To study the interplay between the basic emotion model and the VAD model of affect. The VAD lexicon can be used along with lists of words associated with emotions such as joy, sadness, fear, etc. to study the correlation of V, A, and D, with those emotions.</p>
<p>• To study the role emotion words play in high emotion intensity sentences or tweets. The Tweet Emotion Intensity Dataset has emotion intensity and valence scores for whole tweets (Mohammad and Bravo-Marquez, 2017). We will use the VAD lexicon to determine the extent to which high intensity and high valence tweets consist of high V, A, and D words, and to identify sentences that express high emotional intensity without using high V, A, and D words.</p>
<p>• To identify syllables that tend to occur in words with high VAD scores, which in turn can be used to generate names for literary characters and commercial products that have the desired affectual response.</p>
<p>• To identify high V, A, and D words in books and literature. To facilitate research in digital humanities. To facilitate work on literary analysis.</p>
<p>• As a source of gold (reference) scores, the entries in the VAD lexicon can be used in the evaluation of automatic methods of determining V, A, and D.</p>
<p>• To analyze V, A, ad D annotations different groups of words, such as: hashtag words and emojis common in tweets, emotion denotating words, emotion associated words, neutral terms, words belonging to particular parts of speech such as nouns, verbs, and adjectives, etc.</p>
<p>• To analyze interactions between demographic groups and specific groups of words, for example, whether younger annotators have a higher shared understanding of tweet terms, whether a certain gender is associated with a higher shared understanding of adjectives, etc.</p>
<p>• To analyze the shared understanding of V, A, and D within and across geographic and language groups. We are interested in creating VAD lexicons for other languages. We can then explore characteristics of valence, arousal, and dominance that are common across cultures. We can also test whether some of the conclusions reached in this work apply only to English, or more broadly to multiple languages.</p>
<p>• The dataset is of use to psychologists and evolutionary linguists interested in determining how evolution shaped our representation of the world around us, and why certain personality traits are associated with higher or lower shared understanding of V, A, and D.</p>
<p>We obtained reliable human ratings of valence, arousal, and dominance for more than 20,000 English words. (It has about 40% more words than the largest existing manually created VAD lexicon). We used best-worst scaling to obtain finegrained scores (and word rankings) and addressed issues of annotation consistency that plague traditional rating scale methods of annotation. We showed that the lexicon has split-half reliability scores of 0.95 for valence, 0.90 for arousal, and 0.90 for dominance. These scores are markedly higher than that of existing lexicons. We analyzed demographic information to show that even though the annotations overall lead to consistent scores in repeated annotations, there exist statistically significant differences in agreements across demographic groups such as males and females, those above the age of 35 and those that are 35 or under, and across personality dimensions (extroverts and introverts, neurotic and secure, etc.). These results show that certain demographic attributes impact how we view the world around us in terms of the relative valence, arousal, and dominance of the concepts in it.</p>
<p>The NRC Valence, Arousal, and Dominance Lexicon is made available.17 It can be used in combination with other manually created affect lexicons such as the NRC Word-Emotion Association Lexicon (Mohammad and Turney, 2013) 18and the NRC Affect Intensity Lexicon (Mohammad, 2018). 19</p>
<p>We will refer to the three dimensions individually as V, A, and D, and together as VAD.</p>
<p>NRC refers to National Research Council Canada.</p>
<p>At its limit, when n = 2, BWS becomes a paired comparison(Thurstone, 1927;David, 1963), but then a much larger set of tuples need to be annotated (closer to N 2 ).</p>
<p>Tweets include non-standard language such as emoticons, emojis, creatively spelled words (happee), hashtags (#takingastand, #lonely) and conjoined words (loveumom).</p>
<p>http://www.gutenberg.org/ebooks/10681</p>
<p>All tweets in the HEC include at least one of the eight basic emotion words as a hashtag word (#anger, #sadness, etc.).</p>
<p>The two ends of the arousal dimension were described with the words: arousal, activeness, stimulation, frenzy, jitteriness, alertness AND unarousal, passiveness, relaxation, calmness, sluggishness, dullness, sleepiness. The two ends of the dominance dimension were described with the words: dominant, in control of the situation, powerful, influential, important, autonomous AND submissive, controlled by outside factors, weak, influenced, cared-for,</p>
<p>guided.9 We used the script provided byKiritchenko and Mohammad (2016) to generate the 4-tuples from the list of terms: http://saifmohammad.com/WebPages/</p>
<p>BestWorst.html 10 CrowdFlower later changed its name to Figure Eight: https://www.figure-eight.com</p>
<p>Note that since each word occurs in eight different 4tuples, it is involved in 8 × 6 = 48 best-worst judgments.</p>
<p>12 In a post-annotation survey, the respondents gave the task high scores for clarity of instruction (an average of 4.5 out of 5) and overall satisfaction (an average of 4.3 out of 5).</p>
<p>How people view themselves may be different from what they truly are. The conclusions in this paper apply to groups that view themselves to be a certain personality type.</p>
<p>Note that the term sex refers to a biological attribute pertaining to the anatomy of one's reproductive system and sex chromosomes, whereas gender refers to a psycho-sociocultural construct based on a person's sex or a person's self identification of levels of masculinity and femininity. One may identify their gender as female, male, agender, trans, queer, etc.</p>
<p>For age, we chose 35 to create the two groups because several psychology and medical studies report changes in health and well-being at this age. Nonetheless, other partitions of age are also worth exploring.</p>
<p>Such disagreements are useful as they cause the two words to obtain scores close to each other.</p>
<p>The NRC Valence, Arousal, and Dominance Lexicon provides human ratings of valence, arousal, and dominance for more than 20,000 English words: http://saifmohammad.com/WebPages/nrc-vad.html</p>
<p>The NRC Emotion Lexicon includes about 14,000 words annotated to indicate whether they are associated with any of the eight basic emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, and trust): http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm</p>
<p>19 The NRC Affect Intensity Lexicon provides realvalued affect intensity scores for four basic emotions (anger, fear, sadness, joy): http://saifmohammad.com/WebPages/AffectIntensity.htm</p>
<p>Many thanks to Svetlana Kiritchenko, Michael Wojatzki, Norm Vinson, and Tara Small for helpful discussions.</p>
<p>some personality traits significantly impact a person's annotations of one or more of V, A, and D. Notably, those who view themselves as conscientious have a particularly higher shared understanding of the dominance of words, as compared to those who view themselves as easy going. They also have higher in-group agreement for arousal, than those who view themselves as easy going, but the difference for valence is not statistically significant. Also notable, is that those who view themselves as extroverts have a particularly higher shared understanding of the valence, arousal, and dominance of words, as compared to those who view themselves as introverts.</p>
<p>Finally, as a sanity check, we divided respondents into those whose CrowdFlower worker ids are odd and those whose worker ids are even. We then determined average agreements for even-even, odd-odd, and even-odd groups just as we did for the demographic variables. We found that, as expected, there were no significant differences in average agreements.</p>
<p>We showed that several demographic attributes such as age, gender, and personality traits impact how we judge words for valence, arousal, and dominance. Further,</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f87643039"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T08:15+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The rise and spread of the Internet has led to the emergence of a new form of word of mouth (WOM): electronic word of mouth (eWOM), considered one of the most influential informal media among consumers, businesses, and the population at large. Drawing on these ideas, this paper reviews the relevant literature, analyzing the impact of traditional WOM and eWOM in the field of consumer behavior and highlighting the main differences between the two types of recommendations, with a view to contributing to a better understanding of the potential of both.</p>
<p>Consumers increasingly use online tools (e.g., social media, blogs, etc.) to share their opinions about the products and services they consume (Gupta and Harris, 2010;Lee et al., 2011) and to research the companies that sell them. These tools are significantly changing everyday life and the relationship between customers and businesses (Lee et al., 2011).</p>
<p>The rapid growth of online communication through social media, websites, blogs, etc., has increased academic interest in word of mouth (WOM) and electronic word of mouth (eWOM) (e.g., Hennig-Thurau et al., 2004;Brown et al., 2007;Cheung and Thadani, 2012;Hussain et al., 2017;Yang, 2017). Specifically, the present paper will review the literature on how these two media have evolved, the main differences between them, and the degree to which they influence both businesses and consumers, now that they have become some of the most influential information sources for decision-making.</p>
<p>Word of mouth is one of the oldest ways of conveying information (Dellarocas, 2003), and it has been defined in many ways. One of the earliest definitions was that put forward by Katz and Lazarsfeld (1966), who described it as the exchanging of marketing information between consumers in such a way that it plays a fundamental role in shaping their behavior and in changing attitudes toward products and services. Other authors (e.g., Arndt, 1967) have suggested that WOM is a person-to-person communication tool, between a communicator and a receiver, who perceives the information received about a brand, product, or service as non-commercial. Likewise, WOM has been defined as communication between consumers about a product, service, or company in which the sources are considered independent of commercial influence (Litvin et al., 2008). These interpersonal exchanges provide access to information related to the consumption of that product or service over and above formal advertising, i.e., that goes beyond the messages provided by the companies and involuntarily influences the individual's decision-making (Brown et al., 2007). WOM is widely regarded as one of the most influential factors affecting consumer behavior (Daugherty and Hoffman, 2014). This influence is especially important with intangible products that are difficult to evaluate prior to consumption, such as tourism or hospitality. Consequently, WOM is considered the most important information source in consumers' buying decisions (Litvin et al., 2008;Jalilvand and Samiei, 2012) and intended behavior. For example, tourist satisfaction is of utmost importance because of its influence on behavioral intentions, WOM and purchasing decisions. In other words, overall satisfaction leads to the possibility of revisiting and recommending the destination (Sotiriadis and Van Zyl, 2013).</p>
<p>Similarly, previous research indicates that consumers regard WOM as a much more reliable medium than traditional media (e.g., television, radio, print advertisements, etc.) (Cheung and Thadani, 2012). It is thus considered one of the most influential sources of information about products and services (Lee and Youn, 2009). Users generally trust other consumers more than sellers (Nieto et al., 2014). As a result, WOM can influence many receivers (Lau and Ng, 2001) and is viewed as a consumer-dominated marketing channel in which the senders are independent of the market, which lends them credibility (Brown et al., 2007). This independence makes WOM a more reliable and credible medium (Arndt, 1967;Lee and Youn, 2009).</p>
<p>Today's new form of online WOM communication is known as electronic word-of-mouth or eWOM (Yang, 2017). This form of communication has taken on special importance with the emergence of online platforms, which have made it one of the most influential information sources on the Web (Abubakar and Ilkan, 2016), for instance, in the tourism industry (Sotiriadis and Van Zyl, 2013). As a result of technological advances, these new means of communication have led to changes in consumer behavior (Cantallops and Salvi, 2014;Gómez-Suárez et al., 2017), because of the influence they enable consumers to exert on each other (Jalilvand and Samiei, 2012) by allowing them to obtain or share information about companies, products, or brands (Gómez-Suárez et al., 2017).</p>
<p>One of the most comprehensive conceptions of eWOM was proposed by Litvin et al. (2008), who described it as all informal communication via the Internet addressed to consumers and related to the use or characteristics of goods or services or the sellers thereof. The advantage of this tool is that it is available to all consumers, who can use online platforms to share their opinions and reviews with other users. Where once consumers trusted WOM from friends and family, today they look to online comments (eWOM) for information about a product or service (Nieto et al., 2014).</p>
<p>As a result of ICT, today consumers from all over the world can leave comments that other users can use to easily obtain information about goods and services. Both active and passive consumers use this information medium (eWOM). Individuals who share their opinions with others online are active consumers; those who simply search for information in the comments or opinions posted by other customers are passive consumers (Wang and Fesenmaier, 2004).</p>
<p>Electronic word of mouth also provides companies with an advantage over traditional WOM insofar as it allows them both to try to understand what factors motivate consumers to post their opinions online and to gauge the impact of those comments on other people (Cantallops and Salvi, 2014). However, consumers' use of technology to share opinions about products or services (eWOM) can be a liability for companies, as it can become a factor they do not control (Yang, 2017). To counteract this, businesses are seeking to gain greater control of customers' online reviews by creating virtual spaces on their own websites, where consumers can leave comments and share their opinions about the business's products and services (Vallejo et al., 2015). By way of example, in the field of tourism, companies are starting to understand that ICT-enabled media influence tourists' purchasing behavior (Sotiriadis and Van Zyl, 2013).</p>
<p>Understandably, companies view both types of recommendations -WOM and eWOM -as a new opportunity to listen to customers' needs and adjust how they promote their products or services to better meet them, thereby increasing their return. A negative or positive attitude toward the product or service will influence customers' future purchase intentions by allowing them to compare the product or service's actual performance with their expectations (Yang, 2017).</p>
<p>In the field of consumer behavior, some previous studies (e.g., Park and Lee, 2009) have shown that consumers pay more attention to negative information than to positive information (Cheung and Thadani, 2012). For example, the customers most satisfied with a product or service tend to become loyal representatives thereof via positive eWOM (Royo-Vela and Casamassima, 2011), which can yield highly competitive advantages for establishments, businesses, or sellers, especially smaller ones, which tend to have fewer resources. Some studies have suggested that traditional WOM is the sales and marketing tactic most often used by small businesses.</p>
<p>Additionally, eWOM offers businesses a way to identify customers' needs and perceptions and even a cost-effective way to communicate with them (Nieto et al., 2014). Today, eWOM has become an important medium for companies' social-media marketing (Hussain et al., 2017).</p>
<p>While many authors (e.g., Filieri and McLeay, 2014) consider eWOM reviews to be electronic versions of traditional WOM reviews, this paper aims to summarize and explain the main differences between the two concepts (Table 1). The first such difference is credibility as an information source (Cheung and Thadani, 2012;Hussain et al., 2017), since it can influence consumers' attitudes toward products or services (Veasna et al., 2013), for example, with regard to the purchase of tourism services, which are considered to be high-risk (Sotiriadis and Van Zyl, 2013). Luo et al. (2013) have suggested that the anonymity of online messages could have a negative effect on their credibility. In contrast, other studies (e.g., Hussain et al., 2017) have argued that consumers use eWOM more to reduce risk when decision-making. Likewise, eWOM tends to be more credible when the consumer using it has previous experience (Sotiriadis and Van Zyl, 2013). Message privacy is another feature that sets the two media apart, since with traditional WOM information is shared through private, real-time, face-to-face dialogs and conversations. In contrast, information shared through eWOM is not private and can sometimes be seen by anonymous people who do not know each other. Furthermore, reviews can be viewed at various points in time (Cheung and Thadani, 2012). Indeed, because eWOM reviews are written, consumers and companies can check them at any time; this stands in contrast to traditional WOM, where once the message has reached the receiver, it tends to disappear.</p>
<p>Another salient difference between the two media is the speed of diffusion of the message; eWOM statements spread much faster than WOM statements because of where they are published, i.e., on the Internet (Gupta and Harris, 2010). Online platforms for sharing information (social media, websites, blogs, etc.) are what set eWOM apart from traditional WOM (Cheung and Thadani, 2012). First, they make the reviews accessible to more consumers (Cheung and Thadani, 2012;Sotiriadis and Van Zyl, 2013). Second, because they are written, they persist over time (Hennig-Thurau et al., 2004;Cheung and Thadani, 2012).</p>
<p>This paper has reviewed the literature with a view to providing a clearer understanding of WOM and eWOM in the context of consumer information searches.</p>
<p>To this end, the review found that, in keeping with numerous studies, WOM is both the oldest medium for sharing opinions about products or services and the one most likely to influence consumer behavior, due to the high reliability and credibility transmitted by family and friends. In contrast, few studies have examined the interaction between perceived risk and eWOM source credibility (Hussain et al., 2017).</p>
<p>Notwithstanding the above, the review of the theoretical framework also revealed a gap in the literature on WOM credibility in situations involving multiple or many communicators and receivers and how this ultimately affects the end consumer. This would include, for instance, situations in which one person communicates a message to another, who acts as an intermediary, both receiving the original message and passing it along to a third party, i.e., the end consumer. In such cases, the original message can be altered or distorted, chipping away at the credibility of the WOM review as a source of information. This lends much more strength to written comments and reviews, such as eWOM, which can ultimately reduce risk and increase consumer confidence.</p>
<p>Another feature that distinguishes eWOM from traditional WOM is the speed with which it spreads and the ease of access to it. In this regard, when consumers need information about a product or service, they ultimately turn to online media (eWOM) for two reasons. First, they can get the information more quickly, as there is no need to wait for someone else -a friend or family member -to offer an opinion about what they wish to consume. Second, if they have already received WOM reviews, they can use eWOM to corroborate the information received. Therefore, credibility and speed are the two main features not only distinguishing the two media, but also influencing consumer behavior.</p>
<p>Finally, the analysis of the review showed that these two concepts -WOM and eWOM -while seemingly the same, are at the same time very different. The Internet has transformed traditional WOM into eWOM. The communication of opinions is no longer done interpersonally (i.e., person-to-person or faceto-face), but rather is mediated by ICT. However, the many studies conducted (e.g., Katz and Lazarsfeld, 1966;Brown et al., 2007;Daugherty and Hoffman, 2014;Yang, 2017) agree that they are the media most able to influence consumer behavior and the most often used to obtain information before, during, and after consuming a given product or service. For example, in the field of tourism, eWOM is considered the most influential prepurchase source of travel information (Sotiriadis and Van Zyl, 2013).</p>
<p>This paper tries to offer a clearer understanding of the two concepts through a literature review and an exploration of how, as a result of advances in ICT, traditional WOM has given rise to eWOM. The author has made an important, direct, intellectual contribution to this paper and has approved it for publication.</p>
<p>This research was funded by the Spanish Ministry of Economy and Competitiveness under Research Project ECO2014-59688-R ("Planning and implementation of optimal management strategies for physical, online and mobile POSs based on ICT and innovation").</p>
<p>Frontiers in Psychology | www.frontiersin.org</p>
<p>July 2017 | Volume 8 | Article 1256</p>
<p>The author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f237711831"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Tactile sensing is an essential component in human-robot interaction and object manipulation. Soft sensors allow for safe interaction and improved gripping performance. Here we present the TacTip family of sensors: a range of soft optical tactile sensors with various morphologies fabricated through dual-material 3D printing. All of these sensors are inspired by the same biomimetic design principle: transducing deformation of the sensing surface via movement of pins analogous to the function of intermediate ridges within the human fingertip. The performance of the TacTip, TacTip-GR2, TacTip-M2, and TacCylinder sensors is here evaluated and shown to attain submillimeter accuracy on a rolling cylinder task, representing greater than 10-fold super-resolved acuity. A version of the TacTip sensor has also been open-sourced, enabling other laboratories to adopt it as a platform for tactile sensing and manipulation research. These sensors are suitable for real-world applications in tactile perception, exploration, and manipulation, and will enable further research and innovation in the field of soft tactile sensing.</p>
<p>T he sense of touch is essential for interacting physically with our environment, 1 such as with other humans in social interactions. 2 In robotics, tactile feedback is essential for complex precision manipulation tasks 3 as well as for safe human-robot interaction. Developing robust, customizable tactile sensors is thus an important task that could drive advances in the safety, interactivity, and manipulation capabilities of robots.</p>
<p>A large variety of tactile sensors have been developed over the years, 4 relying on various technologies such as capacitive taxels, resistive wires, and piezoelectric materials. However, there is a general lack of cheap customizable tactile sensors in the field, which is hampering the ease of researching applications of robot touch. We aim to develop these types of tactile sensors and make them available through open resources such as the soft robotics toolkit. 5 Our sensors are soft, with a compliant modular tip that protects sensitive electronic parts from physical contact with objects. When integrated into robotic grippers, compliant sensors have also been shown to improve grasping. 6 Developing soft sensors is also key for safe and comfortable human-robot interaction. 3 Advances in multimaterial 3D printing allow researchers to manufacture rapidly prototyped robot hands and sensors with integrated soft surfaces for compliant, adaptable, and sensorized manipulation. Recent work in the application of soft, 3D-printed tactile sensors, for instance, in demonstrating tactile super-resolution, 7 extends the scope of these devices from prototypes to useful, working versions of sensors whose materials and morphologies can be quickly, easily, and cheaply adapted to suit different practical applications.</p>
<p>The aim of this study is to present a suite of soft sensors of various morphologies using 3D printing, including the tactile fingertip (TacTip) by successive modifications of the original cast tip version (Fig. 1). The TacTip 8 is a low-cost, robust, 3D-printed optical tactile sensor based on a human fingertip and developed at Bristol Robotics Laboratory (BRL). We also introduce the TacTip-M2, TacTip-GR2, and TacCylinder (Fig. 2), more skin-like derived sensors whose fabrication is made possible by multimaterial 3D printing and which are designed for integration in two-fingered grippers and for capsule endoscopy, respectively.</p>
<p>We have open-sourced the open TacTip (www.soft roboticstoolkit.com/tactip) to offer other research institutions the opportunity to adopt and adapt our sensor designs, such as to create different morphologies, as we have done with the TacCylinder. 9 The sensor design can also be modified to integrate with robot hands, as demonstrated with the TacTip-M2 (formerly TacThumb) 10 and TacTip-GR2.</p>
<p>This article presents the first comparative study of our suite of soft sensors, all of which are highly accurate, being able to localize objects to submillimeter accuracy that demonstrates super-resolved acuity. This high performance of the TacTip family of sensors suggests that analogous designs could result in a range of novel soft complex tactile sensors from regions of tactile skin to tactile feet and proboscises.</p>
<p>Most tactile sensors are soft, comprising at least some compliant elements, and rely on a variety of underlying technologies (e.g., strain-gauge, 11 barometric, 12 capacitive, 13 piezoresistive, 14 piezoelectric 15 .) to transmit and record tactile information. Here we review existing compliant optical tactile sensors, which relate most closely to our family of TacTip sensors.</p>
<p>At first glance, the design of the Optoforce force/torque sensor (www.optoforce.com) seems closely related to the TacTip, based on its overall shape and design. However, the Optoforce is designed to compute only the overall force and torque of the contact, rather than relaying tactile information that comprises an array of sensor readings across a sensing surface. Force/torque sensing is unlike human touch and inadequate for tasks requiring more information than a force vector, such as multicontact sensing.</p>
<p>An early precursor to the TacTip used a molded transparent dome with a black dotted pattern. 16 However, the use of ambient light for imaging the dots has drawbacks, including lack of contrast on objects that obscure the ambient lighting and difficulties for automated tracking of the dots; moreover, the design presents difficulties for image recognition of tactile elements independent of lighting conditions.</p>
<p>A further tactile sensor based on optics is the GelSight sensor, 17 which uses colored lights and photometric stereo to reconstruct highly accurate deformations of its surface. This sensor obtains high resolutions, uses inexpensive materials, and can be made into a portable device. While in many ways it represents an excellent, low-cost optical tactile sensor, it presently requires a flat surface and there would be challenges in adapting it to more complex morphologies such as domed fingertips. Similar considerations apply to the Gel-Force sensor, 18 where the sensing surface is a flat elastomer pad.</p>
<p>Other examples include tactile sensors that use an optical waveguide approach, [19][20][21] or patterns of dots 22 or lines 23 drawn on the inside surface of a flexible skin, tracked by a CCD camera. Some sensors also make use of fiber optics to relay light intensities to the camera, 24 allowing the sensor's contact area to be made very small, ideal for medical applications.</p>
<p>All tactile sensors have their pros and cons, and ultimately, the best choice will depend on the application. That being said, an important distinction between the TacTip and the sensors described above is the presence of physical pins attached to the sensing surface; these structures mimic intermediate ridges within the human fingertip, giving a biomimetic basis for the sensor design, as described below.</p>
<p>When the human finger makes contact with an object or surface, deformation occurs in the epidermal layers of the skin and the change is detected and relayed by its mechanoreceptors. 1 Chorley et al. 8 were inspired to consider the behavior of the human glabrous (hairless) skin, as found on the palms of human hands and soles of our feet. They built on previous research showing that the Merkel cell complex of sensory receptors works in tandem with the morphology of the intermediate ridges (Fig. 3) to provide edge encoding of a contacted surface. The TacTip device seeks to replicate this response by substituting intermediate ridges with internal pins on the underside of its soft, skin-like membrane, with optical pin tracking via an internal camera taking the place of mechanosensory transduction of the sensing surface (Fig. 4).</p>
<p>This biomimetic inspiration was recently extended by exploring the role of an artificial fingerprint on tactile sensing with the TacTip. 25 In that study, an artificial fingerprint consisting of a series of outer nodules on the TacTip's skin was shown to enhance high spatial frequency detection. This finding suggests that the inclusion of artificial fingerprints in biomimetic fingertips will improve their ability to perform tactile tasks such as edge perception, contour following, and fine feature classification, with potential implications for object perception and tactile manipulation.</p>
<p>The focus of this section is a description of the developments leading to the TacTip sensors presented here (Fig. 4).</p>
<p>The original TacTip 8 is a soft, robust, and high-sensitivity sensor making use of biomimetic methods for active perception. This sensor has been shown to achieve 40-fold localization super-resolution 7 and successfully perform tactile manipulation on a cylinder rolling task. 26 Further efforts to integrate the TacTip for use with 3Dprinted robot hands and grippers have led to the development of the TacTip-M2 10 and TacTip-GR2 sensors, integrated on the M2 gripper 26 and GR2 gripper, 27 respectively. These open-source robot hands developed at Yale's GRAB Lab enable the investigation of in-hand tactile manipulation with the TacTip sensors.</p>
<p>The TacCylinder, designed for capsule endoscopy, 28 is another adaptation of the TacTip design, expanding the range of tasks that can be tackled with TacTip sensors. The TacTip is thus an extremely useful research tool, due to its low cost, robustness, and adaptability. It fills the current gap in the field for a cheap, compliant, customizable tactile sensor, and can be applied to a number of challenges in industrial robotics, medical robotics, and robotic manipulation.</p>
<p>In the original version of the open-TacTip, 7,8,29 the base, camera mount, and rigid part of the tip are 3D printed, the skin is cast in VytaFlex 60 silicone rubber, and the pins' tips are (painstakingly) painted white by hand. The tip is filled with optically clear silicone gel (Techsil, RTV27905). In the fabrication of the open-TacTip, emphasis is placed on the low cost of the sensor, straightforward manufacture, and ease of assembly.</p>
<p>To enhance the functionality of the open-TacTip, a series of modifications are made to the original version that was described above. These modifications aim to further reduce cost, minimize the sensor form factor, optimize sensor accuracy, and make the TacTip easier to use and modify. The main modifications to the improved version of the TacTip are summarized in the following section.</p>
<p>3D-printed skin. Rather than cast the TacTip's skin in silicone rubber, dual-material rapid prototyping with an Objet 3D printer is used to create the sensor's rigid base in hard plastic (Vero White) and its soft skin in a rubber-like material (Tango Black+). This lowers the cost and accelerates the creation of new prototype TacTip skins, by avoiding the time-consuming mold creation and skin casting/painting fabrication stages. In particular, Vero White tips are now printed directly onto the end of the pins avoiding the need to paint them. Examples of different types of skins include tips with a fingerprint 25 and a rotationally symmetric pin layout. 30 Three-dimensional printing also increases reproducibility of design. Differences in 3D-printed tip dimensions are based on the accuracy of the 3D printer. Conversely, in molded tips, the skin is molded by hand, introducing variability in skin thickness between tips. While one would expect that 3Dprinted skins would be less robust over the long term than their cast counterparts, we have used such 3D-printed skins over months on a daily basis with no obvious drop in performance. Damage is usually due to human error.</p>
<p>The new printing method also provides the opportunity to add complex features to the sensor's skin. For instance, an exterior fingerprint of rubber nodules was included that mechanically coupled to the white pin tips through rigid internal plastic cores. The creation of this complex skin structure was made possible through the use of multimaterial 3D printing and has been shown to improve perceptual acuity at high spatial frequencies. 31 Modularity. To facilitate skin testing and optimization, the skin is printed in a single structure attached to a hard plastic casing (Fig. 4, right panel), forming a tip that connects to the TacTip base with a bayonet mount. The tip (made up of the skin, gel, lens, and plastic casing) is thus a modular component of the sensor, which is easily replaceable or upgradable. By printing tips in this way, it is possible to produce and test different pin layouts and tip structures to optimize the sensor capabilities at a much lower cost than has been possible previously.</p>
<p>We are thus able to update the pin layout to a hexagonal projection of 127 pins with a regular spacing when imaged by the camera, an improvement over the uniform geodesic distribution that had been used in past molded TacTips (Fig. 5). This design gives better performance of the pin tracking algorithms during image processing. We also experimented with different skin thicknesses and pin lengths, eventually converging on a 1 mm thick skin with 2.0 mm long pins for the improved TacTip (3°taper) as a good balance between robustness and sensitivity of the pins to deflection. 3D printing was essential in enabling these trial-and-error experiments requiring extensive hardware testing and leading to an improved sensor design.</p>
<p>Shorter sensor. A more compact sensor is both easier to deploy in practical scenarios and facilitates integration with a wider range of robot hands and arms. Another important benefit is to reduce the torque on the base if struck laterally, which would be an issue for a long sensor. Thus, we take apart the webcam, retaining only the essential components, and reconnect its circuit boards in a horizontal arrangement (Fig. 4). This shortens the spread along the sensor's long axis, reducing the TacTip's height by approximately a factor FIG. 5. Raw images from the TacTip family of sensors. From left to right: improved TacTip, TacTip-GR2, TacTip-M2, and TacCylinder. The TacTip images pins with a Microsoft Cinema HD webcam, whereas the TacTip-GR2 uses a Raspberry Pi spycam (Adafruit) and a fisheye lens to reduce the sensor's form factor. The TacCylinder uses a catadioptric mirror to achieve 360°vision. of 2 (from 161 to 85 mm). The base and camera mount are also combined into a single piece to simplify the overall sensor design (Fig. 4, middle panel). This sensor design is ideal for mounting as an end-effector to an industrial robot arm, which has been the preferred platform for investigating tactile perception and control in our laboratory. 7,[31][32][33] TacTip-GR2. A version of the TacTip created for integration onto the GR2 gripper, 27 the TacTip-GR2 combines the design features of the TacTip sensor with a reduced overall form factor (44 mm; Table 1). A smaller camera (Adafruit spy camera for Raspberry Pi) and fisheye lens replace the Microsoft LifeCam HD webcam, to enable this reduction in size.</p>
<p>The pin layout of the modular tips is maintained for this version of the TacTip, but a flatter skin component creates more space between the gripper's fingers, allowing larger objects to be grasped by the gripper.</p>
<p>This flatter skin (Fig. 4) leads to a change in sensor dynamics, with a smaller volume tip reducing the pin deflections but increasing the contact surface area for flat objects.</p>
<p>TacTip-M2. Applying TacTip design principles to the OpenHand model M2 gripper, 26 we created the TacTip-M2, 10 an elongated tactile thumb (Fig. 6) for application to in-hand dexterous manipulation of an object using only tactile feedback as guidance. We believe tactile manipulation to be an essential component in allowing robots to effectively interact with objects in complex, dynamic environments. The M2 gripper was chosen for integration as it is 3D printed and open source, has good grasping capability, and provides an opportunity for simple tactile manipulation to be investigated along one dimension.</p>
<p>As with the TacTip, the TacTip-M2 is fabricated through multimaterial 3D printing and has regularly spaced rows of pins on the inside surface of its skin. The TacTip-M2 features both an original version for deployment where form-factor is not an issue (e.g., for mounting at the end of a robot arm) and an improved, more compact version for integration on the M2 gripper featuring a rearranged webcam and macro lens.</p>
<p>TacCylinder. The TacTip has been adapted with a catadioptric mirror system to provide a 360°cylindrical tactile sensing surface (Fig. 7), forming the TacCylinder sensor.</p>
<p>The TacCylinder is designed for capsule endoscopy, providing remote tactile sensing capabilities within the gastrointestinal tract. 28 Capsule endoscopy is a pill-like technology swallowed by the patient, which travels through the intestines visually surveying the lumen for suspicious indications of ill health.</p>
<p>The TacCylinder is a larger sensor than the TacTip and thus contains more pins of larger dimensions (Table 1). A tube through its center holds the camera and a 360°mirror system. Filling the inside cavity of the sensor with the optically clear silicone gel is further aided by integrated 3Dprinted O-ring-type seals.</p>
<p>For validation of perceptual performance, we test the TacTip, TacTip-GR2, TacTip-M2, and TacCylinder sensors on the same cylinder rolling task, to evaluate localization performance for each sensor. Note the TacTipGR2 is mounted on the standard TacTip body for convenience (Fig. 8). This experiment was chosen because it is simple to set up for all tactile sensors and was also compatible with the range of different designs, morphologies, and uses of the sensors, from manipulation tasks with robot hands to contacting objects with stand-alone sensors.</p>
<p>The sensors are attached as end-effectors to a 6-DOF ABB IRB120 industrial robot arm (Fig. 8), and brought into contact with a 25 mm diameter cylinder, by lowering the sensor's tip to 3 mm below its first point of contact with the cylinder. The cylinder is then horizontally rolled, with a custom platform constraining movements to one dimension (defined as y). The platform consists of a flat Perspex bottom plate, with two Perspex walls that constrain the cylinder to move along them (Fig. 8). A rubber surface is added to the bottom plate to ensure the cylinder does not slip while rolling. Magnets mounted at the ends of the cylinder and one end of the roller provide a home position for the cylinder. The cylinder is rolled forward in a nonslip motion in 0.1 mm increments over a 72 mm range, totaling 720 different locations along the y-axis.</p>
<p>These data are collected twice for use as distinct training and test sets for offline cross-validation (see the Validation section), ensuring results are obtained from sampling on an independent set from the training data.</p>
<p>Formally, data are in the form of contact data z 1:t ¼ z 1 , . . . , z t f g encoded as a multidimensional timeseries of sensor values</p>
<p>with indices j, k labeling the time sample and data dimension, respectively. In our case, 10 frames are gathered per location, thus N samples ¼ 10 and we consider x-and ydeflections of each of the pins as a separate dimension k, with N dims ¼ 254. These contact data give evidence for the present location class y l , 1 l N loc , considered one of a set of distinct punctual locations (here N loc ¼ 72 locations spanning 72 mm are used).</p>
<p>The location likelihoods P k (z t jy l ) use a measurement model of the training data for each location class y l . log P(z t jy l ) ¼ +</p>
<p>constructed by assuming all data dimensions k and samples s k j ð Þ within each contact are independent (so individual log likelihoods sum). Here this sum is normalized by the total number of data points N samples N dims to ensure that the likelihoods do not scale with the sample number of a contact.</p>
<p>As with previous work on robot tactile perception, 34,35 the probabilities P k s k j ð Þjy l ð Þ are found with a histogram method applied to training data for each location class y l . The sensor values s k for data dimension k are binned into equal intervals I b , 1 b N bins over their range (here with N bins ¼ 100). The sampling distribution is given by the normalized histogram counts n kl b ð Þ for training class y l :</p>
<p>where n kl b ð Þ is the sample count in bin b for dimension k over all training data in class y l .</p>
<p>Technically, the likelihood is ill-defined if any histogram bin is empty, which is fixed by regularizing the bin counts with a small constant (@1). FIG. 8. The TacTip, TacTip-GR2, TacTip-M2, and TacCylinder mounted on the ABB robot arm, with the 25 mm diameter cylinder being rolled over a 72 mm range.</p>
<p>Sensor validation provides an analysis of localization accuracy and algorithm performance using cross-validation performed after data collection. Two sets of data, termed training and testing, are gathered for cross-validation. Data z t is then sampled from the test set and classified according to a maximal likelihood approach, identifying the location y l based on the maximal location likelihoods P(z t jy l ) of that contact data. The mean absolute error for each location class e y y ð Þ is then evaluated over each test run at a given location, with the mean error e y ¼ + y e y y ð Þ N loc the average over all locations.</p>
<p>TacTip. As the TacTip rolls the cylinder across a flat surface in the y direction (as described in the Experimental Setup and Data Collection section), we note the pin deflections in the x-direction (perpendicular to cylinder movement direction) have a regular pattern, with successive rows of pins deflecting outward (deflection reaching -30 to 30 px) and then returning to baseline (Fig. 9A,B). The y-deflections of pins (in the direction of cylinder motion) display an irregular pattern, however, with all pins initially dipping downward before recovering sequentially to baseline positions. This FIG. 9. Tactile data from all four sensors. Data were sampled at 0.1 mm intervals along the 72 mm range of cylinder motion (720 samples). (A, C, E, G) pin displacements along the x-axis and (B, D, F, H) along the y-axis (direction of the cylinder roll). The four right-most panels identify pins for each sensor and display the x-and y-directions.</p>
<p>TacTip-GR2. Data acquired from the TacTip-GR2 produced similar patterns of x-and y-deflections to the TacTip, although deflections are less pronounced (Fig. 9C,D). This is most visible in the x-direction, with an approximate deflection range of -12 to 12 px for the TacTip-GR2 (c.f. -30 to 30 px for the TacTip).</p>
<p>We note that the pins which contact the cylinder first (red and orange in Fig. 9) have the largest y-deflections in the TacTip case, whereas in the TacTip-GR2 data, the pins in the middle of the sensor (yellow and green in Fig. 9) are the most deflected in the y direction. This difference is a consequence of the shape of the sensors, with the TacTip's dome-shaped tip creating large y-deflections close to the initial contact. The TacTip-GR2 is mostly flat with a slight bulge around its center, creating a central area in which internal dynamics enables larger deflections. Note that these dome-shaped morphologies also explain the greater deflections of central pins (yellow and green) relative to pins around the sensors' edges (dark red, dark blue).</p>
<p>TacTip-M2. Data from the TacTip-M2 have a regular, repeated sinusoidal pattern, with a deflection range of -9 to 4 px in the x-direction and more pronounced deflections (-14 to 6 px) in the y-direction (Fig. 9E,F). This makes sense as it is the direction of movement of the cylinder, and is also the direction with most freedom of movement for pins, since it corresponds to the sensor's long axis. The sinusoidal pattern arises from the synchronized movement of rows of pins on the TacTip-M2 as the cylinder moves across them.</p>
<p>An asymmetry is also noticeable in both the x-and ydirections, with the magnitude of x-deflections increasing as the cylinder is rolled forward, and peaks of the sinusoidal pattern in the y-deflections gradually migrating downward from +8 to +2 px. This is likely due to the intrinsic mechanical asymmetry of the TacTip-M2, arising from the way in which the skin and base connect at each end of the sensor (Fig. 6).</p>
<p>TacCylinder. Data for the TacCylinder show a regular pattern of deflections (-6 to 2 px in the x-direction), which is greater in the y-direction (-4 to 12 px) (Fig. 9G,H). We only consider pins from the lower half of the TacCylinder, as the pins on the top half are unaffected by contact with the cylinder. We note a slight initial increase and then decrease of the peak amplitudes of deflections in the y-direction, showing that lower pins with more pressure applied are deflected further.</p>
<p>Thus, we can observe from the data gathered in this experiment from all four sensors that sensor morphology has a huge impact on the aspect and quality of collected data. The overall pattern of pin deflections, their relative and absolute amplitudes, and the order in which they deflect are all strongly dependent on sensor morphology. The next section explores how these differences affect performance on cylinder localization.</p>
<p>TacTip. Localization performance of the TacTip is tested using the validation procedure detailed in the Materials and Methods (Validation section), and results are summarized in Table 2. The localization accuracy is an average e y ¼ 0:20 mm over all location classes (Fig. 10A), and is below 1 mm everywhere. Considering the closest pins on the TacTip skin (in the center) are spaced 2.4 mm apart, and the x-and y-deflections of these pins act as taxels, we consider the resolution of the sensor to be 2.4 mm. As such, the TacTip demonstrates *12-fold super-resolution 7 over the cylinder's movement range.</p>
<p>In a previous study, 31 the TacTip with cast silicone skin was applied to the cylinder roll task as a demonstration of tactile manipulation along complex trajectories. That study found approximately eightfold super-resolved acuity; thus, our novel 3D-printed TacTip gives a similar order of superresolved acuity.</p>
<p>TacTip-GR2. The TacTip-GR2's localization accuracy averages e y ¼ 0:16 mm and remains below 0.3 mm over the entire range (Fig. 10B), corresponding to 15-fold superresolution over the pin spacing of 2.4 mm. We interpret this slight improvement in localization relative to the TacTip sensor as a consequence of the flat surface of the TacTip-GR2 creating a more consistent pattern of pin deflections over the cylinder location range (Fig. 9).</p>
<p>TacTip-M2. Localization accuracy for the TacTip-M2 averages e y ¼ 0:24 mm over all location classes (Fig. 10C), and submillimeter accuracy is evident over the full location range. Internal pins acting as taxels are spaced 3.5 mm apart on the sensor skin in the x-and y-directions. As such, the TacTip-M2 again demonstrates *15-fold super-resolution over the cylinder's movement range.</p>
<p>TacCylinder. Localization accuracy for the TacCylinder averages e y ¼ 0:22 mm over all location classes (Fig. 10D), and submillimeter accuracy is displayed over most of the range of locations (3-72 mm). Note that the high errors on the initial range (0-7 mm) are linked to the TacCylinder not yet being fully in contact with the cylinder. Pins on the TacCylinder are spaced by a minimum of 4.3 mm on the sensor skin. As such, the TacCylinder demonstrates *19fold super-resolution over the cylinder's movement range.</p>
<p>The TacTip has been applied to a quality control task with potential applications to car manufacturing. In this study, active touch algorithms were used to identify gap widths to 0.4 mm accuracy, and vertical depth above the gap to 0.1 mm accuracy. 32 Thus, mounting the TacTip on an industrial robot arm offers an accurate and reliable solution to automated quality control on the production line.</p>
<p>Another application of the TacTip sensor is in composite layup (Elkington et al. Using tactile sensors to detect defects during composite layup; unpublished data), in which tactile sensing could provide a real-time feedback to industrial robots to detect defects and irregularities during composite layup. This is a step toward fully automated composite layup, eliminating the need for costly and time-consuming manual ''hand'' layup.</p>
<p>The TacTip sensor thus presents solutions to the manufacturing industry to automate and potentially improve on tasks currently carried out manually.</p>
<p>The TacTip-M2 is adapted for use on the M2 gripper. 26 As such, objects can be rolled vertically up and down the sensorized gripper along a 20 mm range (Fig. 11, left panel). After training, trajectories can be followed based solely on tactile data, successfully performing one-dimensional inhand tactile manipulation. 10 The TacTip-GR2 integrated in the GR2 gripper can perform in-hand tactile reorientation of objects, a different form of tactile manipulation. Here both mobile fingers are tactileenabled, rotating objects along a curved trajectory 36 (Fig. 11, right panel).</p>
<p>Tactile manipulation tasks allow for the complex and precise handling of objects in-hand. These capabilities will enhance the safety, interactivity, and overall potential of robots in the fields of human-robot interaction, assistive and industrial robotics.</p>
<p>Exploratory tactile servoing has been demonstrated with the TacTip in experiments involving several twodimensional objects: a circular disk, a volute laminar, and circular or spiral ridges. 33 A similar approach to that used here to validate the performance of the tactile sensors was used, adapted with principles from biomimetic active perception to perceive and control the edge orientation and radial location relative to the edge. The control policy rotated the sensor to maintain its orientation and radial location as the sensor moves tangentially along the edge, successfully following the contours of all the tested objects.</p>
<p>This approach combines active perception and haptic exploration into a common active touch algorithm, with the potential to generalize to more complex, 3D tasks. It also relates to human exploratory procedures 37 (contour following here), and the control policy could thus be extended to include more of these exploratory procedures (for instance, enclosure to detect volume in a robot hand).</p>
<p>The TacTip was also used to investigate discriminationbased perception. 38 In that study, the TacTip was trained to discriminate between two edges of different sharpnesses and obtained a just noticeable difference ( JND) of 9.2°, comparing favorably to a previously reported human JND of 8.6°.</p>
<p>Future work with the TacTip sensors could further this approach to explore the concept of robo-psychophysics, 39 in which human psychophysics experimental approaches are used to evaluate artificial sensors.</p>
<p>Recent work by Winstone et al. 28 has shown the ability of the TacCylinder to detect surface deformation of various lumps associated with suspect tissue that could reside within the gastrointestinal tract. These sensing data have been applied to create a 3D rendering of the test environment. Currently, work is focused on the discrimination between lump features and tissue density toward more accurate identification of submucosal tumors. 9 Work has been carried out in parallel to create a self-contained pneumostatic palpating sensor. 40 In the past, the TacTip 41 has been used as part of a teletaction system for lump detection, in which tactile feedback is relayed to the surgeon. More recently, the TacTip's design principles were applied to a pillow used during magnetic resonance imaging (MRI) scans to detect subtle head movements. 42 Thus, TacTip sensors hold promise for multiple medical applications, particularly in tumor detection, capsule endoscopy, and MRI scans.</p>
<p>Future iterations of TacTip sensors could create novel solutions for known practical problems in robotics, bringing tactile sensing to new areas and applications. The 3D-printed nature of these sensors and the open availability of CAD files and fabrication methods (softroboticstoolkit.com/tactip) enable easy use, adaptation, and improvement of the TacTip sensors. As well as further exploration of the areas described above, novel applications include patches of tactile skin to cover a robot surface or tactile feet to improve walking in bipedal robots.</p>
<p>We tested four 3D-printed sensors on a cylinder rolling task: the TacTip, TacTip-GR2, TacTip-M2, and TacCylinder. We found that all four sensors were able to localize the cylinder with submillimeter accuracy. All four sensors demonstrated above 10-fold super-resolution, with the TacTip-GR2 performing best (although it also had a closer pin spacing than the TacCylinder), possibly because its morphology is the most suited to a rolling task.</p>
<p>All the TacTip sensors utilize the same working principle, yet their different morphologies yield appreciable differences in behavior. These results reinforce the validity of the tight link between shape and function in a sensor and show the advantage of using 3D-printing techniques, which allow morphological customization. In particular, multimaterial printing enables a full sensor to be 3D printed, including its soft skin, opening up further possibilities of experimentation with different materials and morphologies. The sensor's compliance could be adjusted for different tasks by modifying the 3D-printed skin material and the shore hardness of silicone gel used in the tip. Further experiments on parameters such as pin length, pin spacing, and pin width could also reveal optimal solutions for TacTip designs applied to specific tasks. The TacTip-M2 and TacCylinder sensors could be made modular to facilitate these experiments. Directions for future work include accelerating the data processing algorithm and overall control loop to establish tasks with continuous, uninterrupted motion and miniaturizing the TacTip further for integration into a wide range of robotic hands.</p>
<p>To encourage the use of the TacTip design principles for new tactile sensing applications, we have open-sourced the hardware on the soft robotics toolkit (www.softrobotic stoolkit.com/tactip) along with fabrication instructions. This submission won the ''2016 contributions to soft robotics research'' prize and aims to provide open access to cheap customizable tactile sensors, which are currently lacking from the field. It is our intention that research groups will use and develop TacTip sensors, and take advantage of 3Dprinting technologies to apply our design principles to novel sensors and systems of their own devising.</p>
<p>Soft tactile sensors are essential for manipulation tasks and safe human-robot interaction. Our suite of soft biomimetic tactile sensors displays strong super-resolved performance on localization tasks. These sensors provide a basis for future research and innovation in the field of tactile sensing.</p>
<p>THE TACTIP PROJECT</p>
<p>WARD-CHERRIER ET AL.</p>
<p>WARD-CHERRIER ET AL.</p>
<p>The authors thank Sam Coupland, Gareth Griffiths, and Samuel Forbes for their help with 3D printing and Jason Welsby for his assistance with electronics. N.L. was supported, in part, by a Leverhulme Trust Research Leadership</p>
<p>Award on ''A biomimetic forebrain for robot touch'' (RL-2016-039), and N.L. and M.E.G. were supported, in part, by an EPSRC grant on Tactile Super-resolution Sensing (EP/ M02993X/1). L.C. was supported by the EPSRC Centre for Doctoral Training in Future Autonomous and Robotic Systems (FARSCOPE).</p>
<p>The data used in this article can be accessed in the repositories at http://doi.org/ckcc.</p>
<p>No competing financial interests exist.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f78066426"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Therapeutic nanoparticles (TNPs) aim to deliver drugs more safely and effectively to cancers, yet clinical results have been unpredictable owing to limited in vivo understanding. Here we use single-cell imaging of intratumoral TNP pharmacokinetics and pharmacodynamics to better comprehend their heterogeneous behaviour. Model TNPs comprising a fluorescent platinum(IV) pro-drug and a clinically tested polymer platform (PLGA-b-PEG) promote long drug circulation and alter accumulation by directing cellular uptake toward tumourassociated macrophages (TAMs). Simultaneous imaging of TNP vehicle, its drug payload and single-cell DNA damage response reveals that TAMs serve as a local drug depot that accumulates significant vehicle from which DNA-damaging Pt payload gradually releases to neighbouring tumour cells. Correspondingly, TAM depletion reduces intratumoral TNP accumulation and efficacy. Thus, nanotherapeutics co-opt TAMs for drug delivery, which has implications for TNP design and for selecting patients into trials.</p>
<p>pproximately half of all cancer patients who receive chemotherapy are treated with one of three clinically approved platinum (Pt) drugs-cisplatin, carboplatin, and oxaliplatin 1 . These Pt compounds are first-line agents in ovarian, lung, head and neck and testicular cancers, among others, and development of combination therapies using Pt compounds is an active area of research 2 . Unfortunately, most cancers either exhibit intrinsic Pt resistance or ultimately develop resistance to treatment through mechanisms including reduced drug uptake, altered cellular metabolism, increased DNA repair, chemoprotective niche formation and/or activation of oncogenic and anti-apoptotic pathways 3 . Dose escalation and combination drug regimens help overcome resistance. However, Pt-related toxic side-effects including neurotoxicity and nephrotoxicity limit some of these approaches, indicating the need for new strategies.</p>
<p>To circumvent these problems, specialized drug-delivery mechanisms such as nanoparticles (NPs) have been introduced to enhance local drug accumulation in tumours while simultaneously mitigating systemic toxicities 4,5 . Non-encapsulated Pt compounds in particular are often plagued by poor pharmacokinetic (PK) properties. They generally must be intravenously administered over a prolonged period (sometimes over 24 h) because promiscuous Pt reactivity causes side effects and the covalent binding to plasma proteins such as albumin consequently neutralizes its activity. Recent work has demonstrated the possibility of using NPs to encapsulate Pt pro-drugs, thereby (i) extending the circulating half-life of the unreacted Pt compound and enabling controlled drug release 6 ; (ii) facilitating precisely engineered Pt-based combination therapies through co-encapsulation with additional drugs 7,8 (or small interfering RNA treatments 9 ); (iii) enabling the administration of more lipophilic and newer-generation Pt compounds 10 and (iv) modifying tissue distribution and enhancing intratumoral accumulation 6,9 . The last is thought to occur through enhanced permeability and retention (EPR) effects and has been termed 'passive NP targeting' 11 . In theory, enhanced permeability of the abnormal tumour microvasculature (TMV) should allow therapeutic nanoparticles (TNPs) to enter the tumour interstitial space, whereas suppressed lymphatic filtration and increased cellular uptake should allow them to stay there 12 . Although TNPs of Pt-based anticancer agents have advanced to clinical trials 13,14 , results have been mixed, presumably due to heterogeneous EPR effects in different tumours combined with limited experimental data from patients on the effectiveness of this mechanism as related to enhanced drug accumulation 15 . Furthermore, the inter-related in vivo PK and pharmacodynamics (PD) of TNPs are more difficult to understand than those of the unencapsulated drug. TNP drug delivery is inherently a multi-step process, defined by PK of the TNP vehicle, drug release dynamics that may change depending on the in vivo environmental context, and PK of the Pt payload itself. Little experimental evidence exists that describes how this multi-step drug delivery sequence performs in vivo and within tumours, despite its critical importance to overall therapeutic outcome. This lack of understanding clearly represents a bottleneck in the design and development of more efficacious therapies.</p>
<p>Here we use high-resolution microscopic imaging in live tumour-bearing mice to test the hypothesis that therapeutic nano-encapsulation not only affects traditional bulk PK properties, but also significantly influences heterogeneous drug uptake and response at the single-cell level within tumours 16,17 . We engineer a platform that for the first time allows simultaneous imaging of both a B100-nm TNP vehicle as well as its Pt payload, in addition to monitoring DNA damage at the single-cell level in real time. As expected, our results show that nanoencapsulated Pt exhibits a longer circulating half-life than traditional unencapsulated Pt compounds. However, we quite unexpectedly find that TNPs accumulate at high levels within tumour-associated macrophages (TAMs), and that TAMs serve as 'cellular drug reservoirs'. Indeed, TAMs release the Pt payload into neighbouring tumour cells over time. Depletion of macrophages significantly decreases intratumoral Pt accumulation and correspondingly increases tumour growth. Overall, this work establishes a paradigm for NP drug delivery based on the principle that TAMs can sequester TNP payload and gradually release it into the surrounding tissue, thereby serving as 'drug depots.'</p>
<p>Dual imaging shows congruent vehicle and payload kinetics. For clinical applicability and generalizability, TNPs in this study were designed to incorporate desirable properties of previously described polymeric nano-formulations that have entered clinical trials 5 , especially those of materials that have received Food and Drug Adminstration approval. TNPs were formulated by combining three compounds (compounds 1-3, Fig. 1a) via nano-precipitation, using spectrally complementary derivatives of BODIPYs as ideal fluorophores for efficient nano-encapsulation that convey lipophilicity and robust in vivo imaging arising from in vivo structural stability, environmentally robust fluorescence, high brightness and high photostability 16,[18][19][20] . Compound 3 (poly(D,L-lactic-co-glycolic acid)-b-poly(ethylene glycol); PLGA-b-PEG) self-assembles to form the hydrophobic PLGA core of the NP and hydrophilic PEG outer shell. For the cytotoxic payload, we used a novel Pt(IV) pro-drug</p>
<p>) with a C 16 aliphatic carbon chain and a BODIPY (l ex ¼ 498 nm, l em ¼ 543 nm; Supplementary Fig. 1a) as the two lipophilic ligands axially coordinated to the Pt(IV) centre. NPs were similar in size (135 ± 1 nm; standard error of the mean (s.e.m.), across n ¼ 12; Supplementary Fig. 1b-c), polydispersity (PDI ¼ 0.18 ± 0.01; s.e.m. across n ¼ 12) and drug release rates (t 1/2 release ¼ 15 h; n ¼ 2; Supplementary Fig. 1d) compared with previously published Pt(IV) nano-formulations 6,9 , and were stable in physiological saline (Supplementary Fig. 1e). Free carboxylic acid terminal groups on the PEG gave TNPs a slight negative charge (zeta-potential ¼ À 23±1.4 mV; s.e.m. across n ¼ 4), which has been shown in some cases to benefit tumoral accumulation [21][22][23][24] and mirrors TNPs in the clinic 5 . C 16 -Pt(IV) remains relatively stable in whole blood 25 . However, upon reduction to the active Pt(II) compound cisplatin, dissociated BODIPY increases fluorescence by sevenfold owing to loss of quenching by Pt(IV) (Supplementary Fig. 1f-g). BODIPY fluorescence thus serves as an effective indicator of both pro-drug delivery and activation. Overall, these properties enable clearly distinguishable imaging of both the TNP vehicle and its payload, in a stable and clinically relevant nanoformulation platform.</p>
<p>We performed a series of in vitro experiments to characterize TNP behaviour in tumour cell culture (Supplementary Fig. 2a). Co-localization studies with fluorescent compartmentally localized proteins showed that the TNP vehicle moved from early to late endosomes over the course of 24 h (Supplementary Fig. 2b). Compared with the TNP vehicle, the TNP payload exhibited more diffuse intracellular localization, and co-localization peaked in the late endosome 24 h post treatment (Supplementary Fig. 2c). Payload fluorescence increased over time owing to Pt reduction and BODIPY de-quenching (Supplementary Fig. 2d). Doseresponse TNP treatment indicated that intracellular fluorescence correlates well with overall Pt uptake (R 2 40.99) and resulting DNA damage (Supplementary Fig. 3), thereby validating the use of fluorescence as a surrogate marker of cellular payload content. Together, these results provide evidence that, over the course of 24 h, TNPs accumulate in endosomes and lysosomal compartments, where the Pt pro-drug is activated through reduction to form cisplatin.</p>
<p>TNPs exhibit long TMV half-life and perivascular cell uptake. We first used time-lapse intravital imaging to characterize PK within a xenograft tumour model often used for intravital studies (Fig. 1) 16,[26][27][28] . Tumours were generated from subcutaneously implanted HT1080 cells expressing a fluorescently tagged DNA damage response protein, 53BP1, which localizes to the nucleus 29,30 . TNPs reached the TMV within 10-15 min of intravenous injection, and at early time points (to30 min) the vehicle and its payload exhibited strong co-localization within vessels (Fig. 2a; intravascular Pearson's correlation r ¼ 0.8 ± 0.02, s.e.m. across n ¼ 4; Mander's M1 and M240.95). Both the vehicle and its payload showed initial vascular PK similar to each other (Fig. 2b; t 1/2 vehicle ¼ 55±5 min; t 1/2 payload ¼ 61±6 min; s.e.m. across n ¼ 6), to previous studies using similar nanoformulations entering the clinic 5,6,31 , and to clinical NP formulations such as PEGylated liposomal doxorubicin (DOXIL; t 1/2 initial o5.2 h in humans and 2 h in rats 32,33 ). Immediately as the TNPs reached the TMV, roughly 10% of the payload diffused into the surrounding tumour tissue. Such an initial burst of drug release was also observed in vitro (Supplementary Fig. 1d) and with similar previously described nano-formulations 34,35 , characterized by significantly faster release kinetics at initial phases followed by a later phase of slower release. Notably, PK imaging of BODIPY-labelled Pt compounds that were not nano-encapsulated revealed much more rapid vascular PK (t 1/2 unencapsulated ¼ 10±5 min 29 ). Therefore, despite an initial burst of Pt release seen both in vitro (Supplementary Fig. 1d) and in vivo (Fig. 2), nano-encapsulation conferred a relatively long circulation half-life.</p>
<p>Over the course of several hours, TNPs moved from the TMV (to1 h) specifically to peritumoral host cells (1-3 h) adjacent to or even extending processes into the TMV. Uptake of TNPs by tumour cells themselves occurred more gradually and to a lesser degree compared with these perivascular host cells. By 24 h, TNPs were undetectable in vessels and had accumulated primarily in a heterogeneous mix of tumour cells and host cells, with host-cell uptake characterized by high local accumulation within cell-sized (7±1 mm; s.e.m. across n ¼ 4 tumours) diameters. At 24 h postinjection, the TNP payload also co-localized with the TNP vehicle in these host cells (Pearson's correlation within tumour tissue: r ¼ 0.7 ± 0.08; Mander's M1 and M240.6 ± 0.05; s.e.m. across n ¼ 4). Compared with the TNP vehicle, however, the payload accumulated more diffusely throughout the bulk tumour tissue, suggesting some payload release from the TNP vehicle (Supplementary Fig. 4a). We quantified these observations by measuring the coefficient of variation (CV) across cells within the tumour tissue (Supplementary Fig. 4b). The payloads exhibited 440% decrease in CV compared with the TNP vehicle, indicating more homogeneous distribution. In contrast to TNPs, naked BODIPY-labelled Pt that was injected in the absence of an encapsulating NP vehicle showed a substantially more homogeneous distribution within tumour tissue, with little preferential accumulation in any particular cell type (Supplementary Fig. 4; 60% reduction in CV). In summary, these data show that (i) nano-encapsulation enables a relatively long circulating halflife of the Pt(IV) pro-drug; (ii) nano-encapsulation influences spatial distribution within the bulk tumour tissue and (iii) TNPs primarily accumulate in perivascular host cells and, to a lesser extent, tumour cells.</p>
<p>We next performed a combination of intravital imaging, flow cytometry and histology studies to determine in which immunologically defined cell populations the TNP vehicle and its payload accumulated within the bulk tumour mass at 24 h, after TNPs had largely cleared the circulation. With the same HT1080 xenograft model used in the previous imaging experiments, we labelled TAMs with a fluorescent dextran-coated NP 16 and found significant TNP uptake in TAM-rich regions of the bulk tumour mass (Fig. 5a). For more detailed immunological examination, we next performed flow cytometry analysis of HT1080 tumours. Results show that tumour cells made up 61% of the bulk tumour; 31% of the cells within the bulk tumour were CD45 À host cells (erythrocytes, tumour associated fibroblasts, endothelium and others); and the remaining 8% were CD45 þ leukocytes (Fig. 5b). TAMs made up the largest population of leukocytes within the bulk tumour and also accumulated the highest levels of both TNP vehicle and payload on a per-cell basis (Fig. 5c). Because tumour cells far outnumbered TAMs in the HT1080 xenograft model, the majority of TNP vehicle and payload within the bulk tumour still resided in tumour cells themselves (Fig. 5d). Nonetheless, even though TAMs comprised only 4% of cells within the total tumour mass, they accumulated more than 40% of the total injected TNPs relative to tumour cells, and 30% of the total TNP overall.</p>
<p>To directly visualize genetically defined tumour-associated host leukocytes, we imaged TNP vehicle uptake in tumour-bearing fractalkine Cx3cr1 GFP/ þ reporter mice, which are known to contain GFP þ macrophages 38 . In this model, KRAS mutant p53 À / À (KP) cells derived from autochthonous lung tumours 39 were subcutaneously implanted into immunocompetent Cx3cr1 GFP/ þ reporter mice, and TNP vehicle (without the green fluorescent payload) was intravenously administered. The vast majority of TNP vehicle accumulated within these GFP þ host leukocytes, especially near TMV (Fig. 6a,b). Using the above described KP lung cancer and intraperitoneal OVCA xenografts, we confirmed by histology that high levels of TNP vehicle accumulate in F4/80 þ host phagocytes in these disease models as well (Fig. 6c and Supplementary Fig. 6). These analyses ultimately corroborate results from the intravital imaging data showing uptake of TNPs in tumour cells but also host cells, which are confirmed here as TAMs.</p>
<p>TNP payload spatially redistributes from TAMs to tumour cells. Based on intravital imaging evidence showing that the Pt(IV)payload was more diffusely distributed within tumour tissue compared with its TNP vehicle (Supplementary Fig. 4), we next quantified the extent of payload redistribution and its effect on drug response. Using flow-cytometry data, we confirmed that tumour cells exhibited more than twice the amount of payload accumulation as a ratio of vehicle accumulation, compared with TAMs (Fig. 7a), thereby suggesting that payload may transfer from TAMs to tumour cells. We hypothesized that local payload release from TAMs into neighbouring tumour cells would lead to elevated payload concentration in these tumour cells, which would in turn enhance DNA damage. By histology we also measured greater than threefold elevated payload concentrations within roughly one cell-length (15 mm) of TAMs (Fig. 7b,c), and analysis of intravital imaging data provided further evidence that relevant payload concentration gradients occur over length-scales ofo25 mm (Supplementary Fig. 7a). One explanation for these observations is that TAMs induce neighbouring tumour cells to take up more TNP directly; however, the TNP vehicle itself was not similarly elevated in the same neighbouring region (Fig. 7c). Tumour cells within the same phagocyte-neighbouring region also exhibited higher DNA damage on average, as determined by histology (Fig. 7d) and supported by corroborating intravital imaging analysis (Supplementary Fig. 7b). These analyses cumulatively show local payload redistribution from TAMs to neighbouring tumour cells exhibiting elevated DNA damage. We next performed a series of in vitro experiments to directly test whether macrophages could release functional, DNAdamaging TNP payload into their surrounding environment. Similar to in vivo observations, we found that in vitro macrophages accumulated TNPs more rapidly and to a greater degree than tumour cells (Supplementary Fig. 8a). Once taken up by macrophages, Pt-payload was released at high levels into the extracellular supernatant. In fact, over the course of 24 h, more Pt was found in the supernatant than in the macrophages themselves (Supplementary Fig. 8b,c). The Pt-containing macrophage supernatant was both DNA damaging (Supplementary Fig. 8d) and cytotoxic (Supplementary Fig. 8e). In contrast, supernatant from macrophages treated with unencapsulated cisplatin at concentrations ranging from 1 to 300 mM was not cytotoxic to tumour cells (Supplementary Fig. 8e). For supernatant from TNP-treated macrophages, filtration with molecular-weight cutoff filters (3 and 100 kDa) did not reduce its potency, which indicated that cytotoxic effects were independent of macrophagederived cytokines or other signalling proteins (Supplementary Fig. 8f). In addition, Pt-containing macrophage supernatant exhibited 50% inhibitory effect on tumour cell viability/ cytotoxicity at Pt concentrations of 1.5±0.5 mM (s.e.m. across n ¼ 3) within the macrophage supernatant (Supplementary Fig. 7e), which is comparable to the potency of the Pt-payload when TNP was directly applied to tumour cells (IC 50 ¼ 1.7 ± 0.02 mM; s.e.m. across n ¼ 2; Supplementary Table 1). Taken together, these combined in vitro and in vivo data further confirmed that TAMs can serve as drug depots that accumulate high levels of TNPs and then release their DNA-damaging cytotoxic payload to the surrounding tumour tissue.</p>
<p>TAM depletion reduces TNP accumulation and efficacy. Finally, we tested whether TAM depletion would reduce the therapeutic efficacy of TNP in cancers. Macrophages were systemically depleted by pre-treatment with clodronate liposomes (clod-lip) 40 before TNP injection. In this tumour model, macrophage depletion itself had no detectable impact on tumour growth (P ¼ 0.2; two-tailed two-way analysis of variance; n ¼ 38 mice). However, it substantially reduced the degree to which TNP treatment was able to slow tumour growth (Fig. 8a). Direct measurement of intratumoral TNP accumulation confirmed that macrophages play a key role in mediating drug delivery: macrophage-depleted tumours exhibited both lower total intratumoral Pt (Fig. 8b) and a lower concentration of Pt (Fig. 8c) compared with macrophage-containing tumours, 24 h post administration of TNP, at which time no TNP remained circulating in the TMV of any tumour. The 24% decrease in Pt concentration (from 5 to 3.8 mM; Fig. 8c after converting to molarity) correlates well with the flow cytometry-based estimate that TAMs accumulate 30% of the total intratumoral TNP. It also correlates with the observation that unencapsulated Pt exhibits 37% lower intratumoral accumulation than nano-encapsulated Pt (Supplementary Table 1) 9 . This decrease disproportionately impacted TNP effects on tumour growth, probably because intratumoral Pt concentrations were near the threshold at which HT1080 tumour cells respond (in vitro IC 50 ¼ 3.7±0.1 mM for unencapsulated Pt(IV) payload; s.e.m. across n ¼ 2). TNP clearance kinetics, TMV leakiness and other EPR factors all may influence drug accumulation within the tumour; nonetheless, the experiments here show that all things being equal, macrophage uptake substantially contributes both to the delivery of TNP to the tumour and, consequently, to the therapeutic impact on tumour growth.</p>
<p>Liver TNP uptake is well tolerated and blocks metastasis. Given our evidence for TAMs in mediating TNP delivery, we next investigated TNP effects in the liver, which is a prominent site of the mononuclear phagocyte system and is known to accumulate NPs 6 . Despite substantial liver accumulation (Supplementary Fig. 9a), TNPs did not significantly impact animal body weight (Supplementary Fig. 9b) and did not cause changes outside of the normal range in blood markers of renal or liver toxicity at the therapeutic dose (Supplementary Fig. 9c). Within the bone marrow, another important site of the mononuclear phagocyte system, TNP payload concentrations were much lower (Supplementary Fig. 9d,e). Although clinically relevant doses of un-encapsulated cisplatin caused a significant reduction in the number of nucleated cells in the bone marrow, TNP effects were not statistically significant (Supplementary Fig. 9f,g). Overall, these results demonstrate a positive safety profile despite liver accumulation.</p>
<p>We next tested whether TNP treatment could block the development of liver micro-metastases in a model of haematogenous breast cancer dissemination. 4T1 murine breast cancer cells were intravenously injected into immunocompetent balb/c mice, thus forming tumours in the liver, lung and other organs. To primarily deliver TNPs to host phagocytes rather than tumour cells, we pre-treated naive mice with TNPs, waited 6 h for a majority of the drug to clear circulation, and then injected a single-cell suspension of 4T1 cells. Two weeks later, livers were excised and analysed by histology for tumour burden. Results show that pre-treatment with TNPs reduced the development of micro-metastases by over 65%, and repeated TNP doses caused a slightly greater reduction of 80% (Fig. 9). No treatment impacted tumour burden in the lung (two-tailed t-test; nZ5). Taken together, these results demonstrate that TNPs can safely accumulate in host cells of the liver, thus allowing TNP payload to block the development of local metastases from haematogenously disseminated cancer cells.</p>
<p>This work presents a new paradigm for employing TAMs as 'drug depots' for local delivery of nanotherapeutics to neighbouring tumour cells. Key to the development of this model was new technology for the in vivo visualization of multi-step drug delivery and the corresponding single-cell PD response at high spatiotemporal resolution. With this approach we demonstrated that nano-encapsulation allows for long circulating drug half-life and guides the delivery of drugs to TAMs, from which their functional cytotoxic payloads locally transfer to and damage neighbouring tumour cells. This paradigm most likely extends to other nanoencapsulated therapeutics and non-cancer disease indications in which macrophages accumulate near the target tissue. The clinically tested TNP platform used here 14 can encapsulate other therapeutics including paclitaxel, doxorubicin and irinotecan, which exhibit release rates similar to the Pt(IV) payload [5][6][7] .</p>
<p>Of relevance is that local macrophage accumulation occurs in multiple diseases including type 1 diabetes 41 , rheumatoid arthritis 42 , endometriosis 43 and cardiovascular diseases such as atherosclerosis and myocardial infarction 44,45 . The imaging approach we describe may thus apply to these other pathologies, especially where intravital microscopy has already been successfully used 46 . Although macrophages themselves are often pharmacological targets 47 , concomitant drug delivery to surrounding tissue may be advantageous 48 . Overall, the drug delivery paradigm presented here, along with the complementary imaging technology, portend broad applicability to other TNP strategies and disease indications.</p>
<p>TAMs have been extensively studied and targeted for their roles in disease development, progression and therapeutic response 48,49 . Nonetheless, TAMs have received less consideration in the context of novel nanotherapeutics entering the clinic. Because of their secretion of growth factors, cytokines and proteases, TAMs have been implicated in supporting disease progression by enhancing angiogenesis, metastasis and cancer stem cell niche formation, all while suppressing anticancer immune responses. In multiple indications, high TAM accumulation at tumour sites correlates with poor prognosis 50,51 . Although TAM-mediated tumour neo-vascularization can increase vascular leakage and corresponding therapeutic delivery 52 , TAMs also provide chemoprotective cues to tumour cells, and TAM infiltration following chemotherapy correlates with poor treatment response 52,53 . For these reasons, therapeutic TAM killing or TAM re-polarization into an anti-cancer phenotype represents an active area of development, for example, by targeting colony-stimulating factor 1 receptor (CSF1R) [54][55][56] . In several examples, blocking leukocyte infiltration via CSF1R inhibition or chemokine receptor type 2 ablation enhances response to chemotherapeutics including cisplatin 52 . However, very little experimental data describes how TAM depletion affects the response to nanotherapeutic formulations, and evidence presented here suggests that complete TAM elimination would be undesirable in such contexts.</p>
<p>In contrast to previous reports that focus chiefly on traditional unencapsulated cytotoxic therapies, we show here that TAMs are critical mediators of drug action for nano-encapsulated therapeutics. TAMs and other leukocytes are implicated in taking up a wide range of clinically relevant nanotherapeutics, including liposomal 57 , polymeric 58 and albumin-binding 59 formulations. Nonetheless, in the past, imaging capabilities have generally not allowed detailed insight into the kinetics of drug uptake, payload redistribution and corresponding PD responses at the single-cell or subcellular level to be determined for these compounds 57,60 . Compared with polymeric NPs such as those used here, liposomal formulations generally are associated with slower payload release and decreased payload bioavailability, and there is little evidence that doxorubicin is released from TAMs after they have taken up liposomes 57,61 . In fact, previous failures to develop liposomal cisplatin have been attributed to insufficiently fast drug release 13 . By contrast, polymeric nano-formulations can be designed to release payloads at prescribed rates 5 and even at programmed environmental (for example, pH) conditions 62 . Here, TNPs were engineered to release their payload over a slightly longer time scale (50% drug release at 15 h; Supplementary Fig. 1d) relative to the observed PKs of cellular uptake (TAM uptake observable at 1 h and gradually increases by 24 h), and therefore were ideally suited for TAM-mediated drug delivery as described herein. Overall, this work builds on previous studies that implicate macrophages in TNP uptake; however, through engineered drug release and fluorescence imaging strategies, we demonstrate how the TNP payload can redistribute to neighbouring tumour cells at the site of local TAM accumulation in a therapeutically beneficial manner.</p>
<p>The results presented have implications for future development and clinical use of TNPs. Given that TNPs accumulate in TAMs at high levels, it follows that one criterion for selecting patients into TNP trials may be the degree of peritumoral TAM content, which can be assessed by magnetic resonance imaging using clinically approved NP contrast agents such as ferumoxytol (Feraheme) 63 or experimental theranostics including drugconjugated ferumoxytol derivatives 64,65 . TAM content is To initially deliver TNPs to host phagocytes (rather than tumour cells), TNPs were i.v. administered (1 mg kg À 1 ) 6 h before i.v. injection of 4T1 cancer cells, such that TNP largely cleared the circulation at the time of cancer cell administration. One-third of the cohort received subsequent TNP treatments as indicated.</p>
<p>especially important in the context of therapies that either increase or decrease infiltration of macrophages to tumours. For instance, doxorubicin 52 and CD40 agonist antibodies 66 enhance macrophage infiltration, whereas CSF1R inhibitors 56 and the clinically approved trabectedin 67 decrease TAM accumulation. The paradigm of TAM-mediated drug delivery presented offers a compelling case for consideration of competing drug effects on TAM recruitment, and highlights the potential use of TNP vehicles for more efficient (via improved kinetics and/or targeting subsets) targeting of both TAMs and their neighbouring tumour cells. 4,4-difluoro-5,7-di-methyl-4-bora-3a,4a-daizas-indacene; 6 mg, 21 mmol), and the orange suspension was stirred at RT for 30 min. Finally, a 4 ml portion of N,N-Diisopropylethylamine (DIPEA) was added to the mixture and the resulting orange solution was stirred at RT for 5 h. A 5-ml volume of saturated aqueous NaCl was added to the reaction mixture and a red precipitate was obtained. The precipitate was washed with 3 Â 3 ml water. The resulting orange solid was dried in the vacuum overnight and the product was isolated by silica chromatography (acetone, R f ¼ 0.5). Yield: 7 mg (30%). 1 Polymer materials. Unless otherwise stated, all chemical reagents were purchased from Sigma-Aldrich. PLGA(55:45 lactide/glycolide) 35.2kDa -PEG 3.5 kDa was purchased from Advanced Polymer Materials, Inc. (Cat. #13-01-CX-55/45-35.2k/3.5k; lot 14-02-169). From the vender, gel permeation chromatography indicated M n ¼ 38.8 kDa, M w ¼ 58.8 kDa and PI ¼ 1.52. PEG weight fraction (8.7%±0.3%) and molecular weight were confirmed by 1 H NMR peak integration values, which were also used to calculate the lactide/glycolide ratio. 1 H NMR in CDCl 3 : d (in p.p.m.) 5.12-5.28 (m, (-OCH(CH 3 )CO)), 4.66-4.9 (m, (-OCH 2 COO-)), 3.64 (s, -OCH 2 CH 2 O-), 1.52-1.62 (m, (-OCH(CH 3 )CO-). Differential scanning calorimetry was performed (Q10; TA Instruments), heating from À 60 °C to 100 °C at 10 °C min À 1 , with no apparent crystallization or melting temperature (Tm); glass temperature (Tg) was observed at 39.5 °C. BODIPY-630-NH 2 (Life Technologies; 2.8 mg, 0.0046 mmol) was conjugated to PLGA(50:50 lactide:glycolide) 30-60 kDa (100 mg, ca 0.0023 mmol; Sigma) using previously published procedures 27 , by stirring at RT under Ar for 10 min, adding 1-Ethyl-3-(3-dimethylaminopropyl)carbodiimide (EDCI) (4.4 mg, 0.023 mmol) and 4-Dimethylaminopyridine (DMAP) (2.8 mg, 0.023 mmol) in CH 2 Cl 2 (0.5 ml), and stirring overnight. Polymer was precipitated in cold 1:1 MeOH/Et 2 O, centrifuged (2,700g, 10 min) and repeatedly washed in minimal CH 2 Cl 2 , followed by MeOH/Et 2 O precipitation and centrifugation. The resulting blue precipitate was dried under vacuum.</p>
<p>NP synthesis and characterization. TNPs were prepared by nano-precipitation. Briefly, the following reagents were dissolved in 50:50 (v/v) DMF/acetonitrile (ACN) at the indicated concentrations: PLGA-BODIPY-630 (0.17 mg ml À 1 ), C 16 -Pt(IV)-BODIPY (0.17 mg ml À 1 ) and PLGA-PEG (0.83 mg ml À 1 ). The resulting solution was then mixed and added drop-wise to nuclease-free H 2 O while maintaining a ratio of 20:1 H 2 O to organic solvent. TNPs were stirred overnight and filtered through sterile 0.45 mm syringe filters (regenerated cellulose, 17 mm, Cole Palmer). The TNPs were concentrated by centrifugation using centrifugal filter units (Amicon; Millipore; molecular weight cut-off, MWCO ¼ 100 kDa). The concentrated TNPs were washed twice with de-ionized H 2 O and re-suspended in 1 ml of nuclease-free H 2 O. TNPs were diluted ten times in H 2 O and characterized by size using dynamic light scattering (DLS; Malvern Zetasizer). Zeta-potential was also measured by DLS in dI-H 2 O ( À 25±2.5 mV) and PBS, pH 7.4 ( À 23 ± 1.4 mV). Although the buffered solution produced a slightly higher zetapotential, measurements were not statistically different from each other (two-tailed t-test; a ¼ 0.05). The Pt concentration was determined by graphite furnace flameless atomic absorption spectroscopy (AAS). BODIPY-630 concentration was determined by a microplate fluorimeter after diluting TNPs in DMF and using pure BODIPY-630 for a standard curve. Transmission electron microscopy (TEM) experiments were performed on a JEOL 1011 electron microscope (JEOL). The TEM sample was prepared by depositing 10 ml of TNPs (5 mg ml À 1 ) onto a carbon-coated copper grid. The excess solution was blotted, and the grids were immersed in a solution of phosphotungstic acid stain. The stain was blotted, and the dried grids were immediately used for imaging. To characterize payload release from TNPs (Supplementary Fig. 1d), they were incubated in PBS at 37 °C, filtered using 100 kDa MWCO centrifugal filters (Amicon; Millipore) at the indicated time points and resuspended in fresh PBS. Filtrate was frozen for later analysis by AAS. After 72 h, both the TNPs and the filtrate were analysed by AAS to quantify the remaining Pt. Based on the above procedure, o5% of total PLGA-BODIPY-630 was released from TNPs over the course of 48 h.</p>
<p>Animal models. All animal research was performed in accordance with guidelines from the Institutional Subcommittee on Research Animal Care (Massachusetts General Hospital). All experiments were performed using female mice that were 5-to 7-week old at the start of the experiment. For experiments with HT1080 tumours, 2 million cells in PBS were subcutaneously implanted into nu/nu mice; roughly 2-3 weeks later (once tumours reached B8 mm diameter), imaging experiments were initiated. For the experimental model of haematogenous metastatic dissemination, 0.25 million 4T1 breast cancer cells suspended in PBS were intravenously (i.v.) injected into balb/c mice; roughly 2 weeks later tumours were excised for histological quantification of liver and lung tumour burden in formalin-fixed paraffin-embedded (FFPE), haematoxylin and eosin-stained sections. For intraperitoneal OVCA imaging, 10 million A2780CP cells suspended in PBS were intraperitoneally injected into nu/nu mice. TNP injection and imaging were performed once ascites or tumour masses became evident (roughly 6 weeks later). For histology and imaging experiments using KP cells, 1 million cells were subcutaneously implanted into C57Bl/6 background animals (all JAX), including Cx3cr1 GFP/ þ R26 mT À mG/ þ dual-reporter mice. For dual reporter mice generation, Cx3cr1 GFP/GFP animals were crossed with R26 mT À mG/mT À mG animals that ubiquitously express membrane-anchored tdTomato 68 . The resulting Cx3cr1 GFP/ þ R26 mT À mG/ þ animals can be used to visualize GFP þ tdTomato þ macrophages, monocytes and dendritic cells, as well as tdTomato þ stroma and endothelium.</p>
<p>Cell lines. With some exceptions, cell lines were obtained from American Type Culture Collection and routinely cultured according to the manufacturer's guidelines. OVCA-429 were a kind gift from Dr Michael Birrer (MGH), and A2780CP were from Sigma. The murine lung adenocarcinoma cell line KP1.9 was generated from lung tumour cells of Kras LSL À G12D/ þ ;p53 fl/fl mice (C57/Bl6 background), which develop lung adenocarcinoma after infection with an adenovirus expressing Cre recombinase by intratracheal administration 39 . KP cells were maintained in Iscove's DMEM media supplemented with 10% fetal bovine serum and 5% penicillin/streptomycin. All cell lines were routinely tested for contamination using mouse antibody production testing (VRL Laboratories) and assaying for mycoplasma (VRL Laboratories; Lonza MycoAlert). The fluorescent protein mApple was subcloned into the pLVX vector using restriction enzymes AfeI and NotI. We inserted a XhoI site at in the 5 0 end of the pLVX-mApple multiple cloning site using QuikChange site-directed mutagenesis (Agilent). The pDsRed-Monomer-Mem membrane targeting sequence (Clontech) was PCR amplified for In-Fusion cloning to construct pLVX-Mem-mApple. PCR product was then ligated into pLVX-Apple after AfeI and XhoI digestion, and fully sequenced. Lentiviral particles were produced using Lenti-X HTX Packaging System (Clontech) for transduction into HT1080 and A2780CP cells, which were then selected using 3 mg ml À 1 puromycin. HT1080-53BP1-mApple and A2780CP-53BP1-mApple were developed as previously described 29 .</p>
<p>Intravital microscopic imaging. TNPs were injected at the indicated dose (1 mg kg À 1 unless otherwise stated) via tail-vein catheter immediately after mixing to a final 1 Â PBS solution, at a final volume of 100 ml. Intravital microscopy was performed on an Olympus FV1000 multiphoton imaging system using a XLUMPLFLN Â 20 water immersion objective (numerical aperture ¼ 1.0; Olympus America). Images were scanned sequentially using 405-, 473-, 559-and 633-nm diode lasers in combination with a DM405/488/559/635-nm dichroic beam splitter. Emitted light was then separated and collected using appropriate combinations of beam splitters (SDM473, SDM560 and/or SDM 640) and emission filters BA490-540, BA575-620, BA575-675 and/or BA655-755 (all Olympus America). Dextran pacific blue (l ex ¼ 405 nm) was injected to initially image TMV as previously described 29 . Briefly, 500-kDa amino-dextran (Thermo) was labelled with Pacific Blue succinimidyl ester (Thermo), purified using 30 kDa MWCO centrifugal filtration (Amicon), and 250 mg i.v. injected 10 min before imaging. Dorsal window chamber imaging was performed following previously described procedures 29,69,70 . Briefly, 2 million HT1080-53BP1-mApple cells were suspended in 50 ml PBS and injected under the fascia of nu/nu mice (Cox7, MGH) 30 min following surgical chamber implantation, and imaged 2 weeks later.</p>
<p>Histology. Excised tumours were embedded in optimal cutting temperature (OCT) compound, flash-frozen, sectioned using a Leica CM1900 Rapid Sectioning Cryostat (Leica), stained using anti-mouse F4/80 antigen eFluor 450 (clone BM8; eBioscience), and imaged using an upright Olympus BX63 microscope and a Â 100 oil-immersion objective. For immunohistochemistry, a biotinylated anti-rat IgG antibody was applied, and VECTASTAIN ABC kit (Vector Laboratories Inc.) along with a 3-amino-9-ethylcarbazole substrate (Dako) were used for colour development. The sections were counterstained with Harris haematoxylin solution (Sigma-Aldrich) and scanned by using Nanozoomer 2.0RS (Hamamatsu). For immunofluorescence, anti-rat IgG-Alexa Fluor 405 (Abcam) as a secondary antibody and anti-mouse CD326 (EpCAM)-PE antibody (clone: G8.8, eBioscience) were used.</p>
<p>In vitro NP characterization. For cytotoxicity assays (Supplementary Table 1), 5,000 cells per well were plated in 96-well plates, treated the next day with Pt-compound or the appropriate buffer control (DMF or drug-free PLGA-PEG NPs, as appropriate), and assessed for viability 72 h later using PrestoBlue (Life Technologies) following the manufacturer's protocol. IC 50 values for each compound were calculated by interpolating from an 11-point dose-response curve.</p>
<p>For live-cell in vitro microscopy of TNP uptake (Supplementary Fig. 2a), HT1080-53BP1-mApple cells were seeded on an optical-bottom 96-well plate (Ibidi; Applied Biophysics), treated the following day with 1 mM TNP for 24 h, washed in warm medium, and immediately imaged on a DeltaVision (Applied Precision) modified Olympus BX63 microscopy system with an environmental chamber. Dose-response analysis of TNP uptake (Supplementary Fig. 3) followed the same protocol. Corresponding measurements of intracellular Pt uptake (Supplementary Fig. 3d) were performed by treating 80% confluent cells in six-well plates for 24 h with TNP, rinsing with PBS, trypsinizing, centrifuging the cell pellet for 300g for 5 min, re-suspending the pellet in 50 ml fresh PBS, and freezing it for subsequent AAS analysis.</p>
<p>CellLight BacMam (Life Technologies) fluorescent protein-signal peptide fusions, delivered using baculovirus, were used for subcellular compartment co-localization experiments (Supplementary Fig. 2b). Briefly, 10,000 HT1080 cells were treated overnight with 20 ml CellLight reagent in 12-well dishes, plated the next day on collagen-I-coated glass coverslips in six-well dishes, and the following day were treated with 0.5 mM TNP for either 3 or 24 h. Following treatment, cells were counterstained with Hoechst 33342 and immediately imaged. Collagencoating was performed by treating coverslips with 100 mg ml À 1 rat-tail collagen-I (BD Biosciences) overnight and then rinsing with PBS.</p>
<p>To analyse de-quenching of the C 16 -Pt(IV)-BODIPY compound (Supplementary Fig. 2d), TNPs were added at 1 mM to full serum medium (DMEM þ 10% fetal bovine serum þ 1% penicillin/streptomycin) in the presence or absence of 90% confluent HT1080 in 96-well plates. Fluorescence was monitored by a Tecan Safire 2 fluorescence plate reader. For monitoring TNP uptake kinetics (Supplementary Fig. 8a), equal numbers of RAW 264.7 macrophages or HT1080 cells were plated in 96-well plates and incubated with 1 mM TNP. At the indicated time points, medium was temporarily transferred to empty wells and replaced with fresh media on cells. Cells were then immediately measured using a plate reader for BODIPY-630 fluorescence, and the TNP-containing media were replaced onto the cells again.</p>
<p>To analyse Pt uptake and release into supernatant by macrophages (Supplementary Fig. 8c), confluent 10 cm tissue-culture dishes of RAW macrophages were treated with 62 mM TNP for 24 h, rinsed in PBS, treated with fresh media, incubated for another 24 h and then analysed for Pt content by AAS. The supernatant was clarified by centrifugation (300g for 5 min) before AAS analysis. Cells were harvested by trypsinization, centrifugation (300g for 5 min), resuspension of the cell pellet in 50 ml PBS and freezing for subsequent AAS analysis.</p>
<p>To analyse whether the Pt-containing macrophage supernatant could invoke a DNA damage response in tumour cells (Supplementary Fig. 8d), RAW macrophages were treated for 6 h with 15 mM TNP, then rinsed and incubated in fresh media. After 24 h, media were clarified by centrifugation (300g for 5 min), transferred to HT1080-53BP1-mApple cells plated on optical-bottom 96-well plates (Ibidi; Applied Biophysics), and incubated overnight. The following day cells were rinsed and immediately imaged.</p>
<p>To analyse whether Pt-containing macrophage supernatant cause cytotoxic effects on tumour cells (Supplementary Fig. 8e), RAW macrophages were treated for 24 h with either TNP or unencapsulated C 16 -Pt(IV)-BODIPY (the latter to achieve high Pt concentrations), then rinsed and incubated in fresh media. After 24 h, media were clarified by centrifugation (300g for 5 min), then transferred to 5000 HT1080 cells per well of a 96-well plate. After 72 h, the cell count was determined by the PrestoBlue assay (Life Technologies).</p>
<p>To analyse whether the above cytotoxic effects depend on proteins in the Pt-containing macrophage supernatant (Supplementary Fig. 8f), RAW macrophages were treated for 16 h with 60 mM TNP, then rinsed and incubated in fresh media. After an additional 16 h, media were clarified by centrifugation (300g for 5 min), filtered using MWCO centrifugal filters (Amicon; Millipore), and transferred to 5000 HT1080 cells per well of a 96-well plate. After an additional 72 h, the cell count was determined by the PrestoBlue assay (Life Technologies).</p>
<p>Tumour growth. Subcutaneous tumours were implanted in 7-week-old female nu/nu mice (Cox7, MGH), injected in four quadrant animal flanks as 1 million HT1080 cells suspended in 50 ml PBS. Nine days later, animals were ranked and sorted into groups of four based on tumour size. According to predefined protocol guidelines, mice were killed when tumour burden reached more than 1 cm in diameter, or 2 cm in diameter if only one tumour was present. Tumour volumes were measured two to three times per week, estimated using the spherical tumour volume formula V ¼ 4 / 3 pr 3 , where r is averaged from four caliper measurements performed by two blinded researchers. Each size-group was randomly distributed to the four treatment-groups such that final treatment-groups exhibited roughly equal distribution in tumour size, with 9-10 mice per group. Groups received 150 ml of clodronate liposomes (clod-lip) or PBS liposomes as a vehicle control, intraperitoneally, on the indicated days (Fig. 8a). Liposomes were from ClodLip BV (Haarlem), with clodronate at a concentration of 5 mg ml À 1 . As separate intravenous injections on indicated days (Fig. 8a), groups received 1 mg kg À 1 Pt of either TNP or the TNP without Pt(IV) as a vehicle control. TNPs for this experiment were formulated as described above, using PLGA 8kDa -PEG 5kDa and non-fluorescent PLGA 30-60kDa rather than PLGA 30-60kDa -BODIPY-630. TNP formulations were made fresh before each injection, and batches were tested for size and monodispersity by DLS and TEM. Pt loading was measured by AAS, and appropriate drug release was measured as previously described. At 19 days post implantation, tumours were excised, rinsed in PBS and processed for histology by freezing in OCT compound, or alternatively processed for AAS analysis by blotting tissue to remove excess water and freezing. One of thirty-eight animals was prematurely killed owing to biting and cachexia.</p>
<p>Flow cytometry. Subcutaneous tumours (HT1080 cells) were harvested from nu/nu mice 3 weeks post implantation, cut into small pieces and incubated in RPMI 1640 medium containing 0.2 mg ml À 1 collagenase type I (Worthington Biochemical Corporation) for 1 h at 37 °C while shaking (250 r.p.m.). Digested tumours were filtered through a 70-mm cell strainer (BD Falcon). The resulting single-cell suspensions were washed and resuspended in PBS with 0.5% BSA and 2 mM EDTA. Cell labelling was performed with appropriate antibodies as indicated below for 45 min at 4 °C. The following cell types were identified by flow cytometry (LSRII, BD Biosciences) depending on cell marker expression: tumour cells</p>
<p>Liver and BM analysis. Pt concentrations in the liver and bone marrow were determined by AAS and fluorescence imaging. Briefly, naive female nu/nu mice 8-week old were i.v. injected with TNP at a dose of 1 mg kg À 1 Pt. 24 h later, animals were perfused with PBS by intracardiac injection before dissection. For fluorescence quantification of TNP payload, livers were excised and frozen in OCT compound for later sectioning. Femoral BM was flushed using PBS and smeared on a glass slide for immediate imaging. Un-injected control animals were used to measure background signal for each organ, which was baseline-subtracted in the quantification. For AAS analysis of Pt content, livers were excised, patted dry and frozen. BM was flushed using PBS, centrifuged at 16,000g to pellet cells and frozen. Tissue was then dissolved in 70% nitric acid and analysed as with the HT1080 tumours (Fig. 8). For quantification of BM cellularity, femurs were excised 24 h post injection with TNP, formalin-fixed overnight, decalcified in EDTA and processed for FFPE sectioning. Immunohistochemistry was performed for apoptosis analysis by terminal deoxynucleotidyl transferase dUTP nick-end labelling, using Apoptag Peroxidase In Situ Apoptosis Detection Kit (Millipore), counterstaining with Harris haematoxylin solution (Sigma-Aldrich), and scanning with a Nanozoomer 2.0RS (Hamamatsu).</p>
<p>Metastasis burden in the lung and liver was quantified by morphological assessment in haematoxylin and eosin-stained liver FFPE sections that had been imaged using Nanozoomer 2.0RS, with organ excision at time of animal euthanasia according to the institutional guidelines (body condition score of 2) or 20 days post cancer injection, whichever came first. No statistically significant difference was observed in animal survival, body weight loss or lung tumour burden across the groups. One mouse from the group receiving repeated TNP dosing was excluded from analysis since no lung tumours (and very few liver tumours) were found by histology, presumably due to failed initial intravenous injection.</p>
<p>Clinical chemistry measurements in Swiss albino mice were performed using previously described TNP and methods 6 . Graphically re-plotted here for context (Supplementary Fig. 9a), bio-distribution of Pt in male rats was measured as described previously 6 .</p>
<p>NATURE COMMUNICATIONS | 6:8692 | DOI: 10.1038/ncomms9692 | www.nature.com/naturecommunications &amp; 2015 Macmillan Publishers Limited. All rights reserved.</p>
<p>NATURE COMMUNICATIONS | 6:8692 | DOI: 10.1038/ncomms9692 | www.nature.com/naturecommunications</p>
<p>&amp; 2015 Macmillan Publishers Limited. All rights reserved.</p>
<p>This work was supported in part by the US National Institutes of Health (NIH) grants RO1-CA164448, P50-CA086355, PO1-CA139980, U54-CA151884 (to R.W.) and RO1-CA034992 from the National Cancer Institute (to SJL), along with the David Koch-PCF Program in Nanotherapeutics (to O.C.F.). C.P. is supported by the Deutsche Forschungsgemeinschaft (DFG) PF809/1-1. We thank Dr Kevin King, Dr Julia Kalow, Dr Basit Yameen, Alex Zaltsman, Matthew Sebas, Greg Wojtkiewicz, David Pirovich and Olivier Kister for technical assistance, and Dr Melissa Sprachman for helpful discussions.</p>
<p>Supplementary Information accompanies this paper at http://www.nature.com/ naturecommunications Competing financial interests: O.C.F. has a financial interest in BIND Therapeutics, Blend Therapeutics and Selecta Biosciences, biotechnology companies developing nanoparticle technologies for medical applications. S.J.L. discloses a financial interest in Blend Therapeutics. The remaining authors declare no competing financial interests.</p>
<p>Reprints and permission information is available online at http://npg.nature.com/ reprintsandpermissions/</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f129069432"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:33+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Quantitative proteomics employing mass spectrometry is an indispensable tool in life science research. Targeted proteomics has emerged as a powerful approach for reproducible quantification but is limited in the number of proteins quantified. SWATH-mass spectrometry consists of data-independent acquisition and a targeted data analysis strategy that aims to maintain the favorable quantitative characteristics (accuracy, sensitivity, and selectivity) of targeted proteomics at large scale. While previous SWATH-mass spectrometry studies have shown high intra-lab reproducibility, this has not been evaluated between labs. In this multilaboratory evaluation study including 11 sites worldwide, we demonstrate that using SWATHmass spectrometry data acquisition we can consistently detect and reproducibly quantify &gt;4000 proteins from HEK293 cells. Using synthetic peptide dilution series, we show that the sensitivity, dynamic range and reproducibility established with SWATH-mass spectrometry are uniformly achieved. This study demonstrates that the acquisition of reproducible quantitative proteomics data by multiple labs is achievable, and broadly serves to increase confidence in SWATH-mass spectrometry data acquisition as a reproducible method for largescale protein quantification.</p>
<p>eproducibility is an essential foundation of scientific research. Recent reports have concluded that a significant fraction of life science research shows poor reproducibility of results and this poses a major challenge to scientists, science policy makers, funding agencies, and the pharma and biotech industry sectors [1][2][3] . The reasons for irreproducibility of research results are many, including inadequate study design and data analysis, limited data quality, incompletely characterized research reagents, poorly benchmarked techniques, and a range of other confounding factors.</p>
<p>The question of whether specific data acquisition methods and platforms are capable of generating reproducible results is best addressed by inter-laboratory studies, where samples of known composition and quality are analyzed across different settings. Such studies have been reported for various "omics" technologies, including RNA-seq and microarray techniques, with varying results 4,5 . Such projects have served to highlight problems in various large-scale strategies, to stimulate discussion in a given field on how to improve reproducibility, and in the best cases to provide confidence in a given strategy within and beyond an analytical field.</p>
<p>In the field of mass spectrometry (MS) based proteomics, a wide range of specific methods have been reported over the past two decades. These can be broadly grouped into discovery and targeted proteomic techniques. The general aim of discovery proteomics is the unbiased identification and quantification of the protein components of biological samples. This is most frequently achieved by data-dependent acquisition (DDA) MS. If the number of precursor ions exceeds the number of precursor selection cycles 6 , precursor selection becomes stochastic and the peptides detected in repeat analyses become irreproducible. This has been documented in a number of intra-and inter-laboratory studies [7][8][9] . In general, these studies confirmed that a high degree of reproducibility is difficult to achieve for complex samples 10 . Computational methods to enable improved quantification via propagation of peptide identifications across runs via alignment of MS1 precursor signals, first introduced as accurate mass and time tags (AMT) 11,12 , are commonly applied to DDA data [13][14][15][16] and can reduce this issue to some degree in discrete data sets where chromatographic alignment can reasonably be applied.</p>
<p>In contrast to discovery proteomics the general aim of targeted proteomics is the detection and quantification of a predetermined set of peptides by selected reaction monitoring (SRM) also known as multiple reaction monitoring (MRM) 17 , or a related technique parallel reaction monitoring [18][19][20] . Because targeted MS eliminates the stochastic component of precursor ion selection in DDA, it has the potential for high reproducibility. This has been demonstrated in intra-laboratory studies where sets of peptides were targeted with a high degree of reproducibility across relatively large sample sets [21][22][23] and by inter-laboratory studies focused on exploring the use of SRM and immuno-SRM for biomarker studies [24][25][26][27][28][29] . Targeted MS is now broadly regarded as a reproducible protein analysis platform 17 . However, the number of proteins measured is restricted (usually to ~100 per injection), limiting its utility for many applications.</p>
<p>SWATH-MS is a more recently introduced approach to MS-based proteomics 30 . It consists of data-independent acquisition 31,32 (DIA) in which all precursor ions within a user defined m/z window are deterministically fragmented. Analysis of SWATH-MS data most often relies on a targeted data analysis strategy in which target peptides are detected and quantified from the SWATH-MS fragmentation data by extracting and correlating previously generated query parameters for each target. In this scheme each unique peptide of interest at a given precursor charge state is queried for in the data, resulting in the detection and scoring of co-eluting transition group signals and associated underlying mass spectral features, referred to as peak groups. Because the method specifically tests for the presence of each target peptide in the essentially complete fragment ion map of each sample, it eliminates the stochastic sampling element of DDA and helpfully provides a direct statistical measure (e.g., qvalue) of whether the peptide is present at a detectable level in the sample. This data analysis strategy, whereby target peptides are directly queried for, has recently been generalized using the term peptide-centric 33,34 scoring to distinguish from more classical approaches where the MS2 spectrum is the query unit for data analysis (referred to as spectrum-centric scoring). The SWATH-MS implementation of the DIA concept therefore preserves the favorable performance characteristics of SRM, while vastly expanding the measurement capacity to thousands of proteins per injection. Of consideration in SWATH-MS is the complexity of the resultant spectra and specific software tools have been compiled to analyze such highly multiplexed data using various approaches [35][36][37][38] . A recent study comparing software tools for the analysis of DIA data using either peptide-centric or spectrumcentric approaches has demonstrated that very similar qualitative and quantitative results can be obtained when analyzing a benchmarking data set 39 . SWATH-MS and related DIA approaches have achieved a high degree of reproducibility in intralaboratory studies in a variety of research questions such as interaction proteomics 40,41 , plasma proteomics 42 , tissue proteomics 43 , microbial proteomics 44,45 , pre-clinical toxicology 9 , analysis of genetic reference strains 46 , and many others. However, interlaboratory robustness and reproducibility of SWATH-MS data acquisition has not been demonstrated.</p>
<p>In this study, we set out to test the reproducibility of peptide and inferred protein detection and quantification by SWATH-MS in an inter-laboratory study. To achieve this goal we distributed benchmarking samples to 11 participating laboratories worldwide for measurement by SWATH-MS according to a predetermined schedule. We analyzed the data from all sites centrally with two separate scopes in mind. Firstly, we analyzed all of the data in an aggregated way to simulate, for example, a large cohort study whereby patient samples would be analyzed in multiple laboratories, aiming to achieve a result set based on all samples. In the second interpretation, we analyzed the data from each site of collection independently and compared the results across sites post analysis facilitating a direct performance comparison.</p>
<p>Our analysis demonstrated that the set of proteins detected and quantified across all participating sites, i.e., from a total of 229 proteome measurements, was very consistent. The reproducibility, linear dynamic range, and sensitivity are approaching those reported for SRM, currently the gold standard approach for protein quantification 17,30,47 . This data supports the conclusion that DIA combined with peptide-centric scoring embodied by the SWATH-MS approach is suitable for both comprehensive and reproducible proteomics at a large scale and across laboratories.</p>
<p>Study design and implementation. To assess the inter-and intra-laboratory reproducibility and performance of SWATH-MS for large-scale quantitative proteomics, we created a benchmarking sample set and distributed aliquots to 11 laboratories worldwide (Fig 1a). The sample consisted of 30 stable isotopelabeled standard (SIS) peptides 48 diluted into a complex background consisting of 1 µg of protein digest from HEK293 cells. To achieve both, a physiologically relevant fold change step, and to cover a large linear dynamic range in a relatively small number of samples that could be analyzed in a 24 h period, we elected to partition the SIS peptides into five groups (A-E), each containing six peptides. In each group, the dilution series started from a different level ranging from 1 fmol to 10 pmol (sample S5). The MS responses of the peptides were measured, ranked, and they were assigned evenly to the five groups (A-E) to ensure there was a range of peptide responses across in each group concentration group. The peptides were then diluted serially threefold into the HEK293 background four times (samples S1-S4). This generated an overall dilution series from 0.012 to 10,000 fmol on column, with a linear dynamic range over six orders (although not covered by any single SIS peptide-Supplementary Data 1 and 2). We acquired all data in SWATH-MS mode, set to 64 variable width Q1 windows chosen to minimize window size in high density precursor ion ranges (Supplementary Data 15).</p>
<p>To standardize the SWATH-MS acquisition protocol and to make an initial quality assessment, we first asked each site to acquire five replicate injections of a test sample containing only the HEK293 background. This data was used to improve quality control procedures and to ensure adequate system performance at all sites (Supplementary Fig. 1; Supplementary Note 1). The finalized study protocol is provided (Supplementary Methods). All sites used the same mass spectrometer (SCIEX TripleTOF 5600 / 5600+ systems), while the nanoLCs consisted of various models from the same vendor (SCIEX). The chromatographic columns had the same dimensions (30 cm × 75 µm) although nine sites used cHiPLC microfluidic systems and two sites used selfpacked columns with emitters and, as such, therefore also used different chromatographic resins (see "Methods"). After the initial quality control phase, participating labs acquired SWATH-MS data for the main sample set consisting of samples S1-S5 with sample S4 injected in technical triplicate, and repeated this acquisition scheme two further times during 1 week. The purpose of this design was to determine reproducibility and quantification metrics within 1 day, across 1 week, or across different sites of data collection. These measurements resulted in a data set containing in total 229 SWATH-MS files from the 11 sites worldwide that are freely accessible for further analysis by the community.</p>
<p>The results are shown in Fig. 2. In Fig. 2a, we depict the number of proteins detected across all SWATH-MS acquisitions in the aggregated data analysis (equivalent plot at peptide query level in Supplementary Fig. 2). The total number of proteins detected at 1% FDR over the entire data set is 4984 from 40,304 proteotypic peptide peak groups (Supplementary Data 3). The median number of proteins detected per file is 4548 from a median of 31,886 peak groups. A total of 4077 proteins were detected in &gt;80% of all samples. Figure 2b shows the distribution of complete/missing values from this data. Of the 4984 proteins detected, 3985 were detected using &gt;1 peptide peak group and, on average, we detected 8.1 proteotypic peptides per protein (Supplementary Fig. 3). Information regarding mass spectrometric and chromatographic performance metrics across the sites that might affect the number of proteins detected is provided in Supplementary Figs. 456789. The accumulation of new protein identifications over the data set-indicated by the blue curve in Fig. 2a-saturates, indicating the comprehensiveness of the SWATH-MS methodology and the minimal number of accumulated false positive identifications across 229 measurements. This also indicates that when we analyzed the data in an aggregated manner (i.e., data from all sites combined), the set of proteins detected by all labs is very consistent. Achieving this consistency was dependent on appropriate FDR control in the global context at both peptide query and protein level. To illustrate this, we plotted the numbers of peak groups and proteins detected when FDR was controlled only at peptide query level and not the protein level, and only on a sample-by-sample basis and not in the global context (Supplementary Fig. 10). The accumulation of new peak groups steadily increased across the data set, indicating a likely accumulation of false positives and, highlighting the importance of appropriate global FDR control 55,56 . We computed the repeatability of detection at the peptide and protein levels, similar to Tabb et al. 7 , defined as the pairwise percent overlap between any two runs. The range of median repeatability within sites was 90.0-98.2% at the protein level and 79.5-95.5% at the peptide level (Supplementary Fig. 11). The median repeatability over the entire data set from all sites was 91.6% at the protein level and 79.5% at the peptide level.</p>
<p>The comparison between the protein detection rates from the aggregated analysis and an individual site-by-site analysis also provides insight into FDR control. Figure 2c shows the number of proteins detected when the data from each site was first analyzed separately by site of data collection with independent FDR control and then aggregated (equivalent plot at peptide query level in Supplementary Fig. 12). In this analysis, the procedure was identical to that of the aggregated analysis, except that the global context for FDR control mentioned above was restricted to the files from an individual site, and that procedure was repeated for each site individually. The information content of the data from each site is different, which likely relates to performance differences between chromatographic, nanospray ionization and/ or instrument efficiencies across sites at the time of data acquisition. When the data is aggregated before analysis and FDR control, the higher quality data effectively supports the lower quality data, because the strict scoring cutoffs required by the 1% protein FDR threshold only needs to be achieved once per protein in the global context, leading to more homogenous results in terms of proteins detected. That is, in our analysis, a protein is considered detected in a given sample if it is detected at the 1% peptide query FDR threshold as long as the peptide has been detected elsewhere in the experiment with a passing the 1% protein FDR threshold (Supplementary Note 2).</p>
<p>From these analyses, we can conclude that using SWATH-MS data collected from instruments in different labs, the set of proteins detected is comparable (Fig. 2a,b). This presents a desirable quality not previously demonstrated at this scale in large-scale proteomics analysis.</p>
<p>To obtain an overview of the linearity and dynamic range of the SWATH-MS method between sites, we computed the average peptide peak area (unnormalized) of the SIS peptides at a given concentration point and plotted this as averaged response curve for each site (Fig 4b, Supplementary Data 9). By averaging over six peptides that have variable responses we obtained a representative picture of the linearity and dynamic range of the method (as opposed to that of individual peptides that are more frequently of greater interest in targeted proteomics studies which employ dilution curves). The linear regressions for the average The response curves for each of the 30 SIS peptides for Site 1 were determined and plotted together (corresponding plots for all other sites are shown in Supplementary Fig. 13). b From this data, an average response curve for each site was constructed by averaging (mean) the responses of peptides at the same concentration point. This visualization facilitates comparison of both the dynamic range and average response between sites. c The average response curves from b replotted after the normalization has been applied. d The proteins detected in the SWATH-MS analysis of the HEK293 proteome matrix were mapped onto a previous in-depth DDA analysis of the U2OS cell line that employed multi-level fractionation to achieve deep proteome coverage. To demonstrate the dynamic range achieved by the single-shot SWATH-MS analysis we plotted the proteins detected by SWATH-MS binned by the protein copies per cell value (log10 scale) determined from the in-depth U2OS DDA study 60 . In the range 10 5-10 7 copies per cell the proteome coverage is essentially complete and decreases with lower copies per cell bins peptide area curve for each site was computed and the R 2 values averaged 0.97 (R 2 values for individual peptides are in Supplementary Data 8). There was signal saturation for the highest concentration point (10,000 fmol), and removal of point increased the R 2 to 0.99. Since this study was performed, a newer instrument platform (
TripleTOF 6600) has increased linear dynamic range through a different detection system, and signal saturation at high peptide load would be significantly reduced in this case. The average response curves were very similar between sites, all exceeding 4.45 orders of linear dynamic range including all data points, with an average across sites of 4.6 (Supplementary Data 9). Dynamic range was computed by taking the log base 10 of the concentration of the highest point divided by the LLOQ concentration. By applying the average peak area and average response curves, the data showed that the linearity and dynamic range for each site is qualitatively similar in terms of slope and span. The raw peak areas obtained from each site, however, are offset by a fixed amount across the dynamic range. When the same averaged response curve plot was constructed from values normalized based on the HEK293 proteome background, the response curves were well overlaid (Fig. 4c). The peptide peak area fold change between dilution steps averaged 2.66 across the concentration range, reflecting the three-fold dilution series (ratios in the middle of the linear dynamic range are close to 3 with some compression 59 of the ratio at the lowest and highest concentration points-Supplementary Fig. 17). The mean fold change for expected ratios of ninefold and 27-fold were 7.49 and 19.6, respectively. The ratio compression is partly explained by the high peptide loads (low pmol on column range) used at the upper end of the dilution series, higher than are commonly used for this experiment type, which caused some MS signal saturation.
</p>
<p>We next attempted to assess the dynamic range of the measurements at the protein level in the HEK293 proteome. At the protein level, no internal standard was available on which to judge dynamic range. Therefore, as a surrogate measure, we mapped the set of proteins detected in our experiment onto a previous in-depth proteomic characterization of U2OS cells which estimated the copy numbers of proteins per cell 60 . Although the reference data is from a different cell line, an indepth quantitative comparison of these two cell lines has shown that the protein abundances are well correlated (Pearson correlation ~0.8) 61 making this a reasonable surrogate measure. From this data we can estimate that the set of proteins detected by SWATH-MS in the HEK293 cell proteome spans ~4.5 orders of magnitude, with the upper ~2.5 orders of magnitude being highly complete (Fig. 4d).</p>
<p>Sensitivity in SWATH-MS and MS1. Based on the experimental design, there is an expected number of the SIS peptides that could be detected at each concentration (Fig. 1a). To get a broad view of the LLOQ across the study, we plotted the percentage of the 30 SIS peptides that were reliably detected (LLOQ and above) at each concentration in the dilution series from each site (Fig. 5a, Supplementary Data 10). Interestingly, the curves depicting % detection of peptides for the SWATH-MS data across different sites of data collection are uniform, indicating that consistent sensitivity can be achieved at different sites despite the high complexity background. The LLOQ for SWATH-MS data spanned the mid-attomole to low-femtomole range. Despite the higher complexity background proteome used in this study, the results are in good agreement with data previously obtained 30,47 .</p>
<p>As the SWATH-MS acquisition method also contains an MS1 scan in every cycle, we were able to extract XICs at the MS1 level and determine the LLOQ in MS1 mode using similar criteria for evaluating the individual peptide concentration curves and the LLOQ as was used for the SWATH-MS data (Fig. 5b). Average lines were computed for each mode of quantification and plotted together for easy visualization (Fig. 5c,d). In our data set the LLOQ of peptides using SWATH-MS2 quantification is nearly 1 order of magnitude lower than in MS1. The benefit in this case is explained in terms of selectivity but not absolute signal abundances. While the signal intensity of the precursor in MS1 is typically higher than the fragment ions from the SWATH-MS signal, the MS1 XICs become contaminated with interfering signals as the LLOQ is approached, whereas the SWATH-MS signal generally has less interference at lower analyte concentrations (Supplementary Figs. 202122, Supplementary Note 4, and Supplementary Data 11 and 12). As with SWATH-MS data, manual inspection of the MS1 data was performed and low concentration peaks not meeting LLOQ requirements were removed. This difference between SWATH-MS and MS1 level sensitivity has also been previously reported 30,35 , although usually with smaller differences between MS1 and SWATH-MS LLOQs that may be explained by the higher complexity of the sample matrix in this study or by the increased number of precursor isolation windows with reduced width compared with previous analyses. Additionally, when compared to the SWATH-MS result, the MS1 data yielded a more divergent detection rate at each concentration across sites, demonstrating that MS1 profiling has a less consistent sensitivity between labs. SWATH-MS demonstrated improved intra-lab reproducibility compared with MS1 with CV values of 8.8 and 13.2%, respectively (Supplementary Fig. 23).</p>
<p>Finally, we elected to examine the global similarity of the normalized quantitative protein abundances determined by SWATH-MS across the different sites of data collection. We performed a hierarchical clustering of the study-wide log2 protein abundance matrix and plotted the resulting dendrogram in Fig. 6a. The data broadly clusters by site of data collection, whereas the day of data collection within one site generally does not cluster. To determine the similarity of the protein abundance profiles more quantitatively, we computed a pairwise Pearson correlation matrix based on the normalized log2 protein abundances of the common proteins from each pair of runs (Fig. 6b). The median Pearson correlation of log2 protein abundances across the entire data set was 0.940. On average, the median Pearson correlation within a given site of data collection was only slightly higher at 0.971 (the range of site medians was 0.948-0.984). The minimum pairwise Pearson correlation between any two of the 229 files across the study was 0.868. From the above analyses, we can conclude that the quantitative similarity within sites of data collection is only marginally higher between sites of data collection.</p>
<p>The importance of quantitative proteomics in clinical and basic research is expanding rapidly because proteins provide a direct insight into the biochemical state of the cell. To determine the utility of particular proteomic technologies a thorough and objective assessment of their performance is essential. For the widespread application of the technology, robustness, reproducibility, quantitative accuracy, data comprehensiveness and completeness are critically important performance parameters 62 .</p>
<p>Targeted proteomics via SRM is a proven technology receiving high grades with respect to these metrics. The Clinical Proteomic Technologies for Cancer Initiative as part of the Clinical Proteomic Tumor Analysis Consortium (CPTAC) projects 24,26,27 have demonstrated that the robust application of SRM across different labs is achievable and an Atlas of SRM assays for the entire human proteome has been published 63 . These results suggest that distributed studies with hundreds to thousands of samples and data integration between labs are becoming feasible. They also generally increased the confidence that smaller and larger scale, comparative proteomic studies are a reality. However, the feasibility of larger scale sample comparisons on protein numbers which exceed that quantifiable by SRM by orders of magnitude has not been demonstrated. SWATH-MS is a technique that has the potential to achieve this ambitious objective.</p>
<p>The goal of our study was to characterize the performance of SWATH-MS data acquisition across different laboratories.</p>
<p>The data set analyzed in this study supports a number of conclusions relating to the above stated questions. Firstly, the set of proteins we detected across all sites is very similar and is effectively saturated after a small number of files are analyzed. This indicates that the level of data completeness from a protein quantification perspective is very high, a quality which is desirable in comparative studies. In this study, we have evaluated technical reasons for missing data in relation to measurement variation. Challenges associated with missing data related to biological variation are discussed in Supplementary Note 5.</p>
<p>Notably, the spectral library and peptide query parameters we used to perform the analysis of the SWATH-MS data were previously published 49 and built by a single lab independent of the current study, illustrating the generic applicability of such spectral libraries. Appropriate FDR control was key to achieving this result. Extending the FDR control to the global context (computed over all files in the analysis), in addition to extending the FDR control from the peptide query to the protein level, were critical in the project where large numbers of samples were analyzed using a large number of peptide queries. In a related manuscript we discuss issues relating to FDR control in DIA data in detail 55 .</p>
<p>We expect that a DDA-based study could not achieve such a high level of completeness across labs due to stochastic MS2 sampling 7 and such a study is likely to experience difficulty aligning MS1 signals arising from different labs where chromatography will inevitably vary (Supplementary Fig. 4). Importantly, our analysis method did not employ any alignment or propagation of peptide identifications as is commonly used in MS1 quantification from DDA data, however, we anticipate that data completeness might be further improved using a feature alignment strategy recently developed for SWATH-MS 64 . Secondly, the quantitative characteristics in terms of reproducibility, limit of detection, and linear dynamic range were also highly comparable across the data from all sites. Again, with regard to large-scale proteome quantification (i.e., 4000+ proteins) across laboratories in &gt;200 measurements, these findings are unprecedented and have evolved to a level where many of the previously described limitations of data acquisition in MS-based proteomics 62 are being significantly overcome.</p>
<p>In the course of analyzing the data, some interesting characteristics of SWATH-MS data became apparent. For example, one observation relates to the absolute signal response of instruments from various sites, which as expected, was variable. Interestingly, the slope, linearity and dynamic range of the response curves from the SIS peptide dilution series are essentially uniform across sites with only an offset in the intensity dimension differing (Fig. 4c). Further, the number of proteins detected at a given site was only moderately correlated with signal intensity (Supplementary Fig. 8). This suggests that the absolute signal intensity is not the critical metric in determining the data quality, but probably rather the signal-to-noise ratio. These observations have important consequences for normalization of label-free quantitative data and, in our study, facilitated the use of a simple global median normalization based on all of the available peptide signals from the HEK293 background proteome to effectively make the data comparable without the use of internal standards. Here, we highlight an advantage of SWATH-MS data; i.e., as with MS1/DDA-based quantification and, unlike more classical targeted methods such as SRM, there are large numbers of peptides available for global normalization that can be used in sample types where the assumptions underlying this type of normalization are valid 65,66 . This data set may also be useful for future optimization of certain general data analysis parameters, such as, selection of the most appropriate peptides for protein quantification. In this study, we used a simple method to infer protein abundance 44 , however, more advanced methods that take into account which peptides are most robust for quantification ("quantotypic" 67 ) across the study could be developed based on our data.</p>
<p>Another comparison that was directly possible in our data set was that of LLOQ in either SWATH-MS or MS1 mode using XIC based analysis within the same data files. As previously reported, we found a clear benefit in sensitivity when extracting quantitative information from SWATH-MS data over MS1 data. This difference was maintained across all sites where the data was acquired, and seems to be generalizable at least with respect to the instrument setup used in this study. It should be stressed that this effect may be somewhat platform dependent, as mass analyzers with higher resolving power for MS1 spectra would facilitate smaller XIC widths, reducing interferences to some degree.</p>
<p>Finally, a further comparison with CPTAC and associated projects focused on targeted proteomics via SRM is of interest as it represents the most advanced work on the robustness and transferability of quantitative proteomics methods to date 24,26,27 . CPTAC has also published inter-lab studies focused on DDA analysis. However, these have primarily focused on the repeatability of peptide/protein identifications or the establishment of quality control metrics 7,10 , or on higher level similarity of differential expression analysis when different instruments and quantitative approaches were applied 66 , but have not addressed specific comparisons of quantitative metrics such as CV, LLOQ, linearity, or dynamic range. Our study is conceptually related to what was achieved by the CPTAC SRM studies although there are also some major differences. Firstly, the scope of the CPTAC SRM studies was different and included variables such as sample preparation, system suitability, and instrumentation from different vendors. In the case of our study, the decision to include only a single instrument type and model was primarily to limit the number of experimental parameters varied and, secondly, because at the outset of the project (September 2013) the adoption of SWATH-type DIA analysis on other platforms was limited. As such, in our study, the main variable tested was the site of data acquisition to assess inter-laboratory SWATH data quality and reproducibility. As we did not evaluate the variance in sample preparation between sites we cannot make any conclusions on this topic. However, we would suggest that the conclusions in the CPTAC analysis are generalizable; i.e., that if samples are prepared at different sites a significant batch effect can be expected. As such, viable options for future distributed studies would be to prepare the samples at central facility or to invest significantly in standardization of sample preparation in combination with the application of more advanced methods for normalization and removal of batch effects. Another significant design difference is that CPTAC SRM studies were focused on achieving essentially clinical-grade assays 68 for relatively discrete sets of targets. Our focus was on quantifying large numbers of proteins in a workflow that might be used either in a discovery mode for hypothesis generation, or in a verification mode to test large numbers of protein analytes in large cohorts. Lastly, as CPTAC has been focused on a relatively discrete set of targets it was possible to include isotope-labeled standards, which helped to determine absolute concentrations and to control matrix interference effects, whereas our study focused on label-free analysis. With these differences stated, we can suggest that our studies lead to a conceptually similar conclusion, albeit with different scopes. That is, using either targeted MS (i.e., SRM) to study discrete panels of proteins with highly validated assays or using DIA (i.e., SWATH-MS) to study large numbers of proteins in exploratory/verification analyses, we can quantify proteins in a robust and complete manner.</p>
<p>This study has demonstrated for the first time that large-scale quantification of several thousand proteins from centrally prepared samples is feasible with reproducible and comparable data generated across multiple labs. The result of our study, focused on assessing variation in data acquisition, is paralleled by concurrent improvements in the robustness of data analysis tools 39 , methods for error rate control 55 , and sample preparation techniques 43 . While further work needs to be done in several areas, such as large-scale sample preparation, long-term instrument robustness, and batch effect normalization during data analysis, these studies collectively advance the reproducibility and transparency of SWATH-MS. As comparative quantitative analysis of a large number of proteomes becomes accessible 42,46,69 , we can expect to see research applications where the analysis of large numbers of samples is a prerequisite. For example, analyses of clinical material from large patient cohorts 42 (e.g., biomarkers, personalized medicine), association of protein abundances to genomic features using genetic reference collections or wild-type populations 46 (e.g., quantitative trail locus or genome wide association studies), or large-scale perturbation screens using in vitro model systems (e.g., drug screens) are now feasible. More broadly, the data presented here demonstrate a significant advance in the robustness of large-scale data acquisition in quantitative proteomics, and we expect the results from this study to increase confidence in SWATH-MS as a reproducible quantification method in life science research.</p>
<p>Generation and distribution of a benchmarking sample. HEK293 cells (ATCClow passage cells-not verified or mycoplasma tested) were cultured in DMEM (10% FCS, 50 μg ml -1 penicillin, 50 μg ml -1 streptomycin). HEK293 cells were selected as they are a common cell line used in molecular biology research with many published orthogonal data sets. Cell pellets were lysed on ice by using a lysis buffer containing 8 M urea (EuroBio), 40 mM Tris-base (Sigma-Aldrich), 10 mM DTT (AppliChem), and complete protease inhibitor cocktail (Roche). The mixture was sonicated at 4 °C for 5 min using a VialTweeter device (Hielscher-Ultrasound Technology) at the highest setting and centrifuged at 21,130×g, 4 °C for 1 h to remove the insoluble material. The supernatant protein mixtures were transferred and the protein amount was determined with a Bradford assay (Bio-Rad). Then five volumes of precooled precipitation solution containing 50% acetone, 50% ethanol, and 0.1% acetic acid were added to the protein mixture and kept at -20 °C overnight. The mixture was centrifuged at 20,400×g for 40 min. The pellets were further washed with 100% acetone and 70% ethanol with centrifugation at 20,400×g for 40 min. Aliquots of 2 mg protein mixtures were reduced by 5 mM tris(carboxyethyl) phosphine (Sigma-Aldrich) and alkylated by 30 mM iodoacetamide (Sigma-Aldrich). The samples were then digested with sequencing-grade porcine trypsin (Promega) at a protease/protein ratio of 1:50 overnight at 37 °C in 100 mM NH 4 HCO 3 (ref. 70 ). Digests were combined together and purified with Sep-Pak C18 Vac Cartridge (Waters). The peptide amount was determined by using Nanodrop ND-1000 (Thermo Scientific). An aliquot of retention time calibration peptides from an iRT-Kit (Biognosys) was spiked into the sample at a ratio of 1:20 or 1:25 (v/v) to correct relative retention times between acquisitions 71 .</p>
<p>Thirty heavy labeled synthetic peptides that were previously used in an SRM study focused on limits of detection in mammalian cells 48 were selected. As such, these peptides are expected to perform well in LC-MS analysis. The MS response for each peptide was measured. The peptides were ranked by MS response and assigned to five groups (A-E) to ensure there was a range of responses across in each group. These peptides groups were diluted into the matrix described above across a concentration range to create the five different samples to be analyzed (Fig 1a, Supplementary Tables 1 and2). Finally, samples were shipped on dry ice to the 11 sites.</p>
<p>SWATH-MS measurements. Peptide mixtures were separated using reversed phase nanoLC using either a nanoLC Ultra system or a nanoLC 425 system (SCIEX). Most sites (9 of 11) used a cHiPLC system (SCIEX) operated in serial column mode (for detailed acquisition information please see SOP in Supplementary Protocol 1), fitted with two cHiPLC columns (75 µm × 15 cm ChromXP C18-CL, 3 µm, 300 Å) to give a total column bed length of 30 cm (Site configuration details in Supplementary Table 13). Two sites used PicoFrit emitter (New Objective) packed to 30 cm with Magic C18 AQ 3 µm 200 Å stationary phase. Peptide samples (2 µL injection) were first loaded on the first cHiPLC column and washed for 30 min at 0.5 µl min -1 using mobile phase A (2% acetonitrile in 0.1% formic acid). Then, elution gradients of ~5-30% of mobile phase B (98% acetonitrile in 0.1% formic acid) in 120 min were used to elute peptides off the first column and through the second cHiPLC column. Both columns were maintained at 35 °C for retention time stability. Similar separations were performed across all sites. Gradients were allowed to minimally vary from site to site to obtain similar peptide separations (see Supplementary Table 14 for gradient information).</p>
<p>NATURE COMMUNICATIONS | 8: 291| DOI: 10.1038/s41467-017-00249-5 | www.nature.com/naturecommunications</p>
<p>Data availability. The mass spectrometry proteomics data has been deposited to the ProteomeXchange Consortium (http://proteomecentral.proteomexchange.org) via the PRIDE partner repository 73 with the data set identifier PXD004886. The data that support the findings of this study are available from the corresponding author upon request.</p>
<p>Supplementary Information accompanies this paper at doi:10.1038/s41467-017-00249-5.</p>
<p>Competing interests: C.H. is an employee of SCIEX, which operates in the field covered by the article. R.A. holds shares of Biognosys AG which operates in the field covered by the article. The remaining authors declare no competing financial interests.</p>
<p>Reprints and permission information is available online at http://npg.nature.com/ reprintsandpermissions/ Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f201073683"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T05:58+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Objective: This review aimed to determine if the use of the patient, intervention, comparison, outcome (PICO) model as a search strategy tool affects the quality of a literature search.</p>
<p>Methods: A comprehensive literature search was conducted in PubMed, Embase, CINAHL, PsycINFO, Cochrane Library, Web of Science, Library and Information Science Abstracts (LISA), Scopus, and the National Library of Medicine (NLM) catalog up until January 9, 2017. Reference lists were scrutinized, and citation searches were performed on the included studies. The primary outcome was the quality of literature searches and the secondary outcome was time spent on the literature search when the PICO model was used as a search strategy tool, compared to the use of another conceptualizing tool or unguided searching.</p>
<p>Results: A total of 2,163 records were identified, and after removal of duplicates and initial screening, 22 full-text articles were assessed. Of these, 19 studies were excluded and 3 studies were included, data were extracted, risk of bias was assessed, and a qualitative analysis was conducted. The included studies compared PICO to the PIC truncation or links to related articles in PubMed, PICOS, and sample, phenomenon of interest, design, evaluation, research type (SPIDER). One study compared PICO to unguided searching. Due to differences in intervention, no quantitative analysis was performed.</p>
<p>Conclusions: Only few studies exist that assess the effect of the PICO model vis-a-vis other available models or even vis-a-vis the use of no model. Before implications for current practice can be drawn, well-designed studies are needed to evaluate the role of the tool used to devise a search strategy.</p>
<p>The impact of patient, intervention, comparison, outcome (PICO) as a search strategy tool on literature search quality: a systematic review</p>
<p>The development of systematic reviews is considered a means of enabling clinicians to use evidence-based medicine (EBM) [1], and the number of systematic reviews is growing quickly [2]. As literature searching forms the underlying basis of systematic reviews, the quality of the literature search is crucially important to the overall quality of the systematic review [3]. Although new techniques can automate the process of systematic reviews, such as using text mining to develop search strategies [4], the task of devising the search strategy still requires intellectual contributions from reviewers. In particular, as the search strategy builds upon the review question, formulating the review question is critical to developing the search strategy.</p>
<p>In their 1992 publication in the Journal of the American Medical Association, the Evidence-Based Medicine Working Group emphasized the precise definition of the patient problem, the required information needed to resolve the problem, and the ability to conduct an efficient search as the skills required for practicing EBM [5]. In addition to these skills, the use of conceptualizing models to structure a clinical question was introduced in 1995, when Richardson et al. proposed the use of a four-part model to facilitate searching for a precise answer [6]. They stated that a clinical question must be focused and well articulated for all four parts of its "anatomy": the patient or problem (P); the intervention or exposure (I); the comparison intervention or exposure (C), if relevant; and the clinical outcome of interest (O).</p>
<p>Despite the existence of other models-such as sample, phenomenon of interest, design, evaluation, research type (SPIDER) [7] and setting, perspective, intervention, comparison, evaluation (SPICE) [8]the PICO model is by far the most widely used model for formulating clinical questions. The purpose of using PICO is considered to be three-fold [9]. First, it forces the questioner to focus on what the patient or client believes to be the single most important issue and outcome. Second, it facilitates the next step in the process-the computerized search-by prompting the questioner to select language or key terms to be used in the search. Third, it directs the questioner to clearly identify the problem, intervention, and outcomes related to specific care provided to a patient.</p>
<p>The PICO model is also frequently used as a tool for structuring clinical research questions in connection with evidence syntheses (e.g., systematic reviews). The Cochrane Handbook for Systematic Reviews of Interventions specifies using PICO as a model for developing a review question, thus ensuring that the relevant components of the question are well defined [10]. The PICO framework is primarily centered on therapy questions, and although it can be adapted to formulate research questions related to prognosis or diagnosis, it is less suitable for other types of clinical information needs [11].</p>
<p>In addition to acting as a conceptualizing tool for asking clinical and research questions, the PICO model can be used as a tool for developing search strategies. According to Considine et al., "the PICO Framework should also be used to develop the search terms that are informed by the PICO question, Medical Subject Headings (MeSH) and any other terms deemed to be relevant" [12]. For a default search, the Cochrane Handbook suggests employing only search terms for patients, the intervention, and the study type [13], thus reducing the PICO model to P, I, and S/T (i.e., study type or types of study). Alternatively, instead of study type or types of study, the truncated PIC approach emphasizes the comparison intervention or exposure.</p>
<p>Although conceptualizing models are widely used by information specialists, little is known about the impact of using them as tools for developing search strategies. Therefore, the aim of this systematic review was to determine whether the use of the PICO model as a search strategy tool improves the quality of literature searches.</p>
<p>We searched PubMed (Table 1), Embase, CINAHL, PsycINFO, the Cochrane Library, Web of Science, Library and Information Science Abstracts (LISA), Scopus, and the National Library of Medicine catalog on January 9, 2017. After testing and validating our PubMed search strategy using the capture-recapture technique as well as evaluating retrieval of known items [16], we translated the search strategy for use in other databases, adjusting the controlled vocabulary as applicable (supplementary Appendix A). We also examined reference lists and performed citation searching (Web of Science, v.
5.23.2, up to February 1, 2017) of included studies to identify other potentially relevant studies.
</p>
<p>We considered all primary studies, regardless of design, as eligible for inclusion if they examined PICO as a tool for developing a search strategy (distinct from other methods for developing a search strategy) for identifying potentially relevant studies in any topic area. We excluded review articles but examined their reference lists to identify other potentially relevant studies. We applied no other restrictions, such as those related to languages or publication years, in this review.</p>
<p>Our primary outcome measure was the quality of literature searches using two measures: precision and sensitivity [17]. The Cochrane Handbook defines sensitivity as the number of relevant reports found divided by the total number of relevant reports in existence and precision as the number of relevant reports found divided by the total number of reports identified [10]. Our secondary outcome measure was time spent on the literature search.</p>
<p>We noted and summarized information pertaining to author, year of publication, study design, searchers, search strategy tools, and calculation of sensitivity and precision. Studies that did not evaluate and quantify the quality of the literature searches in terms of both precision and sensitivity were excluded from analysis. Empirical studies show that recall and precision are inversely related.</p>
<p>High recall can easily be obtained but will, however, be at the expense of precision. Because a trade-off between recall and precision is unavoidable, one should only evaluate searches with both of these measures [18].</p>
<p>No validated criteria exist for assessing the risk of bias in studies evaluating the effect of PICO as a tool for developing the search strategy in terms of the quality of the searches. Therefore, we used a selfdeveloped set of three criteria: (i) searcher skills, (ii) match between model and question, and (iii) performed searches (Table 2). Each criterion consisted of a set of individual considerations and was assessed using the categories "low risk of bias," "high risk of bias," and "unclear risk of bias." If one of the considerations in a criterion was judged as "high risk of bias" or "unclear risk of bias," the overall judgment for that criterion was "high risk of bias" or "unclear risk of bias," respectively. We developed the three criteria by consensus; however, this tool was not validated.</p>
<p>(i) Searcher skills. The searchers (i.e., study participants or authors) were the individuals performing the literature searches. If the searchers differed in their searching skills, this might have affected the overall results of the study. Thus, if some searchers had more training in literature searching than others, this could introduce a risk of bias. Similarly, if some of the searchers were familiar with the search strategy tools prior to the study, this also increases the risk of bias. Furthermore, if searchers used all included models in the study (e.g., were instructed to use particular conceptualizing models or unguided searching), the order in which the search strategy tools were applied might have affected search behavior, thus, introducing a risk of bias. Finally, although blinding of the searchers is not possible, blinding of the reviewers evaluating the search results is possible and serves to reduce the risk of bias resulting from knowing the identity of the searchers or search strategy tools that were applied.</p>
<p>(ii) Match between model and question. Our risk-ofbias assessment for this criterion was based on the consideration that particular conceptualizing models might be developed to fit different topics or quantitative versus qualitative research and might apply to some topics or research areas better than others, which could influence the study results.</p>
<p>Recent recommendations show that different review types require different question formats (i.e., different conceptualizing models and, thus, different search strategy tools) [19]. The fit between model and topic cannot be manipulated (e.g., if a research question does not include an intervention, all elements of the PICO model will not be applicable and, thus, will not fit that particular research question). We considered applying a conceptualizing model that was not fit for that particular research area a high risk of bias.</p>
<p>Table 2 Risk-of-bias criteria</p>
<p>Searcher skills Describe the skills of the searchers as well as their prior knowledge in the specific fields of the searched topics.</p>
<p>Searcher skills had bias due to inadequate random allocation of searchers to topics or order of search strategies applied as well as lack of concealment of searcher identity to reviewers.</p>
<p>Describe the chosen models, the topics to which they are applied, and the number of resulting search blocks. Describe how relevance of search results to topic is determined.</p>
<p>Fit between model and topic bias due to inadequate application of models to topics, varying number of search blocks, and relevance assessment not based on a gold standard.</p>
<p>Quality of searches Describe how the searches are performed and adapted for each database.</p>
<p>Searches performed had bias due to inadequate adaption of searches to each database as well as lack of consistency in search quality across search strategy tools.</p>
<p>Another aspect of the fit between model and question is the relevance of the obtained search results. As sensitivity and precision measures are based on relevance, the search results need to be assessed for their relevance. Determination of the relevance of the obtained search results is performed ideally using a predefined set of publications (i.e., a gold standard), such as those retrieved in a systematic review, that can serve to assess the relevance of the search results. Alternatively, an expert group could assess the relevance of the retrieved results. A system's view of relevance (i.e., the ranking of results or a study being present in the search results) is not sufficient [20]. We considered applying precision and recall without considering relevance based on a gold standard or an expert group a high risk of bias.</p>
<p>Finally, the number of search elements or search blocks needs to be considered, regardless of whether the search was unguided or structured by the use of a search strategy tool. All other things being equal, the number of retrieved articles will decrease as the number of blocks is increased. Consequently, the more elements, the fewer hits, which would affect the results of the study in terms of comparing applied search strategy tools. We considered search strategy tools (i.e., conceptualizing model or unguided search) that had a different number of search elements or search blocks a high risk of bias.</p>
<p>(iii) Quality of searches. Our risk-of-bias assessment for this criterion was based on our consideration that the quality of the literature searches might impact the results of the study. Searches could be consistently high quality or consistently low quality, which does not in itself imply high risk of bias. However, if the quality of the searches is not consistently high or low, bias can occur. The quality of searches in this case was determined using criteria outlined in the PRESS statement [3], stressing that the criteria and methods depended on the specific databases. If the literature search was not conducted uniformly or if subject headings were not correctly adapted for each database, we considered it to have a high risk of bias. Due to differences in the comparisons among search strategy tools in the included studies, we did not perform quantitative analyses. We, therefore, did not follow the sections in the PRISMA 2009 checklist [15] that relate to meta-analysis.</p>
<p>The literature search identified a total of 1,269 unique records (Figure 1). We assessed 22 full-text articles for eligibility and excluded 19 due to wrong study design (i.e., studies that did not examine PICO as a tool for developing a search strategy for identifying potentially relevant studies in any topic area), wrong outcomes, or wrong interventions (supplementary Appendix B). Therefore, three studies were included in the qualitative analysis [21][22][23] (Table 3).</p>
<p>the authors of the study based on the PICO framework and combined into queries; although not explicitly stated, the authors likely also performed the searches [21]. The study evaluated 15 search strategies that varied in their query structure (PIC or PICO), use of PubMed's Clinical Queries therapeutic filters (broad or narrow), and search limits, as well use of PubMed links to related articles. A total of 450 searches were performed. Relevance was assessed on the first 40 records of the search output as well as the complete search output. The study reports that the PICO model resulted in increased median sensitivity and precision of the search results.</p>
<p>Hoogendam et al. evaluated the effectiveness of PICO versus unguided searching among 14 residents and 8 specialists who had an interest in vascular medicine [22]. Participants received a lecture by an expert searcher explaining the basics of PubMed to ensure a basic knowledge of PubMed functionality. Participants performed unguided searching for 5 minutes on 12 therapeutic questions regarding vascular medicine. After 2 weeks, an expert searcher explained the use of PICO, and participants performed PICO searching for 5 minutes on 12 different therapeutic questions.</p>
<p>Although not statistically significant at the p&lt;0.05 level, using the PICO model resulted in a higher average sensitivity and lower average precision than did unguided searching. [23]. The authors developed a detailed search strategy in collaboration with a specialist librarian and information specialist. Identical search terms were combined using the PICO, PICOS, or SPIDER search strategy tools and compared across PubMed, Embase, and CINAHL, resulting in a total of nine searches. The authors found that PICO retrieved the largest number of hits and recommended using PICO instead of SPIDER.</p>
<p>The three included studies varied widely in their design, choice of comparators, number of databases searched, procedure for relevance assessment, and methods of calculating outcomes (Table 3).</p>
<p>Study design. One study was designed as a randomized trial including health professionals (residents and specialists) [22]; the other two were observational studies in which the authors were involved in the literature searches along with a specialist librarian and information specialist [23] or without stating who exactly performed the searches [21].</p>
<p>Relevance assessment. Two of the three included studies used Cochrane systematic reviews to formulate the clinical questions. These reviews were used as a basis for the search strategies and as a gold standard for determining the sensitivity and precision of the search results [21,22]. One study compared PICO to PICOS and SPIDER with a focus on a specific research question; as a consequence, the search strategy was built from elements of the research question, and the relevance of search results was judged against inclusion criteria [23]. Consequently, the included studies calculated sensitivity and precision from a gold standard [21,22] or a list of included studies [23].</p>
<p>Journal of the Medical Library Association 106 (4) October 2018 jmla.mlanet.org Choice of comparator. Two of the three included studies compared the PICO model to alternative conceptualizing models. However, the two studies compared PICO to different conceptualizing models; thus, the PICO model was not compared to the same alternative conceptualizing models across studies.</p>
<p>One study compared the PICO model to the truncated PIC model in PubMed and reported that the PICO model resulted in increased median sensitivity and precision of the searches [21]. However, the performance of the tested search strategies was highly variable depending on the clinical question, and none of the 15 strategies showed a consistently high sensitivity in retrieving relevant articles. The study also used PubMed links to related articles as a search strategy, which resulted in higher sensitivity and precision than both the PICO and PIC models. The calculations were based on the first 40 records of the PubMed output as well as the complete search output. When the full output was screened for relevant studies, about 85% of records were detected by the PIC queries and about 69% by the PICO queries [21].</p>
<p>One study compared the PICO model to PICOS and SPIDER in CINAHL, Embase, and MEDLINE [23]. Although hardly conclusive due to extremely limited data, the use of PICO as a search strategy tool resulted in higher sensitivity and lower precision than the use of PICOS and SPIDER. However, as different numbers of search blocks were used for each model (i.e., PICO: 3 search blocks, PICOS: 4 search blocks,
SPIDER: 6 search blocks), these results are expected.
</p>
<p>One study compared the PICO model to unguided searching [22]. The study reported that use of the PICO model resulted in higher average sensitivity and lower average precision than did unguided searches, although this difference was not statistically significant.</p>
<p>Outcomes reported. None of the included studies investigated the time spent on the literature search.</p>
<p>We used three risk-of-bias criteria to assess the risk of bias: (i) searcher skills, (ii) match between model and question, and (iii) quality of searches. Overall, there were several instances of unclear or high risk of bias with respect to all three criteria (Table 4). The searcher skills criterion revealed either an unclear risk of bias [21,23] or a high risk of bias [22] in the studies. The match between model and question criterion revealed that two studies [21,23] had a high risk of bias and one study [22] had an unclear risk of bias. Finally, we found that the quality of searches criterion revealed that two studies [21,22] had an unclear risk of bias, and one study had a low risk of bias [23]. A complete overview of the risk of bias assessments can be found in supplementary Appendix C.</p>
<p>This study is the first systematic review aiming to determine whether the use of the PICO model as search strategy tool affects the quality of the literature search, which had the potential to provide valuable evidence of the effect of using PICO to formulate search queries. This review is strengthened by the use of rigorous methods based on prespecified criteria in a protocol following both the AMSTAR measurement tool [14] and PRISMA 2009 checklist [15], a comprehensive literature search and duplicate screening process, data extraction, and risk-of-bias assessment. However, we identified only three studies that were eligible for inclusion in the review [21][22][23], and given the marked differences among studies, it was only possible to perform qualitative analysis. Despite the rigorous methodology that we used, there are limitations for this review. No validated assessment tool exists for these types of studies, which led us to develop our own set of risk-of-bias criteria. As opposed to validated criteria such as Cochrane's risk-of-bias tool for assessing randomized trials [24], our tool was not validated, which would have been preferable. Despite the limitations of our risk-of-bias tool, we regarded all three included studies [21][22][23] as having a high or unclear risk of bias. Consequently, it is extremely difficult to draw any conclusions from their findings.</p>
<p>As no similar reviews exist, we turn to the individual studies to enlighten our discussion on whether the use of the PICO model as search strategy tool affects the quality of the literature search. Two issues are prominent: the importance of the number of search blocks and the practice of avoiding outcome-related terms in the search strategy.</p>
<p>First, the number of search blocks in a literature search is important for the search output. That is, the more search blocks that are included, the more restricted the search output will be. One of the included studies did not compensate for the number of search blocks in each strategy, and thus, as expected, the search strategy tool with the lowest number of blocks retrieved a greater number of hits [23]. Existing guidelines recommend using only the truncated PIC version of the PICO model for performing literature searches for systematic reviews [13]. The rationale is that some or all outcome measures might not be mentioned in abstracts, and including a search block defining the outcomes leads to a lower sensitivity of the literature search.</p>
<p>One study that was included in this review investigated the median sensitivity and precision of the PICO model compared to the PIC model [21]. Surprisingly, the study reported that the PICO model performed better than the truncated PIC model with regard to sensitivity and precision. However, these results were based only on the first forty records of the search output, which might explain this surprising finding, because an inverse relationship usually exists between sensitivity and precision [18]. Also, depending on how the search results were sorted, different results could be obtained. When considering the full search output, the PIC model did show a higher sensitivity and lower precision, although both measures varied greatly across different searches [21]. This finding of higher sensitivity and lower precision when using the PIC model (three search blocks) compared with the PICO model (four search blocks) [21] is in accordance with another included study that found that the PICO model (using three search blocks: P, I, and O) resulted in higher sensitivity and lower precision than the PICOS model (four search blocks) or SPIDER model (five search blocks) [23]. Taken together, these results suggest that the number of search blocks impacts the quality of the search output as quantified by sensitivity and precision.</p>
<p>Second, the claim that searching for outcomerelated terms when using the PICO model as a search strategy tool lowers the sensitivity of the search [13] is not substantiated. Based on the limited data from this review, however, we are not able to make any firm conclusions. The study addressing this issue [21] focused on identifying search components and tools that could help clinicians build more effective strategies to answer questions at the point of care and did not include sophisticated strategies used for performing systematic reviews; thus, its results are of limited generalizability. Future studies investigating the effect of searching for outcome-related terms are needed to support this recommendation [10].</p>
<p>The PICO model was developed to help structure a well-built clinical question and enable a literature search [6]. Since its introduction, it has played an important role as a conceptualizing model in EBM [10]. However, evidence of the effect of using the PICO model as a search strategy tool is still lacking, and the studies that were included in this review do not allow us to build upon this important body of evidence. To practice EBM with evidence-based methods, and thus ensure rigorous methodology, the results of this review indicate that more work is needed to assess the applicability of specific conceptualizing models. Furthermore, we propose that it is important for future research on this topic to address three potential risks of bias: (i) searcher skills, (ii) match between model and question, and (iii) quality of searches.</p>
<p>Overall, there have been few studies assessing the effect of using the PICO model versus other available models or unguided searching on the quality of literature search results. Specifically, despite a rigorous search and selection process, we found only three such studies. Due to heterogeneity among these studies, quantitative analysis was not possible, and no solid conclusions about the effect of using the PICO model on the quality of the literature search could be drawn. Before implications for current practice can be made, there is a need for well-designed studies to evaluate the role of the tool used to devise a search strategy.</p>
<p>Fields] OR Online database searches [All Fields] OR Online database searching [All Fields] OR Online databases search [All Fields] OR Online databases searches [All Fields] OR Online databases searching [All Fields] OR Research Based Medical Practice [All Fields] OR Research Based Nursing Practice [All Fields] OR Research Based Occupational Therapy Practice [All Fields] OR Research Based Physical Therapy Practice [All Fields] OR Research Based Professional Practice [All Fields] OR Review Literature as Topic [All Fields] OR Search strategies [All Fields] OR Search strategy [All Fields] OR State of the art review [All Fields] OR State of the art reviews [All Fields] OR Systematic review topic [All Fields] OR Text mining [All Fields] OR Theory Based Nursing Practice [All Fields] #2 Pico [All Fields] OR patient intervention comparison outcome [All Fields] OR patient intervention comparator outcome [All Fields] OR (population intervention comparison outcome [All Fields] OR population intervention comparison outcomes [All Fields]) OR problem intervention comparison outcome [All Fields] #3 #1 AND #2</p>
<p>jmla.mlanet.org 106 (4) October 2018 Journal of the Medical Library Association</p>
<p>jmla.mlanet.org 106 (4) October 2018 Journal of the Medical Library Association</p>
<p>We thank the anonymous referees for their useful suggestions and Rasmus Højbjerg Jacobsen for carefully revising the manuscript.</p>
<p>• Appendix A: Literature searches</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f322482414"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:00+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The extraction of data from the reports of primary studies, on Background: which the results of systematic reviews depend, needs to be carried out accurately. To aid reliability, it is recommended that two researchers carry out data extraction independently. The extraction of statistical data from graphs in PDF files is particularly challenging, as the process is usually completely manual, and reviewers need sometimes to revert to holding a ruler against the page to read off values: an inherently time-consuming and error-prone process.</p>
<p>Our study suggests that the incorporation of this type of tool in Conclusions: online systematic review software would be beneficial in facilitating the production of accurate and timely evidence synthesis to improve decision-making.</p>
<p>Systematic review and meta-analysis are research techniques whereby as much relevant literature as can reasonably be identified on a research question is collated and analysed to give an overview of that field. In a meta-analysis, the quantitative results of the relevant research evidence are extracted from the primary research and statistically synthesised (analysed) to determine an estimate of the overall effect observed across studies and the precision associated with that effect estimate.</p>
<p>In order for the meta-analysis to be based on a sound dataset, the outcome data (i.e., quantitative results) need to be accurately and efficiently extracted from the primary research studies. This is often more challenging than perhaps it sounds. Studies within a review can present relevant outcome data in different ways, whether it be through providing multiple measures of the same outcome, measures at multiple timepoints, or in multiple statistical forms. These variations require skill and attention from the analyst to determine which data points need to be extracted and included in the analysis, in such a way that minimises bias and error in the selection and extraction of data. This can make the process very time consuming, even for small reviews; the labour required is obviously compounded in very large reviews, such as those seen in preclinical research.</p>
<p>A further complication is the actual presentation of the data, as different studies will report the outcomes in different ways, such as graphical plots, in tables, or as text. Whilst it might be difficult to aid reviewers in terms of selecting which pieces of data to extract through a software program, as this will inevitably vary from review to review, we considered there to be clear potential to improve both the speed and accuracy of extraction of outcome data from the included studies once the required outcomes have been identified. This report is of an evaluation of a tool designed to assist specifically with the extraction of outcome data from graphical plots, as these can be particularly time-consuming and prone to error 1,2 . We acknowledge that there is a variety of different ways that papers are presented (online, paper only, etc.), but we focused this work on the challenge of extracting data from papers published using the PDF file format. This format is the most ubiquitous electronic publishing medium for papers and we therefore see greatest efficiencies from improving software support in this area.</p>
<p>The use of systematic reviews is commonplace in clinical research, for example through Cochrane, where they are seen as the pinnacle of high-quality research synthesis, and are used frequently in clinical decision making 3 . In preclinical and in vivo fields, however, systematic reviews are less prevalent, but arguably can be just as useful, for example by guiding future research and bridging the gap between the quantity of research produced and the amount that can be effectively used by an investigator. Whilst there are some research groups pioneering the use of systematic review in preclinical fields (e.g. CAMARADES) systematic reviews have not yet gained the widespread acceptance that they have in clinical research 4 .</p>
<p>One of the key criticisms of systematic reviews is that, once published, they can quickly go out of date 5 . Whilst this is true for clinical systematic reviews, it is especially true for preclinical reviews due to the sheer volume and accrual rate of preclinical literature, which means that a preclinical systematic review and meta-analysis is likely to take a longer time to complete than a clinical one. For example, in a recently completed systematic review of neuropathic pain, data from 229 clinical trials required extraction 6 , whereas for the corresponding on-going preclinical systematic review data are being extracted from approximately 6000 studies. Therefore, to improve the feasibility, acceptance and usefulness of systematic reviews, methods and technologies need to be developed to speed up the process, and these advances need to be made without damaging the quality of the resultant review, and be easy and simple to disseminate on a wide scale.</p>
<p>Once the studies for inclusion in a systematic review have been identified, the process of 'data extraction' (or 'data collection') begins 7 . This usually involves the abstraction of data from each included study in a systematic and standardised way, from the published reports of the studies, into software from which the data can be analysed as a whole. As the synthesis of findings is conducted using these extracted data, it is vital that the data are extracted reliably. To aid reliability, data are usually extracted by two people working independently, and checked against one another. There is empirical evidence that mistakes made at this stage of the review process can affect effect estimates, and hence, review conclusions 2 .</p>
<p>Outcome data can be quite challenging to extract. Transcription errors are a common problem, with some errors not being detected until after the systematic review has been published 2 . Moreover, some outcome data are only reported in graphs, and systematic reviewers must therefore measure values from the graphs as accurately as they can and record the results. The time taken is an important component of the cost of conducting systematic reviews and reduces their currency. While most results from clinical trials tend to be reported in tabular form,</p>
<p>We would like to thank our two reviewers for their helpful feedback. While they both 'approved' the paper, they provided some useful thoughts for clarifications throughout, and we have amended the paper accordingly. We have also included Supplementary File 6 and Supplementary File 7 with the bibliographic details of the studies we used to identify the range of graphs included in the evaluation.</p>
<p>some diagnostic test accuracy studies only report some aspects of their results in graphical form; and in the preclinical field, the reporting of results in graphs alone is commonplace.</p>
<p>To determine if machine assistance for extracting data from a variety of graph types using a tool that has been developed and customised for systematic review needs has a meaningful impact on a) the time taken and b) the accuracy of the data extracted, compared to current methods (typically using desktop measuring software).</p>
<p>As there are no tools for graphical data extraction that have been developed specifically for systematic reviewers to use, we developed a pilot tool for evaluation purposes that is described below. Our primary interest, however, is in the relative performance of a tool which is designed specifically for data extraction in the context of systematic reviews (rather than this specific tool per se).</p>
<p>We attempted to recruit participants from collaborators, colleagues and students on Masters-level systematic review modules using direct communication, email, social media and face-to-face interactions at conferences. The recruitment strategy targeted people who were known to have training and/or experience in conducting quantitative systematic reviews. No formal sample size calculation was performed because in this study the variation between individuals in the time taken in data extraction was not previously known, but we reasoned that a minimum of 10 participants assessing each of 23 graphs using 2 different approaches would give insights to the strengths and weaknesses of each approach, and of areas for future development.</p>
<p>We provided participants with an information sheet (Supplementary File 2) and consent form (Supplementary File 3), which had to be signed and returned before participation could commence. As complete datasets were most useful, participants were encouraged to complete the trial in its entirety.</p>
<p>To guide the development of the tool we first established the structures of graph and data typically featured in research papers, starting with the preclinical literature, where we consider the challenge of extracting data from graphs to be particularly acute. To do this we selected 34 papers (Supplementary file 6) identified in the context of systematic reviews in two different preclinical fields (animal models of neuropathic pain and animal models of D-galactose-induced aging). Papers were selected covering a range of dates to account for any changing publication patterns within the literature. These were hand-checked by F.C. to ensure that they would be relevant for our purpose (i.e. an original research paper that could be included in a review and contained outcome data presented in graphs). The number of papers required at this stage was not predetermined; instead, we continued collecting graph types until no new graph had been found for 10 consecutive papers.</p>
<p>Two team members that do not work in preclinical research (A.O.E. and J.T.) checked the types of graphs collated to determine whether the range of graphs in their disciplines (clinical and public health research -Supplementary file 7) were represented. The team identified that area under the curve (receiver-operator curve) plots, which are common in diagnostic test accuracy systematic reviews, were not represented, and these were added to the list of graph types.</p>
<p>After specifying the position of the axis (or axes) and calibrating them, the user then enters the main data extraction screen (Figure 4). Here, our development work focused on a new interactive data table which can be dragged to any part of the screen, or docked on the far right-hand-side (Figure 5). The structure of the data table matches the parameters entered previously; in the example, we have three columns for data: the mean, and the upper, and lower confidence intervals. This data structure is multiplied by the number of series and the number of data points that have been specified by the user. The titles of the series are editable text boxes and the user can use the tab key to move between them, entering series titles.</p>
<p>The user then clicks in the cell that they want to enter data into and can then use the mouse to click data points on the graph. The user interface automatically advances between cells. For example, in the data table shown in Figure 5, the user would click in the top cell in the 'mean' column and click on the first data point for 'Model + vehicle'. This value then appears in the relevant cell.</p>
<p>The 'active' cell automatically advances to the upper confidence interval, which is filled in when they click on the relevant point on the graph. Note that the data table is 'aware' of the various data types that it contains and calculates this value as a difference between the mean and the corresponding value on the y-axis, rather than just the y-axis value. The data table can have radically different structures; for example, it can capture both individual and aggregate level data when necessary (Figure 6).</p>
<p>The final piece of development that we undertook was to save the data back up to the server ready for analysis.</p>
<p>The graphs for the new graphical data extraction application were the same and in the same order as the current methods condition, with the addition of 4 AUC/ROC graphs.</p>
<p>Participants were given comprehensive instructions, including a YouTube tutorial video (https://www.youtube.com/watch?v=tzg-NUV-wcg&amp;feature=em-upload_owner) and instructed not to leave the platform running when not in use, as this would affect the accuracy of the time measurements. Data validity were also part of the subsequent analysis</p>
<p>We used a qualitative survey hosted on the surveymonkey.com platform. The questions focused on the background experience of the participants and their perceptions on the ease, speed, and features of the tool. Participants were also asked to indicate their preferred method for future extractions and were able to submit suggestions for development of the tool. This was filled in after completion of the trial. The questions on the survey are presented in Supplementary File 1: https://www.surveymonkey. co.uk/r/G5XYQDS.</p>
<p>To establish the time taken to extract the data for each method we used a within-subjects design. As participants were required to extract the same data from the same graphs in each condition, it was possible to directly compare how long it took using each method of extraction. To measure differences between approaches we calculated by subtraction, for each graph and for each participant, the difference in time taken between each approach, such that a positive value would indicate that the current methods took longer than the new method. Then, for each graph we calculated a mean difference in time taken across participants, along with the standard deviation; and we also calculated the total time taken for all 23 graphs represented in both conditions, and expressed this as minutes.</p>
<p>Note that analysis of the difference in time taken for the two conditions could not be computed for the four AUC graphs because they were only presented in the new graphical data extraction application condition (i.e., we do not have data for the four AUC graphs in the current methods condition).</p>
<p>To establish the accuracy of data extraction, we compared extracted values with the known true values used to render the graphs.</p>
<p>We first defined the tolerable bounds of an 'accurate' extraction for each graph (Supplementary File 4). We calculated the bounds as 1/20 th of one increment in the scale of the graph outcome axis (usually the y-axis). For example, if the outcome axis scale had increments of 10, then a bound of ± 0.5 around the true data point was set. If a given true data point had the value of 6, with a tolerable bound of ± 0.5, then we would accept any value between 5.5 and 6.5 as accurate for that data point. The bounds for each graph are shown in Supplementary File 4.</p>
<p>Extracted data points lying on or within these bounds were considered accurate, while those above the upper bound or below the lower bound were considered inaccurate.</p>
<p>In a real systematic review, data extraction is usually performed by two individuals working independently because 100% accuracy in data extraction cannot be guaranteed; errors of one extractor can be detected when disagreement is observed with the other extractor, and these data points identified for third person reconciliation. For each data point, we determined whether 80% or more participant responses were within the tolerable bound. For each graph, we were then able to determine what proportion of data points were ascertained with sufficient accuracy.</p>
<p>We also calculated an odds ratio for obtaining a sufficiently accurate data point in the new method compared to the current method as: (SufficientNewMethod/ InsufficientNewMethod) / (SufficientCurrentMethod/ InsufficientcurrentMethod), where the values represent the number of data points that were of sufficient (or insufficient) accuracy in the two conditions (new and current methods).</p>
<p>Analysis of the open-ended text responses involved coding the text into categories (themes) that were derived from the data (i.e., not a priori); for example, free text comments about how quickly the participant extracted data were coded as relating to the theme of 'speed'. The frequencies of themes mentioned across participants were examined. To protect the anonymity of the participants and encourage completion, the survey data were not linked to the responses from the data extraction conditions.</p>
<p>Emails were directly sent by a members of the research team to more than 50 people. We are unable to state how many people were exposed to the social media adverts, and therefore cannot provide an accurate number of how many people were indirectly approached.</p>
<p>A total of 32 consent forms were returned. Of these individuals, 10 completed the trial, 9 never started the trial, 7 partially completed the trial and 6 were excluded or dropped out. Recruitment commenced 30/06/17 and was completed 01/10/17. Data for a total of 10 participants were included in the analyses. The relatively high drop-out rate can be explained by the time demands of the evaluation. The evaluation -and especially the 'current methods' component took some participants several hours to complete. This was necessary in order to collect sufficient data to be able to compare the two approaches across so many different types of graph, but it did affect recruitment and retention.</p>
<p>A total of nine participants completed the qualitative survey. They were employed at a higher education institute (n=3), by a governmental agency (n=2) or were students (n=3 doctoral and n=1 masters). Their disciplines were preclinical science (n=4), statistics (n=1), clinical science/medicine (n=2) and social sciences (n=2). All had performed at least one stage of a systematic review and seven stated they had extracted outcome data previously. Tools previously used for extracting data from graphs included the universal desktop ruler (n=3 participants), Adobe measuring tool (n=4 participants), Web Plot Digitizer (n=3 participants) and Excel Grabit (n=1 participant). Three participants stated they had not previously extracted graphical data. Unfortunately, because the survey and trial data were not linked, we could not explore whether the background or experiences of the participants' might have been associated with their performance in the trial.</p>
<p>All respondents indicated that if they had to extract a third set of similar graphs using just one of the methods they would choose the new online tool. In a free text box they were asked why this selection was made. Comments referred to speed (n=7), accuracy (n=4), and ease of use (n=5).</p>
<p>Lastly, participants had an option to submit suggestions for improvement of the tool; these included bug-fixing, an undo button, functionality of plotting the points, and an interface to allow the tool to interact with a data storage tool.</p>
<p>For a new technology to be worth developing and disseminating, at least two conditions need to be in place. Firstly, the technology must be not inferior to existing tools. Secondly, the technology must be seen by the end users as preferable to existing tools. We believe that this study provides sufficient evidence that these two conditions have been met.</p>
<p>Aside from the time-saving aspect, the improvement in accuracy alone is compelling evidence for the further development of the software, as it ultimately may lead to more precise systematic reviews and meta-analyses. In line with Jelicic Kadic et al., Notes: Three of the graphs (10, 15, 20) had incompatible data because participants in the new graphical data extraction application condition selected too many different data input types, so a comparison could not be made. The total number of data points in the two conditions differs due to issues including missing data or incorrect selection of graph type in the new graphical data extraction application condition. a This value represents the mean for this column, not the total.</p>
<p>We note that the few graphs for which graphical data extraction application had very poor performance were cases in which some participants had selected completely the wrong graph type; this means that our estimates for the accuracy of data extraction from graphs for the new graphical data extraction application condition are considerably below that which is probably likely in real life conditions. It also suggests that some training or further guidance on graph type selection within the tool (as depicted in Figure 3) is required.</p>
<p>Unfortunately, the complete automation of outcome data extraction from graphs currently seems unlikely due to the varied nature of graphs and, as in most reviews, not every graph requires extraction, so human intelligence is required to decide which graph is the most relevant. However, for us to move towards goals of minimal human time to get maximum output, specifically for outcome measure extraction, we propose that further software development work be undertaken to support the automatic:</p>
<p>• identification of graph axes and their values, and optical character recognition to digitise text (e.g. axes labels), so a reviewer does not need to enter these manually 15 • recognition of figures that are potentially relevant for a research question</p>
<p>• recognition of figures that are definitely not relevant for a research question</p>
<p>• flagging of discrepancies between reviewers and identification of patterns within these, so that time is saved when resolving discrepancies.</p>
<p>There are several potential limitations to this evaluation. First, we are unlikely to have identified all graph types that are present in the clinical and preclinical literature. However, we believe that the graph types identified include most commonly used formats; other formats such as flow cytometry outputs are rarely extracted in the context of meta-analysis and so their omission is unlikely to have a major impact on our findings. This is supported by the observation that 89% of trial participants either agreed or strongly agreed that the online tool covered the most important graph types.</p>
<p>Third, the extent to which the trial accurately reflected 'reallife' data extraction might be questioned, because in real-life, the reviewer would also be reading the rest of the paper, and maybe only extracting one time point from each graph and extracting other information such as group numbers or details of the paper. However, this trial aimed to separate the data extraction from this, so it could be analysed as a separate entity without other confounding aspects.</p>
<p>Finally, although not explicitly measured here, we observed that most data points that were extracted with sufficient accuracy using the graphical data extraction application had 100% of responses within the tolerable bounds; whereas in the current methods, even those that achieved sufficient accuracy often had responses outside of the tolerable bounds. Had we explored accuracy at the individual participant level, we would have likely seen even greater gains in accuracy in the graphical data extraction application condition.</p>
<p>Do you have a reference for this sentence: 'This can make the process very time consuming, even for small reviews; the labour required is obviously compounded in very large reviews, such as those seen in preclinical research.' Information provided later on, about 6000 studies for a corresponding research could be provided here in the Introduction, i.e. moved from its current position in the manuscript.</p>
<p>-It would be beneficial to explain in the introduction what is the motive for this work when free and easy-to-use tools such as Plot Digitizer exist? Please elaborate further would be a motivation to make 'a tool which is designed specifically for data extraction in the context of systematic reviews'. It could be argued that it is irrelevant what is the purpose of data extraction [perhaps to enable some functionalities that the desktop software does not have?]. Perhaps, also to mention methodological research, i.e. research on researchthere are potentially more types of studies that would need data from figures.</p>
<p>Please identify who are 'participants' here.</p>
<p>'we selected 34 papers identified in the context of systematic': it would be good to provide the list of those papers in the supplementary file Design 'would be extracting data from a PDF file': I would remove emphasis on pdf files. Or clearly specify that this tool is only for figures in PDF files.</p>
<p>I would suggest to explain already here how many participants you had in this evaluation exercise</p>
<p>Sentence: 'Our study was not designed to show superiority, but suggests that there may be an average saving in time of around 6 minutes per graph': the same comment for this time as in the abstract. I would only write about time savings but not provide here minutes per graph. Not every graph will be the same, and then the savings will not be the same for each one.</p>
<p>We agree that PDF is not the only format / medium used, but this is the area where we see most need, and made not change to the abstract. However, we have clarified the scope of our evaluation on page 1: "While we acknowledge that there are a range of different ways that papers are presented (from online to paper only), we focused this work on the challenge of extracting data from papers published using the PDF file format. This format is the most ubiquitous electronic publishing medium for papers and we therefore see greatest efficiencies from improving software support in this area." 2.</p>
<p>We have clarified that we're referring to participants' standard practice for extracting data from graphs.</p>
<p>We have clarified that 'standard practice' is referring only to extraction of data from pdf documents.</p>
<p>We have added the number of participants to the abstract. 5.</p>
<p>We have replaced 'prior preferred current approaches' with 'standard practice' to be more consistent.</p>
<p>As clarified above -we have limited the scope of this evaluation to pdf files.</p>
<p>Evaluation design 1.</p>
<p>We think that this information belongs in the results. Discussion 1.</p>
<p>We have revised in the same way as above. 2.</p>
<p>We have revised to clarify that the Jelicic Kadic study compared paper-based to electronic media.</p>
<p>We have revised that sentence as suggested. 5.</p>
<p>We agree that not giving the tool a name is a bit awkward in terms of writing the paper. This was a deliberate choice however, as the tool itself is proof of principle, and not something that systematic reviewers are able to use at the moment. 6.</p>
<p>We can only see one other mention of '6 minutes' in the discussion (apart from the one already revised) and think that this formulation is an accurate reflection of the results. Future work RevMan is really a platform for meta-analysis and review publication, and we do not think its</p>
<p>Really appreciated all the links to supplementary files, raw data and code etc. Excellent in terms of transparency and reproducibility.</p>
<p>If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.</p>
<p>No competing interests were disclosed.</p>
<p>Reviewer Expertise: Health, evidence synthesis, systematic reviews, systematic review</p>
<p>Note: A positive time difference indicates that the current methods condition took longer than the new graphical data extraction application method condition.</p>
<p>work Integration with RevMan would also be nice.</p>
<p>Nice work, overall. Congratulations to the authors.</p>
<p>Wellcome Open Research 2019, 3:157 Last updated:15 MAR 2019</p>
<p>We have replaced 'prior preferred current approaches' with 'standard practice' to be more consistent. 6.</p>
<p>The Wellcome Trust and Medical Research Council (MRC) supported this research through grant MR/N015665/1; and the Grant information: National Institute for Health and Care Excellence (NICE) through support for Lee Doran-Constant.</p>
<p>Raw data associated with this study, including results of the survey, are available on Zenodo, DOI: https://doi.org/10.5281/ zenodo.1482487 9 .</p>
<p>Source code available from: https://github.com/EPPI-Centre/ Graph2Data. Archived code at time of publication: https://doi.org/10.5281/ zenodo.1484506 9 .</p>
<p>License: GNU Affero General Public License</p>
<p>The Wellcome Trust and Medical Research Council (MRC) supported this research through grant MR/N015665/1; and the National Institute for Health and Care Excellence (NICE) through support for Lee Doran-Constant. The views presented here are those of the authors, and not necessarily those of these institutions.</p>
<p>Click here to access the data "a prototype workflow designed specifically around the needs of systematic reviewers" "The aim was not create a new tool that was ready for widespread deployment but to inform future development decisions, based on the evaluation, as to the utility of integrating such a tool in systematic review software" My comment is really just to say that I think these bits are great and cut right to the heart of the paper and what the work aimed to achieve. Perhaps these lines could be brought forward or integrated into the 'Research aim' section at the beginning of the methods?</p>
<p>Valuable paper in this space I think, as we need more evaluations of systematic review tools! No competing interests were disclosed.</p>
<p>I have read this submission. I believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
<p>Author Response 02 Mar 2019 , University College London, UK James Thomas</p>
<p>We would like to thank Chris Marshall for his second review, and are pleased that our revisions have addressed his concerns. We have inserted "The aim was not create a new tool that was ready for widespread deployment but to inform future development decisions, based on the evaluation, as to the utility of integrating such a tool in systematic review software" into the 'aims' section as suggested, to ensure our evaluation focus is clear at the start. We have also made a number of other amendments to improve the paper's clarity in response to our other reviewer.</p>
<p>No competing interests were disclosed.</p>
<p>After reviewing the manuscript 'The development and evaluation of an online application to assist in the extraction of data from graphs for use in systematic reviews', here is my opinion: this is a relevant manuscript, as the process of evidence synthesis would benefit from further methodology refinements, and certainly new ideas for making systematic review methods faster and more accurate are very welcome.</p>
<p>I would like to suggest the following minor revisions:</p>
<p>The extraction of statistical data from graphs in PDF files is': here, I would remove 'in PDF files' because some manuscripts do not have online edition so one would need to rely on printed version. Also, some older manuscripts that are online do not have a PDF version for download. Now, this can be removed if the tool can accept other files too. But if not, it should be specified that the tool in this version was developed only to work with pdf files. Please specify clearly in the abstract what is the 'comparison to standard practice'. I am not sure that there is a standard practice here in a general sense. Many researchers simply disregard data from figures as a 'practice'. Even in some Cochrane reviews one can find a note that data presented only as graphs will be excluded. Later in the text I found more detailed description about what was considered a 'standard practice' and I noticed that four electronic data extraction methods were used, and that ruler-paper method was not used. I think this should be clearly specified in the abstract; that the new workflow was compared with other electronic solutions for data extraction that the participants were using most commonly in their research work. It would be great to mention already in the abstract how many participants took part in the evaluation of design. I would also mention in the abstract that you had qualitative survey with participants. These are all relevant information to present your study more comprehensively. Explain what does it mean 'users' prior preferred current approaches' and how does it compare to 'standard practice' from the previous paragraph of the introduction. See comment above. These terms in abstract should be clearly specified. This statement is very unhelpful 'there may be a saving in time of around 6 minutes per graph,' because there are different types of graphs and savings of time will not be the same if one graph has ten data points to extract, or twenty, or only three, for example. It would be better to be very clear about where is the time savings -how much time is saved to extract one data point if the authors really want to present time saved. This information about six minutes per graph needs to be removed and revised. For example, you can talk about savings per one data point, or to simply say in the abstract that time was shorter with your tool, but refrain from this kinds of inaccurate statements.</p>
<p>Reviewer Expertise: Health, evidence synthesis, systematic reviews, systematic review software/automation</p>
<p>Author Response 14 Jan 2019 , University College London, UK James Thomas</p>
<p>We would like to thank Chris Marshall for his helpful feedback. We have modified the article and provided detailed commentary and screenshots which show the novelty of our approach in more detail (we agree that we should have included this in the original). We have also provided a more explicit statement of our research objectives.</p>
<p>11 December 2018 Referee Report https://doi.org/10.21956/wellcomeopenres.16057.r34420</p>
<p>Trip Database Ltd., Newport, UK An impressive paper with just minor points...:</p>
<p>1) "Systematic review and meta-analysis are research techniques whereby all available literature on a research question is collated and analysed to give an overview of that field." I'm thinking that it should include something like "...an attempt is made to locate and use all available literature".</p>
<p>2) "there is the clear potential to improve both the speed and accuracy of extraction of outcome data from the included studies once the required outcomes have been identified" -I'd say it's not clear if you're not immersed in automated methods.</p>
<p>3) Cochrane collaboration -hasn't it dropped 'collaboration'? I appreciate you made the 'c' in 'collaboration' lower case! 4) "...and are used frequently in clinical decision making" -can we have a reference please? 5) Because of the challenges in manual data extraction from ROC/AUC graphs, these were not offered in this set -I'd have this as a new paragraph. 6) Exploration of drop-outs. 32 signed consent and ten completed the trial -I'm sure it's for mundane reasons -but might this high-level of drop-out be down to some unforeseen reason that might impact future roll out of the technology? 7) Possibly not one for the paper but I do think the long-term future is ensuring the trial variables (including data used in plotting graphs) should be embedded, in computer-readable format, in the articles data used in plotting graphs) should be embedded, in computer-readable format, in the articles meta-data. That removes the problem.</p>
<p>Is the study design appropriate and is the work technically sound? Yes Are sufficient details of methods and analysis provided to allow replication by others? Yes If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.</p>
<p>No competing interests were disclosed.</p>
<p>Reviewer Expertise: Clinical search, automation, question answering, evidence synthesis I have read this submission. I believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
<p>Author Response 14 Jan 2019 , University College London, UK James Thomas</p>
<p>We would like to thank Jon Brassey for his helpful feedback. We agree with all his comments and have modified the article to integrate them all -with the exception of the last one: we agree, but this requires longer-term changes to publication practice! HI Ankit, Thanks for your comment. It is unfortunate that there's a bit of a delay in moderation of these comments, as my guess is that you couldn't see my response to Geoffrey before commenting yourself. I do remember checking for a proper citation for WPD, so apologies it wasn't in the paper -but will be in the next version.</p>
<p>When we did this work (back in 2016), we integrated pdf.js and WPD in what we hoped would become a useful tool, where you could upload a pdf, draw a box around the graph, and then extract the numeric information. As we integrated two tools, and did a lot of additional coding, I think it reasonable to describe the result as a new tool -given that we are clear where the main components came from. I think technology developments have overtaken us a bit, so a future tool to support systematic reviews may use, as you say, just the pdf support that's now in WPD and not need the pdf.js component too. One of the main eye-openers for us when doing this study is just how difficult -and unreliable -our current approaches to extracting data from graphs are, so we fully appreciate and recognise the important contribution to fixing this that WPD makes.</p>
<p>Best wishes, James.</p>
<p>Competing Interests:</p>
</text>
</tei>
  <tei>
    <teiHeader>
        <fileDesc id="f204508709"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:20+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text lang="en">
        <p>Objective: Physical activity (PA) has a profound impact on health and development in children. Parental behaviors (i.e., modeling and support) represent an obvious important factor in child PA. The purpose of this paper was to provide a comprehensive meta-analysis that overcomes the limitations of prior narrative reviews and quantitative reviews with small samples. Methods: Ten major databases were used in the literature search. One-hundred and fifteen studies passed the eligibility criteria. Both fixed and random effects models with correction for sampling and measurement error were examined in the analysis. Moderator analyses investigating the effects of child's developmental age, study design, parental gender, measurement of child PA, and quality rating were performed. Results: Based on the random effects model, the results showed that parental modeling was weakly associated with child PA (summary r = .16, 95% CI .09-.24) and none of the proposed moderators were significant. Separate analyses examining the moderating effects of parental gender and boys' PA found that that father-son PA modeling (r = .29, 95% CI .21-.36) was significantly higher compared to mother-son PA (r = .19, 95% CI .14-.23; p &lt; .05). However, parental gender did not moderate the relationship between parental modeling and girls' PA (p &gt; .05). The random effects model indicated an overall moderate effect size for the parental support and child PA relationship (summary r = .38, 95% CI .30-.46). Here, the only significant moderating variable was the measurement of child PA (objective: r = .20, 95% CI .13-.26; reported: r = .46, 95% CI .37-.55; p &lt; .01).</p>
        <p>Conclusions: Parental support and modeling relate to child PA, yet our results revealed a significant degree of heterogeneity among the studies that could not be explained well by our proposed moderators.</p>
        <p>It has been widely acknowledged by health researchers that participation in regular physical activity (PA) is linked to various health benefits and prevention of chronic disease. In spite of the overwhelming evidence that supports an association between PA and health, much of the populace does not commensurate with the national recommendations. Particularly, many children in North America are insufficiently active to reap the health benefits associated with regular PA. A recent Canadian national survey estimated that 9% of boys and 4% of girls between the ages of six to nineteen met the current recommendations [1]. Likewise, data from the United States showed that more than half of the children surveyed were insufficiently active [2]. At this juncture, intervention efforts to improve child PA levels have produced very modest results [3]. Thus moving forward, it will be crucial to properly identify the key correlates in child and adolescent PA to further the planning and development of PA interventions [4].</p>
        <p>Presently, a total of 14 review papers [5][6][7][8][9][10][11][12][13][14][15][16][17][18] and three reviews of reviews [19][20][21] have been published in this area. From these reviews, parental modeling of PA and parental support of child PA have emerged as major themes. However, many of these reviews have discordant findings. For instance, 12 review papers examining the relationship between parent and child PA have shown variable results [5][6][7][8][9][12][13][14]16,[19][20][21]. Three of the 12 reviews do not support a link between parent PA and child PA [14,20,21], while eight reviews have suggested the association as inconclusive [5][6][7]9,12,13,17,19]. Unlike the findings for parental modeling and child PA, parental support has emerged as a consistent correlate of child and adolescent PA in a number of narrative reviews [6][7][8][9]11,12,14,16,[18][19][20][21]. The more striking absence in this theme is the limited quantitative synthesis in order to provide a point-estimate of the parental support-PA relationship. Only one meta-analysis has examined parental support (r = . 23), but it is several years old and was restricted to three studies [8].</p>
        <p>Another pertinent issue that surrounds parental support as a correlate of child PA has been how support has been defined and measured. Parental support has often been measured as an omnibus of various support behaviours and has no consistent set of behaviours [22]. In some cases, researchers have grouped and measured multiple support behaviours as tangible (e.g., providing transportation, financial support) and intangible forms of support (e.g., praise and encouragement). Through these forms of measurement, it is unclear to which specific individual support behaviours may be important in child PA. A more comprehensive synthesis of these support factors is needed.</p>
        <p>Finally, prior reviews on this topic have been restricted to very specific age-ranges, which reduces our understanding to whether modeling and support vary across the developmental spectrum. No prior metaanalyses have explored the parental correlates according to developmental stages (i.e., preschool, childhood, and adolescence). A meta-analysis is necessary to consolidate and clarify the overall information.</p>
        <p>With these limitations in mind, the aim of this metaanalysis was to provide a cohesive and comprehensive examination of the parental correlates, and potential moderators, of child PA. Here, the five postulated moderators included the child's developmental age, method in which child PA is measured (objective or reported), geographical location of the sample population, study design, and quality of the study. Moreover, we investigated the possibility of intergenerational gender interactions between parent and child behaviours. It was hypothesized that overall parental PA would have a negligible to small correlation with child and adolescent PA, explaining the prior inconsistencies among the narrative reviews; whereas overall parental support will have a small to medium correlation. Among the individual support behaviours, it was postulated that a small effect size will be found for the various support behaviours and child PA. Our analysis of intergenerational gender interactions between parental and child was considered exploratory.</p>
        <p>To ensure transparency and complete reporting, the protocols for this study were in accordance to the recommendations put forth by the PRISMA statement for conducting systematic reviews and meta-analyses [23]. Studies were included if: 1) children were between 2.5 and 18.0 years; 2) an assessment of parental/family support, individual parental support behaviour(s), or parental PA as the independent variable; 3) a measurement of children's PA as the dependent variable; and 4) an effect size illustrating the relationship between independent and dependent variables or the availability of statistics to calculate an effect size (e.g., means and standard deviation). Studies were excluded from the review if: 1) social support measures consolidated parental sources with teachers, peers, or friends; 2) the study was qualitative; and 3) not published in English.</p>
        <p>PA was defined as "any bodily movement produced by skeletal muscles that results in energy expenditure" [24]. This definition encompassed both structured (e.g., organized sports, lessons) and unstructured PA (e.g.. leisuretime PA, play). Encouragement to be active, parent-child co-activity, praising the child's activity, watching the child be active, informing the child that they are performing well, telling the child that PA is beneficial, and providing transportation to PA venues were classified as parental support behaviours. Other behaviours such as supplying the child with PA equipment and financial support, and enrolling the child in PA programs were classified as individual parent support behaviours.</p>
        <p>Publications from January 1970 to November 2014 were systematically reviewed for this paper (Figure 1). Ten databases were used to locate relevant articles: EBSCO (Academic Search Complete, Academic Search Premier, CINAHL, Health Source, MEDLINE, PsycINFO, Social Sciences, SPORTDiscus), PubMed, and ISI Web of Science. The following key terms were used: physical activity, exercise, sport, adolescent, youth, children, preschool, parental support, parental physical activity, role modeling, parental influence, and parental correlates. One author conducted the search and manually cross-referenced studies to ensure saturation of the literature. The eligibility criteria and search strategy followed a protocol used in previously published metaanalyses and reviews [25,26]. The reference sections of reviews and individual studies were carefully inspected to locate any additional publications.</p>
        <p>Using the inclusion criteria previously established by both reviewers, one reviewer initially screened citations based on the title and abstract. Potentially relevant abstracts were selected and the full article was located if it was deemed suitable for the study. A full consensus by the two reviewers was required in order for the studies to be included in the analysis.</p>
        <p>Based on the hypothesized moderators, the studies included in the analysis were categorized and coded by developmental age (preschool 2-5.4 yrs, childhood 5.5-12.4 yrs, adolescence 12.5-18 yrs), geographical location (Australia &amp; New Zealand, Asia, Canada, Europe, USA), study design (cross-sectional, prospective), type of PA measure used to determine child PA (objective: accelerometer, pedometer, heart rate monitor; reported), and quality (high, moderate, low). Upon further investigation of previous meta-analyses and reviews, some of the studies included did not appropriately categorize effect sizes that represented the overall effect sizes for parentalchild PA variables. For instance, samples only examining girls' or boys' PA were previously amalgamated into overall child associations rather than conducted in separate analyses. In our analyses, the correlates for boys, girls, and mixed samples were abstracted, categorized, and analyzed separately.</p>
        <p>In the case that more than one type of PA measure was reported (ex. overall PA levels versus moderate to vigorous PA), the variable that best reflected the national</p>
        <p>(n = 112)</p>
        <p>Figure 1 PRISMA flow-chart.</p>
        <p>recommendations for PA (i.e., moderate to vigorous PA) was incorporated into the analysis. Studies that incorporated a family support measure were included in the analysis.</p>
        <p>To assess the potential risk of bias and methodological quality, each study was critically appraised using an adapted version of Downs and Black's [28] 22-item assessment tool. This modified tool is comparable to the Cochrane Collaboration's instrument for assessing risk of bias and has been used in several published reviews [25,26,29]. For the purposes of this study, items from the original checklist pertaining to experimental studies and items that were not applicable to this study were excluded. The adapted version utilized a 14-point scoring scheme, where each item was scored one point based on a yes (1) or no (0) response. Studies scoring 12-14 points were deemed high-quality studies, 8-11 points were regarded as moderate-quality studies, and lower quality studies were below 7 points. Studies that scored 4 points or less were excluded.</p>
        <p>Effect sizes included in the analysis were further corrected for sample size and attenuated for potential measurement error. Correction of measurement error procedures was based on the reported reliabilities of the measures found in the study. In the case that the reliability of the measure was not detailed, an rxy = .70 was used. Based on previous publications, this reliability has been identified as a conservative, yet acceptable estimate for reliability [30]. For accelerometer measures that have obtained 4-9 days of data, the recommended reliability estimate of .80 was used [31]. No subsequent correction procedures were conducted for effect sizes derived from structural equation models or hierarchical linear models as these forms of analyses account for measurement error.</p>
        <p>A total of 2,293 potentially relevant citations were identified in the initial search. The screening procedures resulted in a total of 112 studies, with 11 studies extracted from the reference listing of the included articles (see Figure 1). Table 1 describes the characteristics of the 115 independent samples included for the investigation. Details of the included studies are presented in Tables 2,3,4,5,6 and 7. Duplicated studies were not included in the analysis. Table 4 Studies and effect sizes for parental modeling and girls' physical activity moderated by parental gender (k = 62) (Continued)</p>
        <p>Overall effect size A total of 36 effect sizes were used in the analysis to determine the overall relationship between parent and child PA (Table 8). Based on the fixed effects model and correcting for measurement error, parent and child PA associations approached a medium effect size (r = .29, 95% CI .28-.30). However, the results showed that the effect sizes in the sample were significantly heterogeneous Q (36) = 1597.52, p &lt; .001. Due to the high degree of heterogeneity, using the point estimate from random effects model was appropriate, which resulted in a small effect size (r = .16, 95% CI .09-.24). Moreover, 98% of the observed variance was explained by true systematic effect size differences between studies.</p>
        <p>Table 8 indicates that subsequent analyses did not find any of the proposed moderators of parent and child physical activity to be significant (p &gt; .05).</p>
        <p>Based on 49 effect sizes, our analyses found that parental gender moderated the relationship between boys' PA and parents' PA (Table 9). The results showed that father-son PA (r = .29, 95% CI .21-.36) was significantly higher than mother-son PA (r = .19, 95% CI .14-.23; p &lt; .05). For parental modeling and girls' PA, results from the 62 effect sizes showed that parental gender did not moderate the relationship. The correlation for fatherdaughter PA (r = .22, 95% CI 16-.27) and mother-daughter PA (r = .23, 95% CI .18-.27) were both similar in magnitude.</p>
        <p>Overall effect size A total of 34 effect sizes were used to estimate the relationship between overall parental support and child PA (Table 10). Both the fixed and random effects model found that the relationship between parental support and child PA was moderate in size (r = .38). Analyses from the fixed model also indicated that a significant degree of heterogeneity within the sample was present (Q (34) = 1204.70, p &lt; .001) and that 97% of the observed variance was explained by true systematic effect size differences between studies.</p>
        <p>According to the corrected random effects models, many of the effect sizes for the various individual support behaviours were small. Parent-child co-activity, praising the child for being active, watching the child participate in PA, providing transportation to a place where the child could be active, monitoring the child's PA levels, and supplying the child with PA equipment ranged between r = .15-.28 (Table 10). The only support behaviour to have a moderate effect size was the relationship between parental encouragement and child PA (r = .34, 95% CI . 25-.41). Overall, the dispersal of the effect sizes calculated was variable, ranging from 66 to 100%.</p>
        <p>Table 10 presented the potential moderators that were investigated in our analysis. In the analysis, child and adolescent PA was moderated by the type of measurement used to quantify the child's PA (p &lt; .001). When objective PA measures were used, the results showed a small effect of r = .20 (95% CI .13-.26) between a composite measure of parental support and child PA; whereas reported PA had a moderate effect size of r = .46 (95% CI .37-.55). Developmental age, study design, and geographical location were not significant moderators of overall parental support and child PA. Due to the limited number of prospective studies, moderator analyses were not conducted to examine the effects of study design.</p>
        <p>Among individual supportive behaviours, only parental encouragement had an adequate amount of studies to examine potential moderating variables (Table 10). Moderating variables such as developmental age and geographical location were not significant moderators of the parental encouragement and child PA relationship (p &gt; .05).</p>
        <p>When examining the relationship between girls' PA and parental support, the summary analysis of 10 effect sizes found that the parental gender did not significantly moderate this relationship (p &gt; .05) (Table 9). Analyses exploring the moderating effects of parental gender in boys' PA were limited by the number of studies and were not conducted.</p>
        <p>Funnel plots were constructed to investigate the possibility of publication bias for parent and child PA, parental support and child PA, and individual support behaviours and child PA associations. When visually inspected, the resulting funnel plots suggested a potential publication bias for parent and child PA, and providing transportation for the child to be active and child PA associations.</p>
        <p>A subsequent classic fail-safe N analysis for child-parent PA associations showed that 7590 studies with a mean effect of zero were necessary for the overall effect found to become statistically insignificant. Based on this relatively large computation, it indicated that the results were not skewed. However, for providing the child with transportation to opportunities to be active, only 198 studies needed to create a mean effect of zero for the effect to be insignificant, alluding to a skewed effect size. Subsequent trim and fill analyses specified that it was necessary to trim two studies from the computation. With the correction, the effect size for transporting the child to physical activities and child PA decreased from the original point estimate of r = .22 (95% CI .12-.31) to a corrected point estimate of r = .14 (95% CI .03-.24).</p>
        <p>The main objectives of this meta-analysis were to thoroughly investigate and quantify the strength of parental correlates and identify whether parent-child gender interactions are notable in child and adolescent PA. Previous systematic reviews have been narrative in nature and meta-analyses attempting to quantify the overall effects between parental support and modeling behaviours and child PA have been restricted to 20-30 studies [8,16] resulting in a partial depiction of the parental correlates in child and adolescent PA. This meta-analysis encompasses 112 studies published to date and thus sheds a more definitive light on the relationship between parental behaviours and children's PA.</p>
        <p>One of the contentious topics has been whether parental modeling is an important correlate in child and adolescent PA. Recent narrative reviews have suggested that parent's PA behaviours were unassociated with child and adolescent PA [14,20]. The meta-analysis conducted by Pugliese and Tinsley [8] found a small effect (r = .10) for parent and child PA. Our results, after correcting for measurement error, concurred with the previous meta-analysis showing a small overall association between parental and child PA.</p>
        <p>During preadolescent years, parental modeling of PA plays an integral role in establishing a social norm regarding activity [7], but as the child matures, modeling behaviours in the PA domain may be drawn from the emergent influence of the child's peers while the influence of parental modeling wanes. It is also possible that in early years of childhood parent-child coactivity is more prevalent; and as the child ages, the association between parent and child PA bifurcates and becomes more independent from each other. In any case, the results suggest the importance of family-based coactivity interventions in the early years of child development.</p>
        <p>A number of narrative reviews have consistently identified an association between parental support and children's PA [6][7][8][9]11,12,14,16,[18][19][20][21]. This meta-analysis is the first to quantify the relationship between overall parental support and child PA as well as various individual supportive behaviours. In our analyses, overall parental support and child PA yielded a medium effect size. This effect is worthy of noting, particularly when compared to other correlates of child behaviour. For example, a recent meta-analysis examining children's affective judgments in PA, found that affect had a small to medium an effect size (r = .26) between children's affect and PA behaviour [25]. Based on these findings, it suggests that parental support for child and adolescent PA may be an important consideration for future PA intervention efforts.</p>
        <p>In line with this thinking, it is important to examine whether any particular support behaviour is of critical value over others as a potential intervention target. Our analyses of specific behaviours such as praising the child, watching the child participate in PA, engaging in parent-child co-activity, transporting the child to places where the child could be active, and providing the child with equipment all had small effect sizes (r = .14-.28). The only individual support behaviour that was moderate in size was parental encouragement. To date, much quantitative reviews have only investigated the individual support behaviour of parental encouragement on child PA, which has been identified as a small correlation of r = .15-.18 [8,16], which is smaller than our results. However, it is important to mention that these correlations were not previously corrected for measurement error. Overall, based on these various small effect sizes, it may be important to consider the potency of parental support taken as an aggregate rather than any individual support behaviour.</p>
        <p>To date, various studies have examined the moderating effect of parental gender in boys' and girls' PA, yet the finding has been unclear and speculative. In a systematic review, a positive association was found for father-son PA [7]. Similarly, among maternal relationships, motherdaughter PA was significantly related [7]. Our results brought forth a degree of transparency regarding parentchild gender interactions further supporting a stronger correlation for father-son PA. However, in our results no differences were found for mother-son and motherdaughter PA correlations. In the area of parental support, no differences were found for the maternal and paternal interaction for girls' PA. However, the parental interaction regarding boys' PA will require further investigation.</p>
        <p>Overall, these results suggested that the importance between the intergenerational relationship between father and son PA and may be an important consideration when targeting boys' activity behaviour. As well, our findings indicated that the incorporation of parental support behaviours, irrespective of parental gender, were an essential component for prospective interventions that target girls' PA.</p>
        <p>The limitations of this review highlight the fact that additional research is needed in several areas to improve our understanding of the correlates in child and adolescent PA. First, the use of parental support instruments and reporting of the correlation between parental support and child PA in this meta-analysis have been quite diverse, which also has been documented in the previously published literature [18,22]. Moving forward, it may be important to utilize previously validated measures, such as the activity support scale [37], and report both individual support behaviours and parental support as a construct (see [22] for an overview of parental support measures). Second, an important consideration may be children's peers and siblings and how they relate the child's behaviour. Thus, future research will be needed to explore the role of socialization of the immediate social network outside of the family unit and whether other children provide more salient models or social support for PA. Third, much of the research has been limited to developed nations such as the United States, Australia, or Europe. More studies will be needed from other countries to explore whether cultural differences are present. Fourth, an important detail to underscore from this review was that many of the parental respondents were mothers. It may be important to investigate the roles of fathers in the area of parental support and child PA. Lastly, several individual support behaviours were unexamined due to the limited amount of research (e.g., informing the child that PA is beneficial or financial support). More research is needed to uncover the relationship these support behaviours and child PA and whether certain parental support behaviours are conducive to a specific type of PA (e.g., structured or unstructured PA).</p>
        <p>In summary, this meta-analysis presents results that align with previous reviews but represent a larger and more robust assessment of the parental and child correlates literature and the consideration for measurement Note: *p &lt; .001; a some countries excluded from the analysis based on &lt; 4 effect sizes.</p>
        <p>error and methodologic quality. The findings demonstrate that both parental modeling and support related to child and adolescent PA. However, overall parental support emerged as a sizeable correlate linked to child activity. In addition to this, our results revealed a significant degree of heterogeneity among the studies that could not be explained well by our proposed moderators. In order to advance our intervention approaches to increase PA in children and adolescents, it will be critical to consider the development of interventions based on the child's developmental age. More notably, it will be essential to integrate parents as a source of social support to change child and adolescent PA behaviour.</p>
        <p>Yao and Rhodes International Journal of Behavioral Nutrition and Physical Activity (2015) 12:10</p>
        <p>Note. *reliability not reported; CLASS = Children's Leisure Activities Study Survey; CS = cross-sectional; d = day; f = female; GLTEQ = Godin Leisure-Time Exercise Questionnaire; m = males; MVPA = moderate to vigorous physical activity; PA = physical activity; PAQ = Physical Activity Questionnaire; PAQ-C = Physical Activity Questionnaire for Older Children; PARQ = Physical Activity Recall Questionnaire; PEACH = Personal and Environmental Associations with Children's Health; PAEC-Q = Physical Activity and Exercise Questionnaire for Children; PRO = prospective; OSRAC-P = Observational System for Recording Physical Activity in Children-Preschool Version; wk = week.</p>
        <p>Note. *reliability not reported; 7DPAR = 7-Day Physical Activity Recall; CS = cross-sectional; d = days; f = females; IPAQ = International Physical Activity Questionnaire; m = males; MAQ = Modifiable Activity Questionnaire; MAQ-A = Modifiable Activity Questionnaire for Adolescents; MPA = moderate physical activity; MVPA = moderate to vigorous physical activity; PA = physical activity; PAQ = Physical Activity Questionnaire; PDPAR = Previous Day Physical Activity Recall; PRO = prospective; VPA = vigorous physical activity.</p>
        <p>Note: *p &lt; .001; a some countries excluded from the analysis based on &lt; 4 effect sizes.</p>
        <p>The authors declare that they have no competing interests.</p>
        <p>Authors' contributions CY was responsible for the conception and drafting of the manuscript, and acquisition of data. RR was involved in revising the manuscript critically for important intellectual content. Both authors were responsible for the design of the manuscript, and analysis and interpretation of data.</p>
        <p>Both authors read and approved the final manuscript, and agree to be accountable for all aspects for the work in ensuring that questions related to the accuracy or integrity of any part of the work are appropriately investigate and resolved.</p>
    </text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f81549417"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T08:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The internet is a ubiquitous medium for business, information and entertainment, but arguably it has had most profound impact as a means of interpersonal communication. Use of social networking sites grew exponentially after the launch of
MySpace and Facebook in 2004. Within a few years, Facebook was being used by four-fifths of internet users aged 13-16 in the UK (Livingstone et al. 2011). Twitter, allowing short messages to be sent to unlimited Abstract Concerns are increasingly raised in academic and lay literature about the impact of the internet on young people's well-being. This systematic review examined empirical research on the relationship between social media use and depressive symptoms in the child and adolescent population. A systematic search of Medline, PsycInfo and Embase databases yielded eleven eligible studies. Relevant results were extracted from each study, with a total sample of 12,646. Analysis revealed a small but statistically significant correlation between social media use and depressive symptoms in young people. However, studies varied widely in methods, sample size and results, making the clinical significance of these findings nuanced. Over half of the studies were cross-sectional, while those of longitudinal design were of limited duration. This review justifies further investigation of this phenomenon, with a need for consensus on variables and measurement.
</p>
<p>New technology can transform society, but fears have been raised about its physical, social and psychological consequences. This has historical precedent. In the nineteenth century, many people were diagnosed with "railway sickness", a condition attributed to the unnatural motions of train travel, most frequently observed in passengers who had faced backwards (Shaw-Mackenzie 1895). Perhaps the rapid and universal growth of social media has created a "cyber carriage", in which vast numbers of people are oblivious to their physical surroundings while fixated on the internet, accessed through handheld devices. Is living in the virtual reality of social media harmful to younger people's social and emotional development, well-being and mental health, or are the dangers exaggerated by older generations? This is a significant question, because there are reports of escalating mental health problems in children, and difficulties experienced at this age may have enduring impact. This article presents a systematic review of studies measuring the relationship between social media use and depressive symptoms in young people.</p>
<p>recipients, was introduced in 2006 and rapidly gained global popularity. Since the launch of internet-connected smartphones, which overtook sales of cell phones in 2013, instant messaging sites such as Snapchat and WhatsApp have become standard tools of communication. In the USA, recent data show that 93% of people aged 15-17 have mobile internet access through a phone or tablet; while Facebook remains highly popular, Instagram and Twitter are more valued by teenagers (Statista 2016). Whether on conventional computer screen or mobile device, young people use social media in every waking hour, in countries rich and poor.</p>
<p>The internet may be a double-edged sword. Neuroscientist Susan Greenfield (2014) argued in her book Mind Change that digital technology has deleterious effects on personality, identity and relationships. Applying Prensky's (2001) distinction between "digital immigrants" and "digital natives", Greenfield explained that whereas the former were schooled in a pre-digital era, now using the internet alongside older media, the latter have known nothing else. According to this conceptualization, digital immigrants confer higher value on face-to-face interaction, sometimes criticising younger people for contravening traditional social norms when focusing on their mobile devices, while digital natives dismiss this as older people's fear of change.</p>
<p>As described in Turkle's book Alone Together: Why We Expect More from Technology and Less from Each Other (2011), family relationships are weakened when proximate reality is neglected in favor of online contact. Digital technology may be changing conceptualizations and language of human relationships. Defined as a "dyadic, co-constructed phenomenon characterized by reciprocity, closeness and intimacy" (Amichai-Hamburger et al. 2013: 34), friendship is vital for the well-being of children and adults, but the advent of social media appears to have modified its meaning. For "Generation Wired" (a term used by Tam and Walter 2013), such relationships are increasingly generated and maintained online. Data from the Pew Research Center (Madden et al. 2013) show an average of 300 Facebook friends for teenagers in the United States, but the quality of such relationships is more important than the quantity. With a much larger social circle than in traditional friendships, inevitably much communication is shallow (Grieve et al. 2013). Virtual reality may become the real world for some users, to the extent that friends known only through cyberspace become their closest confiding relationships (McKenna et al. 2002).</p>
<p>Evidence suggests that while people with strong social skills and technological abilities accrue benefit from online interaction, those who are less adept do not fare so well. This exacerbation of differences was portrayed by Kraut and colleagues (2002) as "the rich get richer". By contrast, the social compensation hypothesis postulates that socially-awkward people derive benefit from online contact that they do not find with face-to-face interaction (Valkenburg and Peter 2007;Amichai-Hamburger and Schneider 2014). However, while Dolev-Cohen and Barak (2013) suggested that online communication is supportive for shy, anxious or depressive young people, it may compound their difficulties by reinforcing poor selfesteem (Staksrud et al. 2013).</p>
<p>Concerns have arisen about the mental health impact of internet activity on the young, with frequent coverage of this topic in the mass media. Early evidence of adverse psychological impact was presented by Kraut and colleagues (1998) and by Young and Rodgers (1998), who found that frequent internet use raised the risk of depressive symptoms. Since then, studies have shown correlations of online activity by younger people with low self-esteem (Caplan 2002), loneliness (Clayton et al. 2013), self-harm (Lam et al. 2009) and autistic traits (Finkenauer et al. 2012). However, other studies have indicated higher self-esteem and satisfaction with life, and reduced risk of mental health problems (Valkenburg et al. 2006;Bessièrre et al. 2008;Grieve et al. 2013;Best et al. 2014). Development of supportive social bonds and belongingness can protect against adversities such as loneliness and bullying (Wu et al. 2016).</p>
<p>A high proportion of serious mental health problems in adulthood emerges during adolescence (Kessler et al. 2005;Children Young People's Health Outcomes Forum 2012). Epidemiological data predating mass use of online social media showed a high risk of depression in this age group, with estimates of 2-5% prevalence of major depressive disorder (Costello et al. 2003), but recent reports show an alarming increase in depressed younger people (Office for National Statistics 2014). The internet, and related social trends, may be a major factor in the rise of psychological morbidity in the young.</p>
<p>Various theories have been proposed for the putative link between social media use and psychological problems in younger people. Socialization is crucial to the progression from adolescence to adulthood, and use of social media may have profound influence on this adjustment (Wood et al. 2016). Applying John Bowlby's psychanalytic theory, Oldmeadow and colleagues (2013) found that people with attachment anxiety were more likely to turn to Facebook for emotional support. However, reduced face-to-face contact detracts from a traditional supportive environment that can help young people to manage the challenges of adolescence. Development of self-awareness may be inhibited in young people who lack engagement in reflective interactions with family and friends (Siegel 2014). Empathy is honed through social relationships, which may not be as close and meaningful online, where superficial behavior such as virtue-signalling prevails.</p>
<p>The internet may be changing the process of identity formation, which psychoanalyst Erik Erikson (1980) emphasized in the adolescent stage of his model of eight stages of the human lifespan. Each stage presents conflict, which must be resolved to advance successfully to the next stage. Most young people overcome the stress and difficulties of adolescence, but some flounder. Successful progress from adolescence to adulthood entails acquisition of social skills, confirmed and rewarded by social acceptance. Selfpresentation is tested through display and response. As friendships become more complex in adolescence, with the emergence of romantic intimacy and sexual interest, there is need for privacy, yet social media encourage openness and divulgence of personal information. A review of studies of online identity development by Wängqvist and Frisén (2016) showed that aspects of identity constrained in offline contact are freely expressed online, and that anonymity in internet communication has implications for cohesive identity formation.</p>
<p>As argued in an influential book Generation Me by Jean Twenge (2006), narcissism may be increasing in Western society. Twenge and colleagues (2008) found considerably higher scores in this trait in students compared to a group of 20 years earlier. Narcissistic behavior has always been more evident in younger people, who have relatively little responsibility to others while tending to be self-absorbed. The extent is probably exaggerated in the media, as the term is used for people merely taking "selfies": such behavior may be vain, but is socially normative and should not be pathologized if it does not pervasively disrupt daily functioning (Webber 2016). However, the internet has provided more opportunity for expression of narcissistic aspects of personality. People with narcissistic traits are prone to low mood when their high expectations are not fulfilled (Webber 2016). Huprich (2014) described a narcissistic personality pattern including depressive and masochistic tendencies as "malignant self-regard". A depressive reaction to setbacks is a prominent feature of the DSM-V condition of narcissistic personality disorder.</p>
<p>Several socio-cultural theories have emerged on the effect of digital media on mental health. The internet can be a harsh environment for young people, who are heavily influenced by peer pressure. A review by Wu and colleagues (2016) of research on use of the internet for social purposes showed that a major motive for young people is positive reinforcement of their social connectedness. Social media are the forum for the setting and reinforcing of norms. Conformity is rewarded, while a careless remark might result in a person being ostracized. Unrealistic expectations arise as users see the relative popularity of others, as indicated by their number of friends and "likes". A study of college students (Feinstein et al. 2013) showed that negative comparisons with peers on Facebook leads to rumination, which increases the risk of depression. Online self-disclosure may relieve stress, generates supportive messages and raises a person's profile (Tamir and Mitchell 2012), but control of sensitive information is lost. Depressed or anxious young people do not always make sensible decisions about privacy, sometimes revealing personal details in a way that they later regret (McKenna et al. 2002).</p>
<p>Young people are expected to be in perpetual contact, and to project themselves visually as well as verbally. Attractiveness is a major criterion of status and popularity. Young female internet users are particularly keen to choose the most favorable image of themselves on Facebook (Pempek et al. 2009). "Selfies" may be uploaded to seek approval, but an adverse remark may be distressing for someone of delicate self-esteem. Young people are increasingly transmitting sexualized messages or images ("sexting"), with little concern for consent or for exploitation by abusive peers or strangers (Staksrud et al. 2013). Impulsive behavior online may jeopardize future careers, and in some instances children have been criminalized for disseminating sexual images. Aggressive behavior or "trolling" is a common problem in internet use by young people (Ko et al. 2012;Hinduja and Patchin 2013). A review of 113 studies by Kowalski and colleagues (2014) found that cyberbullying correlates with mental health problems in adolescence; in some cases it has led to suicide (Hinduja and Patchin 2010). Bullying may be worse online than in physical proximity, factors being the anonymity of the bully and the inescapable public embarrassment and shame (Slonje et al. 2013). The three most frequent problems arising in counselling sessions provided by ChildLine (a British helpline for children) in 2016 were low self-esteem or unhappiness, family relationships and bullying (online and offline); the latter was the most common reason for counselling in children aged 11 and under, and third in the 12 to 15 years age group (National Society for the Prevention of Cruelty to Children 2016).</p>
<p>Gender differences are an important consideration. Rodgers and colleagues (2013) found that body image concerns correlate with social media use by young female but not male users; such perceptions may lead to eating problems and poorer outcomes of adolescent adjustment. A review of 67 studies of internet use and body image concerns in adolescence by Rodgers and Melioli (2016) described various theoretical perspectives on this link. One theory is self-objectification, which is based on the feminist argument that women are seen as sexual objects under a male gaze. Self-objectification is a form of consciousness manifesting in habitual monitoring of physical appearance, with tendencies for anxiety and shame. Work by Tiggemann and Slater (2013) suggests that self-objectification is a significant cause of psychological problems in adolescence. The combination of media and peer pressure on girls to be thin and sexually attractive is compounded by the internet. Being constantly connected turns a young person into a commodity, to be compared with others (Gonzales and Hancock 2011). However, a limitation of sociocultural theories is their emphasis on structure over agency, which reduces internet users to passivity.</p>
<p>Research has repeatedly shown that girls use the internet mostly for relational purposes (thus being highest users of social media), while boys tend to use it more for instrumental activities such as video-gaming (Park 2009;Kuss and Griffiths 2012). In a study of Canadian teenagers by Sampasa-Kanyinga and Lewis (2015), 71% of girls used social networks for more than 2 h daily, compared to 29% of boys, which partly explained their finding of a marked gender imbalance in psychological distress. A recent UK government survey of children aged 14-15 (Department of Health and NHS England 2015) showed that girls were more than twice as likely as boys to suffer from symptoms of common mental disorder (37-15%), with the proportion of girls with anxiety or depression rising by 10% since the previous survey 10 years earlier. Among various factors discussed by experts was excessive use of social media (Times 22nd August 2016). Gender-related differences in case ascertainment for mental health problems also need consideration, with girls possibly more likely to seek help.</p>
<p>Addictive personality traits may be stimulated by the internet. Soon after the emergence of the worldwide web, psychiatrist Ivan Goldberg (1995) proposed internet addiction as a specific disorder; manifestations are similar to other compulsive behaviors such as gambling, including preoccupation, mood problems, functional impairment and withdrawal effects (Leung 2004). Young (1999) devised the Internet Addiction Scale, which has been used widely in research on internet use. Another instrument is the Facebook Addiction Scale, which measures mood and withdrawal symptoms (Andreassen et al. 2012). Although such addiction was not included by the American Psychiatric Association (2013) in the latest Diagnostic &amp; Statistical Manual of Mental Disorders, internet gaming disorder was entered as a condition for further investigation. However, such diagnostic expansion has been criticized as medicalisation of everyday life (Moynihan and Henry 2006).</p>
<p>Disruption of the body clock may also be a factor in the psychological consequences of internet use. Blue light emitted by digital screens inhibits secretion of melatonin, which is necessary for sleep. A meta-analysis by Carter and colleagues (2016) showed that sleeping beside mobile devices stimulates the brain. Disturbed sleep patterns may cause obesity, weakened immunity and stunted growth. Daytime tiredness and irritability may have social and educational consequences. Change to normal circadian rhythms has known influence on mood (Lewy et al. 1998).</p>
<p>Thus it can be seen that research on the relationship between social media and mental health in young people is multifaceted. Much of the discussion of this topic has occurred in lay media including the popular press, possibly leading to uncritical acceptance of untested ideas and assumptions. Studies indicate benefits as well as harmful effects of internet use, but evidence is complicated by the lack of either causal mechanisms or a certain direction of relationship between variables. Results in one study setting may not be generalizable to young people elsewhere. Whether any increase of psychological distress in adolescence is attributable to online social media activity is not yet understood. A review of relevant peer-reviewed studies was therefore indicated.</p>
<p>This review examined empirical research on the relationship between social media use and depressive symptoms in the child and adolescent population, with three objectives. First, we aimed to produce a critique of the design and conclusions of relevant studies. It is apparent that research findings, particularly as reported in the popular media, may lack inferential validity in measuring the impact of social media on mental health. Secondly, the review was to analyze correlations between social media use and depressive symptoms, including a "dose" effect, taking account of limitations considered above. Thirdly, the review investigated the role of gender, as differences between male and female behavior and response to social media use have been highlighted in research.</p>
<p>A systematic literature search was conducted, seeking relevant articles in peer-reviewed journals. Eligible studies had a generic child or adolescent sample, rather than selecting groups by mental health morbidity or vulnerability. Social media were defined as websites used primarily for social interaction: these include social networking sites such as Facebook, instant messaging (e.g., WhatsApp) and imagesharing applications (e.g., Instagram). Excluded were studies measuring depressive symptoms in relation to use of the internet rather than social media specifically. Although the internet is a rapidly changing phenomenon, no time period was applied, or geographical restriction; such limits would be arbitrary and a risk of selection bias (McCrae and Purssell 2015). As there was no resource for translation, only studies in English language were included. The databases Medline, PsychInfo, and Embase were used, with the following search strategy: Population: child/adolescent aged 5-18 Exposure: social media Outcome: depression/depressive symptoms Articles were screened first by title, then by abstract. At the final stage of screening, full articles were read and assessed independently by all three authors, with any differences in verdict followed by discussion to gain consensus. Eligible articles were summarized and assessed for risk of bias, using the Cochrane Collaboration Methods Group Tool to assess risk of bias in cohort studies.</p>
<p>The computerized search yielded 2357 unique studies with a further 18 from the hand search. After screening by title, 349 abstracts were read. This second stage of screening reduced the total to 134, of which all but one unobtainable article were inspected. Eleven studies fulfilled the eligibility criteria and were included in the analysis (Fig. 1).</p>
<p>Of the 11 studies, six were cross-sectional and five were longitudinal (Table 1). Two studies each were conducted in the United States, Australia and the Netherlands; and one each from Belgium, Spain, Romania, Canada and Taiwan. Overall, the studies had 13,532 participants, although for this review the results applied to a slightly smaller sample of 12,646. In four studies depressive symptoms were the only psychological correlate or outcome variable, while seven studies had two or more such variables (these included social anxiety, stress and suicidal ideation). A variety of different measures were used, the most common being the Children's Depression Inventory, which was used in three studies. DSM criteria for depression were measured in one study.</p>
<p>Risk of bias across studies was high due to the preponderance of cross-sectional studies or longitudinal studies with short follow-up times, lack of exclusion of existing cases of depression, reliance on self-report, and (in some studies) measurement that had not been validated or use of instruments in a different context than originally intended (see Supplementary File 1).</p>
<p>The "rich get richer" and social compensation hypotheses were tested by Selfhout and colleagues (2009), who compared incidence of depression and anxiety between use of internet for communication and other uses in high school pupils. Van der Eijnden and colleagues (2008) studied the relationship between compulsive online communication and psychological well-being, based on previous research indicating that unlike instrumental activities online, use of the internet for social purposes raises the risk of loneliness and depression. The researchers tested several hypotheses to investigate a possible bidirectional relationship.</p>
<p>Self-identity was the theoretical basis for three studies. Social comparison and feedback-seeking are important means of forming a self-identity in adolescence, but Nesi and Prinstein (2015) were interested in how young people may engage in such behaviors in maladaptive ways on the internet. They hypothesized that a high frequency of social comparison and feedback-seeking online would predict depression, although this would be moderated by peer popularity. Neira and Barber (2014) applied self-concept theory in their study of adolescent use of social media. Social comparison and peer feedback are integral to the younger person's self-evaluation, and these are dramatically increased by internet use, thus making a plausible link between social media, self-concept and depressed mood. Dumitrache and colleagues (2012) studied self-image and depressive tendencies in teenage Facebook users. Referring to the contrasting hypotheses of enhancement and compensation, they examined the relationship between positive or negative self-image and the quantity and type of information posted online.</p>
<p>In a female sample, Tiggemann and Slater (2015) investigated correlations between self-objectification, body shame, dieting and use of various types of media. Internet use was considered as a predictor of self-objectification and its adverse consequences, including depression. Gámez-Gaudix (2014) applied the cognitive-behavioral model to investigate problematic internet use and depressive symptoms in teenagers. In this model, online social communication is less threatening than face-to-face interaction, but this readily available source of emotional support can lead to excessive and dysfunctional use. Online activity may be a maladaptive response to depressive tendencies.</p>
<p>Stress was the focus of two studies. Frison and Eggermont (2015) noted that stress increases in adolescence, due to pressures at school and in family relationships. Coping mechanisms include actively seeking social support and avoidance, which are respectively adaptive and maladaptive. While the internet facilitates social support, friendship on Facebook is often weaker, to the effect that support may not be received, with potentially adverse psychological consequences. The researchers studied relationships between daily stress, seeking and receiving of social support, and depressed mood. A psycho-physiological study by Morin-Major and colleagues (2016) investigated Facebook activity (frequency of use, network size, self-presentation and peer interaction) with basal cortisol level (a measure of stress) and depressive symptoms. It is known that social support is a buffer to biological response to acute stressors. Hwang and colleagues (2009) considered the internet as a means of social support in the rapidly changing context of Taiwan. In contrast to the individualism of Western societies, Taiwan has a collectivist culture, and young people are subjected to high social pressures in academic performance, sometimes to the detriment of their well-being. Whereas depression has been normalized in American life, it remains stigmatized in Oriental countries, causing double jeopardy for sufferers. The study by Hwang and colleagues was primarily concerned with the online and offline activity of younger people with depressed mood, but it recruited a general adolescent sample and measured the behavioral and psychological variables in a regression model.</p>
<p>The study by Ybarra and colleagues (2005) had no stated theoretical rationale, but they referred to previous research showing differences in use of the internet by young people in relation to depressive symptoms. Through the Youth Internet Safety Survey they measured online communication, self-disclosure and exposure to sexual content and harassment. Depressive symptoms were assessed using DSM categories of minor and major depressive disorder.</p>
<p>Ybarra and colleagues (2005) categorized the most frequent purpose of internet use (chatroom, e-mail, instant messaging and others). From an overall sample of 1501, chatroom was used most by 136, of whom 101 were not depressed, 22 had symptoms of minor depressive disorder and 13 of major depressive disorder. The proportion depressed (minor or major) was 34%. For this review an odds ratio for depression was calculated, comparing chatroom users with those in the category of other purposes; the result was a statistically significant excess of depression in the chatroom group. Although not included in statistical analysis in this review, the instant messaging category was also relevant. This was the most common use of internet for 154 participants, of whom 133 were not depressed, 18 had symptoms of minor depressive disorder, and 3 of major depressive disorder; the depressed proportion was 14%. Hwang and colleagues (2009) found a statistically significant relationship between online communication and depressed mood. Overall, the study showed that adolescent participants who reported depressive mood were more likely to use the internet for friendships and to express feelings compared to those who did not report depressive symptoms. From the study by Dumitrache and colleagues (2012) of self-image and depressive tendencies in Facebook users, we extracted the correlation between amount of identity-related items in Facebook profiles and depressive symptoms; this was statistically significant. Overall, the study showed that depressive symptoms correlated with low self-image and identity-type information on Facebook.</p>
<p>Extracted from the study by Neira and Barber (2014) was the correlation between frequency of social network use and depressed mood, which was a statistically significant negative result. However, the study also measured participants' investment in social media, which produced a statistically significant correlation of 0.22. The study showed that although depression reduced with frequency of social network use, it increased with excessive use. Frison and Eggermont (2015) found that stress levels predicted seeking of social support on Facebook. We extracted the correlation between seeking social support and depression, which was statistically significant. While seeking social support increased the risk of depressed mood, actual support decreased it. From the study by Tiggemann and Slater (2015) of correlations between self-objectification, body shame, dieting and use of media, we extracted the result for Facebook and
MySpace use and depressive symptoms; this was statistically significant. Statistically significant correlations with social media use were also found with selfobjectification, body shame and dieting.
</p>
<p>In the study of social comparison and feedback-seeking and depressive symptoms by Nesi and Prinstein (2015), a statistically significant relationship was found between these online behaviors at baseline and depression 12 months later. Van der Eijnden and colleagues ( 2008) modelled the relationship between various internet uses, loneliness and depressive symptoms, with two time points (0 and 6 months). The result for instant messaging was extracted, as this was much more widely used by participants (49-55%) than chatrooms (3-5%). For instant messaging at time 1 and depressive symptoms at time 2, the correlation was 0.17, while the result for chatroom use was 0.07 (not statistically significant). Unlike other types of internet use, social media raised the risk of compulsive internet use 6 months later. Selfhout and colleagues ( 2009) compared incidence of depression and anxiety between use of internet for communication and other uses, with two time points (0 and 12 months). Extracted was the correlation between instant messaging and depression at time 2; the negative result was not statistically significant. Compared to surfing the internet, time spent in socializing online is more beneficial. Participants with lower quality of friendships and who used the internet for purposes other than communication were more likely to become depressed or socially anxious. Gámez-Gaudix (2014) measured temporal relationships between features of problematic internet use and depressive symptoms, with an interval of 12 months. Extracted was the result for preference for online over offline communication (time 1) and depressive symptoms (time 2), which was statistically significant. A bidirectional relationship was found between depression and use of social media: the former at time 1 predicted increase in the latter at time 2, and vice versa. Morin-Major and colleagues (2016) modelled the relationship between basal cortisol level, Facebook activity and depressive symptoms, over a period of 3 weeks. Extracted was the correlation between Facebook use frequency and depressive symptoms, which produced a negative but not statistically significant result. Also measured was Facebook peer interaction behaviors and depressive symptoms, producing a negative result (not statistically significant). The study showed that cortisol levels were positively correlated with the number of Facebook friends and negatively with peer interaction; no relationship was found with depressive symptoms.</p>
<p>Several of the studies found gender differences in the relationship between social media use and depressive symptoms. Nesi and Prinstein (2015) found a stronger correlation of social comparison and feedback-seeking and depressed mood in girls. Neira and Barber (2014) found a similar result with online social networking: girls who invest in social network sites were more susceptible than boys to depressed mood. Frison and Eggermont (2015) found that stress predicted depressed mood in girls but not boys. The study by Ybarra and colleagues (2005) showed that girls with high internet use were 3.8 times more likely to have major depressive symptoms than no symptoms. Other studies found no gender differences, while two studies (Van der Eijnden et al. 2008;Dumitrache et al. 2012) found that girls were less likely to show depressive symptoms than boys. Several studies showed that girls and boys use the internet for different reasons, and that through greater investment in social media, female users derive benefits while also being more prone to adverse consequences. There was imbalance in the sex of study subjects: one study (Tiggemann and Slater 2015) was confined to girls, but this does not account for an overall female sample of 59%.</p>
<p>The overall random effects pooled estimate was 0.13 (0.05, 0.2), p = 0.001; Q = 131.47, df = 10, p = &lt; 0.0001, I 2 = 92.4% (Fig. 2), suggesting a clinically and statistically significant relationship between social media use and depressive symptoms (Table 2). There was little evidence of publication bias: the linear regression test of funnel plot asymmetry showing no evidence to reject the null hypothesis of funnel plot symmetry (t = 0.3, df = 9, p = 0.77); although this measures small study effects rather than bias directly. The funnel plot for this is shown in Fig. 3. Additionally the trim and fill analysis showed two outlying studies (Dumitrache et al. 2012;Nesi and Prinstein 2015), trimming and filling of which had some effect in reducing the random effects estimate, r = 0.09 (95% CI 0.01, 0.16), p = 0.03; Q = 180.67, df = 12, p &lt; 0.0001, I 2 = 93.4% (see Supplementary File 2).</p>
<p>To assess any possible impact from publication type, sub-group analyses were conducted for the two types of study design. The pooled estimate for cross-sectional studies (n = 6) was r = 0.12, (95% CI 0.02, 0.22), Q = 81.01, I 2 = 93.8%; while that for longitudinal studies (n = 5) was r = 0.12, (95% -0.01, 0.25), Q = 38.98, I 2 = 89.7%; suggesting little effect, although the difference between study types was not always marked and the time over which the longitudinal studies were conducted varied widely. Although there was a difference between the two estimates, this is not clinically significant and the test for subgroup difference was not statistically significant (Q = 0.0, df = 1, p = 0.98). In order to try to understand the results Euclidean cluster analysis was undertaken based on the results alone. The agglomerative coefficient was strong (0.94) and showed three main clusters (Fig. 4), suggesting that study outcomes could be broadly put into three groups. Examination of the clusters revealed two groups of outlying studies; one showing small negative correlations and the other large positive effects. However, the third and largest cluster, accounting for the majority of studies, had a limited range of outcomes. Thus although we cannot account for the clusters methodologically, this distribution of results is supportive of our pooled estimate being an accurate reflection of the underlying phenomenon.</p>
<p>The internet has transformed lives, with young people now spending several hours per day online. While there are obvious benefits of technological progress, including the communication facility of social media, problematic activity online may detract from the development and wellbeing of younger people. Mental health problems appear to be increasing in younger people (Office for National Statistics 2014), and use of social media is an important factor to consider. Although the putative depressogenic impact has been investigated by several researchers, it is not yet known whether use of social networking sites and instant messaging are causative, or whether there is a "dose" effect; or if it is an artefact of increased case ascertainment and general societal concern. This systematic review makes an important contribution to the literature: first, by showing a small but statistically significant correlation between social media use and depressive symptoms in the child and adolescent population; and secondly, by indicating further research goals. However, there are limitations to consider. Most of the studies were not directly answering the review question, and heterogeneity in design and results with wide confidence intervals temper any conclusion that can be drawn. The number of eligible studies was low, as the majority of research on internet use and mental health problems does not specifically measure the effect of social media on depressive symptoms. Consequently, the amount of evidence collated for this review was modest. Sample size varied widely, and it should be noted that while small studies provide imprecise estimates of the population parameter due to sampling error, large studies can have the opposite effect of producing statistically significant but clinically spurious differences.</p>
<p>Studies of the psychological effects of internet use are often reported in the mass media, but as noted by McConway and Spiegelhalter (2012), methodological weaknesses are scarcely acknowledged. A preponderance of observational designs does not allow proper causal attribution. Over half of the studies reviewed here were crosssectional, while longitudinal studies had short time periods, with 12 months the longest interval between assessments. Indeed, the fundamental difficulty in research on the impact of internet behavior is the direction of relationship. Building a more robust evidence base is challenging: with the globally pervasive use of social media, there is no naturalistic control group, and historic comparison groups would have dubious validity.</p>
<p>The task for researchers is to measure psychological impact while taking account of the complex, probably bidirectional relationship between habitual social media activity and mental health. In a systematic review of social media use and business management, Ngai and colleagues (2015) proposed a causal-chain framework, pursuing a sophisticated interactional model of the socio-psychological causes and effects of social media activity. In this framework, the relationship between antecedents and outcomes is not simply linear but is interpreted as the product of influence by moderators and mediators. Until more is known on the interplay of variables, straightforward causeand-effect studies are not fully credible, unless a large sample can be observed and analyzed over a suitably long time period. Furthermore, research should be designed not only on methodological logic, but also informed by theory of child and adolescent development (Amichai-Hamburger et al. 2013).</p>
<p>Notwithstanding these qualifying comments, it would be fair to conclude that some degree of correlation exists between social media use and depressive symptoms in the young. However, it is possible that any increase in mental health problems is temporally but not causally connected to the internet. Fears about the harmful effects of online behavior may be stoked by greater public awareness and concern about mental health problems in young people. Recent government policy in the UK (Department of Health and NHS England 2015) has pledged substantial investment in child and adolescent mental health services, enabling early identification of vulnerable young people, with better access to support and treatment. A recent report highlighted a 54% increase in British children prescribed antidepressant drugs from 2005 to 2012 (Bachmann et al. 2016), but while this coincides with the rapid expansion of social media, this may be due to unrelated patterns in case ascertainment and marketing of these drugs. However, 54% was a relatively small absolute increase, from 0.7 to 1.1%.</p>
<p>Whether the incidence of depression has actually increased is a moot point. Arguably, there are material gains in the expansion of the detection and treatment of mental health problems in the child and adolescent population. Various factors could result in a lowering threshold for diagnosis of depression, including professional and commercial interests. Critics of medical hegemony, most notably Ivan Illich (1975), have alerted society to the concept of disease mongering, which Moynihan and Henry (2006) defined as "the selling of sickness that widens the boundaries of illness and grows the markets for those who sell and deliver treatments". This is particularly apparent in mental health, where standard classifications of illness have expanded with each revised edition. As noted earlier, internet-related disorders have entered the psychiatric taxonomy. O'Keeffe and Clarke-Pearson (2011) proposed "Facebook depression" as a specific illness, but this has been criticized by other scholars who assert the need for hypothesis-driven research questions and robust scientific investigation.</p>
<p>Another possible reason for the rising rates of depression in young people is emotional articulacy and encouragement of expression in online social networks. Gender is an important factor here. As the study by Neira and Barber (2014) showed, social media use may have more adverse psychological impact on girls than on boys, which may simply be due to higher frequency of use. Irrespective of gender, depressed mood was predicted by investment in online communication. Nesi and Prinstein (2015) found a strong relationship between social comparison and depressive symptoms in girls. The impact of negative messages may be compounded by the overlap of online and offline networks. Social media may be triggering narcissistic behavior, as suggested by the amount of "selfies" posted on Facebook and Instagram, and a perhaps excessive emphasis on the presentation of self. Research by Tiggemann and Slater (2013) suggests that Facebook use exacerbates body image distortion in adolescent girls. However, Dumitrache and colleagues (2012) found a lower rate of depressive tendencies in girls than in boys.</p>
<p>Social media offer tremendous opportunities for interaction, unbounded by the constraints of face-to-face contact, but they also have antisocial uses. The internet reflects society, but it may exacerbate darker sides of human nature as shown by online bullying and abuse. This phenomenon may be similar to "road rage", whereby people behave aggressively to other drivers, shielded from normal social restraint. Several studies here showed higher correlations of social media use and depressive symptoms in young people with psychological vulnerability. Gámez-Gaudix (2014) found prior psychological problems to be a predictor and outcome of problematic internet use, with academic and social impairment raising the risk of depressive symptoms. A factor may be limited access to reliable support in offline relationships. Ybarra and colleagues (2005) found that young people with depressed mood were less likely to have face-to-face interaction, communicating instead with virtual friends.</p>
<p>This could be explained in part by the nature of depressed mood, where symptoms can include lethargy and reduced interest in usual social activity; socializing online may be preferred as a substitute to interacting face-to-face, which may require more effort including travel. Furthermore, symptoms of depression can include irritability, and teenagers may have some predisposition to impulsivity (Siegel 2014); if these factors influence online communication they could post comments that they later regret, possibly detracting from their popularity. Online friends not already known sufficiently well offline may be less forgiving of an online faux pas, and may not be aware or sympathetic to another social network user's psychological difficulties. Social media use in this situation could have negative consequences for a young person with depressive symptoms.</p>
<p>Online friendships lack some of the benefits of physical contact: interaction is often superficial, and lacking in genuine interest. Hwang and colleagues (2009) showed that depressed young people find difficulty in making friends face-to-face and instead seek friendship on the internet; two-fifths of participants with depressive symptoms expressed thoughts and feelings online that they could not do otherwise. Although this suggests social media as a valuable resource, there is a danger of reinforcing negative beliefs and behavior. Young people struggling with stress turn to Facebook for social support, but as Neira and Barber (2014) reported, as much as 80% of requests for support were unanswered, raising the risk of depressive symptoms. Attachment theory would be relevant to such findings.</p>
<p>The "rich get richer" hypothesis is supported by studies in this review. For most internet users, online interaction reinforces friendships, rather than replacing one set of friends with another. That young people with fewer proximate friends derive less benefit from social media may not be a problem, as quality of close relationships should trump quantity of online contacts. However, as Nesi and Prinstein (2015) indicated, the online environment facilitates social comparison and feedback-seeking, and less confident young people may be more likely to use social media for such purpose. The cluster analysis indicated three groups; however, there was no clear pattern to this that would explain why study results had clustered in this way. Depressive symptoms are perpetuated by negative online experiences. Much of the socialization process in childhood development now occurs through social media, and mood problems may be a temporary feature of the transition to adolescence. However, as many psychiatric disorders of adulthood first appear in adolescence, vulnerability in this developmental stage is high and protective factors such as positive friendships offline and positive relationships with caring adults therefore gain importance for young people to build resilience.</p>
<p>Various interventions have been devised to prevent harm to young people online, including policies to tackle cyberbullying in schools (e.g., Childnet International 2015). Also, more awareness of the hazards of social media is needed in parents: "digital immigrants" may not be fully alert to the rapidly changing patterns of internet use by young people. Facebook was not designed for use by children, and does not adequately protect their identity and privacy. Lack of parental guidance on internet use exposes children to potential harm from reckless or malevolent communication, as well as from violent or pornographic content (O'Keeffe and Clarke-Pearson 2011). However, controlling use of the internet is difficult, particularly with teenagers, who use online media for educational as well as interactional purposes. Meanwhile, some parents are not good role models for internet use, posting pictures of their children on Facebook which may later cause embarrassment. While schools teach about sex and relationships, such education must be updated regularly in relation to trends of online activity by young people. In the context of an expanding virtual reality, more facilities should be provided for children to meet friends in physical proximity. Instead of focusing on the negative effects of internet use, the benefits of face-to-face contact should be accentuated.</p>
<p>Young people are not a homogenous group in relation to internet use. Most of the studies reviewed here had a wide age range, mixing pre-pubescent children with imminent school-leavers. Data from the Pew Research Center show differences in how younger compared to older children use social media; many teenagers lose interest in Facebook as they seek privacy for aspects of their personal lives (Madden et al. 2013). Meanwhile, social media platforms are continually developing and new risks and harms may arise with each functional advance. Current trends will not continue forever, and social media may be used differently or abandoned in the near future. Today, typed communication prevails while oral communication has declined, as the "mobile telephone" has become a misnomer. However, keypads could soon be outmoded by devices that enable users to communicate without the need for manual input.</p>
<p>Vast data obtained from social networking sites can be used for marketing purposes and by potential employers. Exploration of its use in a healthcare context would be beneficial. If a degree of "profiling" from online communication is possible, there may be a moral argument towards considering using such data in a risk assessment context. For example, a sophisticated screening mechanism could potentially identify patterns suggesting concern (around a person's wellbeing, e.g., suicidal ideation) and an offer of support could be "triggered" for the social media user with a view to preventing escalation of difficulties they might be experiencing or to even put them in touch with services that could help.</p>
<p>The influence of the functionality of the social media platform requires further exploration in this context, e.g., the perceived reward systems involved. Exploration of the young person's expectation from online communication, and coping mechanisms they have if they encounter unwanted outcomes from using social media would help to gain more in-depth understanding of the relationship between social media and young people's mental health. Some examination of the change in relationship with social media through developmental stages and as the young social media user's experience grows would also be informative. The social communication needs of young people could be better provided for through involving young people in the design and development of social networking sites. Similarly, improved safeguards could be integrated into platform functionality if appropriate.</p>
<p>Hyperbole should be avoided in discussing the impact of internet use by young people. Observing moral panic as a recurring reaction to social change, Furedi (2015) described how the emergence of commercial publishing in the eighteenth century led to popular novels being blamed for "fevers". The Sorrows of Young Werther was banned in parts of Europe because readers identified strongly with a self-destructive character, allegedly causing a spate of suicide. More recently, the term "Werther effect" was used by American sociologist Dave Phillips (1974) for uncritical belief in media-stimulated imitations of suicidal behavior. Perhaps the same phenomenon has arisen with digital media.</p>
<p>A degree of correlation is found between social media use and depressive symptoms in young people. However, causality is not clear, and further development is needed in research on this topic. Researchers have lacked consensus on the phenomena for investigation, resulting in limited replication. Qualitative methods also have an important part to play in understanding the phenomenon of mental health impact of internet use from young people's perspectives. Such enquiry would help to develop explanatory models and hypotheses for inferential studies. The cyber carriage continues to speed along the tracks, and it is not yet understood whether it causes sickness for its passengers.</p>
<p>Acknowledgements Trevor Murrells (King's College London) provided statistical support.</p>
<p>Author contributions NM, SG and EP conceived of the study, participated in its design and coordination and drafted the manuscript; EP performed the statistical analysis; EP, NM and SG participated in interpretation of the data. All authors contributed to the writing, read and approved the final manuscript.</p>
<p>Conflict of interest The authors declare that they have no conflicts of interest.</p>
<p>Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f201868209"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:48+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Culture, language, and learning strategies form a grand tapestry, which is this article's theme. The authors explain each part of the tapestry, provide ideas for teaching all parts in a smoothly united way, and explore key cultural issues (i.e., cognitive flexibility, ethnocultural empathy, intercultural understanding, and needs of intercultural trauma survivors). The article discusses cultural types, cultural communication styles, and related strategies, and it identifies publications that draw together culture, language, and strategies. The article offers new insights and abundant examples for teachers, teacher educators, and researchers.</p>
<p>Culture and language are interwoven, as shown in Figure 2. Language is part of a vast web of culture, and, as Kramsch (1993Kramsch ( , 1998) ) put it, language is a social practice that expresses cultural reality. This article reveals how learning strategies, culture, and language work together. It is written for teachers, researchers, graduate students, and program administrators in the broad area of second language acquisition. Readers who are interested either in ordinary classrooms or in immigrants' needs regarding language and culture will find much of value in this article. The contents of the paper are symbolized by Figure 1, which shows the closely woven, colorful tapestry of culture, language, and learning strategies. In the best of all possible classrooms, the threads of this tapestry will not and cannot be separated.</p>
<p>Figure 1 The tapestry of culture, language, and learning strategies. Photo by R. L. Oxford</p>
<p>As noted above, the tapestry contains culture, language, and learning strategies, and these elements intertwine. For the last three or four decades in our field, more books about language teaching, language learning, and language learning strategies 1 have been published than about culture teaching, culture learning, and culture learning strategies. 2 In this article we try to bring these elements together and redress the imbalance.</p>
<p>The sections included in this article concern the following issues: Section 1 focuses of the tapestry of culture, language and learning strategies. Section 2 provides guidance for what to do before overtly teaching any learning strategies. This guidance includes recognizing cultural issues such as cognitive flexibility, ethnocultural empathy, intercultural understanding, and needs of intercultural trauma survivors. Culture teaching and strategies for culture learning are the keys to Section 3. Section 4 offers detailed cultural examples, such as cultural types, cultural communication styles, and related learning strategies. Section 5 highlights culture-related strategy instruction using the CRITERIA format (Oxford, 2017). Section 6 presents published frameworks and standards that combine culture, language, and strategies, and the conclusion is in Section 7. The appendix presents rich, varied teaching techniques for culture-language relationships and learning strategy use.</p>
<p>Culture and language form a tightly woven tapestry, rich with vibrant colors, shadows, and highlights. When an individual is learning culture and language, the tapestry also includes learning strategies, that is, conscious, learner-regulated thoughts and actions for developing specific skills and general proficiency.</p>
<p>As we know, language is a system involving complex communication, either spoken or written, to express ideas and feelings. Pragmatics, or the appropriate use of a language in situational contexts, is the nexus of language and culture. In this article, we sometimes use the terms target culture and target language to refer to what the person is trying to learn at a given time.</p>
<p>Culture is often seen as the human-made part of our environment (Oxford, 2014) or the software of the mind (Hofstede, 2001) -the shared attributes (i.e., common history, attitudes, values, behaviors, practices, and artifacts) of a group (Boulding, 2000). However, sometimes culture is used to refer not to the shared attributes but to the people, in large or small groupings, who share the attributes. For example, culture can refer to a social stratum, like the Brahmin (Brahman) class of India, and to the "small culture or micro-culture" of a specific family/clan or organization, or even a school class (Holliday, 1999). Cultural groups might not be contained within certain geopolitical boundaries. This is especially true at times of mass migration, in particular the permanent or temporary movement of people due to political or cultural oppression, war, and extremes of climate. Examples are the Kurds and the Rohingya. From a more abstract perspective (Kramsch, 1998), culture has three layers: (a) social (i.e., current, synchronic), (b) historical (i.e., across time, diachronic), and (c) imaginative (i.e., future-oriented imaginings, dreams, and hopes embedded in the culture), with all three layers funneled together simultaneously in a given place and time.</p>
<p>The "cultural iceberg" model (American Field Services Intercultural Programs, 1984) is simple and attractive, so it is amazing how many language teachers do not know about this model or, if they are aware of it, do not mention it to their students. In the iceberg model, visible culture and invisible culture constitute an important distinction. Food, celebrations, and clothing are part of the visible tip of the cultural iceberg, and below the waterline are invisible, often unconscious feelings, beliefs, or attitudes. For virtually any aspect of visible culture it is usually possible to discover its correspondingly deeper, invisible elements. For instance, above the water line (in the visible culture), we might see or hear about "burkinis," the modest swimming attire desired by some burka-wearing Muslim women. Burkinis have much deeper (invisible) meanings and implications than merely the garments themselves. Clashing, often invisible, issues include the role of women in a patriarchal society, generational views about women's role, male anxiety or anger about women's empowerment, female modesty/immodesty in relation to religion, and (for non-Muslims perhaps) fear of the religious "other." In teaching Arabic, instructors should help learners recognize and face deep cultural issues like these, rather than paying attention to only stereotypical aspects of culture. The unconscious (invisible) aspects in the cultural iceberg, such as attitudes and values, are the most powerful because they are generally unquestioned and because they drive the conscious aspects. Culturally responsive students understand the conscious elements of their culture and are enthusiastic about exploring -or at least willing to explore -the unconscious elements of the target culture and their own culture.</p>
<p>Learners benefit from employing strategies, defined earlier as conscious, learnerregulated thoughts and actions for developing specific skills and general proficiency (Figure 2 offers a more detailed definition). A few examples of learning strategies are: (a) using background knowledge about culture and language to predict what will come next in a story or a news program; (b) collaborating with someone else to learn culture and language; (c) combining intuition, logic, and facts with cultural experience to communicate more effectively in the language; and (d) asking a native speaker questions to understand the target culture.</p>
<p>Learning strategies . . . a) are conscious, teachable, intentional, self-chosen, and self-regulated thoughts and actions for learning the target culture and language; b) have several interlocking purposes: improving performance on immediate tasks, developing specific skills, and improving autonomy and long-term proficiency; c) support cognitive, emotional (affective), social, motivational, and metastrategic regulation (e.g., planning, organizing, monitoring, and evaluating) of learning (Oxford, 2017b); and d) are flexibly and creatively combined into strategy clusters (strategies used simultaneously) and strategy chains (strategies used in sequence) to meet the learner's needs and fit the context and the task.</p>
<p>Longer definition of learning strategies (adapted from Oxford, 2017b) Strategy instruction usually involves finding out students' current learning strategies, choosing a new strategy (or a combination of strategies) that students need the most for current tasks, demonstrating and naming the strategy for the students, explaining why it is helpful, asking students to try out the strategy in an authentic task, asking students to decide how useful the strategy was, and reminding students to use it again (i.e., transfer it to new, relevant tasks). This pattern is sometimes called fully informed, overt strategy instruction, because the teacher gives learners full information about the strategy. Teachers can adapt this sequence to create simple, organic steps to meet students' needs. Sometimes strategy instruction is rapidly offered to one or two learners, rather than a whole class. Chamot (2018) recommended differentiating strategy instruction to meet students' needs based on diversity in cultural, socioeconomic, and educational background; personality factors; motivation and willingness; target language proficiency level; and strategy knowledge. Not every learning strategy will work for every learner. Psaltou-Joycey and Gavriilidou (2015), and Cohen (2014) created teachers' guides taking into consideration many crucial factors for tailoring strategy instruction to learners' individual and group needs.</p>
<p>Most of this section is designed to help teachers pave the way to strategy instruction. This means setting the scene by providing a welcoming, culturally-open atmosphere before overtly teaching any learning strategies. What if the teacher is not ready for conducting strategy instruction? What if the students have just arrived and have no way of grasping strategy instruction yet? In 3.1, we explain that the teacher can set the scene by creating an atmosphere of support, kindness, and understanding and by helping students develop confidence and cultural competence. Three basic cultural competences are the focus: cognitive flexibility, ethnocultural empathy, and intercultural understanding. Working on these competences first makes it much easier for strategy instruction to occur successfully. In 3.2 we concentrate on the needs of trauma survivors. If students are traumatized from famine, war, and mass migration, they need special help before strategy instruction can begin. This is perhaps the only time strategy experts have ever said, "Whoa! Some teachers should hold off on strategy instruction until the students are ready!," but keep in mind that the scene-setting we are proposing is for the purpose of preparing the atmosphere and the students so that strategy instruction will be successful and helpful when it comes. Scene-setting or paving the way is an early, crucial stage, yet it is often forgotten. Jumping into strategy instruction without that early stage can be problematic if teachers and/or students are often unready.</p>
<p>When teachers stop to pave the way before conducting overt strategy instruction, they cultivate a highly positive, nonthreatening, and welcoming environment for students. In such an environment, students can thrive. In such an environment, some students in a given class simply start using good learning strategies on their own. That is fine. These students will become even more strategic when the stage is set for everyone and when overt strategy instruction does begin.</p>
<p>Given that language classrooms across the globe are becoming increasingly multilingual and multicultural (sometimes now called plurilingual and pluricultural), learners need to control and manage their emotions within the context of multiple interactions with peers and teachers from different social and cultural backgrounds. Thus, strategic learning is crucial both for emotion regulation and academic achievement in the target language. Within 21st-century classrooms, there is indeed an urgent need for language learners first to just fit in interculturally in order to be able to learn (Matsumoto, Yoo, &amp; LeRoux, 2007;Spencer-Oatey &amp; Franklin, 2009).</p>
<p>The three competences (three needs) noted at this section's opening are crucial for anyone teaching or learning another language and culture. Cognitive flexibility is the ability to create new categories and see more than one cultural perspective. Ethnocultural empathy refers to the ability to understand the feelings of individuals who are ethnically and/or culturally different from oneself. However, ethnocultural empathy goes beyond merely understanding those people's feelings; it involves an emotional response that is congruent with the perceived welfare of the individuals; we feel their feelings and care about them. It involves the ability to walk in another's shoes or "feel with" a person quite different from oneself. Intercultural understanding is defined as people's ability to understand, appreciate, and be open to various aspects and forms of cultural and social diversity. All of these three competences are highly interconnected and encompass self-awareness and strong interpersonal competence. Kramsch (1993), mentioned earlier, stressed that since language is social practice, culture is at the heart of language teaching and learning. Thus, the three competences should naturally be developed along with language competence.</p>
<p>The following teaching techniques can be used to enhance learners' cognitive flexibility (see Figure 3). Please note that these teaching techniques help create a positive ethos in the classroom, but they do not represent specific strategy instruction. However, when the classroom encourages cognitive flexibility, quite often learners develop creativity and power when using learning strategies.</p>
<p>Encourage perspective-taking among learners.</p>
<p>Promote learners' self-awareness by helping them to identify their own strengths and weaknesses and work toward improving the latter.</p>
<p>Enable learners to initiate their own learning and take the lead.</p>
<p>Highlight the importance of group work and enhancing a team spirit.</p>
<p>Open up opportunities for inquiry and trial and error.</p>
<p>Encourage a range of perspectives and expanded perspectives.</p>
<p>Setting the scene for cognitive flexibility as a step toward strategy instruction: Some teaching techniques</p>
<p>Ethnocultural empathy can develop when the teacher focuses attention on it and uses relevant teaching techniques. These techniques, while not themselves constituting learning strategy instruction, can foster the kind of atmosphere that helps students in the classroom to care about each other and about people from the target culture and other cultures. As suggested earlier, such empathy helps students feel what someone in another culture is feeling. Ethnocultural empathy (across cultural groups) has been studied to determine how similar or different it is from basic empathy (within one's own cultural group). Rasoal, Jungert, Hau, and Andersson (2011) found that the two forms of empathy were correlated, that largely similar predictors were found for the two constructs, and that a confirmatory factor analysis failed to confirm two separate constructs. Figure 4 presents some teaching techniques that can sow the seeds for strategy instruction, particularly related to ethnocultural empathy. These techniques are not the same as strategy instruction. Instead, they create the environment necessary for students to relax and care about people from other cultures.</p>
<p>Include stories in instructional practice, both in the form of personal anecdotes and students' own stories to share with the rest of the class.</p>
<p>Provide ample opportunities for communication practice so that learners can find the appropriate words to convey their emotions and feelings.</p>
<p>Encourage peer support and collaboration.</p>
<p>Initiate discussions on learners' experiences with different cultures and a reflection on the similarities and differences between one's native culture(s) and the target culture(s).</p>
<p>Use literature -in any form, such as novels, poems, and plays -in the language classroom.</p>
<p>Display empathy, creating a caring and trusting environment, where learners can open up to each other, identify their shared values and treat cultural differences as a doorway that invites learning about other cultures.</p>
<p>Setting the scene for ethnocultural empathy as a step toward strategy instruction: Some teaching techniques</p>
<p>The third need is the competence of intercultural understanding inside and outside of classrooms. Figure 5 presents some teaching techniques to pave the way for strategy instruction fostering intercultural understanding. Naturally, paving the path is not the same as overt strategy instruction; instead, it prepares the classroom ambiance to understand other cultures more deeply. This positive atmosphere allows students to be prepared to develop and use learning strategies for intercultural understanding.</p>
<p>Make and highlight connections between language use and cultural values.</p>
<p>Respect differences that students from various native languages experience.</p>
<p>Use problem-based learning and/or scenario-based learning to help learners understand other cultures, especially the target culture, by means of debates, role plays, discussion groups or literature.</p>
<p>Provide assistance about main points, which can be missed across cultural lines. Initiate explicit, candid discussions about examples of understanding people from another culture.</p>
<p>Help students become aware of negative situations (e.g., bullying, rudeness, sarcasm, physical aggression and violence, all the way to war) that might result from the lack of intercultural understanding.</p>
<p>Setting the scene for intercultural understanding as a step toward strategy instruction: Some teaching techniques</p>
<p>Here we discuss the varied learnings that are needed by trauma survivors for regaining emotional control and for learning the target language and culture. Let us discuss terminology first. We use the term trauma survivor rather than trauma victim to refer to refugees, immigrants, and others who have been able to live, persist and carry on despite multiple traumas. For instance, Nadia Murad ( 2018) is a young woman from Iraq's Yazidi minority. Like many thousands of other Yazidi women and men, she was caught up in the Islamic State's effort to exterminate her people. She was captured, enslaved, raped, tortured, and humiliated by the Islamic State. Her mother and many others were killed. Nadia escaped and somehow found her way to Germany. Due to her migration history, she necessarily became a learner of culture and language. She became a spokesperson at the United Nations to describe the plight of Yazidi women. She urges us not to call her and other Yazidi women "victims" but instead "survivors" of trauma who want to take back their lives. Nadia's argument seems to fit countless other refugees and immigrants, even those whose traumas have not been as fierce as hers. Therefore, we respectfully use the term trauma survivors here.</p>
<p>Contemporary classrooms often include many learners who have fled their home country due to its unstable socio-political and financial condition. Mass migration means that different cultures encounter each other constantly, and unfortunately often not positively. Newcomers who have entered a country as immigrants, refugees, or terrorism survivors have challenges to cope with: they are already physically, emotionally, and socially traumatized, and simultaneously they have needs regarding orientation, resettlement, interculturalism, and language. Various second language learners (in London and many other major cities) include diverse, traumatized refugees or immigrants from distant areas (e.g., northern Iraq, where Nadia came from) who are struggling with the language of their new country and have inadequate housing and funds; and individuals who come from the local community but do not know its language well and have financial issues and discrimination issues. All these people bring to the language classroom their own cultural perspectives, along with traumas and anxieties about fitting into the majority culture. Even inside the language classroom, these students, especially trauma survivors, might be overwhelmed by things they observe for the first time, such as new teaching styles, books, freedom to express their opinion in public, and all sorts of cultural expectations in dress, food, religious behavior, and family interaction. Additionally, these people need learning strategies for language and culture.</p>
<p>Figure 6 contains some techniques that teachers could use to address the emotional, social, and linguistic needs of trauma survivors in the classroom. The techniques, except perhaps the technique Teach organizational skills are not directly aimed at strategy instruction. Instead, the purpose is to provide a supportive socioemotional, cultural, and linguistic environment for trauma survivors. Strategy instruction can be incorporated into that environment when students have sufficient confidence and understanding. We think it will not be long.</p>
<p>Foster social immersion in the classroom.</p>
<p>Highlight the pros of student diversity in the classroom.</p>
<p>Create opportunities for collaboration when culturally feasible.</p>
<p>Assign peer mentors to assist refugee and immigrant students.</p>
<p>Explain the importance of sharing cultural experiences and learning from each other.</p>
<p>Consider learners' new contexts and whole environments.</p>
<p>Incorporate new contexts into lessons (i.e., make their new lives part of what is going on in class in order to facilitate learning, adjustment, and listening strategies).</p>
<p>Teach organizational skills explicitly as students may not know how learning could be achieved.</p>
<p>Focus on the "whole person" by identifying unique strengths and talents and by accentuating the positive traits to motivate students.</p>
<p>Give all students the same materials and affordances even if the refugee students have difficulties with the target language.</p>
<p>Setting the scene to support trauma survivors as a step toward strategy instruction: Some teaching techniques</p>
<p>Teaching culture in the students' target language is often very difficult but might be effectively accomplished by a creative, lively teacher who uses visual images, nonverbal language (Gregersen &amp; MacIntyre, 2017), and music to bring learners into the target culture. Teaching culture and language together can focus on pragmatics, that is, the use of the language appropriately in situational contexts (Ishihara &amp; Cohen, 2014). An occasional question is how to teach culture if certain students are xenophobic. Of course, they are often the ones who need cultural exploration the most. All students, and especially xenophobic ones, should be offered opportunities to get to know the culture through artistic means (music, art, literature, dance), through the media (emailing, tandem learning, online news), and through meeting and working with people from the culture (through field trips, long-term peer-to-peer project work, interviews, video-making). Figure 7 presents some culture learning strategies. Some of them help build up still further the cultural competences mentioned earlier. These learning strategies can be translated, simplified, and culturally adapted. compare and contrast roles of men and women in your culture and the target culture.</p>
<p>compare and contrast how you feel in your own culture and the target culture.</p>
<p>apply the right medium for learning a culture (e.g., use a notebook, use a smartphone, use YouTube).</p>
<p>analyze why certain aspects of culture seem surprising to you.</p>
<p>analyze ways that such a response, if unhelpful, could be minimized.</p>
<p>ask about culturally acceptable ways to talk about emotions in the target culture.</p>
<p>notice feelings about one's own small and large cultures.</p>
<p>apply new knowledge about these aspects of culture. Note. "I" is used to make the learning strategy more personal Here we discuss cultural types, communication styles, and relevant learning strategies, as well as ways to teach these. Incredibly, many language teachers do not know about cultural types or cultural communication styles, and this creates an area of poverty at the center of much language learning and teaching. The first author, though having a master's degree in a foreign language and years of experience in teaching languages and directing language-related programs, was shocked to learn about these massively important cultural elements for the first time only when she started doing research on cultural aspects of peace in her fifties. What if she had known earlier? What if many other language professionals could now learn about these crucial cultural factors and could help their students to develop much better cultural understanding? The tragedy of ignorance would be removed, and the teaching of language and culture would be revolutionized.</p>
<p>A key cultural variable related to attitudes, behaviors, and communications is cultural types. The collectivist cultural type represents 70% of the world's cultures, and the individualist cultural type represents 30% (Triandis, 1995).</p>
<p>Communication trends are different within collectivist and individualist cultures (Oxford, 2013a(Oxford, , 2014)). Collectivist cultures value high-context communication, while individualist cultures are known for low-context communication (Hall, 1976). High-context style involves communication that is indirect, nonlinear, polite, hierarchical, and face-to-face when possible. Low-context style calls for communication that is direct (often blunt), linear, and less concerned with politeness, hierarchies, or face-to-face exchanges. Face is very important in highcontext communication, but it has a much smaller role in low-context communication (see Table 2 for details).</p>
<p>Face-to-face relationships emphasized for bonding Emphasis is not on bonding, so face-to-face communication is sometimes less needed or even undesired Face (honor, including avoidance of shame) is prominent; concern for saving one's face and saving others' face Face plays less of a role; concern, if any, is saving one's own face</p>
<p>Based on the discussion in the two previous subsections (5.1 and 5.2), Figure 8 presents useful learning strategies, which can be translated, simplified, and otherwise adapted. read about collectivist and individualist cultures and the communication styles that relate to them.</p>
<p>take notes about these readings using a table or a Roman-numeral outline.</p>
<p>based on readings, list questions for the mentor/informant about the target culture, especially related to collectivism or individualism, whichever is relevant to the culture; use everyday terms, not technical terms like collectivism and individualism.</p>
<p>seek a mentor/informant from the target culture.</p>
<p>ask the mentor/informant about the target culture in everyday terms, flexibly using my list of questions.</p>
<p>identify differences between collectivist and individualist cultures with specific examples based on answers from the mentor/informant (and any differences).</p>
<p>focus my attention to recognize signs of high-context communication or low-context communication in target language conversations, films, and video. find examples of "facework" differences in collectivist and individualist cultures as I read culturally authentic books and magazines or watch movies or YouTube.</p>
<p>apply new knowledge about individualist and collectivist cultures as I continue to learn the target language and culture.</p>
<p>Useful learning strategies for understanding cultural types and their communication styles (based on Oxford, 2013a)</p>
<p>The best way to teach strategies involves integrating strategy instruction into authentic learning tasks for culture and language. Figure 9 provides an example of strategy instruction, specifically for learners when the target culture's type is collectivist and its communication style is high-context. This example can easily be adjusted for learners when the target culture's type is individualist and its communication style is low-context.</p>
<p>Background: a) This is strategy instruction for students who are learning a language associated with a collectivist culture. b) These steps assume that the students have already encountered at least some general information about identifying collectivist and individualist cultures. c) Halfway through the strategy instruction process described in this table, students are introduced to the characteristics of such cultures and the typical communication styles of such cultures.</p>
<p>NOTE: The strategy instruction ideas below are comfortably adaptable for use in strategy instruction for students whose target culture's style is individualist (naturally with a low-context communication style).</p>
<p>These strategies are woven into language learning in the steps below.</p>
<p>Step A: Introducing the strategies for identifying collectivist cultures</p>
<p>The teacher looks at a globe and world map and mentions learning strategies in the process. To help students review, the teacher brainstorms a few collectivist cultures, such as Korean and Japanese, and then points them out on the globe or map (using resources). Then the teacher lists these collectivist cultures on the board or screen. The teacher reminds the students of the strategies just used: brainstorming, using resources, and listing, and explains that these strategies often go together in a cluster or a sequence. The teacher asks students to explain why these strategies were useful to them.</p>
<p>Step B: Practicing the strategies for expanding the list of collectivist cultures The teacher invites students, in pairs, to go up and look at the globe or map if they wish (using resources) in order to find the location of collectivist cultures. The teacher asks the pairs to use the strategies of brainstorming and listing on large sheets of paper at least 7 collectivist cultures that were not named by the teacher (examples: many cultures in the Far East, Africa, South America, the Middle East; indigenous cultures, like the Maori, in different parts of the world). Students compare lists and consolidate them.</p>
<p>Step C: Extending the listing strategy in order to make comparisons The teacher asks the students, in the same pairs as above, to use the strategy of making a comparison chart. It could be a tabular chart with the left side listing the 7 collectivist cultures named earlier and the right side listing 7 individualist cultures, or it could be some other kind of chart (Oxford, 1990). The teacher asks the students how this strategy helps them organize and remember information.</p>
<p>Step D: Looking back and thinking ahead The teacher asks the members of the whole class to use the strategy of reflecting together on what they learned, how the strategies helped, and which strategies could easily be transferred to other learning activities.</p>
<p>At this point (if it has not happened before), the teacher explains the characteristics of collectivist cultures, individualist cultures, and their corresponding communication styles. In order to understand the target collectivist culture for the target language (e.g., learning the mainstream Chinese culture and the Mandarin language), students must also learn about individualist cultures.</p>
<p>In pairs or in the whole class, students might compare characteristics of collectivist cultures with those of individualist cultures OR go more deeply into collectivist culture through a variety of classroom activities, such as game-playing, role-playing, drawing, outlining, video-watching, etc. To make these activities successful, the teacher might ask the students to use certain learning strategies, with a focus on only a few strategies that are the most helpful. A very useful selection of strategies might come from these: taking notes, making a chart to compare, using a semantic map, analyzing, synthesizing, inferencing (e.g., figuring out the culture's beliefs by means of its proverbs; figuring out how to act by means of watching videos), taking one's emotional temperature (e.g., identifying emotions, such as feeling more comfortable with one communication style more than another or being anxious about the culture and the language), using deep breathing, relaxing with meditation, asking questions for verification, asking questions for more information, and using symbols (e.g., a question mark to indicate what needs to be asked). Many other strategies are found in Oxford (2011Oxford ( , 2017b)). Alternatively, students might be encouraged to use their own favorite strategies.</p>
<p>Either way, after every three or four activities, the teacher might lead a strategy discussion, with the students talking about which strategies worked the best for them, how they used the strategies, and how they might transfer the strategies to other activities later.</p>
<p>Example of strategy instruction when the target culture is collectivist and therefore uses high-context communication (based on Oxford, 2013a)</p>
<p>The acronym CRITERIA (see Table 3) stands for cooperation, respect, integrity, tolerance of ambiguity, exploration, reflection, intercultural empathy, and acceptance of complexity (Oxford, 2017b). The elements represented by the letters are connected with various learning strategies. Some letters are linked with just one strategy, others with two strategies, and just one ("E") with three strategies. For example, the strategies for the letter "E" are: "Watch videos, read, and use other resources to explore the culture. Take notes to refer to later. Have a friend on social media from the culture."</p>
<p>The CRITERIA acronym lends itself to cognitive flexibility, emotional self-regulation, and the search for understanding across cultures. An interesting idea is to ask students to role-play a situation in the CRITERIA acronym and then act out several learning strategies that could relate to those situations. Consider "T" for tolerance of ambiguity (in Table 3): A specific, culturally confusing or mystifying situation has occurred, and students could identify it and act it out. Then they would choose and act out a number of relevant learning strategies to educate themselves in dealing effectively with the situation. Strategies named for the letter "T" are "analyze the situation and, if necessary, ask for help." Students can act out those strategies, but they can also creatively generate and act out other strategies. Teachers can ask individual learners (or small groups of learners) to suggest their own favorite culture-related strategies for each letter of the acronym. Teachers can incorporate the acronym into strategy instruction in multiple ways, such as teaching the strategies related to one letter of the acronym at a time. Tasks involving the acronym CRITERIA assume strong proficiency or else simplification and adaptation.</p>
<p>Table 3 Intercultural competence and related learning strategies useful for strategy instruction (Oxford, 2017b) Envision myself as someone I know from another culture and experience that person's feelings and thoughts.</p>
<p>A Acceptance of complexity -an important counterweight to the human desire to oversimplify the cultural data and accept stereotypes.</p>
<p>Overcome stereotypes by recognizing that they are merely generalities, often negative ones, and by focusing on complex characteristics of specific, authentic people from the culture.</p>
<p>For the CRITERIA acronym (or other modes for teaching culture strategies) to be helpful, the setting must offer at least some chances for communication across cultures. Consider differences in communication possibilities in the following examples of second and foreign language learning. For a student who is learning English as a second language in the UK, the US, Australia, or New Zealand, English is the most frequent vehicle of daily communication in those countries, so there are many face-to-face opportunities to use the language. However, for a student who is learning Swahili as a foreign language in those countries, Swahili is not the primary mode for everyday communication mode for most people there, so those countries offer comparatively few in-person possibilities for using Swahili, especially in small towns. When there are not many face-to-face chances to use the target language and learn the target culture, social media offer unparalleled, technology-based, global opportunities for engagement in language and culture. These opportunities can be used by individuals or by whole classes.</p>
<p>A classroom combination of culture, language, and learning strategies is very important. Fortunately, some published frameworks and standards provide guidance about the triad of culture, language, and strategies. One of the best known is the Common European Framework of Reference for Languages: Learning, Teaching, Assessment, or CEFR (Council of Europe, 2001). The title refers to language, but the content clearly emphasizes the interaction of culture and language. The 2001 CEFR contends that greater language knowledge facilitates intercultural respect, tolerance, cooperation, and communication and reduces prejudice and discrimination. In this powerful document, sociocultural competence is described as involving</p>
<p>• attitudes of curiosity and openness;</p>
<p>• knowledge of social groups and their products and practices in various cultures; • ability to interpret a text or event from another culture and relate it to one's own culture; • ability to acquire new cultural knowledge and interact across cultures under real-time constraints; • and critical cultural awareness. The need for learning strategies is explained and illustrated throughout the 2001 CEFR. The time period including the CEFR's development and publication is known for significant professional awareness of learning strategies and learner autonomy in Europe and many parts of the world.</p>
<p>More recently, the latest (provisional) edition of the Common European Framework of Reference for Languages: Learning, Teaching, Assessment -Companion Volume with New Descriptors (North, Goodier, &amp; Piccaro, 2017), like the 2001 CEFR, overtly demonstrates the relationship between culture and language. It includes the following competences in which culture plays a significant role: sociolinguistic competence, pragmatic competence, and plurilingual and pluricultural competence. It also embraces multiple aspects of linguistic competence (e.g., vocabulary, grammar, phonology, and orthography), which -unless they are being treated as an academic memory exercise -must exist in a culturallinguistic nexus. The 2017 (provisional) CEFR looks distinctly different from the 2001 CEFR and was surely written by a different team. The 2017 (provisional) CEFR could have strengthened its comments about the value of learning strategies, but at least it mentions strategies for both learning and performance.</p>
<p>Another recent and intriguing work published by the Council of Europe (Beacco, Byram, Cavlli, Coste, Cuenat, Goullier, &amp; Panthier, 2016) again brings together culture and language. It is called Guide for the Development and Implementation of Curricula for Plurilingual and Intercultural Education. This publication explains the unified meanings of plurilingual and intercultural competence, that is, the ability to: (a) use a plural repertoire of linguistic and cultural recourses for communication and interaction in different cultures, (b) understand otherness, (c) mediate between or among members of two or more social groups, and (d) question assumptions of cultures, including one's own. This guide offers ways to develop these interwoven competences but surprisingly does not emphasize learning strategies.</p>
<p>The European Language Portfolio or ELP (see Cavana, 2012;Council of Europe, 2018a, 2018b) is a document allowing language learners to record and reflect on their learning of multiple languages and their intercultural experiences. It also supports the development of learner autonomy, which is ordinarily connected with learning strategies. The ELP is linked to the CEFR. The ELP's values are in synchrony with those of the European Centre for Modern Languages (ECML). The ELP contains three components: a language passport, a language biography, and a dossier (Council of Europe, 2018b). The Council of Europe stopped officially registering portfolios in 2014, but individual learners continue to use the ELP system.</p>
<p>The World Readiness Standards for Learning Languages (American Council on the Teaching of Foreign Languages [ACTFL], 2017) include the development of cultural understanding along with language skills. The standards are called the 5 C's: cultures, communication, connections, comparisons, and communities. Though only one standard is called "cultures," strands of culture are quietly present in all the standards. An alert teacher or professor would likely notice the standards' linkage of language and culture. Chamot (2004) developed an excellent, learning-strategy-based pattern for teaching language by using an earlier version of the 5 C's, although ACTFL surprisingly failed to integrate these valuable ideas about learning strategies into its documents about standards.</p>
<p>Let us return to the tapestry metaphor, which contains culture, language, and learning strategies. The appendix interweaves all three factors in a lively, strategic exercise. All parts of the tapestry should be intertwined in every language class. Developing an understanding across cultures often means interacting with others in their language rather than one's own, and learning how to do these things necessitates learning strategies. Besides the metaphor of weaving, other metaphors also exist: (a) culture, language, and learning strategies combined as the nucleus of a cell; (b) learning strategies as a bridge to cultural and linguistic understanding; and (c) a journey on the Culture and Language (C&amp;L) Railroad, with learning strategies as the fuel. We hope that this article has provided insights about relationships between culture and language learning, strategy instruction, and the importance of setting the scene for strategy instruction.</p>
<p>Thinking more broadly about our theme, in fostering competencies in culture and language, we are seeking nothing less than the creation of peace cultures (Boulding, 2000(Boulding, , 2008;;Oxford, 2014) and, in fact, peace at multiple levels (Ghaith &amp; Shaaban, 1994;Kruger, 2012;Medley, 2016;Oxford, 2013bOxford, , 2017a)), from inner peace and interpersonal peace all the way to global peace. These aims can be achieved only through learning to interact beyond our own language and culture. Learning strategies can profoundly help in this lifelong process.</p>
<p>Help learners to pay close attention to menus, applications, and business forms, which are practical, useful, and rich with the target culture and the target language. Facilitate student-to-student pen pal systems to increase competence in the target culture and the target language. Though students can send letters in handwriting, most likely they will use email or Facebook. 3 We know instances in which Spanish language students have written native Spanish speakers, as well as situations in which students of English as a second language have written to native English speakers who happen to be studying Spanish. To make student-to-student exchanges more culturally specific, guide students in creating a "matchbox" in which they put ten tiny things that represent their culture. For instance, an English child might include a stamp of the queen's head, a teabag, a small photo of Prince Harry and Meghan Markle, a trinket of the Queen's Guard, and other things. Help students exchange their matchboxes with members of the target culture. Facilitate email discussions across the cultures (adapted from a suggestion from Vee Harris). Foster tandem learning outside of the target language as a way to improve speaking and listening while enhancing cultural knowledge. A student whose native language is X and who is studying language Y meets on
Skype (or some other way) with a student whose native language is Y and who wants to learn language X. They teach their native languages to each other while sharing personal and cultural experiences. Use local, regional, national, and international maps as a source of culture-based discussions in the target language. Map activities (how to get from one place to the other and what will be found there) build reading, writing, speaking, and listening, especially if vocabulary supports are provided. Encourage students to journal in the target language about cultural events. Expand students' competence in the target culture and the target language and their peace communication competence by using peace activities. There are so many that we simply refer you to Oxford (2013bOxford ( , 2014Oxford ( , 2017a)). Note. Certain activities as noted were suggested by V. Harris (personal communication, 6 June 2017), while others came from both of this chapter's authors
</p>
<p>Table 1 is a definitional comparison of collectivism and individualism. Collectivism focuses on the individual only as part of the group (even regarding achievement), and it promotes harmony, tightly-knit relationships, collaboration, and strong hierarchies. In contrast, individualism focuses on the individual, accepts less harmony, and encourages independence, competition</p>
<p>find media (e.g., movies, YouTube) and focus to see examples of the target culture, if it is not close at hand; look for emotional, social, and other factors, cultural types, and cultural communication styles. depict</p>
<p>Facebook has problems for pen-pal writing: shortness of messages and lack of privacy. However, it might be a start.</p>
<p>Column A in the table below displays a variety of teaching techniques (instructional activities) emphasizing culture but also linking culture and language. These teaching techniques can often be enhanced by interweaving learning strategy instruction. Strategy instruction is noted in Column B, which leaves space for readers to insert the strategies they might like to teach with regard to the activities in Column A. The authors would like to express their gratitude to Vee Harris for several suggestions.</p>
<p>Column A Teaching techniques (instructional activities) for culture and for culture-language relationships Column B Strategy Instruction: Which relevant learning strategies to teach the students? (write below learning strategies that relate to Column A techniques/activities). Invite guests from the target culture to come to talk about their lives and experiences. Encourage students to ask questions of the guest and make comparisons with their own culture. Ask students to talk about what surprises them in the target culture and which culture, theirs or the target culture, they would prefer? Encourage use of technology (e.g., YouTube, Twitter, CNN,
Google Images, BBC, or online newspapers), art (all kinds), dance (varied), and music (e.g., hip hop, rock, pop, indigenous, or orchestral music) to uncover differences in cultures, with a special emphasis on comparing the target culture and the students own culture. Ask students to note down three differences and three similarities to the way people behave, dress, eat, or talk to each other in the target culture compared to their own culture (suggested by Vee Harris). Ask students to identify ways in which the target literature they are reading now differs from literature in their own culture (suggested by Vee Harris). Play a YouTube video of a pet rabbit in class, and ask students to discuss attitudes about animals in the target culture. For instance, people in France might eat rabbits (suggested by Vee Harris). Encourage students to read used comic books, comic strips, and graphic novels, as well as condensed, illustrated classics in the L2 (Romeo and Juliet, Shakespeare's play, was recently read by Sheltered English students in Alabama by means of condensed books, as reported in one of our graduate classes).
</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f192909631"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:53+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>A deep machine-learning technique based on a convolutional neural network (CNN) is introduced. It has been used for the classification of powder X-ray diffraction (XRD) patterns in terms of crystal system, extinction group and space group. About 150 000 powder XRD patterns were collected and used as input for the CNN with no handcrafted engineering involved, and thereby an appropriate CNN architecture was obtained that allowed determination of the crystal system, extinction group and space group. In sharp contrast with the traditional use of powder XRD pattern analysis, the CNN never treats powder XRD patterns as a deconvoluted and discrete peak position or as intensity data, but instead the XRD patterns are regarded as nothing but a pattern similar to a picture. The CNN interprets features that humans cannot recognize in a powder XRD pattern. As a result, accuracy levels of 81.14, 83.83 and 94.99% were achieved for the space-group, extinction-group and crystal-system classifications, respectively. The well trained CNN was then used for symmetry identification of unknown novel inorganic compounds.</p>
<p>It would be a very difficult to describe an actual crystal structure perfectly using only powder X-ray diffraction (XRD) patterns as the raw data source, because the threedimensional electron-density distribution is condensed into just one dimension in the powder diffraction pattern. Such data condensation leads to both accidental and exact peak overlap, which complicates the determination of individual peak intensities. This complication is the reason that the crystal symmetry (space group) cannot be obtained correctly from a powder XRD pattern for many low-symmetry phases, no matter what type of measurement tool is employed. Singlecrystal diffraction data improve this complication and ease structural analysis compared with the use of powder diffraction. However, sample preparation for single crystals remains a challenge, although a small-sized single-crystal technique has recently become available for single-crystal XRD (Hirosaki et al., 2014). It should also be noted that the most frequently encountered type of structural data in scientific and engineering fields is powder diffraction data, because the generally usable form of most engineering materials is in either a polycrystalline or a powder form.</p>
<p>A typical structural analysis for inorganic compounds should be able to extract the structural descriptors from the spectral descriptors. The typical structural descriptors are lattice parameters, overall symmetry and site symmetries, atomic type and position, site occupancy and thermal factor. Raw powder XRD pattern data are simplified by spectral descriptors such as peak position, height, width and shape, which are parameterized mathematically by introducing well defined peak profile functions such as pseudo-Voigt and others. The Rietveld refinement method (Rietveld, 1967(Rietveld, , 1969) ) is known to treat powder XRD patterns not as discrete structure factors (F hkl ) but as a full-profile continuous spectrum, and even includes some parameters designating the instrumental and sample conditions. Nonetheless, the Rietveld refinement method still employs only a number of discrete spectral descriptors, although the number of parameters is dramatically enhanced compared with other traditional analyses. More importantly, it should be noted that the utility of the Rietveld refinement method has been restricted to limited cases where the structure was roughly known. While we have successfully implemented the structure determination of many unknown novel compounds using either the direct method or the direct-space method (Park, Shin et al., 2012;Park, Singh et al., 2012;Park et al., 2013Park et al., , 2014)), we find that initial steps such as indexing and space-group determination play crucial roles. These can be extremely difficult to establish, however, particularly in the presence of a small number of impurity phases with peaks that overlap the main phase.</p>
<p>In our opinion, the deep machine-learning technique could compensate for the incompleteness of rule-based powder XRD pattern interpretation. In this context, deep learning was introduced in the hope that it could outperform auto-peaksearch-based indexing and the ensuing space-group determi-nation without human intervention. The final goal of the present approach was to establish a deep-learning-based structure analysis platform, which would be easily accessible to non-experts who have only just begun to work in inorganic materials science, by providing them with an equal chance that only a well experienced expert might have grasped in the past.</p>
<p>Prior to the boom in the art of deep learning, a number of powder XRD-related modelling studies used a conventional ANN. However, most of the previously reported cases were dealing with various feature engineering skills, such as manual featurization (Tatlier, 2011;Kustrin et al., 2000), principal component analysis (PCA) (Obeidat et al., 2011;Mitsui &amp; Satoh, 1997;Chen et al., 2005;Matos et al., 2007), partial leastsquares regression (PLSR) (Lee et al., 2007) and various special statistical approaches (Gilmore et al., 2004;Barr et al., 2004). Feature engineering can simply be thought of as data contraction, which is more precisely defined as data-dimension contraction. It should also be noted that all of these previous machine-learning approaches were far removed from big-data analysis, and were restricted to a small data set consisting of manipulated data that shared common features, such as a small number of powder XRD patterns for mixtures consisting of a few previously well identified inorganic compounds. Less positively, all the previous machine learning for powder XRD pattern analyses has been associated with shallow ANNs. Consequently, the excessive feature engineering (dramatic data-dimension contraction), the shallow ANN and the small size of the training data set constituted a somewhat vicious circle, which imparted machine learning-based analysis with no merit by comparison with rule-based analysis prior to the advent of deep learning.</p>
<p>In contrast with such conventional approaches, we adopted a novel approach that coupled a deep convolutional neural network (CNN) with a seemingly overwhelming amount of powder XRD pattern data without the use of any handcrafted feature engineering. Neither data contraction nor knowledgebased data manipulation were involved in the preparation of the raw data for use in the CNN training. The full-profile powder XRD pattern was not treated as deconvoluted discrete peak-position and intensity data, but was instead regarded as nothing but a pattern, as if it were a picture. We prepared 150 000 powder XRD patterns that represented almost all of the inorganic compounds that exist on earth. Finally, we constructed a virtuous circle that was composed of no feature engineering (no data contraction), but only contained a deep CNN architecture, and big data. Such revolutionary and unprecedented CNN modelling for a powder XRD pattern classification enabled us to predict the crystal systems, the extinction groups and ultimately the space groups of totally unknown materials.</p>
<p>To achieve a reliable CNN model, we prepared as much powder XRD pattern raw data as possible, with no feature engineering involved. The larger the data set, the more successful will be the modelling. It is unfortunate, however, that no database can provide raw data for powder XRD patterns. The International Centre for Diffraction Data (ICDD; http://www.icdd.com) does not allow subscribers to download all of their Powder Diffraction File (PDF) data in any type of primitive data file format. Therefore, we used the crystal structure solution data from the Inorganic Crystal Structure Database (ICSD; http://www.fiz-karlsruhe.de/icsd. html) to produce sufficient powder XRD pattern data for CNN modelling. In fact, the ICSD provided only structure solution data rather than experimental measured powder XRD patterns. It is practically impossible to collect an acceptable number of experimentally measured powder XRD patterns that would be sufficient for use in CNN learning. Thus the powder XRD patterns that we used for the CNN modelling were not experimentally measured real data, but were instead the calculated data from the structure solutions of every entry registered in the ICSD.</p>
<p>We produced a very large number of plausible powder XRD patterns calculated from the refined structure solution data. The structure solution data presented in the ICSD include symmetry information (space group), refined lattice parameters, atomic coordinates, occupancies and thermal factors. To simulate realistic powder XRD patterns from such a refined solution requires additional parameters such as the multiplicity for each peak, the Lorentz polarization factor, the preferred orientation, the background shape and the peak profile function. The first three parameters can be uniquely determined and fixed for each entry. The multiplicity can be obtained with ease from the symmetry data presented in the ICSD, the polarization correction was applied for laboratory XRD in the Bragg-Brantano geometry fitted with a graphite monochromator in the incident beam and the preferred orientation was considered to be non-existent. However, the background shape and the peak profile functions were varied randomly. The background was varied randomly using sixthorder polynomial functions. The peak profile function (pseudo-Voigt) was also varied by a random choice of mixing parameters as well as Caglioti parameters (Caglioti et al., 1958). By adopting these random parameters, we produced ten slightly different powder XRD patterns for every single entry residing in the ICSD. Thereafter, we selected only one out of the ten and used it for CNN learning. Finally, Poissonian noise was added to the deterministic calculated pattern. Among the plausible powder XRD patterns created by all entries (181 362) registered in the ICSD up to January 2016, some erroneous and heavily duplicated data were eliminated. As a result, we finally secured 150 000 simulated powder XRD patterns. The entire procedure for the acquisition of these powder XRD data is described schematically in Fig. 1.</p>
<p>The CNN for the powder XRD pattern classification is composed of an input layer, three pairs of convolutional and pooling layers, two fully connected layers, and an output layer. Each layer has a number of neurons that collect information from the previous layer. This information is converted into a specific value by using an activation function to be transferred to neurons in the next layer. The rectified linear unit (ReLu) has been a breakthrough in improving the performance of deep learning by replacing the conventional sigmoid activation function (Nair, 2010). This enhancement is doubled when a ReLu is coupled with a dropout that arbitrarily skips some neurons when conducting the back-propagation algorithm to derive the weight parameters of a CNN. The rate of the dropout was set at 30% in all three CNNs that were used for XRD classification.</p>
<p>The performance of a CNN depends upon its architecture, which is based on the selection of hyper-parameters such as the numbers of convolutional, pooling and fully connected layers, the number of neurons in each layer, the size and number of convolutional filters with their stride size, and the rate of dropout. Unfortunately, there is no rigorous principle for determining the hyper-parameters. We chose them on a trial-and-error basis. The proposed architecture was determined after testing as many plausible versions as possible. The final versions of the architecture for the three different classifications are depicted in Fig. 2. Fortunately, the CNNs used for the three different structural classifications shown in Fig. 2 shared a common structure until flattening of the last pooling layer. They all had the same number (= 2) of fully The CNN, composed of an input layer, three pairs of convolutional and pooling layers, two fully connected layers, and an output layer. Each layer has a number of neurons that collect information from the previous layer. This information is converted into a specific value using an activation function to be transferred to the neurons in the next layer. The filter size was halved from one layer to the next. connected layers, whereas the number of neurons in the layers differed. The output layer for each CNN was compatible with the number of classes (230 space groups, 101 extinction groups and seven crystal systems).</p>
<p>What follows is a description of how the proposed CNNs performed the XRD classification. Powder XRD data can be regarded as a string (vector), which is similar to a generic signal sequence. The dimensions of the XRD string are 10 001 Â 1 Â 1. The first convolution layer was created using eighty 100 Â 1 Â 1 filters, each of which slid through an input string with a stride value of 5. Each cell value of the convolutional hidden layer was computed by the linear combination of a filter's weight and the values of the portion of a target sequence that the filter covered, and then the filter was activated by a ReLu. At this stage, each filter captured its own basic feature regardless of the feature location within a sequence. In addition, the adoption of filters had the advantage of reducing the number of weight parameters to be estimated, since each filter shared weight parameters wherever it resided (so-called weight-sharing). Following convolution, a new layer was created by pooling each of the 3 Â 1 Â 1 cells of the convoluted layer with average values, which had a smoothing effect on the original sequence and also provided a basis on which the subsequent convolutional filters could capture composite features by remote cells in the target sequence. The latter effect cannot be accommodated by mathematical tools based solely on a linear interaction between variables.</p>
<p>In the next stage, a second convolution layer was created by allowing eighty 50 Â 1 Â 80 filters to slide through the previous pooled layer. The second-level convolution filters extracted more complex features than those elicited from the first-level filters. The stride size (= 5) remained the same as the first convolutional layer. Following average pooling, a third convolution layer was created using eighty 25 Â 1 Â 80 filters. As shown in Fig. 2, the filter size was halved layer-by-layer. After average pooling again, the third convolutional hidden layer was flattened to facilitate connection to a fully connected hidden layer. The connection between the flattened layer and the next fully connected layer was the same as that between two consecutive hidden layers of a generic feed-forward neural network. After accommodating another fully connected layer, the second fully connected layer linearly fed neurons in the final output layer. The neurons of the final output layer were then activated with a soft-max function (Bridle, 1990), unlike the neurons within previous hidden layers which were activated by a ReLu. The final activation values from the soft-max function corresponded to the probability that an input data point belonged to each specific XRD class.</p>
<p>In principle, indexing is a process by which reflection indices, hkl, are assigned to all the peaks in a powder diffraction pattern. Accurate indexing leads to the correct determination of a crystal system and the correct estimation of lattice parameters. However, the lattice parameter was not taken as an output for this particular CNN, since our primary concern was a systematic classification of powder XRD patterns in terms of symmetry. In this regard, the activation function for the fully connected output layer in our CNN was the soft-max function, which represents probabilities rather than physical numbers. Therefore, precisely speaking, the CNN that we set up is not a model for indexing but is a classification platform to discern the crystal system, extinction group and space group of all the entries in the ICSD. In other words, the CNN could be a prediction model for the crystal systems, extinction groups and space groups of unknown inorganic compounds. This means that the labels for our XRD pattern data were comprised of the crystal system, the extinction group and the space group. The architecture of this CNN has three different output layers with seven, 101 and 230 neurons, which designate the probability density values for seven crystal systems, 101 extinction groups and 230 space groups, respectively. On the other hand, the input layer includes 10 001 neurons, which represent every intensity value in the 2 range from 10 to 110 . The adoption of the full profile of the XRD pattern data as an input contrasts sharply with conventional analysis, which uses a dramatically contracted input vector via various feature engineering skills.</p>
<p>One might doubt why we employ a deep machine-learning technique for such a simple task as crystal-system determination, since the indexing can be completed perfectly well, using only a few peak positions, by the already well established commercial (or free) computational software packages, although determination of the ensuing extinction groups (or space groups) is difficult. Once $20-40 exact peak positions have been pinpointed, commercially available software enables us to index them with an acceptable figure of merit. The extinction group (or space group) can then be determined by checking the systematic absences. More precisely speaking, even when an exact extinction group can be identified, determination of the exact space group may be thwarted in many cases, because some extinction groups include a large number of probable space groups that are by definition not distinguishable.</p>
<p>As a matter of fact, the CNN model cannot perform the complete indexing of a powder XRD pattern, but simply identifies the crystal system, extinction group and space group.</p>
<p>Generally, it is difficult to account for why a CNN can classify a powder XRD pattern with a relatively high degree of accuracy. Deep-learning models have been criticized by many researchers as resembling a black box. The present study depended on deep CNN models and will not escape this criticism. The following explanation is intended to be a plausible answer to such criticism.</p>
<p>The CNN treats the powder XRD pattern as a sort of picture, rather than as a set of deconvoluted discrete peak position and intensity data, and thereby it excavates key features from the raw data through a number of filters. An implicit advantage of the use of CNN over conventional rulebased indexing comes from the fact that equal weight is placed not only on the low-angle data but also on the high-angle data, which are full of high-index peaks with tiny intensities and complicated multiple overlaps. In addition, the use of highangle side data in the conventional rule-based indexing process creates some complications, which inherently originate from Bragg's equation. For example, if we are working with a cubic material, then the following relationship holds</p>
<p>Based on this equation, a small erroneous change in the lattice parameter (a) can induce a huge change in the angle (). Therefore, the high-angle side data are considered to be problematic and difficult to treat. However, due to the pictorial consideration of the XRD patterns in the CNN, the higher-angle data are treated the same as all the other data.</p>
<p>A CNN is known to recognize features within an input sequence irrespective of scale and location. In particular, signals located far from each other in the original sequence could constitute a single hidden feature and a CNN could capture that feature. This can be recognized neither by human intuition nor by any shallow-learning model. Also, the filters of the convolution layers at higher angles were expected to capture features from small-scale signals in the input sequence, which has never been considered in rule-based XRD studies.</p>
<p>The filters were expected to abstract the features of an XRD profile, and the profile was then classified into a specific class via the last fully connected layer fed by the features. Each filter's role of extracting a specific feature could be visualized by weight parameters. Each filter of a convolutional hidden layer had weights, each of which corresponded to a cell within the filter. For example, if the weight value of a filter cell is large, the filter captures a cell of the input sequence that is covered by the filter cell. On the other hand, if a filter cell value is small, the filter discards a cell of the input sequence that is covered by the filter cell.</p>
<p>The abstracted features then contributed to classifying XRD patterns, although the features were not intuitively recognizable enough to be linked to the known characteristics of an XRD pattern. convolution layers, respectively. Each row of these patterns indicates a more complex feature at a higher level than those extracted by a filter in the lower layers. Unfortunately, the visualized features look like random codes, but with a certain pattern that defies interpretation. These patterns might be successful in classifying the XRD pattern. It should be noted, however, that interpreting the performance of deep learning at the level of human intuition is meaningless.</p>
<p>Although we are not fully aware of how the CNN works, it is clear that it extracts information evenly from the full profile of data, which is in sharp contrast to the conventional indexing process where only a few low-angle peaks are taken into account. If a material of concern has a high symmetry with a relatively small unit cell then there would be fewer peaks available, which would make the indexing much easier for use of the conventional method. On the other hand, if the symmetry of an unknown material is low and the cell is large, then the number of peaks would be tremendously increased, and thereby the CNN would function as an auxiliary tool along with the conventional method.</p>
<p>Although we have already tested the performance of the trained CNN using a randomly selected test data set, an additional checkup is needed for a better understanding of our deep CNN model for prediction of the crystal system. For this double-check, we prepared two novel compounds (S-1 and S-2), which were discussed previously (Park et al., 2013(Park et al., , 2014)). The actual XRD patterns were measured experimentally for both S-1 and S-2 (Fig. 4) and were tested by the trained CNN. As a result, the CNN correctly predicted the crystal systems. It should be noted that we removed both S-1 and S-2 from the training data set and included them in neither the training nor the test data sets. Many entries in the ICSD exhibit similar compositions with similar structures. Such entries also give rise to similar powder diffraction patterns. In this regard, although test accuracies of 81.14, 83.83 and 94.99% were obtained for the space-group, extinction-group and crystal-system classifications, respectively, it was worthwhile to test whether or not our CNN could predict a completely unique structure with no similar structure types in the training set. However, it is very difficult to obtain experimental powder diffraction patterns of compounds that have unique structures. We pinpointed S-1 and S-2 because we had recently discovered them and been assured of their structural novelty and unique nature (Park et al., 2013(Park et al., , 2014)).</p>
<p>All entries in the ICSD are regularly categorized and those results are announced several times each year. Such a structural categorization principle is clearly based on reasonable crystallography-based principles (Allmann &amp; Hinek, 2007). If an entry of concern belongs to one of the existing structural types (a so-called prototype), then the entry can be categorized into the prototype structure. The current number of prototype structures is 9093 according to the latest announcement in 2017 (ICSD web page). Most of the entries belong to one of these prototype structures, and a minor number of entries never belong to any of them. S-1 and S-2 belong to the latter case. This means that these two compounds have no similar compounds (XRD patterns) in the ICSD database and therefore had no similar patterns in our training data set. When the CNN made the correct determination of the structural system for these two, its applicability showed great promise. Although it is not clear whether such a wonderful result was fortuitous or not, the fact remains that our CNN gave us the correct crystal-system determination for these two.</p>
<p>The CNN architectures designed for the classification of extinction and space groups exhibited accuracies of 83.83 and 81.14%, respectively. However, both of these CNN architectures were unsuccessful in the confirmative test, and failed to predict the correct extinction and space groups for these two real XRD patterns. Nonetheless, we remain optimistic because a CNN with 101 or 230 neurons (nodes) at the output layer would require a deeper network architecture along with a much larger data set. We should be able to achieve success soon, in parallel with further advancements in computation capacity.</p>
<p>In summary, three CNNs were developed for the space-group, extinction-group and crystal-system classification of 150 000 powder XRD patterns, and returned test accuracies of 81.14, 83.83 and 94.99%, respectively. The powder XRD patterns used for the CNNs were prepared using crystal structure data acquired from the ICSD, along with a set of random para-meters for the background and peak width. In contrast with conventional structure analysis, the CNN-based space-group, extinction-group and crystal-system classification was accomplished by a totally data-based process from scratch. More importantly, it incorporated neither human (expert) interference nor assistance. Two actual powder XRD patterns of novel structures were tested, which belonged to none of the prototype structures listed in the ICSD and even involved a small amount of impurities. In these cases, the crystal-system prediction by the CNN was correct. The CNN read the entire raw powder XRD data as a picture, and it recognized the crystal system without the need for any theoretical analysis. This small success will be a milestone for further development of deep-learning-based analysis for many other conventional theoretical rule-based tasks in materials science.</p>
<p>IUCrJ (2017). 4, 486-494 Woon Bae Park et al. A convolutional neural network 487</p>
<p>Woon Bae Park et al. A convolutional neural network IUCrJ (2017). 4, 486-494</p>
<p>IUCrJ (2017). 4, 486-494 Woon Bae Park et al. A convolutional neural network 489</p>
<p>IUCrJ (2017). 4, 486-494</p>
<p>IUCrJ (2017). 4, 486-494 Woon Bae Park et al. A convolutional neural network 491</p>
<p>Woon Bae Park et al. A convolutional neural network IUCrJ (2017). 4, 486-494</p>
<p>IUCrJ (2017). 4, 486-494 Woon Bae Park et al. A convolutional neural network 493</p>
<p>This research was supported by the Creative Materials Discovery Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Science, ICT and Future Planning.</p>
<p>Funding for this research was provided by: National Research Foundation of Korea (NRF) (award No. 2015M3D1A1069705).</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f387895472"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:17+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Cumulative cultural evolution occurs when social traditions accumulate improvements over time. In humans cumulative cultural evolution is thought to depend on a unique suite of cognitive abilities, including teaching, language and imitation. Tool-making New Caledonian crows show some hallmarks of cumulative culture; but this claim is contentious, in part because these birds do not appear to imitate. one alternative hypothesis is that crows' tool designs could be culturally transmitted through a process of mental template matching. That is, individuals could use or observe conspecifics' tools, form a mental template of a particular tool design, and then reproduce this in their own manufacture -a process analogous to birdsong learning. Here, we provide the first evidence supporting this hypothesis, by demonstrating that New Caledonian crows have the cognitive capacity for mental template matching. Using a novel manufacture paradigm, crows were first trained to drop paper into a vending machine to retrieve rewards. they later learnt that only items of a particular size (large or small templates) were rewarded. At test, despite being rewarded at random, and with no physical templates present, crows manufactured items that were more similar in size to previously rewarded, than unrewarded, templates. Our results provide the first evidence that this cognitive ability may underpin the transmission of New Caledonian crows' natural tool designs.</p>
<p>Cultural traditions are common in the animal kingdom 1-3 , but cumulative cultural evolution is rare 4 .</p>
<p>Despite decades of study of animal traditions (group-typical behaviour patterns that rely on socially transmitted information 5 ) -such as the iconic sweet potato washing by macaques or milk bottle opening by tits 6,7 -there is minimal evidence that these, or any other, animal traditions have evolved and accumulated improvements over time (cumulative cultural evolution) 3,8 . This contrasts sharply with findings from the human archaeological record, where clear indications of cumulative culture are present from at least 100,000 years ago 9 . Moreover, technological transitions from Oldowan flake-based tools, to more standardised Acheulean bifacial hand-axes, suggest that the cumulative evolution of technology could have begun as early as 1.6 million years ago in our lineage 10 .</p>
<p>Several researchers have argued that a suite of adaptations were required to enable this ratchetting up of technologies and traditions, including our uniquely human capacities for teaching, language and imitation 8,11-13 . However, social learning is not just underpinned by the copying of actions. It is defined as learning that is "influenced by observation of, or interaction with another animal or its products" 14,15 (our emphasis). It has been argued that emulative mechanisms -learning from observing the end-products, rather than the actions which produced the products -can produce only low-fidelity copying, insufficient to support cumulative cultural change 8 . However, it remains possible that copying end-products might offer an alternative route towards cumulative cultural evolution in some situations 16 . In the laboratory, transmission chain studies demonstrate that both adults 17,18 and children 19 can replicate or iteratively improve on the design of manufactured artefacts when provided only with end-products to copy (allowing for emulation), without teaching, language or the opportunity to observe the</p>
<p>manufacture process (i.e. without imitation). Though subjects are provided with spoken and written instructions as to the goal of the task. This demonstrates that action information is not always necessary for cultural transmission, and that, at least in certain artificial settings, cumulative culture can emerge in humans through emulative social learning processes, focused only on learning from products.</p>
<p>Among non-human animals, tool-making New Caledonian crows are remarkable in that they produce tools which show some of the hallmarks of cumulative cultural evolution 20 . Across the island of Grande Terre, New Caledonian crows manufacture basic stick tools, hooked stick tools 21 and barbed tools torn from the leaves of pandanus plants 22 . They routinely manufacture at least three distinct pandanus tool designs in the wild, including wide (short, wide leaf sections, ca. 15 by 0.5 cm), narrow (long, thin leaf sections, ca. 23 by 0.25 cm), and stepped designs, where stepped tools taper from a wide base to a narrow working tip in a series of rips and cuts. The specific tool designs made in different areas do not have obvious ecological correlates, and have persisted for at least several decades (at least pre-2000 to present) 20 , suggesting high-fidelity transmission. The functionality of different pandanus tool designs is not yet well understood; however, their geographic distribution raises the possibility that stepped tools represent modifications made to the simpler wide design. Thus, New Caledonian crows may possess a material culture that has incorporated incremental changes over time 20 .</p>
<p>At present, whether New Caledonian crow tool designs are culturally transmitted, and have evolved over time, remains contentious 23 . In part this is due to an absence of evidence, in this species, for the types of sophisticated social learning mechanisms thought to be necessary for such behaviour. Specifically, New Caledonian crows do not appear to imitate 24,25 ; nor do these birds teach or possess language 26,27 . In a social learning experiment, captive New Caledonian crows exhibited stimulus enhancement, but no other social learning mechanisms, when retrieving food from a puzzle box in the presence of trained demonstrators 24 . They do not appear to closely observe the process of tool manufacture in the wild 26 and experiments in captivity suggest they may have poor social cognition 28 . However, one hypothesis is that New Caledonian crow tool designs could be culturally transmittedwithout teaching, language or imitation -through a form of end-state emulation, termed mental template matching 24,26 . Under the mental template matching hypothesis, New Caledonian crow tool designs could be passed on to subsequent generations if an individual used or observed the products of tool manufacture (such as their parents' tools), formed a mental template of this type of tool design (a mental representation of some or all of the tool's properties), and then reproduced this template in their own manufacture. This mechanism can be considered analogous to avian song learning, in which juveniles first acquire a song template from listening to conspecifics, and then later adjust their own vocalisations until they match that of the memorised template 29 . Significantly, the formation of a mental template would enable a bird to produce standardised tools without the requirement that existing tools are visible during manufacture. Most importantly, an improvement made by a crow during its lifetime could become part of the template learnt by subsequent generations, leading to an increase in tool complexity over time. Mental template matching is therefore a specific type of end-state emulation that could potentially allow for cumulative cultural change in the design of material artefacts.</p>
<p>Here, we provide the first test of the template matching hypothesis in New Caledonian crows. This hypothesis makes a clear prediction: that New Caledonian crows have the cognitive capacity to manufacture items that are similar to previously experienced templates. We developed an arbitrary manufacture task that mirrored pandanus tool manufacture, in that it required the ripping of material in order to gain food. However, instead of pandanus leaves, we used an unfamiliar manufacture material (card). By requiring crows to use this man-made material to create items that take different shapes than pandanus tools, our task had sufficient novelty to prevent the crows from transferring learnt rules formed during their prior tool manufacture experience in the wild. Eight New Caledonian crows learnt to drop squares of white paper into a vending machine to receive rewards. They later learnt that only pieces of card of a specific size (either large templates: 40 × 60 mm or small templates: 15 × 25 mm) were rewarded. Having learnt which template was successful, birds received manufacture probe trials where very large sheets of card were provided, from which they could rip sections to drop into the vending machine -a form of manufacture by subtraction 30 . After manufacturing 20 pieces, they were trained that the alternative size (large or small) was rewarded, and the manufacture test was repeated. Conditions were counterbalanced across birds. No templates were present during manufacture test trials, and, to exclude the possibility of operant conditioning or trial-and-error learning during these trials, crows were rewarded at random for 50% of the items they manufactured and dropped into the vending machine. Our experiment, therefore, required crows to make either large or small card pieces at test, without reference to a card template they could see, and without differential reinforcement during the test for making pieces of a particular size.</p>
<p>We observed that New Caledonian crows manufactured differently sized card pieces after learning that either large or small templates were rewarded. The mean area of manufactured pieces was 2.47 times larger when birds had learnt that a large, rather than small, template was rewarded (LMM: p &lt; 0.001). Individually, six of the eight birds manufactured significantly differently sized pieces in the two conditions (4 adults, 2 juveniles; Mann Whitney U-tests: p &lt; 0.05, Fig. 1). The two birds that did not were both juveniles. There was a significant difference in size over time in both conditions; in the large condition, birds manufactured larger pieces in later trials (GLMM: p = 0.0004, Supplementary Figure S1) and, in the small condition, they manufactured smaller pieces in later trials (GLMM: p = 0.05 Supplementary Figure S1). This is consistent with subjects improving their manufacture technique over time, as occurs in the wild 26 . It is not consistent with trial-and-error learning or operant conditioning during these manufacture test trials, because birds were rewarded at random. Birds had been presented with the templates shortly before the manufacture trials, but no templates were present during the manufacture trials. Thus, at test the size of the manufactured pieces could only have been influenced by the crows' prior experience: learning which of two differently sized templates was rewarded during the earlier object choice task.</p>
<p>The behaviour of one bird (Emma, an adult female) provides compelling evidence that this species has the ability to manufacture items that match the absolute, not just relative, sizes of rewarded templates. On a number of trials, after detaching a section of card, Emma modified the size of the detached piece before dropping it into the vending machine (see the Supplementary Video S1 for an example of this behaviour). This occurred on 5/20 trials in the large condition, and 1/20 in the small condition. In all cases, modifications were made to pieces that were longer than the template, and, following modification, all pieces became more similar in length to the rewarded template. Modifications were made in the small condition by a further 3 birds (Azzuro: 2, Stella: 1, Joe: 1), but only Emma reduced the size of overly large pieces in the large condition. In line with this behaviour, Emma's pieces were particularly accurate. Based on their length and width, all pieces except one (39/40) were more similar to the rewarded than the unrewarded template (Supplementary Figure S2).</p>
<p>Our results provide the first evidence to suggest that New Caledonian crows have the cognitive capacity to manufacture objects from a mental template. The New Caledonian crows tested here manufactured items that matched the relative size of the previously rewarded templates, without being rewarded for doing so during manufacture test trials and without templates being present at the time of manufacture. One bird in particular, Emma, manufactured pieces that were highly similar to each template, and made secondary modifications to reduce the length of overly large pieces. This strongly suggests that this crow possessed a capacity to remember and reproduce the absolute, not just relative, size of rewarded templates.</p>
<p>Alternative explanations to the crows using mental representations of the different, previously experienced card designs to drive manufacture are ruled out by the design of our study. Crows were not rewarded for manufacturing card of different sizes during training. In fact, crows had only been rewarded for ripping pieces of paper or card irrespective of size during training and so would be predicted to rip pieces of card of any size if they simply transferred learnt rules from training to test. Instead, crows clearly used their prior experience of choosing card of a particular size to then guide subsequent card manufacture, despite no small or large card templates being visible for crows to base manufacture off and the apparatus being identical across conditions. Even during the test, due to us rewarding 50% of card manufacture trials, irrespective of the size made, there was no differential reinforcement that the crows could have used to guide their tool manufacture. Thus, the only way that crows could have made a card template of the correct size was if they had a mental representation of its size, there were simply no physical cues available to guide them.</p>
<p>Our results provide evidence for one of the key predictions of the mental template hypothesis, namely that New Caledonian crows have the cognitive capacity to manufacture items that are similar to previously experienced templates. While there are clearly several other predictions of this hypothesis that require testing, given the results here, we argue that mental template matching is now the leading hypothesis to explain why New Caledonian crow tools show some of the hallmarks of cumulative cultural evolution. Other hypotheses, such as language, teaching, and imitation, can be ruled out due to past work establishing that New Caledonian crows do not have these abilities. In contrast, the mental template matching hypothesis is supported by the results here and recent work showing that humans can iteratively improve on the design of manufactured artefacts such as constructing paper planes 18 or baskets to transport rice 17 , when copying solely the products of social learning, rather than observing an interaction between another social agent and the product. Finally, the mental template matching hypothesis fits well with this species' ecology. The tendency to acquire basic stick tool manufacture is widespread, develops early, and appears to have a genetic basis in these crows 31 . In contrast, pandanus tool manufacture is not universal, and, when it does occur, adult-like tool manufacture develops slowly over the first year of life 26 . During this time, juveniles associate closely with their parents 32 , regularly borrowing their parents' tools and using them to acquire food 26 . Thus, juveniles have ample opportunities to form a mental template of a particular tool design in the wild from both observing and using the tools of their parents. This template allows these crows to recreate this tool even when neither parents nor the parents' tools are within sight. Crows could then modify this template during their extensive experience of foraging with the tool via differential reinforcement 33 , leading to the development of tool innovations. Innovations would then be incorporated into the mental template of subsequent generations allowing for the faithful transmission of tool designs with iterative improvements over time. This hypothesis therefore explains the maintenance of different pandanus tools in the wild over decades, in the absence of specific ecological correlates, and the absence of evidence for imitation in this species. Turning to captivity, the behaviour of the New Caledonian crows tested here also bears considerable similarities to one of the most famous instances of tool manufacture by these birds. In 2002, Betty, a captive New Caledonian crow, spontaneously bent a piece of wire into a hook to pull a bucket out of a tube 34 . Betty had successfully used a pre-made hook to obtain the bucket on a small number of preceding trials; however, in follow-up tasks she did not appear to possess a full causal understanding of hooks 35 . One explanation for this surprising behaviour is that Betty had formed a mental template of a hooked wire, which she then reproduced.</p>
<p>The mental template matching hypothesis also fits with our current understanding of avian song learning. The acquisition of birdsong comprises a memorisation phase, during which a juvenile acquires a song template from listening to conspecifics, followed by a production phase, during which juveniles adjust their own vocalisations until they match that of the memorised template 29 . Although some researchers do not include song in discussions of animal culture (see discussion in 36 ) strikingly, song learning -among both birds and cetaceans -is currently the only domain for which there is robust evidence that cumulative cultural evolution does occur among nonhuman animals 37,38 . That is, changes in songs are demonstrably passed among individuals via learning, and these changes can accumulate over time 39,40 . New Caledonian crows are vocal learners, displaying cultural call variation in the wild 41 ; thus, these birds possess the neural architecture for memorising and reproducing auditory input 42 . In light of our findings, we hypothesize that a similar mechanism may potentially enable them to memorise and reproduce material artefacts.</p>
<p>One key prediction of the mental template matching hypothesis is that this ability transmits information about tool design with high fidelity. Here, it is important to note that our arbitrary manufacture task likely underestimated the fidelity with which tool designs could be reproduced by wild crows. First, we supplied birds with a novel material: card. Card does not rip in a wholly predictable manner and is likely to be a more challenging material than pandanus leaves for these crows (particularly juveniles) to manipulate accurately with only their beak and feet. Pandanus leaves, in contrast to paper, rip in straight lines due to the veins that run parallel to their leaf edges, and can be snipped into precisely with the beak. Thus, the properties of pandanus leaves, used in the wild, limit variation in the form the tool can take. This may allow for higher-fidelity transmission of natural tool designs, than we observed using card that does not rip in fixed, straight lines. Second, the designs we provided were arbitrary, and birds were rewarded at random for the items they produced. This design choice was necessary in the current experiment to ensure performance during manufacture test trials could not be explained by trial-and-error learning or operant conditioning; however, in the wild, producing functional tools has high adaptive significance 43 , as non-functional deviations from a standard design cannot be used to rake in food. Thus, under natural conditions, it is likely that a capacity for mental template matching would be scaffolded by additional mechanisms, including trial-and-error learning, to facilitate the high-fidelity transmission of tool designs 44,45 . Future work, assessing New Caledonian crow manufacture under conditions that more closely replicate their natural environment is needed to confirm this.</p>
<p>Further research should also consider how long New Caledonian crows' mental representations persist over time. In our experiment, the delay between reminder trials and manufacturing trials was short, allowing us to confirm that any failures to replicate the templates could not have stemmed from forgetting which template was rewarded. However, in the wild, the delay between using another individual's tools and manufacturing one's own is likely to be much greater than the intervals tested here. Understanding more about the nature of these crows' mental representations -including how this information is stored and for how long -will help us to interpret these birds' behaviour in the wild.</p>
<p>Whether the cognitive abilities demonstrated here are unique to New Caledonian crows, or are more phylogenetically widespread, is currently unknown. Several species manufacture tools 30,46 or perform construction behaviours, such as nest building 47 , and may have the opportunity to observe or use end-products made by other individuals. Another corvid species, rooks, do not habitually manufacture tools in the wild, but will in captivity 48 (as do a small number of other species, such as Goffin cockatoos 49 ), suggesting that the cognitive abilities demonstrated here might also be present in related species. Of particular interest is whether some form of mental template matching might account for the transmission of manufactured tool designs among primates, where debate over the existence of cumulative cultures is ongoing 23,50,51 .</p>
<p>To date, emulative learning mechanisms -learning from end-results rather than actions -have been considered by many researchers to be insufficient to support cumulative cultural evolution 8,13 . However, the argument that imitation, teaching and language are the only transmission mechanisms capable of supporting cumulative material cultures may stem in part from the fact that the clearest examples of cumulatively evolved human traditions are cognitively opaque 52 . That is, they involve products for which construction techniques are difficult to infer simply from viewing the product's final form 53 . This is the case for Acheulean stone tools, where a novice cannot infer the precise technique used to strike a core simply from inspecting a finished tool 12 . However, many situations -including the creation of pandanus tools by New Caledonian crows -are likely to be more cognitively transparent, where manufacture methods can be inferred or discovered without explicit guidance. Here, emulation could be sufficient to enable cultural transmission and evolution. Evidence for this comes from human transmission-chain studies, where end-state emulation can lead to cumulative improvements on cognitively transparent tasks, such as constructing paper planes 18 or baskets to transport rice 17 , but not on cognitively opaque tasks, such as manufacturing stone tools 54,55 . Prior to the emergence of stone tools, it is likely that hominin tool behaviour involved a greater proportion of cognitively transparent behaviours 56 , and emulative processes may have played an important role in their transmission 17 . These findings also raise the possibility that other cases of transparent tool manufacture, such as the varied fishing probes manufactured by chimpanzees 50 , could potentially allow for cumulative cultural evolution. In sum, our results provide the first demonstration, to our knowledge, that a non-human, tool-making species can manufacture items that match the size of previously rewarded templates. Our findings take the first step towards uncovering why New Caledonian crows show evidence of cumulative cultural evolution. While further work is clearly needed to test other predictions of the mental template matching hypothesis, our results do establish this mechanism as a leading contender for the wild tool designs of this species. A capacity for manufacture via emulation, through a mental template matching mechanism, could potentially reflect one of the minimal cognitive requirements for the emergence of cumulative material cultures.</p>
<p>ethics statement. All aspects of this research were conducted under approval from the University of Auckland ethics committee (reference: R602), and in accordance with ASAB guidelines for animal behavioural research.</p>
<p>subjects. Subjects were 8 wild New Caledonian crows, caught and temporarily housed in an 11-cage outdoor aviary on Grande Terre, New Caledonia. Based on sex-size dimorphism 4 birds were female. Based on mouth colouration 4 birds were juveniles less than 2 years old (Blue, Anton, D3R, D4R). Two pilot birds were caught and tested in 2014 (D3R, D4R), and six birds were caught and tested in 2015. All birds were released at their site of capture after testing. These subjects were caught from areas with no obvious pandanus bushes and they did not manufacture tools from pandanus or use provided pandanus strips as tools in the aviary; thus it is unlikely that these particular birds manufactured pandanus tools in the wild.</p>
<p>Apparatus. The vending machine was a 33 × 30 × 20 cm wooden box with a 6.3 × 3 cm slot in its top surface into which the crow could insert items. Rewards (bottle caps containing meat) were dispensed from an adjacent slot by the experimenter at the push of a button from outside the cage.</p>
<p>Subjects were first trained to drop stones, then white paper squares (35 × 35 mm, 80GSM paper), into the vending machine to receive rewards. The number of trials taken to acquire stone dropping varied, but all birds inserted at least 24 paper squares at this stage. They then received a spontaneous ripping test. Subjects received 10 × 2-minute trials in which large sheets of white paper (10-15 cm²) were provided, from which they could manufacture items to drop into the vending machine. Half of the birds ripped sections from these sheets without training, the remainder were shaped to rip paper. In shaping trials birds received partially ripped sheets, and the quantity of rips were decreased until the bird would tear sections from unmodified white paper sheets. All manufactured items dropped into the dispenser were rewarded, and birds manufactured and inserted at least 24 pieces of paper at this stage. The birds then experienced that only certain items were rewarded in a colour discrimination test. 6 of 8 birds learnt to drop only a rewarded colour of paper into the vending machine within 30 training blocks, these 6 birds then received a manufacture test. Here, sheets of both the rewarded and unrewarded colours were presented; subjects were rewarded for manufacturing items from the correct colour only. All tested birds, except Blue, passed with at least 19/24 correct choices (binomial test: p &lt; 0.05). Following this, and immediately prior to the experimental training all birds (except the first pilot bird: D3R) were required to manufacture 20 pieces from card (160GSM) as a baseline measure (Supplementary Figure S3).</p>
<p>experimental training procedure. To assess whether New Caledonian crows were capable of template matching, birds were trained that either large (40 × 60 mm) or small (15 × 25 mm) pieces of card could be inserted into the vending machine to obtain rewards (Fig. 2A). On each block 8 large and 8 small templates were placed on the table next to the vending machine. Birds could drop these pieces into the vending machine until all 8 of the rewarded size had been inserted and rewarded, at which point the block ended. Training continued until the subject inserted all 8 pieces of the rewarded size and none of the unrewarded size into the vending machine on 5 consecutive blocks (this criterion was set at only 2 consecutive blocks for the pilot birds: D3R &amp; D4R). This training took 2-4 days (11-19 blocks, including criterion blocks) per condition to complete.</p>
<p>Over the course of the manufacture test trials birds were given the opportunity to manufacture 20 pieces of card to drop into the dispenser. Test trials were conducted in blocks over 1-2 consecutive days, beginning either the same day or the day after training completed. At the start of each block the bird received a reminder trial where 2 large and 2 small pieces were placed on the table and the bird could drop the correct option into the vending machine to receive rewards (Supplementary Video S1, Figure S4). If a bird made a mistake during a reminder trial the test was abandoned and the bird reverted to training trials until they completed one block with no mistakes. This occurred 3 times. Approximately 30-90 seconds after the reminder trial birds began a manufacture trial where they were given two sheets of card with which they could manufacture items: one loose sheet (10 × 10 cm), and one secured under two wooden blocks (accessible section: 21 × 16 cm, Fig. 2B). The loose sheet was too large to fit into the slot in the vending machine without being torn. No templates were present during manufacture trials. Subjects were allowed to rip up either piece of card and insert the ripped pieces into the vending machine. Subjects were rewarded on 50% of trials, regardless of the size of the piece they inserted. To maintain motivation all subjects (except the first pilot bird: D3R) were permitted to rip multiple pieces per trial, with birds manufacturing an average of 1.97 pieces per trial (range: 1-6). The experimenter attempted to enter the room and end the trial after 2 pieces had been manufactured, but did not interrupt if the bird rapidly began manufacturing another item. Each block comprised 3 reminder trials, alternating with 2 manufacture trials, and a maximum of 8 rewards were dispensed on each block. Testing continued until birds made 20 pieces, which took 4-10 blocks per bird. Once birds had completed one size, they were then trained that the alternative size was rewarded using a new colour of card and the manufacture test was repeated. Condition order was counterbalanced across birds.</p>
<p>Scientific RepoRts | (2018) 8:8956 | https://doi.org/10.1038/s41598-018-27405-1</p>
<p>This study was supported by the NZ Marsden fund (RDG), a Rutherford Discovery Fellowship and the 2015 Prime Ministers MacDiarmid Emerging Scientist prize (AHT). SAJ thanks the ERC (Grant Agreement No. 3399933) for funding. We thank Province Sud for permission to work in New Caledonia, Kim Sterelny, Natalie Uomini and Olivier Morin for helpful comments, Jamie Diprose for building the vending machine and Martina Schiestl for training birds.</p>
<p>S.A.J. conceived, designed and conducted the experiment and drafted the manuscript. A.H.T. and R.D.G. contributed to the design &amp; R.J.H. performed the image analysis. All authors contributed to the manuscript.</p>
<p>Supplementary information accompanies this paper at https://doi.org/10.1038/s41598-018-27405-1.</p>
<p>The authors declare no competing interests.</p>
<p>Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f554060804"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:44+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>COVID-19 vaccination is being conducted in over 200 countries and regions to control SARS-CoV-2 transmission and return to a pre-pandemic lifestyle. However, understanding when non-pharmaceutical interventions (NPIs) can be lifted as immunity builds up remains a key question for policy makers. To address this, we built a data-driven model of SARS-CoV-2 transmission for China. We estimated that, to prevent the escalation of local outbreaks to widespread epidemics, stringent NPIs need to remain in place at least one year after the start of vaccination. Should NPIs alone be capable of keeping the reproduction number (R t ) around 1.3, the synergetic effect of NPIs and vaccination could reduce the COVID-19 burden by up to 99% and bring R t below the epidemic threshold in about 9 months. Maintaining strict NPIs throughout 2021 is of paramount importance to reduce COVID-19 burden while vaccines are distributed to the population, especially in large populations with little natural immunity.</p>
<p>T he novel coronavirus disease 2019 (COVID-19) pandemic is far from over, with cases still surging in many countries across the globe, particularly with India suffering from a catastrophic second wave 1 . In 2020, epidemic suppression and/ or mitigation have relied on non-pharmaceutical interventions (NPIs), including social distancing, school closure, mask use and case isolation. Although effective and widely adopted to limit severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission and reduce COVID-19 burden, these interventions entail enormous economic costs and negatively affect quality of life 2 . Additionally, in many countries, relaxation of NPIs has led to a resurgence of the epidemic as herd immunity has not been reached thus far 3 .</p>
<p>Effective vaccines against COVID-19 remain the only foreseeable means of both suppressing the infection and returning to pre-pandemic social and economic activity patterns. Globally, several vaccines have been licensed, and vaccination programmes have been initiated in more than 200 countries/regions, including China 4 . However, the projected global production and delivery capacities are likely to be inadequate to provide COVID-19 vaccines to all individuals who are still susceptible to SARS-CoV-2 infection 3 . The effectiveness of COVID-19 vaccination campaigns will depend on several factors, including pre-existing immunity, vaccine supply, willingness to receive the vaccine and strategies for vaccine allocation and deployment 5 .</p>
<p>To avoid widespread transmission of SARS-CoV-2, since the end of the first COVID-19 wave in the spring of 2020, China has implemented strict NPIs and has successfully controlled local outbreaks, preventing a second widespread wave of COVID-19. Since December 2020, China has given conditional approval or emergency use approval for seven COVID-19 vaccines. As of 1 June 2021, 681.9 million doses (roughly corresponding to 24.3% of the population) have been administered 6 . However, such a coverage is still extremely low, and thus China remains highly vulnerable to importations of SARS-CoV-2 and onward transmission, as proved by several local outbreaks that occurred in the first four months of 2021, the largest of which occurring in Heilongjiang Province led to 636 reported cases and spilled over to a neighbouring province (over 300 cases were reported in Jilin) 7 . At present, estimating whether and when NPIs can be lifted, and the extent to which we need to rely on NPIs while vaccines roll out, represents a top priority for policy making. This question has not been well addressed in China, one of the few countries in the world where nearly the entire population is still susceptible to SARS-CoV-2 infection and home to almost 1.4 billion individuals (roughly 18% of the world population). To fill this gap, we built on top of the wide body of work adopting mathematical models of the infection transmission process to evaluate vaccination programmes [8][9][10][11][12] . In particular, we developed an age-structured stochastic model to simulate SARS-CoV-2 transmission triggered by cases imported in Mainland China, based on a susceptible-infectious-</p>
<p>NATuRE HuMAN BEHAVIOuR removed (SIR) scheme (Supplementary Fig. 1). We consider a situation with (i) no ongoing widespread SARS-CoV-2 transmission, (ii) nearly no immunity in the population and (iii) high risk of importing SARS-CoV-2-infected individuals, possibly leading to an upsurge of COVID-19 cases. Since COVID-19 vaccines are expected to continue rolling out throughout 2021-2022, we consider also alternative scenarios where SARS-CoV-2 infections leading to an outbreak are imported when 10%, 20% (close to the coverage as of the end of May 2021) and 30% of the Chinese population has already been vaccinated (according to the simulated vaccination programme).</p>
<p>In the model, we account for heterogeneous mixing patterns by age 13 and progressive vaccine deployment among different population segments based on a priority scheme (essential workers, older adults, individuals with underlying conditions, etc.) 14 . Further, we overlay a disease burden model on the transmission model to estimate the number of symptomatic cases, hospitalizations, intensive care unit (ICU) admissions and deaths under different vaccination scenarios and based on empirical data [15][16][17][18][19][20] . The resulting integrated model is informed by data on COVID-19 natural history, age-mixing patterns specific to China quantified during the pre-pandemic period and the size of the different vaccination targets in the Chinese population (for example, individuals with pre-existing conditions). A qualitative model description is reported in Methods section, a summary of model parameters and data sources is reported in Supplementary Table 1 and all other details are reported in Supplementary Files 1-5.</p>
<p>The combined effects of NPIs and vaccination programmes are evaluated in terms of their ability to reduce the disease burden caused by outbreaks arising from possible importation of cases.</p>
<p>We considered a baseline vaccination scenario where: (1) vaccination starts 15 days after an outbreak triggered by 40 breakthrough imported SARS-CoV-2 infections; (2) vaccine efficacy (VE) against SARS-CoV-2 infections for a two-dose schedule (with a 21-day interval) is set at 80% 21 ; (3) vaccination coverage is capped at 70% across all ages 14 ; (4) 6 million doses are administered daily (4 per 1,000 individuals, informed by the ongoing COVID-19 vaccination programme 6 , and estimates of vaccine supply till 2021 in China [22][23][24][25][26] );</p>
<p>(5) the first priority target consists of older adults and individuals with underlying conditions (descriptions in detail shown in Supplementary Table 2); (6) there is no prior population immunity from natural infection, which aligns with the situation in most of China, where there has been little circulation of SARS-CoV-2 as of May 2021 (ref. 3 ); (7) we assume an initial reproductive number R t = 2.5 at the start of the outbreak [27][28][29][30][31][32] , in the absence of NPIs and vaccination; (8) children under 15 years of age were considered to have a lower susceptibility to SARS-CoV-2 infection as compared with adults (that is, individuals aged 15-64 years), while individuals aged 65+ years had the highest susceptibility to infection (Supplementary Table 1) 33,34 ; (9) we let the model run for 2 years. To evaluate the impact of the baseline assumptions on our results, we conduct comprehensive sensitivity analyses.</p>
<p>Main analysis. In the absence of NPIs, the vaccination programme is too slow to lower and delay the epidemic (Fig. 1a) and does not effectively reduce COVID-19 burden. R t falls below the epidemic threshold (&lt;1) 69 days after the epidemic start (Fig. 1b), but this is primarily attributable to immunity gained through natural infection rather than vaccination. Indeed, in this time frame, 52.2% of population gets infected, while only 6.7% of population has been vaccinated (Fig. 1c). The cumulative number of symptomatic cases and deaths over a 2-year period only decrease by 3.3% (95% CI 3.1-4.7%) and 6.7% (95% CI 4.5-8.9%), respectively, as compared with a reference scenario where there is no vaccination and no NPIs, which would lead to 306.7 million (95% CI 282.7-320.6 million) symptomatic cases, 99.3 million (95% CI 92.6-104.5 million) hospitalizations, 7.2 million (95% CI 6.0-7.8 million) ICU admissions and 9.4 million (95% CI 7.7-10.3 million) deaths (Fig. 2).</p>
<p>Provided that NPIs are in place and can keep R t at 1.3 in the absence of vaccination ('moderate NPIs scenario'), the vaccination programme could reduce COVID-19 burden by about 99% compared with the 'reference scenario' , with 5.5 million (95% CI 2.5-13.4 million) symptomatic cases, 1.8 million (95% CI 0.8-4.4 million) hospitalizations, 73,500 (95% CI 7,300-152,100) ICU admissions and 76,700 (95% CI 8,200-165,700) deaths (Fig. 2). In this context, vaccination decreases COVID-19 burden by about 40% (Fig. 2) compared with a situation with moderate NPI alone, and R t falls below the epidemic threshold about 9 months after the epidemic start (Fig. 1h). At the time that R t falls below 1, we estimate that 50.8% of the total population would have been vaccinated, while 0.8% would have been naturally infected (Fig. 1i). This highlights that a relevant proportion of the population would still be susceptible to SARS-CoV-2 at that time. Although in the long term vaccination can ultimately lead to the suppression of transmission, it is necessary to maintain NPIs for one year after the onset of vaccination. Indeed, if NPIs are relaxed from moderate (R t = 1.3) to mild (R t = 1.5) 9 months after vaccination start, the cumulative number of symptomatic cases could double (Extended Data Figs. 1 and2), and the cumulative death toll could increase from 76,700 to 173,000 (Extended Data Fig. 3). In contrast, a small increase in cumulative deaths from 76,700 to 81,700 is expected if this relaxation occurs one year after vaccination start (Extended Data Fig. 3), while earlier or more drastic relaxations of NPIs lead to substantial increases in deaths (Extended Data Fig. 3).</p>
<p>A combination of more stringent NPIs (that is, capable of keeping R t = 1.1) and vaccination ('vax + strong NPIs' scenario) could suppress the epidemic, with &lt;2,300 symptomatic cases, and &lt;50 deaths on average. Although the majority of the reduction of COVID-19 burden is ascribable to NPIs in this case (over 85%), the deaths averted due to vaccination are about 1.2 million (Figs. 1j-l and2).</p>
<p>If we consider a set of mild NPIs ('vax + mild NPIs' scenario), even a relatively low initial reproduction number under NPIs of R t = 1.5 could still lead to a disastrous epidemic, with nearly 2 million deaths. Despite the high death toll of the resulting epidemic, NPIs and vaccination would jointly reduce around 80% of the disease burden compared with a scenario with no NPIs and no vaccination (namely, 239 million symptomatic cases and 8.2 million deaths averted) (Figs. 1d-f and2).</p>
<p>Vaccine distribution capacity. Should the daily vaccination rollout be limited to 1.3 million doses (1 per 1,000 individuals, a slower rate than during the 2009 H1N1 pandemic), vaccination would not effectively reduce COVID-19-related deaths unless there was adoption of stringent NPIs. In a scenario where vaccination capacity reaches 10 million doses administered per day (7 per 1,000 individuals), vaccination would reduce COVID-19-related deaths to &lt;5,000 for moderate NPIs and &lt;30 for strong NPIs. Should the daily vaccination capacity be increased to 15 million doses (10 per 1,000 individuals), vaccination could effectively reduce deaths to &lt;100,000 (similar to the annual influenza-related death toll in China 35 ) even in the presence of mild NPIs. However, even if the daily vaccination capacity could be increased to 30 million doses (20 per 1,000 individuals), in the absence of NPIs, we estimate that over 7.7 million deaths would still occur (Fig. 3). Similar patterns are estimated for the number of symptomatic cases, hospitalizations and ICU admissions (Extended Data Fig. 4 and Supplementary Figs. 2 and3).</p>
<p>Increasing daily vaccination capacity could largely shorten the time needed to control SARS-CoV-2 transmission. For instance, when considering a daily capacity of 10 million and 15 million doses and moderate NPIs, R t would drop below 1 about 8 and 6 months, respectively, after epidemic onset (compared with the 9.3 months</p>
<p>NATuRE HuMAN BEHAVIOuR estimated with the baseline capacity of 6 million doses). At that time, over 60% of the population would be vaccinated and ≤0.1% would be naturally infected. An upscale in the daily capacity to 10 (Extended Data Figs. 5 and6) or 15 million doses (Extended Data Figs. 7 and8) would allow a relaxation of NPIs from moderate to mild already 6-9 months after vaccination start, that is, 3-6 months ) from the time series of symptomatic cases in the no-NPIs scenario in the presence of vaccination. The horizontal line indicates the epidemic threshold R t = 1, and the vertical line indicates where R t crosses this threshold. Note that, for the first few generations of cases, R t shows an increasing pattern linked to the highly stochastic nature of epidemics in their initial phase when epidemics with initially larger R t are more likely to survive 69 . For the same reason, the adopted methodology tends to overestimate R t in the epidemic tail ; as such, R t is shown in the core part of the epidemic only. c, Absolute numbers and proportion of the Chinese population infected and vaccinated over time in the no-NPIs scenario in the presence of vaccination. The population of China in 2020 is 1,439,324,000 (ref. 57 ). d-f, As in a-c but for the mild NPIs scenario (initial R t = 1.5). g-i, As in a-c but for the moderate NPIs scenario (initial R t = 1.3). j-l, As in a-c but for the strong NPIs scenario (initial R t = 1.1). Line denotes median, and shadow denotes quantiles 0.025 and 0.975.</p>
<p>earlier with respect to the baseline. On the other hand, more drastic relaxations of NPIs (for example, from moderate to no NPIs) would still lead to substantial increases in symptomatic cases and deaths (Extended Data Figs. 5678).</p>
<p>Vaccination prioritization. We consider alternative vaccination scenarios that prioritize essential workers (staff working in healthcare, law enforcement, security and community services, individuals employed in cold chain, etc.) to maintain essential services and then explore different prioritization strategies for the rest of the population. Our results suggest that the relative timing of the epidemic and of the vaccination rollout play a key role in determining the most effective strategy. In particular, if we consider vaccination to start two weeks after 40 cases are detected, there is no clear prioritization strategy that minimizes deaths, as the outcome of the vaccination campaign depends heavily on the timing at which the epidemic unfolds (Fig. 4 and Supplementary Figs. 4 and5). Instead, if the epidemic is already underway when the vaccination campaign starts (&gt;5,000 cases), prioritizing working-age groups minimizes the number of deaths when R t ≤ 1.3. In contrast, prioritizing older adults and individuals with underlying conditions is more effective when R t ≥ 1.5 (direct benefits are higher; Fig. 4 and Supplementary Figs. 4 and5). Two results are independent of the adopted prioritization strategy: (i) if R t ≥ 1.5, then an epidemic cannot be avoided, and (ii) when R t = 1.1, over 99% of deaths can be averted (Supplementary Figs. 4 and5).</p>
<p>Population immunity at the onset of an outbreak. In December 2020, vaccination started in China, while measures to detect imported cases and case surveillance are in place. The number of doses distributed per day has changed over time, following an increasing trend and with a daily average of about 6 million doses over the period between late March and mid May 2021 (Supplementary File 7). As of 1 June 2021, the vaccination coverage is about 24.3% 6 . The effectiveness of the vaccination programme and NPIs in preventing new COVID-19 outbreaks and limiting COVID-19 burden will thus depend on the level of vaccine-induced immunity in the population should an outbreak of locally transmitted cases start to unfold.</p>
<p>To simulate this situation, we initialize the model by considering different fractions of vaccinated population (SA1: 10%; SA2: 20%; SA3: 30%) at the time the infection is seeded. Given a certain level of NPIs in the absence of immunity, increasing proportions of vaccinated individuals will decrease the effective reproduction number (for example, R t = 1.1 in the absence of immunity corresponds to R t below the epidemic threshold if 10% or more of the population has been vaccinated). Should 30% of the population already have been vaccinated before the start of a new wave, continuing the vaccination programme while adopting mild NPIs would reduce the death toll by 98% (42,400 deaths as compared with 1.8 million if no one was vaccinated). However, in the absence of NPIs, even if 30% of population were already vaccinated before the start of a new wave, carrying on with the vaccination programme alone would not be enough to prevent a widespread epidemic leading to 6 (95% CI 4-7) million deaths (Fig. 5).</p>
<p>No significant difference in willingness to vaccinate between age groups has been reported in China [36][37][38] . Accordingly, we use a homogeneous vaccine coverage of 70% among all age groups in the main analysis. Here, we present the results of a set of sensitivity analyses assuming vaccination coverage of 50% (SA4) and 90% (SA5) among all age groups, and considering heterogeneous coverage by age: (1) 70% for adults ≥20 years and 50% for younger individuals (SA6), (2) 90% for adults ≥20 years and 70% for younger individuals (SA7) and (3) 70% for adults ≥20 years and no vaccination for younger individuals (SA8). By considering moderate NPIs (R t = 1.3) and vaccination coverage of 50% in all age groups, the number of symptomatic individuals is estimated to decrease by 33% with an 8% decrease of the death toll with respect to the baseline vaccination scenario (70% coverage) (Supplementary Figs. 6 and7). In fact, the lower coverage in older age groups would lead to an earlier vaccination in younger age groups who are characterized by the highest contact rates 13 . Conversely, increasing the coverage to 90% would decrease the death toll but lead to an increase of symptomatic cases (Supplementary Figs. 6 and7). It is important to remark that these results consider that moderate NPIs remain in place over the entire duration of the epidemic, and they do not provide indications of the coverage needed to suppress any further resurgences of cases.</p>
<p>As compared with the baseline vaccination scenario (70% vaccination coverage in all age groups), if the vaccine is not distributed among individuals aged less than 20 years, we estimate an increase of the death toll of 55% and of symptomatic infections of 69% (Supplementary Figs. 6 and7). The scenario assuming 90% vaccination coverage for adults ≥20 years and 70% for younger individuals leads to a lower reduction of COVID-19 burden as compared with the baseline vaccination scenario (Supplementary Figs. 6 and7). The higher coverage in the adult population results in a delayed start of vaccination of the young population, which is characterized by higher contact rates 13 . Nonetheless, it is important to remark that this result depends on the timing of the introduction of the initial seeds (see Population immunity at the onset of an outbreak section).</p>
<p>Vaccine efficacy. Three types of COVID-19 vaccine are currently in use in China, including inactivated, recombinant protein subunit and adenovirus-vectored vaccines. VE for these vaccines ranges from 65% to 90%, with the exception of the one tested in Brazil where P1 variant is prevalent (VE 50%) [39][40][41][42][43] . With respect to an 80% VE adopted in the baseline scenario, by considering VE of 60% (SA9), we estimate a 1.64-fold increase of the death toll and 1.02-fold increase of symptomatic cases, whereas a 37% and 29% decrease of deaths and symptomatic cases, respectively, is estimated for VE of 90% (SA10). (Supplementary Figs. 6 and7) SARS-CoV-2 variants. Multiple SARS-CoV-2 variants have been documented globally, three of which are of particular concern: lineage B.1.1.7 identified in the United Kingdom, B.1.351 in South Africa and P.1 in Brazil 44 . These variants are estimated to have higher transmissibility 45,46 and possibly increased mortality 47,48 . To assess the effect of vaccination in this context, we consider higher values of Minimum denotes the lowest deaths in each scenario on the basis of median value. We compare other strategies with the one with minimum deaths using a rank-sum test. For example, in the context of 5,000 initial cases, R t = 1.5 and using mean values of contact patterns and relative susceptibility, the baseline is the optimal strategy to minimize deaths.</p>
<p>NATuRE HuMAN BEHAVIOuR R t (that is, 1.7, 1.9 and 2.1, about 30-60% increased transmissibility with respect to the main analysis 45 ) to account for enhanced transmissibility, and use a mean death hazard ratio of 1.64 to account for higher mortality 47 . With the assumption of VE of 80% against the new variant, COVID-19 burden substantially increases compared with the scenario based on the historical lineage. The number of symptomatic cases increases from 2,000 to 173 million, and deaths increase from &lt;50 to 7 million even when strict NPIs are implemented (Extended Data Fig. 9).</p>
<p>A further set of sensitivity analyses are conducted to evaluate the impact of baseline assumptions on our results for R t = 1.3 (moderate NPIs).</p>
<p>Provided that vaccination can only protect against illness (SA11) but not SARS-CoV-2 infections, COVID-19-related deaths increase by 33-fold with respect to the baseline: from 76,700 to 2.66 million (Supplementary Fig. 6). In this case, maintaining stringent NPIs measures in place for a prolonged time horizon would be necessary as such vaccine would not be effective to suppress transmission (as reported previously 49 ). Assuming a shorter duration of vaccine-induced protection of 6 months (SA12) instead of lifelong protection (that is, longer than the 2-year time horizon considered; Supplementary Fig. 6) has a similarly large effect on projections.</p>
<p>In our main analysis, we use the contact matrix estimated from a contact survey conducted in Shanghai before the COVID-19 pandemic 13 . Should a new COVID-19 wave start to unfold in China, it is unclear to what extent pre-pandemic contact patterns could be representative of such a situation. Therefore, we add a sensitivity analysis in which we assume the mixing patterns estimated in Shanghai in March 2020 50 , when schools were still closed as a response to the COVID-19 pandemic (SA13). For R t = 1.3 and the baseline parameters for the vaccination, the estimated number of deaths would be 16,000 as compared with 76,700 estimated using the pre-pandemic mixing patterns (79% decrease; Supplementary Fig. 6). In fact, the relative contribution of the adult population (which is the main target of the vaccination campaign) to the overall transmission as compared with children is higher than when considering pre-pandemic mixing patterns (when schools were open and school-age individuals had the highest number of contacts).</p>
<p>Other factors such as excluding detected symptomatic cases from vaccination (SA14 and SA15), the time interval between two doses (SA16 and SA17) and assuming an all-or-nothing vaccine (SA18) do not substantially affect estimates of deaths and symptomatic infections (Supplementary Figs. 6 and7). A similar trend is observed for hospitalized cases and ICU admissions.</p>
<p>Using a stochastic dynamic model of SARS-CoV-2 transmission and COVID-19 burden tailored to the epidemiological situation in China, we find that, in the absence of NPIs and independently of the vaccine prioritization strategy and capacity of the vaccination campaign, timely rollout of an effective vaccine (VE 80%) would not be enough to prevent a local outbreak from escalating to a major widespread epidemic. Provided that NPIs are in place and capable of bringing R t to 1.3, a daily vaccine rollout of 4 doses per 1,000 individuals could reduce COVID-19 burden by around 99%, and bring R t below the epidemic threshold about 9 months after the start of the vaccination campaign. A relaxation of NPIs that brings the value of R t to 1.5 could not prevent sustained epidemic growth, which would cause 1.8 million deaths. A net reproduction number of 1.5 could only be sustained when accompanied by an improvement of the vaccine administration capacity up to 10 doses per 1,000 individuals per day. Relaxation of NPIs in the first 6-9 months of vaccine rollout could lead to substantial increases of COVID-19 burden if daily vaccination capacity could not be enhanced to 10-15 million doses.</p>
<p>Bubar et al. evaluated COVID-19 vaccine prioritization strategies and found that prioritizing older adults is a robust strategy to minimize deaths across countries when R t = 1.5, while prioritization shifted to the 20-49-year-old group when R t = 1.15 (ref. 51 ). The broad scope of that multi-country analysis does not account for features of COVID-19 epidemiology and vaccination programme that are unique to China. In particular, differently from most countries where natural immunity is building up after widespread epidemics, China has been able to suppress SARS-CoV-2 transmission for most of 2020. As a result, prior immunity is very low, thus calling for specifically tailored analysis. Nonetheless, our findings confirm that, if NPIs can maintain transmission rates at low levels during the vaccination campaign, strategies that target indirect benefits perform better, while if transmission rates remain high, strategies maximizing direct benefits may save more lives 51 .</p>
<p>As highlighted in vaccination studies in Italy 52 , in the race between the vaccination campaign to build population herd immunity and the progress of the epidemic, the speed of vaccine deployment is critical. Considering the average vaccine distribution capacity of the current COVID-19 vaccination campaign in China 6 , we use 6 million doses administered per day in the baseline analysis. Several manufacturers state that a total of 3.9 billion doses of COVID-19 vaccine could be produced in 2021, equivalent to about 10 million doses per day [22][23][24][25][26] . China committed to provide COVID-19 vaccines to &gt;100 countries, which could reduce the number of doses to be distributed locally. Even if these candidate vaccines could be licensed and manufactured smoothly, it would take about one year to vaccinate 70% of the population.</p>
<p>Six months after initiating vaccination programme, roughly 24.3% of Chinese population has been vaccinated 6 . Limited vaccine production capacity, particularly at the initial stage, could slow the speed of vaccine rollout. Slower rates of vaccine production and administration may result in a longer period of SARS-CoV-2 transmission. It is thus crucial to keep monitoring local outbreaks and invest resources in outbreak management (as currently done in China) to keep R t close to the epidemic threshold at least for the next 1-2 years. In the very unique context of China, a value of R t of 1.3 would result in about 76,700 cumulative deaths, comparable to the annual influenza-related death toll in China 35 . The development of detailed logistical plans and tools to support an increased vaccination capacity as well as effective logistic (vaccine transport, storage and continuous cold-chain monitoring) are key factors for a successful mass vaccination campaign.</p>
<p>In the early phase of COVID-19 spread in Wuhan in 2019, before interventions were put in place, R 0 was estimated to be in the range 2.0-3.5 (refs. [27][28][29][30][31][32] ). Given the knowledge of mechanisms of SARS-CoV-2 transmission, and the devastating consequences of an uncontrolled COVID-19 epidemic, the Chinese population would maintain cautious behaviour (such as cleaning hands often, coughing or sneezing in bent elbow, avoiding close contact with someone who is sick, etc.) even without the need to impose NPIs. As such, in our analysis simulating an epidemic triggered by imported cases, we decided to consider an initial reproduction number of 2.5, which is at the lower end of the estimated spectrum.</p>
<p>SARS-CoV-2 variants are circulating globally and quickly became dominant in countries such as the United Kingdom and Italy (lineage B.1.1.7) and South Africa (lineage B.1.351). Recently, variant B.1.617 identified in India has raised global concern. Mainland China border control screenings have already identified imported cases with SARS-CoV-2 lineage B.1.1.7 and B.1.617. Our study shows that the spread of new more transmissible and/or more lethal variants could substantially decrease the net benefit of vaccination. Strict border quarantine and isolation as well as genomic surveillance will be key while vaccines roll out in China.</p>
<p>Our analysis on the VE shows that, if we consider VE of 60%, both the number of symptomatic cases and deaths are estimated to double as compared with the baseline vaccination coverage of 80%. Given that the final composition of a nationwide rollout will likely include a combination of vaccines with varying efficacy, monitoring VE on the ground will remain a priority.</p>
<p>Here, we propose a general framework to evaluate the impact of COVID-19 vaccination programmes in the absence/presence of NPIs and to explore priority target populations to minimize multiple disease outcomes. The proposed modelling framework is adaptable to other country-specific contexts. However, this requires the collection of country-specific data about the epidemiological situation (for example, landscape immunity of the local population, prevalence of infections), vaccination parameters (for example, vaccine supply and capacity of immunization services, efficacy of different vaccines, target age groups), socio-demographic characteristics of the population (for example, size of the priority population by age group, age-mixing patterns) and the priorities of the pandemic responses (for example, limiting the death toll or preventing infections).</p>
<p>Our study has a number of limitations. First, we integrate the impact of NPIs through a simple reduction in the value of R t at the beginning of the outbreak, homogeneously across age groups. However, our analysis does not suggest which combination of NPIs should be adopted to lower R t to a certain level or how this would affect transmission rates in different age groups. Li et al. estimated that individual NPIs, including school closure, workplace closure and public events bans, were associated with reductions in R t of 13-24% on day 28 after their introduction 53 . Further studies are needed to pinpoint the specific NPIs to be adopted in parallel with the vaccination campaign and their impact on the quality of life of the population.</p>
<p>Second, in China, vaccines have not been licensed for children, so we assume a 50% lower or equivalent VE for them compared with other adults. Although we show that variations in these rates do not substantially affect the overall effect of the vaccination campaign, further data on age-specific VE could help refine priority groups. Our sensitivity analyses on vaccine coverage reveal the importance of extending the vaccination to the young population once the use of vaccines is authorized for that age segment of the population.</p>
<p>Third, we assumed that immunity after natural infections lasts longer than the time horizon considered (2 years). If this is not the case, waning of immunity would inflate the rate of susceptible individuals and thus require booster vaccinations. This could become an issue with the emergence of immune-escape variants, as reported in South Africa 54 . Given limited information at this stage, we did not consider this scenario in our analyses, but this is an important area of future research.</p>
<p>Fourth, age-mixing patterns are key to assess the impact of vaccination as individuals of different ages are exposed to different transmission risks. In the main analysis, we assumed the mixing patterns to correspond to those estimated before the COVID-19 pandemic, indicating the goal of a return to pre-pandemic interactions. We have also performed a sensitivity analysis based on the mixing patterns estimated in China in March 2020 50 , after the lockdown was lifted but schools were still closed. How the population would mix in case of a new wave of COVID-19 starts to unfold in China remains to be seen.</p>
<p>Moreover, our study is performed at a national scale and thus our estimates of the impact of vaccination should be interpreted cautiously at the local scale. In fact, spatial heterogeneities within China in terms of risk of case importation, socio-demographic characteristics of the population, mixing and mobility patterns, vaccination coverage and capacity may affect our results 55 .</p>
<p>Enhanced vaccination efforts in conjunction with NPIs have been successfully used during the COVID-19 outbreak in Ruili City (Yunnan Province, China) in March-April 2021. Our analysis, however, focuses on the assessment of whether and to what extent we need to rely on NPIs to prevent a COVID-19 epidemic while vaccines are rolled out. As such, our results cannot be used to guide a reactive spatially targeted strategy. To properly capture the peculiarity of that context, specific modelling tools mirroring the interventions adopted in China as a response to emerging outbreaks are needed.</p>
<p>Finally, it would be interesting to analyse adaptive vaccination prioritizations that change as the epidemiological situation evolves over time, but that would require the development of dynamic optimization algorithms that lie beyond the scope of this work 56 . Nonetheless, our study provides estimates of the effect of relaxing NPIs over the course of the epidemic.</p>
<p>In conclusion, vaccination alone could substantially reduce COVID-19 burden, but in the foreseeable future may not be enough to prevent local outbreaks from escalating to major widespread epidemics due to limitation in the vaccine production and supply (particularly at the initial stage of the vaccination), as well as the capacity of vaccination system. This is especially relevant in contexts where most of the population is still susceptible to SARS-CoV-2 infection, as is the case in most of China. Maintaining NPIs (such as social distancing, testing, case isolation and contact tracing, wearing masks and limitation on large gatherings) throughout 2021 is necessary to prevent resurgence of COVID-19 epidemics until a sufficiently high level of immunity is reached, which depends on the transmissibility of the variants circulating at that time.</p>
<p>We developed a model of SARS-CoV-2 transmission and vaccination, based on an age-structured stochastic SIR scheme, accounting for heterogeneous mixing patterns by age as estimated in Shanghai 13 . The Chinese population was distributed into 18 age groups (17 age groups of 5 years from 0 to 84 years and one age group for individuals aged 85 years or older) 57 . Each age group was further split into two subgroups: individuals with or without underlying conditions, where the former was considered to be associated with an increased risk of severe outcome of COVID-19 (ref. 14 ).</p>
<p>In the main analysis, susceptibility to SARS-CoV-2 infection was assumed to be heterogeneous across ages. Children under 15 years of age were considered less susceptible to infection compared with adults aged 15-64 years, while the older adults more susceptible 33,34 . Homogeneous susceptibility across age groups was explored in sensitivity analysis SA19. Asymptomatic and symptomatic individuals were assumed to be equally infectious 33,34 , and infectiousness was also assumed to be the same across age groups 33,34 .</p>
<p>Vaccine is administered with a two-dose schedule. In the baseline model, we assumed that: (i) vaccination reduces susceptibility to SARS-CoV-2 infection; (ii) only susceptible individuals are eligible for vaccination, that is, we excluded all individuals that have experienced SARS-CoV-2 infection; (iii) duration of vaccine-induced protection lasts longer than the time horizon considered (2 years).</p>
<p>The baseline model is shown schematically in Supplementary Fig. 1 and is described by differential systems presented in Supplementary Files 1 and 2.</p>
<p>In China, the first pandemic wave of COVID-19 was controlled by intense NPIs 58,59 . Almost the entire population of Mainland China is still susceptible to COVID-19 (ref. 3 ). As such, the model is initialized with a fully susceptible population.</p>
<p>China has been facing mounting pressure from imported COVID-19 cases. Containment of COVID-19 has been possible only through a combination of measures such as complete or partial lockdown, citywide mass screening using reverse-transcriptase polymerase chain reaction (RT-PCR) testing, tracing of contacts and contacts of contacts of COVID-19 cases, which were promptly applied wherever COVID-19 transmission emerged in Mainland China 60 . Despite all the efforts, containment of COVID-19 appears to be hit and miss, and sporadic outbreaks inevitably occur. Simulations are thus initialized with 40 cases, roughly corresponding to the number of cases with symptoms onset in Beijing before the detection of a local outbreak on 11 June 2020 (ref. 61 ).</p>
<p>Vaccination scenarios. To explore the impact of vaccination, we ran a set of simulations in which neither NPIs nor vaccination are implemented as a reference scenario (no vax + no NPIs, that is, effective reproductive number R t = 2.5 at the beginning of simulations 17,28,58 ), and compared it with a scenario in which vaccination only is implemented (vax + no NPIs). Further, we considered different sets of simulations in which NPIs are used to bring R t respectively down to 1.5 (mild NPIs), 1.3 (moderate NPIs) and 1.1 (strong NPIs), with (vax + mild/ moderate/strong NPIs) or without vaccination programme (no vax + mild/ moderate/strong NPIs). In the main analysis, vaccination is assumed to begin 15 days after the epidemic start. Alternative scenarios about the seeding of the epidemic were explored as sensitivity analyses. In particular, we considered the epidemic to start when 10% (SA1), 20% (SA2) and 30% (SA3) of the Chinese population has already been vaccinated.</p>
<p>The model is run considering daily time steps. Gradual delivery of vaccine doses is implemented by vaccinating a fixed number of individuals each day. Although manufacturers state that a total of 3.9 billion doses of vaccines could be available by the end of 2021 (refs. [22][23][24][25][26] ), scale-up and delivery will take months. On the basis of the 2009 H1N1 influenza pandemic vaccination programme implemented in Mainland China 62 , in the main analysis we assumed that 6 million doses of COVID-19 vaccines could be administered each day (4 doses per 1,000 individuals) until uptake reaches 70% for all groups 14 . Different values of the daily vaccine administration capacity, that is, 1.3 (SA20), 10 (SA21), 15 (SA22) and 30 (SA23) million dose per day, are explored in separate sensitivity analyses. Sensitivity analyses were also performed on the vaccination coverage, which is assumed to be either homogeneous (SA4 and SA5) 14 or heterogeneous by age (SA6, SA7 and SA8).</p>
<p>In the main analysis, vaccination is administered to susceptible individuals only. This represents an ideal scenario where we assume that all infected individuals can be identified (for example, either via RT-PCR while infected or via serological assays later on) and that SARS-CoV-2 infection confers long-lasting immunity. Since infection ascertainment could be challenging and pose additional strain on the health system, we also consider two sensitivity analyses in which only detected symptomatic cases are excluded from vaccination (SA14 and SA15).</p>
<p>In the context of fast RT-PCR-based mass screening if there is an outbreak, under-ascertainment of symptomatic cases could be only related with the sensitivity of RT-PCR tests. The sensitivity is quite high (98%) if the interval between symptom onset and RT-PCR test is within 7 days, but decreases to 68% if the time interval is 8-14 days (ref. 63 ). The mean time interval from symptom onset to the date of collection of the sample for PCR testing was estimated to be 4.7 days in Hunan 33 . Accordingly, we considered as ascertainment probabilities of symptomatic cases 70% (SA14) and 90% (SA15).</p>
<p>Vaccination schedule and efficacy. Since December 2020, China has given conditional approval or emergency use approval for seven COVID-19 vaccines. The National Health Commission recommends that inactivated vaccines are administered on a two-dose schedule with an interval of ≥21 days, recombinant subunit vaccines administered on a three-dose schedule with an interval of ≥28 days, and recombinant adenovirus type-5-vectored vaccines administered one dose. For simplicity, in the main analysis, we modelled the administration of an inactivated vaccine developed by the Beijing Institute of Biological Products 64 , which entails a two-dose schedule across all age groups with an interval of 21 days. In separate sensitivity analyses, we explored an interval of 14 and 28 days (SA16 and SA17).</p>
<p>China approved its first local COVID-19 vaccine (developed by Sinopharm) for general public use on 31 December 2020, with an estimated VE of 79.3% 21 . In the main analysis, we used a VE of 80% against infection in individuals aged 20-59 years. In the developed model, vaccination confers partial protection, that is, vaccinated individuals are 80% less likely to develop infection upon an infectious contact. Sensitivity analyses using a VE of 60% (SA9) and 90% (SA10) were performed separately. The alternative values of VE were selected on the basis of published upper efficacy of vaccines of 94-95% and in such a way to cover a plausible efficacy range of forthcoming vaccines [65][66][67] .</p>
<p>Phase 2 clinical trials demonstrated that vaccine immunogenicity was lower among older individuals than in younger adults 64 . And for other inactivated vaccines such as influenza vaccine, a lower VE is observed in children compared with young adults 68 . Accordingly, we assumed an age-dependent VE. In particular, given a baseline efficacy VE among individuals aged 20-59 years (80% in the main analysis), we assumed a 50% lower VE in individuals &lt;20 and ≥60 years of age (namely 40%). A scenario without age-specific variations in VE was explored as sensitivity analysis SA24.</p>
<p>Individuals vaccinated with the first dose could still develop infections without any immune protection, while the second dose vaccination could produce the expected VE after an average of 14 days. In the main analysis we assume both natural infection-induced and vaccine-induced immunity to SARS-CoV-2 infection does not wane within the considered time horizon (2 years). In additional sensitivity analyses, we considered an average duration of vaccine-induced protection of 6 months (SA12) and 1 year (SA25). We also consider a sensitivity analysis assuming that vaccination is effective in preventing symptomatic illness but not infection (SA11), and another one assuming an all-or-nothing vaccine, that is, the vaccine confers full protection to VE percent of vaccinated individuals (SA18).</p>
<p>Priority order of vaccination. The doses available to be distributed daily (6 million in the main analysis) are assigned by considering the following order of priority 14 : In the main analysis, healthcare workers are considered as the top priority (tier 1 of the vaccination strategy); law enforcement and security workers, personnel in nursing home and social welfare institutes, community workers and workers in energy, food and transportation sectors are included in tier 2; adults ≥60 years of age with underlying conditions, and adults ≥80 years of age without underlying conditions, who are at the highest risk of severe/fatal COVID-19, are considered in tier 3; individuals aged &lt;60 years with pre-existing medical conditions and pregnant women are included in tier 4; individuals aged 20-59 years without underlying conditions are included in tier 5; school-age children and younger children aged ≤5 years without underlying conditions are recommended for vaccination in tier 6 (Supplementary File 3).</p>
<p>Different priority orders are explored as sensitivity analyses. Healthcare workers and the other essential workers listed above are fixed in tier 1 and 2 of vaccination, while the remaining population is vaccinated as described in Supplementary Table 2 by considering different orders of prioritization only based on age and disregarding the presence of underlying conditions (SA26: first prioritization to old adults; SA27: first prioritization to working-age groups; SA28: first prioritization to school-age groups). We explore the impact of 5,000 initial cases on the prioritization strategy (SA29). To understand the impact in terms of number of infections by age, we compare the prioritization strategy when we account for the uncertainty in the contact matrix and in the susceptibility to infection by age, or not (in this context, median values of contact numbers and relative susceptibility are used).</p>
<p>COVID-19 burden model. The main output of above transmission model is the age-specific number of new infections per day in the subpopulation with or without underlying conditions. On top of that, we developed a model of COVID-19 disease burden to estimate the number of symptomatic cases, hospitalization, ICU admissions and deaths in different scenarios in the presence/absence of vaccination.</p>
<p>We computed the age-specific number of symptomatic infections in individuals with and without underlying conditions on a daily basis by applying an age-specific probability of respiratory symptoms of 18.1%, 22.4%, 30.5%, 35.5% and 64.6% respectively for 0-19, 20-39, 40-59, 60-79 and 80+ years of age, as estimated from contact tracing data in Lombardy 20 . We assume that individuals with and without underlying conditions have the same age-specific probability of developing symptoms.</p>
<p>The daily age-specific number of hospital admissions in the two subpopulations was computed by applying the age-specific proportion of laboratory-confirmed symptomatic cases requiring hospitalization (Supplementary File 4), delayed by an average time of 3.8 days between symptom onset and hospitalization 17 .</p>
<p>The daily age-specific number of patients admitted to ICU in the two subpopulations was computed by applying to hospitalized cases an age-specific probability of being admitted to ICU 19 , and distinguishing patients requiring intensive care in survivors and non-survivors. Survivors are admitted to ICU after an average time of 7 days from hospitalization. Non-survivors are admitted to ICU after an average time of 8 days after hospitalization 16 .</p>
<p>The daily age-specific number of deaths in the two subpopulations was computed by applying the age-specific fatality ratio among symptomatic cases (Supplementary File 4), delayed by an average time of 13.9 days between symptom onset and death 18 . Data analysis. For each scenario, 200 stochastic model realizations were performed. The outcome of these simulations determined the distributions of the number of symptomatic infections, hospitalizations, ICU admissions and deaths. We defined 95% credible intervals as quantiles 0.025 and 0.975 of the estimated distributions. We used a Bayesian approach to estimate R t from the time series of symptomatic cases by date of symptom onset and the distribution of the serial interval 17 . The methods are described in detail in Supplementary File 5.</p>
<p>Reporting summary. Further information on research design is available in the Nature Research Reporting Summary linked to this paper.</p>
<p>NATure HuMAN BeHAVIOur | VOL 5 | AUgUST 2021 | 1009-1020 | www.nature.com/nathumbehav</p>
<p>NATure HuMAN BeHAVIOur | www.nature.com/nathumbehav</p>
<p>The study was supported by grants from the National Science Fund for Distinguished Young Scholars (no. 81525023, H.Y.), Key Emergency Project of Shanghai Science and Technology Committee (no. 20411950100, H.Y.), European Union Grant 874850 MOOD (MOOD 015, V.M., G.G., P.P. and S.M.). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p>
<p>No vax Vax No vax Vax No vax Vax No vax No NPIs Mild NPIs Moderate NPIs Strong NPIs Number of symptomatic cases (1,000,000) Vax No vax Vax No vax Vax No vax Vax No vax No NPIs Mild NPIs Moderate NPIs Strong NPIs Number of hospitalizations (1,000,000) Vax No vax Vax No vax Vax No vax Vax No vax No NPIs Mild NPIs Moderate NPIs Strong NPIs Number of ICU admissions (1,000,000)</p>
<p>Data used in this study can be downloaded from GitHub at https://github.com/ DXW-sola1015/2021_Yang_COVID-19-Vax_China_Code.</p>
<p>Extended data is available for this paper at https://doi.org/10.1038/s41562-021-01155-z.</p>
<p>The online version contains supplementary material available at https://doi.org/10.1038/s41562-021-01155-z.</p>
<p>H.Y. conceived the study. H.Y., S.M. and M.A. designed and supervised the study. J.Y., J.Z., J.C., W.W., Q.W., W.Z., Z.Z, K.D. and G.Z. participated in data collection. V.M., G.G., P.P. and F.T. developed the model. J.Y., V.M. and X.D. analysed the model outputs and prepared the tables and figures. J.Y. prepared the first draft of the manuscript. H.Y., V.M., C.V. and M.A. commented on the data and its interpretation, and revised the content critically. All authors contributed to review and revision and approved the final manuscript as submitted and agree to be accountable for all aspects of the work.</p>
<p>All these data were in the public domain. Ethical review for the re-use of these secondary data is not required.</p>
<p>Extended Data Fig. 1 | Time series of symptomatic cases given relaxation of NPIs 6, 9 and 12 months since vaccination, provided a vaccination capacity of 6 million doses per day. a-c, For scenario with strong NPIs (R t = 1.1), we increment the value of R t to 1.3, 1.5, 2.5 after 6, 9, and 12 months since vaccination, respectively; d-e, for R t = 1.3, we increment the value of R t to 1.5 and 2.5 after 6, 9, 12 months, respectively; f, for R t = 1.5, we increment the value of R t to 2.5 after 6, 9, 12 months, respectively. Line denotes median, and shadow denotes quantiles 0.025 and 0.975. Note that the red line is barely visible as it is almost entirely overlapping with the green one.</p>
<p>Extended Data Fig. 9 | Cumulative burden of COVID-19, SArS-CoV-2 variants compared to non-variants. We consider higher values of R t to account for enhanced transmissibility of SARS-CoV-2 variants. a, The number of symptomatic cases in the context of strong NPIs, R t = 1.1 for historical lineage, while R t = 1.7 for variants; b, the number of symptomatic cases in the context of moderate NPIs, R t = 1.3 for historical lineage, while R t = 1.9 for variants; c, the number of symptomatic cases in the context of mild NPIs, R t = 1.5 for historical lineage, while R t = 2.1 for variants. d-f, as a-c but for the number of hospitalizations. g-i, as a-c but for the number of ICU admissions. j)-l) as a-c but for the number of deaths. Number denotes median, and error bars denote quantiles 0.025 and 0.975.</p>
<p>Nature Research wishes to improve the reproducibility of the work that we publish. This form provides structure for consistency and transparency in reporting. For further information on Nature Research policies, see our Editorial Policies and the Editorial Policy Checklist.</p>
<p>For all statistical analyses, confirm that the following items are present in the figure legend, table legend, main text, or Methods section.</p>
<p>The exact sample size (n) for each experimental group/condition, given as a discrete number and unit of measurement A statement on whether measurements were taken from distinct samples or whether the same sample was measured repeatedly</p>
<p>The statistical test(s) used AND whether they are one-or two-sided Only common tests should be described solely by name; describe more complex techniques in the Methods section.</p>
<p>A description of any assumptions or corrections, such as tests of normality and adjustment for multiple comparisons A full description of the statistical parameters including central tendency (e.g. means) or other basic estimates (e.g. regression coefficient) AND variation (e.g. standard deviation) or associated estimates of uncertainty (e.g. confidence intervals) For null hypothesis testing, the test statistic (e.g. F, t, r) with confidence intervals, effect sizes, degrees of freedom and P value noted Give P values as exact values whenever suitable.</p>
<p>For Bayesian analysis, information on the choice of priors and Markov chain Monte Carlo settings For hierarchical and complex designs, identification of the appropriate level for tests and full reporting of outcomes Estimates of effect sizes (e.g. Cohen's d, Pearson's r), indicating how they were calculated Our web collection on statistics for biologists contains articles on many of the points above.</p>
<p>For manuscripts utilizing custom algorithms or software that are central to the research but not yet described in published literature, software must be made available to editors and reviewers. We strongly encourage code deposition in a community repository (e.g. GitHub). See the Nature Research guidelines for submitting code &amp; software for further information.</p>
<p>All manuscripts must include a data availability statement. This statement should provide the following information, where applicable:</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f386423226"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T10:13+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Background: A positive surface charge has been largely associated with nanoparticle (NP) toxicity. However, by screening a carbon NP library in macrophages, we found that a cationic charge does not systematically translate into toxicity. To get deeper insight into this, we carried out a comprehensive study on 5 cationic carbon NPs (NP2 to NP6) exhibiting a similar zeta (ζ) potential value (from + 20.6 to + 26.9 mV) but displaying an increasing surface charge density (electrokinetic charge, Q ek from 0.23 to 4.39 µmol/g). An anionic and non-cytotoxic NP (NP1, ζ-potential = -38.5 mV) was used as control.</p>
<p>The 5 cationic NPs induced high (NP6 and NP5, Q ek of 2.95 and 4.39 µmol/g, respectively), little (NP3 and NP4, Q ek of 0.78 and 1.35 µmol/g, respectively) or no (NP2, Q ek of 0.23 µmol/g) viability loss in THP-1-derived macrophages exposed for 24 h to escalating NP dose (3 to 200 µg/mL). A similar toxicity trend was observed in airway epithelial cells (A549 and Calu-3), with less viability loss than in THP-1 cells. NP3, NP5 and NP6 were taken up by THP-1 cells at 4 h, whereas NP1, NP2 and NP4 were not. Among the 6 NPs, only NP5 and NP6 with the highest surface charge density induced significant oxidative stress, IL-8 release, mitochondrial dysfunction and loss in lysosomal integrity in</p>
<p>A large variety of nanoparticles (NPs), defined as particles with a size of less than 100 nm in one dimension, are currently developed for a wide range of applications including consumer goods manufacturing, foodstuff elaboration as well as medical applications [1]. These NPs are increasingly present in our professional and domestic environment, which raises the question of their potential adverse effects on human health [2]. Nanotoxicology, the branch of science that studies the hazard posed by NPs to humans and their environment aims at addressing this issue [3,4]. However, this task is made complex by the huge diversity of NPs in terms of physicochemical characteristics, including chemical composition, size, shape, and surface charge and chemistry [1,4]. One of the challenges of nanotoxicology is therefore to define the chemical and physical properties that drive NP adverse health effects in order to better predict NP toxicity and allow the production of safe-by-design NPs.</p>
<p>In the last decade, numerous studies have been conducted on the toxicological effects of engineered NPs in the lung, since inhalation is likely the main route of exposure to NPs. These studies have shown that NP inhalation may be harmful to the lung. Indeed, NPs have been reported to be cytotoxic towards lung cells such as macrophages and airway epithelial cells [5,6]. As well, NP administration into the lung of laboratory animals was shown to induce airway inflammation, characterized by a cellular infiltrate composed of neutrophils and macrophages, and the production of proinflammatory cytokines [7][8][9][10][11][12]. Also, NP inhalation has been found to promote asthma onset and exacerbation, resulting in increased allergen sensitization and worsening of airway inflammation and remodeling in mouse models of the disease [13][14][15][16][17][18][19]. The toxicological effects of engineered NPs in the lung are however dictated by their physicochemical characteristics, such as their size and chemical composition, but also their charge, surface chemistry and shape [20,21]. Indeed, these characteristics determine the surface reactivity of NPs, i.e. their capacity to react with their immediate environment [22,23]. They thus influence their interaction with the components of biological media (e.g. proteins or cell surfaces), to the point of drastically modifying their fate in the organism, and their toxicity.</p>
<p>Among NP physicochemical characteristics, the surface charge is one of the key factors for toxicity [24]. In vitro or in vivo studies conducted on NPs of different composition (silicon-, silver-, polystyrene-, or carbonbased NPs), have shown that a positive zeta potential (ζ-potential) is associated with greater NP toxicity compared to a negative one [25][26][27][28][29]. This is generally attributed to a greater capacity of positively charged NPs to interact with the cell membrane through attractive electrostatic interactions with negatively charged phospholipids or membrane proteins, and to a subsequent higher NP cell uptake [4,26,30]. It should be noted, though, that some authors have reported lower cell uptake of cationic NPs as compared to anionic ones, which was tentatively explained by the formation of large NP agglomerates at the membrane that could not be internalized by the cell [31,32]. By screening a library of 35 carbon-based NPs with various surface functionalizations and ζ-potential values in human macrophages, we recently demonstrated that a cationic charge is not sufficient to confer toxicity to NPs [33]. Indeed, although a significant positive correlation was found between NP toxicity and ζ-potential value, several cationic NPs exhibited no or weak toxicity, while having a marked positive ζ-potential. Some of these non toxic or slightly toxic cationic NPs displayed PEG decoration, which could explain their relative safety [34], but not all of them. Noteworthy, the cationic NPs in this library were produced by pyrolysis of various organic materials, in the presence of nitrogen-containing passivation reagents with an increasing number of amino groups, though this did not strictly translate into increasing ζ-potential values. This led us to hypothesize that the amount of positive charges on NPs (surface charge density), rather than the ζ-potential value is predictive of the NP toxicity, when these two concepts are often mixed up.</p>
<p>Therefore, in the present study, to get deep insight into the role of the surface charge in the toxicity of cationic NPs, we synthesized 5 cationic carbon-based NPs displaying various amounts of amino groups at their periphery. This was achieved through the pyrolysis of a mixture of citric acid and various passivation reagents, namely high molecular weight branched poly(ethylenimine) (MW = 25 kDa, bPEI25k), low molecular weight branched poly(ethylenimine) (MW = 600 Da, bPEI600), pentaethylene hexamine (PEHA), N,N-dimethylethylene diamine (DMEDA) and DMEDA/poly(ethylene glycol) (MW = 550 Da, PEG550). A negatively charged and non-cytotoxic NP prepared from ammonium citrate was also produced as a control. These spherical carbon nanomaterials called carbon dots (CDs) were chosen to conduct this study because of their unique properties that attracted much attention of researchers in the last decade [35,36]. Indeed, CDs are easy to synthetize from small molecules and to functionalize. They are of very small size (a few nm) and fully water-soluble. In addition, they exhibit intrinsic fluorescence, that allows to study their cellular fate without prior derivatization with a fluorescent dye [37,38]. Thus, CDs are currently developed for optical imaging applications, small drug or nucleic acid delivery, or theranostic applications [39][40][41][42]. In the present study, CDs were prepared as previously described [33,43]. They were characterized in terms of size, hydrodynamic diameter, surface charge, but also surface charge density. Their uptake by human macrophages and airway epithelial cells was studied using confocal laser scanning microscopy (CLSM) and fluorescence activated cell sorting (FACS), thanks to their intrinsic fluorescence properties. Their cell toxicity was assessed by measuring viability loss, oxidative stress, inflammation, mitochondrial perturbation and lysosome integrity. We also investigated airway inflammation induced by the NPs in healthy mice, and their effects in a mouse model of asthma. Our data revealed that the surface charge density of a cationic carbon NP rather than the absolute value of its ζ-potential may be a relevant descriptor for predicting its toxicity.</p>
<p>The elemental composition, ζ-potential, size, surface charge density, and optical properties of the 6 NPs were determined as described in Methods section. The nitrogen, carbon and hydrogen contents in the various CDs were in between 2.4 and 14.6%, 26.6 and 49.0%, and 6.1 and 8.5%, respectively (Table 1). These data however are difficult to interpret, as these particles were all titratable and contained sodium (NP1) or chloride (NP2 to NP6) counter ions in various amounts at pH 7.4. The five cationic carbon NPs (NP2 to NP6) exhibited similar ζ-potential in between + 20.6 and + 26.9 mV, whereas the negative NP (NP1) had a ζ-potential of -38.5 mV (Table 1). The rather high ζ-potential, in absolute values, of the 6 NPs did translate into high colloidal stability in water as was observed for all the samples. The NP size (TEM) and hydrodynamic diameter (DLS) were measured in 1.5 mM NaCl pH 7.4, and ranged from 12.6 to 39.5 nm and from 7.2 to 43.9 nm, respectively (Table 1). TEM and DLS provided consistent results, in some cases (NP1, NP2, and NP4). In other cases, however, significant differences between size and hydrodynamic diameter were observed (NP3, NP5 and NP6). This might result either from the overestimation of populations of aggregates in DLS (according to Rayleigh's approximation, intensity of scattering depends on the particle diameter raised to the sixth power), or arbitrary removal of NP aggregates in TEM micrographs before image processing (most of aggregates were assumed to form under capillary forces upon deposition and drying of the samples on the TEM grids). The surface charge density as determined by polyelectrolyte titration increased from 0.23 to 4.39 µmol/mg for NP2 to NP5 (Table 1), which did reflect the nature of the passivation reagent used in the preparation of the NPs. Indeed, the higher the nitrogen content of the passivation reagent, the higher the surface charge density of the resulting NPs. One exception was observed with bPEI25k-based NP6 which surface charge density was lower than that of bPEI600-based NP5 (Table 1). This is explained by the fact that NP6 was obtained by pyrolysis of a mixture of two parts of citric acid and one part of bPEI25k (by weight), whereas NP5 resulted from the pyrolysis of one part of citric acid with four parts of bPEI600. Thus, it could be expected that NP5 would display a higher density of charge than NP6, although the polyamine chains in bPEI25k are longer than those in bPEI600. Besides, when considering the DMEDAbased NPs, it appeared that PEGylation in NP2 resulted in a decrease in the density of charge by a three-fold factor when compared to NP3 (Table 1). Due to its hydrophilic nature, PEG chains grafted on the NPs generate a hydrated cloud with a large exclusion volume that sterically precludes the NP cationic charges from interacting with the negative charges of the titrant PAA. This is fully consistent with the picture of a hydrated steric barrier on the particle surface that has been introduced in the 1970s [44].</p>
<p>In biological fluids, NPs tend to aggregate or/and agglomerate due to ionic strength, pH or protein adsorption [45]. To assess the behavior of the title NPs during in vitro experiments, DLS measurements were performed on NP dispersions prepared in complete RPMI-1640 or DMEM-F12 culture medium. The results were expressed as a score, as measured size was out of the apparatus measurement range for three NPs. NPs with size remaining less than 100 nm were considered as dispersed (score none). NPs with a diameter ranging between 100 and 500 nm were considered as partially aggregated (score +), and NPs with a diameter greater than 500 nm were designated as highly aggregated (score ++). NP1 and NP4 remained dispersed, whereas NP2, NP3, NP5 and NP6 tended to aggregate in both culture media. The aggregation of NP2, NP3, NP5 and NP6 was more or less pronounced. Due to PEGylation, NP2 was only partially aggregated, whereas NP3, NP5 and NP6 were highly aggregated (Table 1). Neither ζ-potential nor surface charge density data would have enabled to anticipate the aggregation behavior of the NPs in culture media.</p>
<p>Regarding optical properties, all the NPs displayed a UV-visible absorption spectrum with an absorption peak centered at 336-361 nm and extending to 600 nm, without noticeable structure (Table 2). A mass attenuation coefficient, ε m , was calculated at the maximum absorption (around 360 nm). While the ε m value was close to ca. 2 L g -1 cm -1 for most NPs, NP3 and NP6 were exceptions. Indeed, NP3 displayed an especially high ε m value of 8.80 L g -1 cm -1 , as was attested by the deep brown color of the sample. At the opposite, NP6 sample was only faint colored, which translated into the low ε m value. The NPs displayed various photoluminescence characteristics, as could be expected due to the various protocols carried out for their preparation, particularly with regard to the reaction temperature [43]. Thus, the excitation wavelength ranged from 351 to 522 nm, while the fluorescence emission wavelength was maximum at 437-512 nm, which is easy to use for in vitro imaging (vide infra). Also, it is worth to note that NP3 demonstrated up-conversion photoluminescence emission but that was not investigated in further detail.</p>
<p>To assess NP cytotoxity, phorbol 12-myristate 13-acetate (PMA)-activated THP-1, A549 and Calu-3 cells were exposed to increasing concentrations of NP1 to NP6 (3 to 200 µg/mL) for 24 h, and their viability was determined by assessing cell mitochondrial activity using the MTT assay. The 6 NPs exhibited various toxicity grades in the different cell types tested. In THP-1 cells (Fig. 1), the high-(bPEI25k) and low-(bPEI600) molecular weight bPEI-passivated NPs, NP5 and NP6, with a ζ-potential of + 23.9 ± 2.0 and + 22.7 ± 0.1 mV, respectively, induced a significant and dose-dependent loss in cell viability that reached nearly 100% at the concentration of 200 µg/mL. NP3 and NP4 that were passivated with short oligoamines (DMEDA and PEHA, respectively) and exhibited a ζ-potential of + 21.0 ± 1.5 and + 20.6 ± 1.2 mV, respectively, triggered some toxicity at 100 and 200 µg/mL NPs, but viability loss did not exceed 37.2%. At last, the cationic CD NP2 that was passivated with DMEDA + mPEG550 (ζ-potential of + 26.9 ± 1.6 mV) and the negatively charged CD NP1 (ζ-potential of -38.5 ± 1.9 mV) did not affect THP-1 cell viability. In A549 and Calu-3 cells, a similar trend was observed for the 6 NPs, but with less viability loss than in THP-1 cells for NPs exhibiting toxicity (Fig. 1). Indeed, in A549 cells, NP6 and NP5 induced a significant and dose-dependent loss in cell viability that reached nearly 100% at the concentration of 200 µg/ mL, but with a higher IC 50 value than in THP-1 cells: 2) µg/mL in THP-1 cells, for NP6 and NP5, respectively. In A549 cells as well, NP4 induced no significant viability loss in contrast to THP-1 cells. In Calu-3 cells, only NP6 and NP5 evoked some toxicity, but this toxicity did not exceed 43.6 and 68.7%, respectively at 200 µg/mL, when compared to nearly 100% in THP-1 cells for the two NPs. Thus, the present data confirmed our previous observation made on THP-1 cells [33] which was that the toxicity of cationic carbon NPs is not linked to the absolute value of their ζ-potential, since although exhibiting similar high ζ-potential, not all cationic NPs investigated herein triggered viability loss, whatever the cell model. Toxicity of the NPs appeared rather linked to their density of surface charge (Q ek ). In the case of CDs, it is governed by the structure of the passivation reagent, the reagent stoichiometry, and the pyrolysis conditions. Thus, NP toxicity decreased with Q ek as follow: NP6 (Q ek = 2.95 µmol/mg) ≈ NP5 (Q ek = 4.39 µmol/mg) &gt; NP4 (Q ek = 1.35 µmol/mg) ≈ NP3 (Q ek = 0.78 µmol/mg) as depicted on Fig. 2 for THP-1 cells. Furthermore, the PEG decoration introduced at the surface of the NPs (compare NP2 to NP3) significantly decreased the density of the cationic charges (Q ek = 0.78 µmol/mg for NP3 vs. 0.23 µmol/mg for PEGylated NP2) interacting with external components, which translated into lower toxicity (Fig. 2).</p>
<p>NP surface charge is considered to impact NP toxicity by influencing NP cell uptake [24]. We thus assessed NP cell uptake by THP-1 and A549 cells using FACS and CLSM, thanks to the intrinsic fluorescence properties of CDs. Cells were exposed to 25 µg/mL NPs for 4 h before internalization measurements. FACS analysis showed a significant increase in fluorescence intensity in THP-1 cells treated with NP3 (4.9-fold, p &lt; 0.01), NP5 (10.9-fold, p &lt; 0.001) and NP6 (5.5-fold, p &lt; 0.01) when compared to the control cells, suggesting internalization of these NPs. In contrast, no fluorescence increase was observed in cells exposed to NP4, NP2 and NP1 (Fig. 3). CLSM observations carried out after cell staining with the membrane probe DSQ12S (green fluorescence) confirmed the internalization of NP3, NP5 and NP6 measured by FACS (Fig. 3). Indeed, a blue labeling due to CD fluorescence was observed in THP-1 cells treated with NP3, NP5 or NP6, whereas no blue fluorescence was detected in cells exposed to NP4, NP2, and NP1. Similar data were obtained in A549 cells (Additional file 1: Fig. S1), with significant cell uptake being evidenced for NP3, NP5 and NP6 by both CLSM and FACS, although internalization appeared as less pronounced from FACS results except for NP3 (increases in fluorescence by 5.5-(p &lt; 0.001), 3.1-(p &lt; 0.001) and 2.4-fold (p &lt; 0.01) for NP3, NP5 and NP6, respectively). Thus, internalization of the 6 NPs was overall consistent with their toxicity in both THP-1 and A549 cells, and was thus reflected by the surface charge density of the NPs rather than the value of their ζ-potential.</p>
<p>Oxidative stress is a central mechanism of NP toxicity, including in the lung [46,47]. Indeed, direct and/or indirect NP interaction and/or damage to cellular organelles such as lysosomes or mitochondria can lead to oxidative stress, which in turn evokes toxicological responses such as inflammation and viability loss. In a previous work, we found that cationic CDs passivated with high molecular weight bPEI evoked a dose-dependent viability loss that was associated with oxidative stress, IL-8 release, mitochondrial perturbation and loss in lysosome integrity in THP-1 cells [48]. Thus, to get further insight into the link between surface charge/charge density and cytotoxicity of cationic NPs, we investigated these cellular responses in THP-1 and A549 cells exposed to NP1 to NP6, as described in Methods section. NP5 and NP6 induced significant oxidative stress (p &lt; 0.05 for the two NPs), IL-8 release (p &lt; 0.001 for the two NPs), mitochondrial perturbation (p &lt; 0.01 for the two NPs) and loss in lysosome integrity (p &lt; 0.001 for the two NPs) in THP-1 cells (Fig. 4). Some increases in IL-8 secretion, mitochondrial perturbation and loss in lysosome integrity were also observed in response to NP3, but theses changes were significant for lysosome integrity only (p &lt; 0.05). By contrast, NP2, NP4 and NP1 evoked no effect. In A549 cells, NP5 and NP6 induced some cellular responses in contrast to NP1 to NP4 (Additional file 1: Fig. S2). These effects related to oxidative stress and IL-8 secretion but not mitochondrial perturbation. Furthermore, they were of lower magnitude than in THP-1 cells, which is consistent with lower viability losses evoked by the NPs in A549 cells (Fig. 1).</p>
<p>As inflammation is an important in vitro and in vivo response to nanomaterials [5][6][7][8][9][10][11][12], an inflammatory cytokine multi-analyte ELISArray allowing the simultaneous assessment of 12 cytokines/chemokines was used to further characterize the inflammatory response evoked by the NPs (200 µg/mL) in THP-1 cells (Additional file 1: Table S1). Several cytokines (TNF-α, IL-6, IL-12, IL-17 and eotaxin) remained non detectable or in the background signal (i.e., similar to that recorded with non-exposed cells) after cell treatment with the various NPs. The release of MDC remained unchanged whatever the NPs the cells were exposed to. The two most toxic NPs, i.e. NP5 and NP6, increased by a 5-to 10-fold factor the release of IL-1β, MIP-1α, MIP-1β, and MCP-1. Although less pronounced (1.5-to 5-fold), some increase in MIP-1α and/or MIP-1β production was observed in cells exposed to NP3 and/or NP2. Besides, NP3 increased by more than 10-fold MCP-1 release. By contrast, no increase in the release of detectable cytokines was observed in response to NP1. Thus, IL-8 was not the only pro-inflammatory cytokine induced by the NPs that evoked cell toxicity.</p>
<p>All together, the cellular responses induced by the NPs in both THP-1 and A549 cells were overall consistent with their cell internalization (Fig. 3 and Additional file 1: Fig. S1) and the cell viability loss they triggered (Fig. 1), and better correlated with the surface charge density of the NPs, Q ek , than with their ζ-potential.</p>
<p>In toxicology, in vitro models may have limited reliability, mainly due to the fact that these models do not fully reflect the complexity of an organ or the interplay between different cell types or organs in the body [49]. To strengthen our in vitro results, we thus assessed inflammation induced by NP1 to NP6 in the lung of healthy mice. Animals received a single intrapulmonary administration of the NPs at fixed or increasing dose, and total and differential cells and inflammatory cytokines were measured in animal bronchoalveolar lavage fluids (BALFs) at 24 h. In a first experiment, we conducted a dose-response study on the two most toxic NPs in vitro, NP5 and NP6 (i.e., the bPEI-based NPs). NP5 induced a dose-dependent inflammation in the lung of mice. This inflammation was characterized by an influx of neutrophils and an increase in IL-6, KC and MCP-1 in BALFs (Fig. 5). It was non significant at the dose of 25 µg for all parameters, and maximal at the dose of 100 µg (p &lt; 0.001 for all parameters). A similar dose-dependent inflammation was observed with NP6 (Additional file 1: Fig. S3).</p>
<p>In a second experiment, we compared the toxicity on the 6 NPs using the effective dose of 100 µg. NP5 and NP6 exhibited a significant inflammatory activity, as expected (Fig. 6). NP4 triggered a non-significant neutrophil influx and an increase in IL-6 (p &lt; 0.01), whereas cell counts and inflammatory cytokine levels remained unchanged for NP1, NP2 and NP3. Thus, like in vitro data, in vivo results on lung toxicity support the hypothesis that toxicity of cationic carbon NPs is not linked to the absolute value of their ζ-potential. Lung toxicity of NPs rather decreased with Q ek , supporting the idea that surface charge density of a cationic carbon NP is a more relevant descriptor for predicting its in vitro and/or in vivo toxicity. sensitization and worsening of allergen-induced airway inflammation and remodeling in animal models of the disease [12][13][14][15][16][17][18]. So, in a last experiment, we compared the effect of NP1, NP2, NP3 and NP5 in a mouse model of allergic asthma induced by HDM, one of the main causes of the disease in humans [19]. HDM extract or vehicle was administered in the lung of mice on days 0, 7, 14 and 21 of the protocol and NPs (50 µg) were given every other day from day 0 to day 16. On day 23, total and HDM-specific IgG1 levels, total and differential cell counts and levels of the eosinophil chemoattractant eotaxin were measured in mouse serum, BALFs or lung homogenates. HDM alone significantly increased levels of total (p &lt; 0.05) and allergen (HDM)specific (p &lt; 0.001) IgG1 in serum (Fig. 7a,b), total cell (p &lt; 0.001) and eosinophil (p &lt; 0.01) number in BALFs (Fig. 7c) and production of the eosinophil chemoattractant eotaxin (p &lt; 0.001) in lung homogenates (Fig. 7d). NP5 aggravated all allergen-induced responses, with significant effects (p &lt; 0.001) on total and allergen-specific IgG1 in serum, total cell and macrophage number in BALFs, and production of the eosinophil chemoattractant eotaxin in lung homogenate when compared to the allergen (HDM) group. On the other hand, NP1, NP2 and NP3 did not exacerbate any allergen response. To extend the results obtained on NP5, histological analysis was conducted on mouse lung sections to evidence changes in tissular inflammation and mucus production. Perivascular and peribronchial inflammatory cell infiltrate (Fig. 8a) and increased mucus production (Fig. 8b) were observed on lung sections of allergen-exposed mice (HDM) when compared to control mice (CTL), and these changes (Fig. 8a,b) were more pronounced on sections from allergentreated mice exposed to the NP (HDM + NP5).</p>
<p>To investigate the role of the surface charge in the toxicity of cationic NPs, we synthesized and assessed the in vitro and in vivo lung toxicity of 5 cationic carbon NPs displaying various amounts of amino groups at their periphery. A non-passivated and non-toxic anionic NP was added to this NP library as control. Our data demonstrate that the surface charge density of a cationic carbon NP rather than the absolute value of its ζ-potential is a relevant descriptor for predicting its toxicity.</p>
<p>The NPs that were prepared in the present study are spherical carbon nanomaterials called CDs that possess intrinsic fluorescence among other interesting properties. A large number of methods have been described for the synthesis of these NPs and have been reviewed in the recent literature [50][51][52][53][54][55]. Especially, bottomup methods producing CDs by thermal treatment of organic precursors, generally a carbon source and a passivation reagent, became very popular as they use low cost starting materials and do not require any sophisticated equipment. Though it is widely acknowledged that intrinsic properties of CDs depend on the experimental conditions carried out for their preparation, the latter are extremely difficult to anticipate, and their fine tuning still relies on protocols to implement step by step, through a trial and error approach. Herein, several independent protocols have been selected in order to produce cationic CDs with various charge distributions at their periphery. We thus varied the carbon source (citric acid and ammonium citrate), passivation reagent (DMEDA, PEHA, bPEI600, bPEI25k, and mPEG550), and activation mode (microwave irradiation, thermal decomposition, and solvothermal treatment). The obtained cationic NPs exhibited very similar ζ-potential (in between + 21.0 and + 26.9 mV), but different surface charge density (from 0.23 to 4.39 µmol/mg), which allowed us to investigate the hypothesis that the amount of positive charges on NPs rather than the ζ-potential value is predictive of NP toxicity.</p>
<p>In the first part of our study, human macrophages (PMA-activated THP-1 cells) and airway epithelial cells (A549 and Calu-3 cells) were used to assess the in vitro toxicity of our NP library. These two cell types were selected as they are the two main potential targets of NPs in the lung [3,12]. PMA-activated THP-1 cells are widely used as a model of human macrophages in nanotoxicology [56]. We and others used this model to screen a large library of carbon or metal NPs with different physicochemical characteristics [5,33,57,58]. Besides, A549 and Calu-3 cells are epithelial cells representative of the two main regions of NP deposition in the airways, namely the alveoli and the bronchi, respectively. They are also among the most commonly used lung epithelial cell lines in nanotoxicology studies [49]. Our data show that although exhibiting similar ζ-potential, not all cationic NPs of our library were internalized and triggered viability loss and/or NP-associated cell responses including oxidative stress, cytokine secretion, mitochondrial perturbation and lysosome integrity changes. Consistent data among the different toxicity endpoints we measured were obtained for all NPs. Thus, we confirmed our previous observation made in macrophages that cytotoxicity of cationic carbon NPs is not necessarily linked to the absolute value of their ζ-potential [33] and extended this observation to airway epithelial cells. The two tested epithelial cell lines were however less sensitive to the toxicity of the cationic NPs than macrophages. This is in agreement with previous reports in the literature on metallic or PLGA NPs [5,59]. The difference in sensitivity observed between macrophages and epithelial cells could be explained by the phagocytosis activity of macrophages and their major role in particle clearance in contrast to alveolar epithelial cells. Besides, among the two epithelial cell lines investigated herein, Calu3 cells appeared as less sensitive than A549 cells. This could be explained by the capacity of Calu-3 cells to secrete mucus that acts as an important protective barrier at epithelial interfaces and may thus reduce NP cell uptake [59]. In agreement with this hypothesis, uptake of polystyrene particles by Calu-3 cells was reported to be reduced when compared to A549 cells [60,61].</p>
<p>In nanotoxicology, the relevance of in vitro studies to predict in vivo nanomaterial toxicity has been questioned because these models do not fully reflect the complexity of an organ or the interplay between different cell types within an organ, but also for more specific reasons [49]. Indeed, some in vitro assays widely used for toxicity assessment of chemicals have been reported to generate false results with some NPs because these nanomaterials interfered with chemical or fluorescent probes [6,62]. As well, in biological fluids, NPs may adsorb biomolecules such as proteins and/or lipids due to their large specific surface area. These biomolecules, which alter the surface chemistry of the NPs and therefore their interactions with cells and their toxicity, may be different in in vitro and in vivo models, due to difference in microenvironment composition [23]. However, in this study, in vivo data reinforce the observation made in vitro that toxicity of cationic carbon NPs is not a reflection of the absolute value of their ζ-potential, since only cationic NPs that exhibited significant in vitro toxicity, namely NP5 and NP6, triggered airway inflammation in healthy mice and/ or exacerbated systemic immune response, and airway inflammation and mucus production in mice exposed to an allergen. Thus the in vitro models we selected were rather predictive of the in vivo lung toxicity of our NPs, especially THP-1 and A549 cells in which NPs exhibiting potent in vivo toxicity triggered significant changes in several toxicity endpoints, particularly oxidative stress which plays a central mechanistic role in NP-induced toxicity, including in the lung [19,46,47].</p>
<p>ζ-potential is widely used to characterize the charge of NPs and to predict NP toxicity, cationic NPs being generally more toxic than anionic ones, due in part to their greater cell uptake and/or their damaging effect on cell and lysosomal membranes [25-27, 48, 63]. A correlation was thus found between ζ-potential and hemolytic activity and lung inflammogenicity of polymeric or polystyrene NPs [28,29]. However, not all studies found a correlation between ζ-potential of NPs and cytotoxicity [64,65]. By screening a library of 35 carbon-based NPs with various surface functionalization in human macrophages, we found that a cationic charge is not sufficient to confer toxicity to NPs [33]. The cationic NPs in this library were produced by pyrolysis of organic materials, in the presence of nitrogen-containing passivation reagents with an increasing number of amino groups, though this did not strictly translate into increasing ζ-potential values. ζ-potential is defined as the average electrostatic potential existing at the slipping plane (i.e., the boundary plane delimitating the NP and associated counter ions that move together when an electrical field is applied) [66]. Thus, whether the slipping plane is close to the particle surface or not, the surface charge density determined by the amount of charged functional groups (ammonium) tethered to the NP within the electrical double layer (delimited by the surface of the NP core and the slipping plane) may vary a lot when the ζ-potential value may be the same. Therefore, the amount of positive charges on NPs (surface charge density), rather than the ζ-potential value could be a better predictor of NP toxicity. In agreement with our hypothesis, in their review on how physicochemical characteristics of NPs cause their toxicity, Luyts et al. came to the conclusion that the charge at specific spots contributes significantly to the NP toxicity, making ζ-potential not a safe predictor of nanotoxicity [20]. However, NP charge density has not been investigated as a descriptor of NP safety in the literature. The determination of the surface charge density (Q ek ) of cationic NPs is especially difficult and cannot be achieved by standard acid-base titration. Indeed, due to high local concentration of amino groups at the surface of cationic NPs, their apparent pK a span over a wide pH range that can extend from 11 to 2 [67,68]. In the present study, we thus used polyelectrolyte titration to determine the charge density of our cationic NPs [69,70]. We found thereby that toxicity of the cationic carbon NPs decreased with Q ek in both in vitro and in vivo lung models whatever the measured endpoints as summarized in Table 3. The investigated NPs appeared to rank in 3 groups according to their toxicity. The first group includes the non toxic PEGylated DMEDA-passivated CDs, NP2, that displays the lower Q ek value in the series. In the second group, we find NPs exhibiting low in vitro toxicity and no in vivo toxicity, i.e. NP3 (DMEDApassivated CDs) and NP4 (PEHA-passivated CDs). These NPs are characterized by low/medium Q ek . NP5 (bPEI600-passivated CDs) and NP6 (bPEI25k-passivated CDs) that triggered both significant in vitro and in vivo toxicity are arranged/classified in the third group, and display the higher Q ek values in the series. This may suggest the existence of a threshold surface charge leading to harmful lung effects.</p>
<p>All together, using both in vitro and in vivo models, this study clearly reveals that the surface charge density of a cationic carbon NP rather than the absolute value of its ζ-potential may be a relevant descriptor for predicting lung toxicity. In the case of CDs, surface charge density is governed by the nature of the passivation reagent, the reagent stoichiometry, and the pyrolysis conditions. Whether our observation may apply to other kinds of NPs and other toxic responses, and by the way, whether surface charge density can be an important feature to better predict cationic NP safety deserves deeper investigations.</p>
<p>The NPs investigated herein were produced according to some previously reported protocols [33,43]. They were purified by extensive dialysis and were obtained in 10-44% yield. NP1. Triammonium citrate (5.00 g) and potassium phosphate monobasic (1.00 g) in pure water (10 mL) were mixed to homogeneity in an Erlenmeyer flask and heated in a domestic microwave oven for 120 s at 700 W (i.e., under normal pressure). The resulting glassy residue was resuspended in EtOH (50 mL) and refluxed under stirring for 4 h. The suspension was then cooled down and stored at 4 °C overnight for decantation. Filtration of the supernatant through a 0.22 µm polyethersulfone (PES) membrane and solvent removal under reduced pressure yielded NP1 (0.70 g).</p>
<p>NP2. Neat citric acid (0.50 g), mPEG550 (4.30 g), and DMEDA (1.00 g) were heated at 150 °C, under normal pressure, and volatile was integrally driven out of the reaction vessel. After 30 min, the temperature was raised to 230 °C and the reaction mixture was stirred at this temperature for 30 min. The resulting residue was cooled down to rt, dissolved in water and dialyzed (Spectra/Por 3, MWCO 1000 Da) for 24 h. The resulting brown solution was filtered through a 0.22 µm PES membrane and freeze-dried to yield NP2 as a hygroscopic powdered dark brown material (0.64 g).</p>
<p>NP3. These NPs (2.40 g) were obtained from citric acid (6.00 g) and DMEDA hydrochloride (11.31 g) using the same protocol as for NP2.</p>
<p>NP4. These NPs (5.63 g) were obtained from citric acid (6.00 g) and PEHA (21.70 g) using the same protocol as for NP2.</p>
<p>NP5. Citric acid (125 mg), bPEI600 (500 mg), and HCl 0.1 N (5 mL) were homogenized in an Erlenmeyer flask, then heated in a domestic microwave oven at 620 W for 170 s. The residue was dissolved in HCl 0.1 N, centrifuged (7,500 g, 5 min), and supernatant was loaded in a dialysis bag (MWCO 3,500 Da) for extensive dialysis against HCl 0.1 N (24 h) and ultra pure water (24 h). Freeze-drying of the dialysis bag content yielded NP5 (275 mg) as a brown hygroscopic powder.</p>
<p>NP6. Citric acid (5.00 g) and bPEI25k (2.50 g) in water (50 mL) were stirred under reflux for 24 h. The mixture was cooled to rt, centrifuged (7500g, 5 min), and supernatant was loaded in a dialysis bag (MWCO 3500 Da) for extensive dialysis against HCl 0.1 N (96 h) and ultra pure water (24 h). Freeze-drying of the dialysis bag content yielded NP6 (0.75 g) as a brown hygroscopic powder.</p>
<p>where V is the volume of titrant added (µL), c the concentration of the acrylic acid titrant (µmol AA /µL), and w the amount of titrated NPs (mg). The results were thus expressed in mmol/g. Approximating the density of CDs at 1, the amount of charge per particle (C/particle) and per surface unit (C/nm 2 ) were also calculated. To characterize optical properties of the NPs, NP samples (0.10 mg/mL) were prepared in ultra-pure water and UVvisible and fluorescence measurements were done using a UviKon XL spectrometer (Bio-Tek Instruments) and a Fluoromax-4 spectrofluorometer (Horiba Scientific) respectively, in a 1-mL quartz cuvette.</p>
<p>THP-1 (TIB-202 ™ ), A549 (CCL-185TM) and Calu-3 (HTB-55TM) cells were grown in culture flasks at 37 °C in a 5% CO 2 humidified chamber. RPMI-1640 culture medium containing Lglutamine (2 mM), 2-mercaptoethanol (0.05 mM), penicillin (100 UI/mL), streptomycin (100 µg/mL), and heat inactivated fetal bovine serum (10%) was used to cultivate THP-1 cells. A549 and Calu-3 cells were grown in DMEM/F12 culture medium containing L-glutamine (2 mM), penicillin (100 IU/mL), streptomycin (100 µg/mL), Hepes (5 mM) and fetal bovine serum (10%). All cells and culture reagents were from ATCC and GIBCO, respectively. The day prior experiments, cells were transferred into culture plates or IbiTreat ® µ-Slides (1.5 polymer coverslip, IBIDI), as described below.</p>
<p>Changes in cell viability evoked by the NPs were assessed in THP-1, A549 and Calu-3 cells using the MTT assay. Cells were seeded into 96-well culture plates at a density of 3.10 4 (A549) or 10 5 (THP-1 and Calu-3) cells/well. PMA (Sigma, 10 ng/mL) was added to culture medium of THP-1 cells to induce their differentiation into macrophages. The following day, all cells were incubated with increasing concentrations of NPs (3-200 µg/mL) for 24 h. Then, cells were carefully washed with phosphate buffered saline (PBS) before addition of MTT (100 µL, 1.0 mg/mL in complete culture medium, Sigma). After a 1-h incubation period, culture medium was removed and cells were lysed with DMSO. Absorbance of the resulting samples was read at 570 nm with a correction at 690 nm using a Multiskan FC reader (Thermo Scientific). Cell viability was expressed as the percentage of the absorbance of treated cells relative to the absorbance of the non-exposed control cells. Concentration-response curves were obtained after logarithmic transformation of the data and fit with the Hill equation. Then, the Hill equation was used to calculate the effective concentration triggering 50% (EC 50 ), when possible.</p>
<p>NP cell uptake was assessed in THP-1 and A549 cells by CLSM and FACS, thanks to the intrinsic fluorescence properties of CDs. CLSM experiments were carried out as previously described [48]. Briefly, THP-1 and A549 cells were seeded into 8-well IbiTreat µ-Slides at a density of 10 5 and 75.10 3 cells/well, respectively. PMA (10 ng/mL) was added to culture medium of THP-1 cells to induce their differentiation into macrophages. The following day, the different cultures were incubated with 25 µg/mL NPs for 4 h. At the end of the incubation time, cells were carefully washed with culture medium to remove non-internalized NPs and the DSQ12S fluorescent probe (10 nM in PBS) was added to the samples for 5 min to label the cell membrane [71]. The intracellular distribution of NPs was then observed using a Leica SP2 microscope equipped with a 63× oil immersion objective (NA = 1.2). The NPs and the membrane probe were excited with 405 and 635 nm laser sources, respectively. The emission bands were detected with a photomultiplier. The position and the width of the detection channels were adjusted for each dye.</p>
<p>Oxidative stress was assessed by measuring changes in cellular reduced glutathione (GSH) induced by NPs in THP-1 and A549 cells using the naphthalene-2,3-dicarboxaldehyde (NDA) probe. Cells were seeded into 24-well culture plates at a density of 18.10 4 (A549) or 5.10 5 (THP-1) cells/well. PMA (10 ng/mL) was added to culture medium of THP-1 cells to induce their differentiation into macrophages. The following day, the cells were incubated with 100 µg/mL NPs for 4 h. At the end of the incubation period, cells were washed with a buffer containing 5 mM EDTA, 40 mM NaH 2 PO 4 , 110 mM Na 2 HPO 4 , pH 7,4 and lysed with 0.1% Triton X100 ® . Then, proteins were denatured and precipitated with 0.1M hydrochloric acid and 50% sulfosalicylic acid, before sample centrifugation (10,000g, 15 min, 4 °C). Cell lysates were then incubated with the NDA probe for 25 min at 4 °C, before fluorescence measurement (λ ex = 485 nm; λ em = 528 nm, Varioskan ™ LUX reader, Thermo Scientific). A calibration curve was used to calculate the amount of reduced GSH in the samples. This amount was then expressed in nmol of GSH per mg of protein. To do so, protein concentration in cell lysates was determined using the bicinchoninic assay according to the manufacturer's instructions. All reagents were from Sigma.</p>
<p>Mitochondrial membrane potential was assayed in THP-1 and A549 cells using the JC-10 fluorescent probe (Sigma). Cells were seeded into 96-well culture plates at a density of 3.10 4 (A549) or 10 5 (THP-1) cells/well. PMA (10 ng/mL) was added to culture medium of THP-1 cells to induce their differentiation into macrophages. The following day, all cells were incubated with 100 µg/mL NPs for 4 h. Then, the cell culture supernatant was removed and the JC-10 probe (100 µL) was added to the cells for 1 h. Fluorescence of the samples was then measured (functional mitochondria: λ ex = 540 nm, λ em = 590 nm; non functional mitochondria: λ ex = 490 nm, λ em = 525 nm), and the ratio of fluorescence intensity at 525 nm to fluorescence intensity at 590 nm was calculated for each sample. Then, data were expressed as the percentage of fluorescence of NP-exposed cells relative to the fluorescence ratio of non-exposed control cells.</p>
<p>Neutral red (NR, Sigma) assay was used to assess lysosomal membrane integrity after exposure of THP-1 or A549 cells to NPs. Cells were seeded into 96-well culture plates at a density of 3.10 4 (A549) or 10 5 (THP-1) cells/well. PMA (10 ng/mL) was added to culture medium of THP-1 cells to induce their differentiation into macrophages. The following day, the cells were exposed to 100 µg/mL NPs for 24 h. At the end of the incubation period, culture medium was removed and cells were carefully washed with PBS. Complete culture medium containing NR (200 µL of a 100 µg/mL solution) was added to the cells for dye incorporation into intact lysosomes. After a 3-h incubation period, culture medium was removed and cells were lysed with 1% acetic acid solution containing 50% ethanol to release the incorporated dye. Absorbance of the resulting samples was read at 570 nm with a correction at 690 nm. Results were expressed as the percentage of the absorbance of treated cells relative to the absorbance of the non-exposed control cells.</p>
<p>Nine-week-old male Balb/c mice were purchased from Charles River Laboratories. They were housed in polycarbonate exhaust ventilated cages with bedding made from spruce wood chips. The animal room was maintained under controlled environmental conditions (temperature of 20 ± 2 °C, relative humidity of 50 ± 10% and 12 h/12 h light/dark cycle). Food and tap water were available ad libitum. The animals were acclimated for 1 week before the initiation of the study. Animal experiments were conducted in compliance with the European legislation (Directive 2010/63/EU). Experimental protocols were approved by the local ethics committee (CRE-MEAS) under the agreement number #4674.</p>
<p>Healthy mice received one intrapulmonary administration of NPs at increasing (10, 50 and 100 µg) or fixed (100 µg) doses and were used 24 h later. NPs were administered by intranasal instillation of 25 µL of a NP solution prepared in saline. Instillations were carried out under anaesthesia (50 mg/kg ketamine (Imalgen ® , Merial) and 3.33 mg/kg xylazine (Rompun ® , Bayer) given i.p.). Control animals received instillations of the same volume of saline alone.</p>
<p>A house dust mite (HDM) model of asthma was used as previously described [19]. Mice were divided into six groups: a group that received the vehicle alone (control group), a group that received HDM alone (HDM group), and four groups that received HDM + NP1, NP2, NP3 or NP5 (HDM + NP groups). HDM extract (Dermatophagoides pteronyssinus extract, 2 µg Der p 1/administration, GREER ® Laboratories Inc.) or vehicle was administered to mice on days 0, 7, 14 and 21 of the protocol. NPs (50 µg/administration) were administered every other day from day 0 to day 16. All animals were used on day 23. HDM extract, NPs or their vehicle were administered in the lung of mice by intranasal instillation of a saline solution (25 µL/administration) containing HDM alone, NPs alone or HDM + NP. Instillations were carried out as described above.</p>
<p>The experiment was terminated by i.p. injection of a lethal dose of ketamine (150 mg/kg) and xylazine (10 mg/ kg). Blood was drawn from mice by vena cava puncture, and collected serum was stored at -80 °C until immunoglobulin measurements. After tracheotomy, the lungs were lavaged by 6 instillations of 0.5 mL ice-cold saline supplemented with 2.6 mM EDTA (saline-EDTA). Bronchoalveolar lavage fluids (BALF) recovered from the two first instillations were centrifuged (200g for 5 min at 4 °C) and the resulting supernatant was stored at -20 °C until cytokine measurements. Cell pellets recovered from the 6 instillations were resuspended in saline-EDTA and used to determine total and differential cell numbers. After BALF collection, lungs were perfused in situ through the pulmonary artery with ice-cold PBS, collected and either frozen in liquid nitrogen and stored at -80 °C until lung homogenate preparation and assays, or fixed in 4% paraformaldehyde for histology. Lung homogenates were prepared by homogenizing frozen tissue in 2 mL of PBS containing a protease inhibitor cocktail (Complete EDTA-free tablets, Roche) using an Ultra-Turrax ® homogenizer (T25, Ika).</p>
<p>Serum levels of total and HDM-specific IgG1 were determined by ELISA. Briefly, microtiter plates were coated with an anti-mouse IgG1 antibody (0.2 µg/well in PBS, pH 7.4, BD Biosciences) or HDM extract (0.25 µg Der p 1/well in 0.1 M bicarbonate buffer, pH 9.6) and blocked with PBS containing 1% bovine serum albumin (BSA). Serums diluted in PBS containing 1% BSA were then incubated overnight at 4 °C. Next, the plates were incubated with a biotinylated anti-mouse IgG1 antibody (BD Biosciences), an extravidin-horseradish peroxydase (Sigma-Aldrich) and the horseradish peroxydase substrate tetramethylbenzidine (TMB, BD Biosciences), successively. Sample absorbance was measured at 450 nm.</p>
<p>BALFs were centrifuged (200g for 5 min at 4 °C) to pellet cells and erythrocytes were lysed by hypotonic shock. Cells were then resuspended in 500 µL ice-cold saline-EDTA and total cell counts were determined using a Neubauer's chamber. Differential cell counts were assessed on cytologic preparations obtained by cytocentrifugation (Cytospin 4, Thermo Scientific) of 200 µL of diluted BALFs (250,000 cells/mL in ice-cold saline-EDTA). Slides were stained with Microscopy Hemacolor ® (Merck) and at least 400 cells were counted for each preparation. Eosinophil, neutrophil, lymphocyte and macrophage numbers were then expressed as absolute numbers from total cell counts.</p>
<p>Cytokines were quantified in culture supernatants of THP-1 and A549 cells by ELISA (IL-8) or a Multi-Analyte ELISArray (tumor necrosis factor-α (TNF-α), IL-1β, IL-6, IL-12, IL-17A, IL-8, monocyte chemoattractant protein 1 (MCP-1), regulated on activation normal T cell expressed and secreted (RANTES), macrophage inflammatory proteins MIP-1α and MIP-1β, macrophage-derived chemokine (MDC) and eotaxin), according to instructions of the manufacturer (R&amp;D Systems for the ELISA and Qiagen for the ELISArray). Eotaxin was measured in lung homogenates of mice by ELISA, according to the manufacturer's instructions (R&amp;D Systems). In the ELISA assays, a calibration curve was used to calculate cytokine concentrations, expressed in pg/mL. In the ELISArray, absorbance values were expressed as fold change compared to the positive or negative control.</p>
<p>Fixed lungs were rinsed in PBS, dehydrated and embedded in paraffin using standard procedures. Tissue sections (5 µm) were prepared and stained with hematoxylin and eosin (H&amp;E) for morphologic assessment, and Periodic Acid-Schiff (PAS) for mucus visualization, respectively.</p>
<p>The authors thank Alexandra Bert for NP titration.</p>
<p>This work was supported by the Agence Nationale de Sécurité Sanitaire de l'alimentation, de l'environnement et du travail (ANSES -Grant number: EST-2015/1/005) and the Agence Nationale de la Recherche (ANR -Grant number: ANR-18-CE34-0005-1).</p>
<p>All data generated or analysed during this study are included in this published article and its supplementary information file.</p>
<p>The online version contains supplementary material available at https ://doi. org/10.1186/s1295 1-020-00747 -7.</p>
<p>Animal experiments were conducted in compliance with the European legislation (Directive 2010/63/EU). Experimental protocols were approved by the local ethics committee (CREMEAS) under the Agreement Number #4674.</p>
<p>Not applicable.</p>
<p>The authors declare that they have no competing interests.</p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f201868373"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:48+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The role of self-regulation in general learning has been investigated for some time now. Its significance and contribution to second language (L2) listening, however, has yet to be discussed extensively with empirical support. This article reports a case study involving four college EFL students in China over a six-month period of self-regulated learning (SRL) in developing their listening in independent settings. The study examined how the achievement and metacognitive awareness of four high-achieving and low-achieving listeners may have been affected by strategies they used for self-regulating extensive listening activities. It also examined the learners' engagement during four phases of self-regulated listening, namely, task definition, goal setting and planning, strategy enactment, and metacognitive adaptation. Findings revealed substantial differences in the two groups' metacognitive engagement in three SRL phases. The article argues that the achievements of the respective learners in listening development were affected by these differences. Pedagogical implications of a self-regulated learning approach in extensive listening for L2 listening development are discussed.</p>
<p>Listening is a critical dimension in language learning and plays an important role in second language (L2) pedagogy. The importance of listening in communication has also been well documented (Feyten, 1991;Wolvin, 2010;Wolvin &amp; Coakley, 2000). Nevertheless, many scholars agree that listening is still being overlooked in L2 learning, as greater prominence is accorded to the development of more "visible" skills such as speaking and writing, as well as reading, which is seen to be an important gateway to knowledge in academic contexts (Nation &amp; Newton, 2008;Nunan, 1997;Vandergrift 1997). Listening remains a much neglected skill and listening strategies are seen as the "Cinderella" of strategies (Vandergrift, 1997), receiving little research attention as compared to reading, writing or speaking.</p>
<p>Even when the curriculum recognizes the importance of listening, such as the current curriculum of college English in mainland China, more is needed to facilitate a principled approach to helping language learners develop their abilities. In China, listening comprehension is a compulsory module for all non-English major undergraduates. In the important College English Test Band 4 (CET4) the assessment of listening comprises 35% of the total weighting of the test (Goh &amp; Zeng, 2014). Beyond language learning and assessment, listening is also valued as an important language communication skill in the current economic landscape.</p>
<p>In spite of this, listening is the weakest skill for Chinese tertiary-level EFL learners (Jiang, 1994). Chinese students who are studying in other Englishspeaking countries also consider listening to be their greatest challenge (Liu, 2005). Given the limited classroom instruction time (an average of 2 hours per week of listening instruction for 30-32 weeks in an academic year) and an approach that mainly emphasizes exam preparation, there is a need to find other ways of helping college English learners improve their listening through independent learning outside class. Chinese EFL students have for decades practiced extensive listening on their own, but what is needed is teacher support that promotes self-regulated learning (SRL) to ensure that listening development through extensive listening practice is directed and not left to circumstances. Drawing on experiences from educational psychology and second language learning in general (Oxford, 2011;Pintrich, 2004), such a teacher-supported SRL approach to independent listening development would include principles for planning and implementing learner-oriented SRL activities in independent settings. It underscores the critical role of metacognition in the learning process and provides learners with essential metacognitive tools for self-regulated learning beyond the listening classroom (Vandergrift &amp; Goh, 2012).</p>
<p>To understand the effectiveness of an SRL approach, we conducted a comparative case study of two high-proficiency listeners and two low-proficiency listeners who experienced a six-month independent listening program after class by engaging in SRL activities and materials prepared specially to support their independent learning.</p>
<p>Learner strategies refer to deliberate procedures used by learners to enhance comprehension, learning and retention of the target language (Chamot, 1995;Cohen, 1998). In L2 listening, learners use appropriate strategies to achieve comprehension goals, particularly when they have limited ability to understand the oral texts (Gu, Hu, &amp; Zhang, 2009;Vandergrift, 2008). Strategies help learners improve comprehension, retention, and recall of information; and, at the same time, they assist them in planning for overall listening development as part of their language learning effort (Vandergrift &amp; Goh, 2012).</p>
<p>Recent research shows that successful L2 listening involves careful orchestration or clustering of both metacognitive and cognitive strategies (Graham &amp; Macaro, 2008;Vandergrift, 2003b). In addition, Vandergrift and Goh (2012) contend that listeners with heightened metacognitive awareness are able to orchestrate the enactment of various strategies according to task and learner variables. General listening strategies can also be examined in terms of tactics or individual techniques through which each strategy is operationalized (Goh, 2002), and this can offer greater clarity about hierarchic relationships among strategies (Oxford &amp; Cohen, 1992).</p>
<p>Despite early debates about whether strategy instruction is useful for listening (Field, 2000;Ridgway, 2000), possible resistance from learners (Huang, 2006) and other challenges, researchers have argued that learners can benefit from learning to use listening strategies to compensate for incomplete understanding, missed linguistic or schematic input, misidentified clues and other listening limitations (Flowerdew &amp; Miller, 2005;Rubin, 1994;Vandergrift, 2003a). The consistent use of metacognitive strategies, in particular, is a feature of high achieving L2 listeners (Goh, 1998) and can contribute to improving learners' L2 listening comprehension (Vandergrift, 2004). One form of L2 listening pedagogy integrates listening tasks with teacher-directed strategy use by learners (Vandergrift &amp; Goh, 2012).</p>
<p>Vandergrift (Vandergrift, 2004;Vandergrift &amp; Tafaghodtari, 2010) proposed a metacognitive cycle to help learners integrate the use of strategies while listening and guide listeners in the acquisition of implicit knowledge about listening processes. Besides developing metacognitive awareness about L2 listening, this cycle also develops L2 perception skills and word recognition skills, as recommended by Graham (2006). Vandergrift (2007) argues that this metacognitive listening cycle has strong theoretical support as it closely parallels the research demonstrating implicit learning through task performance. Further empirical support is found in a number of studies applying this metacognitive cycle in listening classes (Cross, 2011;Liu &amp; Goh, 2006;Vandergrift &amp; Tafaghodtari, 2010).</p>
<p>While the metacognitive listening cycle develops strategic processes during listening comprehension, it is essentially a classroom pedagogy. Learners also need to have support in using strategies to strengthen activities for developing listening beyond the classroom, in particular, in raising their metacognitive awareness of how to self-direct and manage their efforts (Goh, 2008). This calls for an approach to supporting L2 learners' extensive listening endeavors which enable them to self-regulate their learning process with the help and guidance of the teacher, thereby taking greater ownership of their listening development in an informed manner.</p>
<p>Self-regulated learning (SRL) is a complex process by which learners personally activate and sustain cognition, affect and behavior that are systematically oriented toward the attainment of learning goals (Efklides, 2009;Schunk, 2008). Our study adopts the definition of SRL by Pintrich (2000) as "an active, constructive process whereby learners set goals for their learning and then attempt to monitor, regulate, and control their cognition, motivation, and behavior, guided and constrained by their goals and the contextual features in the environment" (p. 453). The concept of self-regulated L2 learning strategies was first put forward by Oxford (2011Oxford ( , 2017) ) in her S 2 R model. This framework examines closely the theoretical underpinnings of self-regulation in L2 learning and applies selfregulation for understanding development in each of the L2 skill areas, including listening. Participants in our study were responsible for taking charge of their overall listening development and initiating extensive listening tasks in independent settings. We follow Winne and Hadwin (1998) in characterizing selfregulated learners as learners who are actively and efficiently managing their own learning through monitoring and strategy use. Their mode of SRL model emphasizes the importance of metacognition, which is an important construct for the process of learning to listen in an L2 (Goh, 2008;Vandergrift &amp; Goh, 2012;Vandergrift &amp; Tafaghodtari, 2010). Metacognition is defined as cognition about cognition and involves monitoring and control functions (Dinsmore, Alexander, &amp; Loughlin, 2008;Flavell, 1979;Schunk, 2008). Research has shown that metacognition interacts with motivation and affect, and these interactions have important implications for SRL (Efklides, 2009). Winne and Hadwin's (1998) SRL model presents SRL as a more global and inclusive construct which subsumes metacognitive knowledge and strategy use (Pintrich, 2000;Winne &amp; Hadwin, 2008). It describes the specific cognitive processes that entail a learner's self-regulation through four basic phases that are considered to be recursive in nature: task definition, goal setting and planning, strategy enactment, and metacognitive adaptation (Greene &amp; Azevedo, 2007). This model enables the forging of linkages between learners' metacognitive knowledge system and their self-regulatory behaviors in EFL listening development. To our knowledge, this L2 study, which adopts a self-regulatory learning theoretical framework in order to understand the efficacy of learning strategies, is the first of its kind for extensive listening.</p>
<p>Listening is often perceived to be the weakest language skill among Chinese tertiary-level EFL learners at the lower or intermediate proficiency levels (Wang, 2002;Wu, Liu, &amp; Jeffrey, 1993). In spite of this, many Chinese learners receive a limited amount of in-class listening instruction per week, with lessons focusing heavily on checking the answers to pre-set comprehension questions. In similar kinds of listening classes, the process of helping students learn to listen was often overlooked (Mendelsohn &amp; Rubin, 1995;Vandergrift, 2004). A great number of students passively relied on classroom listening instruction and may not have realized that they themselves should take charge of their listening development (Goh &amp; Taib, 2006;Vandergrift, 2003b;Wang, 2002). It was also not unusual for some students to give up on their listening because they felt they had caught very little of what was said (Goh, 2000). With the availability of technology-enabled resources, it is important that teachers consider ways of supporting learners in their extensive listening efforts so that they can learn how to manage their learning and benefit from the authentic resources made available through their mobile devices. To this end, an SRL approach merits consideration, as self-regulated listening activities not only increase learners' exposure to authentic oral texts but also enhance their metacognitive knowledge and self-regulatory abilities for listening success (Berne, 2004;Mendelsohn, 2006).</p>
<p>An SRL approach that emphasizes the role of metacognition and learning strategies is adopted in this study to help Chinese EFL learners plan and carry out extensive listening activities beyond their classrooms. The study aimed to understand how such an SRL approach to extensive listening practice could benefit language learners and whether the gains that learners derive from an SRL program might be affected by their level of engagement during the program. This study is also an example of a study that heeds Hu's (2016) call to strategy researchers to conduct strategy research that is emancipatory where learners' participation can assist them in acquiring new knowledge and developing greater awareness of themselves so that their learning endeavors can be guided by these new understandings.</p>
<p>This study was undertaken to answer the following research questions:</p>
<p>1. Do learners engaged in a SRL approach to extensive listening benefit differently in terms of listening development and metacognitive awareness of the listening process? 2. What are the self-regulatory behaviors of high-and low-achieving listeners at the four self-regulated learning phases of task definition, goal setting and planning, strategy enactment and metacognitive adaptation? What similarities and differences are there between the two groups of learners? 3. To what extent can the self-regulatory behaviors of the two groups of learners account for the differences in the benefits they derived from the SRL program?</p>
<p>6. Method</p>
<p>Four participants (three females and one male) with an average age of 19 were selected from one intact class. They had been learning English for an average of seven years, beginning from secondary school education. Of these an average of six years included practicing L2 listening. Results from listening tests and participants' self-reports confirmed that their listening ability remained the weakest of the four language skills. For the purpose of comparison, the four participants were placed into two groups according to their achievements in two tests: The National Entrance Examination (English paper) and a mid-term listening test (Table 1). Two top performers in both tests in the class (N = 30; 90th percentile) were designated as high achieving (HA1 and HA2) while two participants in the 20th percentile were designated as the low achieving group (LA1 and LA2). These groupings served to provide some comparison among the learners according to their listening performance. This study adopted the Metacognitive Awareness Listening Questionnaire (MALQ; Vandergrift, Goh, Mareschal, &amp; Tafaghodtari, 2006) as an instrument to assess the learners' metacognitive awareness and perceived use of strategies while listening to oral texts. The MALQ is a 21-item questionnaire comprising items from five factors related to L2 listening comprehension processes: problem-solving, planning and evaluation, mental translation, directed attention and person knowledge. It was used without any adaptions or translations in the present study because the items were written in simple English that the Chinese college EFL learners could understand.</p>
<p>The Self-regulated Learning Portfolio (SRLP) consisted of a set of templates for the participants to record their listening activities and track their progress in both metacognition and listening performance. Part I consisted of a weekly listening plan for the learners to record their plans for listening tasks as well as their monitoring and evaluation of the completion of these tasks. It also recorded time spent on each task and how many times learners listened to each text. Part II was a self-directing listening guide which helped learners to plan how to approach the task, monitor their comprehension during the task and evaluate their efforts after it. Part III was a form for a weekly listening diary where the learners wrote their reflections on their weekly listening activities in and outside the classroom and their description of strategy use. A listening strategy inventory comprising various metacognitive and cognitive strategies was also included for their reference. It functioned as a learning tool, familiarizing students with listening strategies and helping them to expand their strategy repertoire and promote more effective strategy use (Macaro, Graham, &amp; Vanderplank, 2007;Vandergrift, 2003aVandergrift, , 2003b)).</p>
<p>At the end of the SRL program, the participants completed a reflection form which was aimed to evaluate what they had gained from the SRL program and the challenges they had faced. This was done in Chinese to facilitate the learners' expression of any complex thoughts that they might have difficulty expressing in English.</p>
<p>Individual and group interviews were conducted in Chinese to obtain detailed information on the participants' evolving metacognitive awareness, strategy use, and self-regulatory skills in listening. Individual interviews were conducted before the learners began the SRL program when they had completed the MALQ questionnaire. A group interview was also conducted in Chinese with the four participants at the end of the SRL program. The purpose of this interview was to supplement data from the students' value reflection forms and to allow the researchers to explore specific issues that arose during the conversation and which might not have been included in the written reflections.</p>
<p>Scores of two large-scale listening tests (a university-based mid-term listening test and a national CET4 listening test) were used to assess the participants' progress in listening performance after the SRL program. A comparison of the participants' results in these two tests (overall score and listening score) was used as an indicator of the participants' improvement in listening performance.</p>
<p>Data collection was completed in the following ways:</p>
<p>1. Collection of participants' test results for the two listening tests (midterm and CET4), responses to the MALQ and individual and group interviews were conducted at different points of the study. The interviews in Chinese were recorded, transcribed and translated.</p>
<p>2. Completed SRLP documents were submitted via email to one of the authors, who provided answers and feedback to the questions and comments in the SRLP through online text chatting and email. At the end of the SRL program, the participants took part in a specially arranged session, in which they wrote individual value reflections and completed a second response to the MALQ. After that they participated in a group interview led by one of the researchers. 3. Comments from the participants' listening teacher were obtained to provide qualitative evaluation on the performance of the four participants.</p>
<p>To address the second and third research questions, data were collected mainly through verbal reports and interviews. Retrospective verbal reports written in Chinese were translated independently and cross-checked against the translation of another translator for consistency. Coding was done in two stages. In Stage one, one of the authors and a colleague coded a set of transcripts from one participant independently according to a preliminary coding scheme that was based on previous studies on educational objectives (Anderson et al., 2001;Krathwohl, 2002) and listening strategies (i.e., Goh, 2002;Gu, Hu, &amp; Zhang, 2009;O'Malley, Chamot, &amp; Kupper, 1989;Vandergrift, 2003b). Informal calibration discussions were held to resolve inconsistencies and disagreements before the coding scheme was finalized. In Stage two, the data was divided into two sets and coded independently according to the coding scheme. The transcripts were then double-coded by the two coders with inter-coder reliability improving from .69 to over .84 after the two stages.</p>
<p>Table 2 shows the four participants' listening performance on the pre-and posttest. While HAs improved by almost 20 marks on a 100-mark test paper, LAs improved by only 9 marks. Furthermore, scores of HAs improved from 2-7% (pretest) to 14-16% (posttest) above the class mean score in the CET4 listening test, showing that they achieved greater progress in their listening performance. Scores of LAs on the other hand dropped from 7-8% to 10-12% below the class mean score after six months of participation in the SRL program. With respect to the changing level of metacognitive knowledge in listening, although all four participants benefitted from the SRL approach, HAs' response scores showed an overall 80% increase compared with the LAs in the five metacognitive factors in the MALQ framework, as indicated in Table 3. The results showed that HAs manifested greater progress than LAs in terms of listening performance. Although it is not possible to establish a clear causal effect of the SRL program, the data from the SRLP, reflections, evaluations and interviews strongly suggest that HAs were more engaged in their listening practice and development through self-regulated extensive listening. This would have contributed to their listening development compared with Las, who were less engaged (see sections to follow on three other phases of SRL). This result is different from classroom-based studies where metacognitive instruction utilizing a pedagogical cycle was found to benefit less-skilled listeners more in their listening development (Cross, 2011;Vandergrift &amp; Tafaghodtari, 2010). This could be argued to be due to learners' self-regulated learning contexts where there was limited teacher input during the listening tasks, unlike previous classroom-based studies (see e.g., Vandergrift &amp; Tafaghodtari, 2010).</p>
<p>Results also revealed much higher overall improvement in five metacognitive factors for HAs, lending further support to previous studies demonstrating the positive outcomes of different kinds of metacognitive interventions for L2 listening development (Goh &amp; Taib, 2006;Goh &amp; Zeng, 2014;Graham &amp; Macaro, 2008;Mareschal, 2007;Vandergrift &amp; Tafaghodtari, 2010;Zeng, 2007). Moreover, HAs showed much stronger metacognitive awareness than LAs in factors such as planning/evaluation, directed attention and problem-solving. The increase in reported use of these three strategies reflect HAs' stronger self-regulatory skills in listening: planning, evaluating, managing attention for better comprehension and applying strategies to infer and to monitor these inferences (Kintsch, 1998;Vandergrift, 2003a). As skilled and effective listeners are generally found to frequently employ these strategies while listening, it could be argued that good control of planning/evaluation, attention-managing and problem-solving strategies signals a great step for learners to becoming self-regulated and autonomous listeners. As indicated by their responses on personal knowledge, HAs were also more confident and less anxious compared to LAs in English listening after the self-regulated learning program. Similarly, their lower mean scores for mental translation indicate that they were refraining from using mental translation strategies.</p>
<p>The four SRL phases for listening development in independent settings are task definition, goal setting and planning, strategy and tactic enactment and metacognitive adaptation. Results of the HAs-LAs comparisons in these four phases are first presented in Table 4, and these will then be discussed and further illustrated with excerpts from the learners' reflections. These behaviors are analyzed and presented in terms of the learners' understanding of their general listening development and the specific listening tasks that they engaged in during their weekly listening.</p>
<p>Task definition refers to an understanding of what a task is. All four participants largely shared a common understanding of what the general task of developing listening and specific listening tasks entail. They regarded listening in English as a real challenge and felt that listening was more difficult than other three macro-skills of English. This is indicative of learners' lack of confidence and levels of anxiety, both of which can result in an inability to apply metacognitive knowledge while listening in particular (Vandergrift et al., 2006). HAs, nevertheless, reported that they did not feel nervous when listening to English, which might have resulted from their increased exposure to English listening materials through the SRL program.</p>
<p>Results indicated that definition of specific listening tasks was generally determined by a learner's understanding of the nature of listening and the task type concerning selected listening materials. An example of such perceptions was the belief that "the dictation task is far more difficult than a MCQ task" (LA1). This reflected the participants' understanding of task demands or the difficulty level of different task types.</p>
<p>The HAs and LAs differed considerably in goal setting and planning in their overall listening development or when approaching specific listening tasks (Table 5 andTable 6). LAs expressed explicitly the strong desire to get appropriate grades to pass the national CET4 test. In contrast, although passing CET4 was also mentioned by the HAs, they were more focused on deep understanding of tasks, mastering skills, and selfimprovement. In line with their distinct goal-orientations, the learners planned their listening development in quite different manners, and the implementation of listening plans also varied considerably. As shown in Table 5, while LAs spent only 34 minutes per week on learning to listen, HAs invested almost four times more in this effort (123 minutes). Likewise, for each listening task, HAs tended to listen to it about four times. HA1 even reported that for a difficult listening task the text was repeated seven times. In contrast, LAs listened to it only two times, regardless of the difficulty level of the tasks. Such a considerable difference in planning for and implementation of listening plans between the high-and low-achievers was consistent with their differing goal-orientations. HAs benefitted more from the SRL approach as they were prepared to invest more and they also adhered more faithfully to their learning plans. Group interview data also revealed that LAs' much poorer investment in listening could have been caused by their relatively lower level of confidence, as they were weaker in their listening to start with (Goh &amp; Zeng, 2014). As in the excerpt below, LA1 had clearly prioritized the learning of other skills as a result of this.</p>
<p>Excerpt 1</p>
<p>Such significantly different degrees of investment in listening either in overall time spent (frequency) or in repeated listening (repetition) would have contributed to HAs' higher scores (30%) on the CET4 listening test (Vandergrift &amp; Goh, 2012).</p>
<p>HAs and LAs also differed considerably in implementing action plans while carrying out specific listening tasks. Listening is a goal-directed strategic behavior and a purposeful process, in which the listening purpose drives the comprehension process (Goh, 2002;Goh &amp; Zeng, 2014;Rost, 2005). Different listening purposes would therefore affect the comprehension process, as the analysis of the SRLP protocols concerning the multidimensionality of listeners' purposes for specific recordings revealed. Following Pintrich (2001), these dimensions are behavioral, cognitive, and metacognitive.</p>
<p>As can be seen in Table 6, the two low achievers tended to set more behavioral and cognitive goals for specific listening tasks, while the two high achievers clearly perceived more demanding cognitive purposes and metacognitive purposes of listening. For LAs with a performance-oriented approach, finishing the assignments seemed to be their top priority, either because they were required to do so or they did not want to be considered inferior in the class. They also listened to English songs or movie clips for relaxation and entertainment, indicating their preference for less demanding listening tasks. In contrast, the two high achievers explicitly pointed out they were trying to cultivate a good learning habit through regular listening training. Although they also listened to English songs and watched English movies in their spare time, they reported to have chosen more demanding listening materials for intensive listening from their textbooks and original CET4 listening test papers, demonstrating their mastery-orientation.</p>
<p>It is possible that these two stronger listeners felt they had the ability to manage these more demanding listening tasks and were setting up challenges for themselves while the less able listeners preferred to choose easier ways of practicing their listening. While this seems like a logical thing to do, it is also possible that the two LAs had missed out on opportunities to develop their listening further. This factor combined with a lower frequency of practice and fewer repetitions of listening would have contributed to their slower progress.</p>
<p>In addition, LAs' cognitive learning purposes were limited to knowing and understanding, with knowing or remembering taking up the highest percentage of occurrence. In contrast, HAs not only set goals for more exposure to aural input and deeper understanding and comprehension of gist and details, but they also tried to apply their linguistic knowledge and what they got from the oral texts to improve their dictation skills. Dictation takes up a little less than 30% of the CET4 listening test and is also the weakest listening skill for Chinese EFL listeners (Jin, 2005). HAs' resolution to overcome this listening difficulty and more self-initiated investment in dictation exercises were evidence of their much higher cognitive goals in listening.</p>
<p>The strategy enactment pattern of high achievers showed considerable differences from that of low achievers either in the frequency of strategy use or in the way specific cognitive or metacognitive tactics operationalize strategies used (Table 4). It should be noted that the reported use of listening tactics and strategies based on participants' retrospection for each listening task was not necessary in tandem with the actual use in listening learning and the 44 listening tactics included in our checklists were illustrative and not exhaustive. Furthermore, due to the limited sample size (n = 4), no statistical measures were adopted here to determine the significance level of strategy deployment. Instead, the occurrences of cognitive and metacognitive strategy use for each participant were counted and ranked accordingly.</p>
<p>Research in both learner strategy for language learning and L2 listening highlighted the significance of strategy development for listening success and L2 acquisition (Goh &amp; Zeng, 2014;Vandergrift, 2003b;Wenden, 2002). The fact that six cognitive tactics and eight metacognitive tactics were jointly used by all participants was strong evidence of the similarity and convergence of Chinese EFL listeners' strategy use preference in approaching listening tasks or developing listening proficiency. In line with what has been reported by Goh (2002), the four participants reported an average 64% of use of inferencing strategy, using contextual clues and familiar content words or drawing on knowledge of the world to help them bridge gaps in their understanding, which stressed the key role that prior knowledge played in learner comprehension. As such, these listening tactics can be prioritized and highlighted in strategy instruction in listening classes to promote learners' higher level of awareness and future use. Furthermore, all participants reported they had never used the strategy of noticing how information is structured, for example, the presence of discourse markers. This finding has strong implications for listening pedagogy in China. Specifically, familiarizing Chinese EFL learners with various genre types and corresponding meta-discourse markers and rhetorical devices assumed greater importance in teaching listening. Thus, genre-based teaching intended to promote listening discourse comprehension should thereby be prioritized in listening classes. However, we found a marked difference in cognitive strategy enactment as reflected by the frequency/occurrence of participants' perceived strategy use. First, HAs used four cognitive strategies, up to one third more often than LAs. This might help explain HAs' higher level of strategy awareness and stronger ability in deep level processing and tackling listening comprehension problems.</p>
<p>Second, HAs reported relying heavily on the visualization strategy of mentally displaying the shape or spelling of key words while listening, which was only occasionally used by LAs. Chinese EFL learners frequently mentioned the importance of the size of their vocabulary in relation to their learning, as observed by Zhang (2010). Hence, the considerable difference identified here might have been caused by learners' varied vocabulary size in general and word recognition or spelling abilities in particular.</p>
<p>Third, the finding that the strategy occurrence of mental translation for HAs was almost 30% lower than that of LAs might indicate HAs' much improved awareness of the detrimental effect of this strategy and fruitful efforts in restricting its use while listening. Or it might have resulted from their greater level of automaticity in processing lexical chunks. The finding is consistent with L2 listening literature (e.g., Vandergrift et al., 2006).</p>
<p>Finally, the high-and low-achievers differed in operationalizing the fixation strategy, which involves focusing attention on understanding a small part of a text. Compared to Las, who frequently tried to memorize/repeat the sounds of unfamiliar words, HAs were more engaged with memorizing words or phrases for later processing, indicating their stronger ability in matching the sound of words with their forms as well as engagement in deep level processing to construct meaning during listening (Field, 2008).</p>
<p>Similarly, there were also more differences between HAs and LAs in how the metacognitive tactics were enacted. First, the frequency disparity of metacognitive strategy use between HAs and LAs was even greater compared to that of their cognitive strategy use. The much higher frequency of metacognitive strategy use for HAs was in line with L2 listening literature claiming that skilled listeners revealed using about twice as many metacognitive strategies as their less-skilled counterparts, primarily in comprehension monitoring (Goh, 2002;Vandergrift &amp; Goh, 2012). It also helped explain HAs' stronger ability to self-regulate their listening learning as well as their greater degree of progress in listening performance in the SRL case study.</p>
<p>Second, HAs reported 42% more use of pre-listening preparation strategies such as previewing contents, which underscored the key role that preparation strategies played in listening success (Goh, 2002;Rost, 2005). The three preplanning preparation tactics not only covered learners' mental and emotional preparation to reduce anxiety and enhance confidence but also included actions to pre-process the content semantically and phonologically. In this sense, HAs were far better prepared mentally and emotionally for achieving success in listening tasks as compared to LAs.</p>
<p>Third, the much higher level of strategy use in directed attention and selective attention suggests that HAs tended to monitor attention and avoid distractions by concentrating hard and continuing to listen in spite of difficulty. Moreover, HAs managed to pay particular attention to familiar content words and listen for gist to secure satisfactory comprehension. Such strategy use disparity between HAs and LAs in both attention strategies is consistent with L2 listening research (Goh, 2002;Rost, 2002;Vandergrift et al., 2006) claiming that attention strategies are mainly adopted by higher ability listeners and are believed to be essential for second language listening success.</p>
<p>Fourth, while HAs frequently tried to notice intonation features to help them in comprehension, LAs seldom did so. Specifically, HAs were found to have paid particular attention to pronunciation and intonation for better oral English through reading-aloud in the mornings and active participation in after-class English activities.</p>
<p>Lastly, while HAs tended to use another two types of selective attention strategies, which were to listen to specific parts of the input and to pay attention to visuals and body language for video texts, LAs reported never using these tactics. Listening has been proven highly demanding and very much memory consuming for Chinese EFL listeners (Wang, 2002). Thus, it is especially important that LAs learn to focus on specific parts of input and discard irrelevant or less important information to achieve satisfactory understanding. In the same vein, it is also important that they are able to capitalize on visuals and body language to compensate for their limited knowledge of the target language for better comprehension of video texts or in face-to-face communications with native speakers.</p>
<p>High-achieving listeners engaged in varied and more sophisticated metacognitive adaptation, either for immediate change or for long-term listening development, compared to Las, who appeared to have restricted themselves to simple and limited forms of immediate and long-term metacognitive adaptations, as indicated in Table 7.</p>
<p>L2 listening research has well attested to the benefits and significance of evaluation after listening (Goh &amp; Zeng, 2014;Rost, 2002;Vandergrift et al., 2006). As reported, the four participants showed marked difference in making long-term metacognitive adaptation for listening development. Although both high-and low-achievers tended to make metacognitive changes to reduce anxiety, regulate attention, and take down more notes to compensate for the limited working memory, HAs also reported having engaged in other essential metacognitive adaptations for long-term listening development, which were not reported by LAs. • Need to consult the dictionary to get to know some words and expressions involved in such games (HA1).</p>
<p>• Take down those unclear parts and then consult the dictionary afterwards to make clear their pronunciations (HA1).</p>
<p>• Could listen according to scripts and try to find some patterns (HA2).</p>
<p>• Scripts are helpful for repeated listening (LA2).</p>
<p>Long-term metacognitive adaptation for listening development</p>
<p>• Often neglect to use these strategies while listening and I should learn to use these strategies more (HA1).</p>
<p>• Calm down and do not be anxious if I can't catch the listening (HA1). • Try to reduce listening anxiety (HA2).</p>
<p>• Try to relax while listening (LA2). • Should prepare well before listening (LA1).</p>
<p>Reduce anxiety</p>
<p>• Very important to focus attention while listening (HA1). • Understand more when I stay focused (HA2).</p>
<p>• Should focus more as I often get distracted (LA1). • Just can't concentrate on the task (LA2).</p>
<p>• Very important to predict the content based on the title (HA1). • Guess according to common sense knowledge (HA1). • Quite important to predict before listening (HA2). • Sometimes the content could be predicted through test item choices (HA1). • Predict using the test items (HA1).</p>
<p>• Try to train ability to preview the test items quickly (HA1).</p>
<p>• Impossible to catch every sentence so key points are important (HA1). • Impossible to understand every part even if I want to (HA2). • Should focus on key points (HA1).</p>
<p>• Try to catch sensitive and key details while listening (HA2).</p>
<p>• For the inferential test items, I need to grasp the main theme and key sentences (HA1). • Pay attention to some questions related to the theme and pay attention to several sentences in the beginning of the text (HA1). • Learn to catch the main theme of the text (HA1). • Learn to catch key sentences to improve accuracy (HA2). • Should take down more notes in case I forget what I've heard (HA1).</p>
<p>• Taking down more notes as it is helpful (LA2).</p>
<p>• Train my dictation ability consciously after class (HA1).</p>
<p>• Should learn to link what I hear to related questions while listening (HA2).</p>
<p>Note. N.A. = means not available from the data Results showed that HAs possessed stronger strategic awareness in listening and they decided to learn and use more strategies in listening tasks. This is supported in one of HAs' SRLP protocol, as indicated in Excerpt 2. In addition, HAs were more aware of the value of prediction for listening success and tended to preview test items to get themselves better prepared before listening. Given the limited working memory and weak word recognition skills of Chinese EFL listeners (Zheng &amp; Li, 2002), effective prediction and previewing test items or questions before listening, which is what HAs did in our study, seemed to have contributed the lion's share of learners' listening success.</p>
<p>Furthermore, HAs stressed the importance of the theme and key points of the oral texts. Unlike LAs, HAs would "pay attention to some questions related to the theme and pay attention to several sentences in the beginning of the text," as one high achiever put it. Therefore, the ability to grasp the theme and key points to guarantee overall comprehension and to solve inferential questions or test items appeared to well distinguish HAs from LAs.</p>
<p>Finally, HAs reported having made another two metacognitive adaptations for listening development, which were not found in LAs' listening protocols. One was to train the dictation ability and the other was to develop association skills. First, improving dictation ability directly addressed the urgent need to pass CET4 listening test, where dictation takes up almost 30% of the total listening score. Second, active association across the comprehension process to link what has been heard to questions demonstrated HAs' dynamic assessment of their level of comprehension. It appears that LAs have much to learn from HAs in applying these two metacognitive adaptations to enhance their listening ability.</p>
<p>This study adopted a self-regulated learning (SRL) approach for developing L2 listening in independent settings. It helped to extend the current classroombased, process-oriented discussions of L2 listening instruction into one that focuses on learner-oriented, self-regulated learning activities. It also provides evidence for the validity of transferring the theoretical construct of self-regulated learning to the area of second language acquisition, as first proposed by Oxford (1999) and explicated in Oxford (2011Oxford ( , 2017)). This concept was further emphasized by Dörnyei and associates (Dörnyei &amp; Skehan, 2003;Hornstra, van der Veen, Peetsma, &amp; Volman, 2013;Tseng, Dörnyei, &amp; Schmitt, 2006). At the same time, by adopting a metacognition-inclusive SRL framework, we were able to examine the use of strategies and how they can benefit language learners in self-directed listening activities.</p>
<p>As argued by Vandergrift and Goh (2012), strategy instruction during class time and listening practice after class need not be mutually exclusive. We demonstrated that listening teachers in China could use carefully designed metacognitive tools to help learners plan and prepare well for listening tasks, check and monitor comprehension, and evaluate strategic efforts in listening process in independent settings.</p>
<p>Finally, our study took the research on skilled listeners further by identifying distinct and differing developmental paths of self-regulatory skills in L2 listening for learners with different achievement levels. This research evidence was especially helpful for less skilled listeners to reflect on their poor performance in specific self-regulated learning phases. Listening teachers can also capitalize on the limited listening class time to offer individualized instruction for low achievers. As such, it was expected that low achievers' self-regulatory skills in listening could be greatly enhanced along the way for them to become skilled listeners.</p>
<p>Our study was limited in its scope as the proposed SRL approach focused primarily on examining listening as an individual cognitive entity and the developmental paths of learners with different achievement levels. Future research on self-regulation in SRL in L2 listening should include an examination of the affective and social aspects of the skill. In addition, research is needed in which both the constructive nature of learning and the important role that L2 learners play in the social process of learning to listen could be equally emphasized. How teacher scaffolding or support can be integrated into the SRL approach, as well as how their on-going interaction with learners in an SRL program can help learners achieve more progress in listening also merits further research.</p>
<p>Furthermore, research that would contribute to fuller understanding of metacognition and self-regulated learning in L2 listening both within and beyond the classroom is warranted. Whether different listening task types exert a differential influence on learner's growth in metacognition and listening performance also appears to be an area requiring further research. Additional research is also needed to combine others' ratings (such as teachers' and peers') and self-ratings to produce comprehensive assessment of listeners' metacognition and self-regulated learning. Lastly, it should also be cautioned that the interpretation and discussion are based on feedback from two cases (two high achievers vs. two low achievers) only. Therefore, the generalizability of the findings is very much limited to the context where the case study was carried out.</p>
<p>In spite of this, the study can offer some practical insights for consideration. Firstly, L2 listening development outside class can benefit from a teachersupported self-regulated learning approach. Instead of asking students to just "listen more," teachers can provide tools to support their learning endeavors. These tools, such as the SRLP, can help learners articulate their plans and chart their progress. More able listeners may be more motivated to adopt such an approach, and the weaker ones who want to master their listening would also be likely to invest more time and effort in it. Although this study showed that it was the higher-achieving students who benefitted more and were more engaged, teachers should not exclude weaker listeners from a teacher-supported self-regulated approach. They could use the two cases in this study to illustrate the importance of taking charge of one's listening development by engaging in and being committed to self-regulated learning beyond the classroom. Learners who are mainly motivated to pass examinations, however, may not fully appreciate the rationale for such an approach, as they may see it as taking away time from other language learning activities. Teachers would therefore need to decide for themselves whether or not it is necessary to complement their classroom instruction with such extensive listening activities. More importantly, they would need to be convinced themselves that their learners can benefit from such an approach, as this study has shown, and motivate their learners to invest time and effort in this form of extensive listening that can bring about longer term benefits in listening development.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f429255948"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:31+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Predictive Soil Mapping (PSM) aims to produce the most accurate and most objective predictions of soil variables either for bulk estimates or for specific soil depths. PSM, a sub-field of Applied Predictive Modeling 1 , can be considered to be an interdisciplinary field incorporating statistics, soil science and Machine Learning 2-5 .</p>
<p>• Harmonization of training points (merge from multiple datasets) revealed problems with incomplete meta- data which made the data less reliable. Predictions of extractable phosphorous (see Fig. 5 in Hengl et al. 17 ), for example, were shown to over-estimate values at multiple locations. Such systematic oscillations usually arise due to incorrect use of measurements units or errors in importing the soil sample data. • During this earlier predictive soil mapping exercise, spatial clustering of points (i.e. over-representation of specific soil types and landscape positions)</p>
<p>were not yet accounted for in the methodology 19 . This possibly introduced a bias in the earlier 250 m scale predictions. • Predictions were based on the use of relatively coarse resolution covariates only, with limited up-to-date Earth Observation imagery available at that time to help map nutrient content.</p>
<p>We recently re-examined these problems and concluded that a complete redesign and re-implementation of the entire PSM process was required, beginning from point data import and harmonization, into modeling and spatial cross-validation methodologies. Our main hypothesis was that the accuracy of the previous predictions could be much improved if we:</p>
<p>1. Utilize an improved predictive mapping framework: spatially-adjusted Ensemble Machine Learning, that better accounts for spatial clustering of points; 2. Invest more effort into fine-tuning the Machine Learning algorithms: especially to account for spatial clustering of points, and more efficiently subset features of interest; 3. Include in the prediction process new, state-of-the-art, Earth Observation data: especially Sentinel-2 imagery which is available for the entire continent at fine spatial resolutions (10-30 m); 4. Include per pixel error predictions i.e. to quantify prediction uncertainty per pixel.</p>
<p>In addition to redoing the spatial analysis of soil nutrients, we also decided to extend the original list of target soil nutrients 17 to include soil chemical (pH, eCEC) and physical (bulk density, clay, sand and silt fractions) properties, so that we can produce a more holistic representation of soils.</p>
<p>We present here results of modeling and predicting soil variables for the entire African continent. These are now made available at relatively detailed spatial resolution (30 m), with prediction uncertainty estimates included per pixel. We focus here on the main results and discoveries that could potentially impact any similar continental or global scale soil mapping projects, and then provide detailed explanation of steps followed.</p>
<p>Engine and subsequent correlation analysis with Sentinel-2 percentiles (for the period 2016-2019), Landsat-8 percentiles (for the period 2013-2019) revealed that there was indeed potential, especially for Sentinel-2 products, to use Earth Observation (EO) data to increase the accuracy of mapping of soil properties and nutrients in Africa. These results clearly indicate predictive potential with the most correlated soil/environmental parameters being soil pH (Sentinel-2 B04, B12, B9), soil organic carbon (Sentinel-2 B04, B05, B11, B12) and clay content determined by laser diffraction method (Sentinel-2 B11, B12, B8A) with respective best R-square based on spatial tenfold cross-validation at 0.38, 0.32 and 0.26 (Fig. 1). For Mehlich3 extractable nutrients and micronutrients, Sentinel-2 and Landsat-8 products commonly explained &lt; 25 % of observed variation, but were still significant. In the case of Sentinel-1 products (HH, HV, HH/HV), detectable correlation with soil nutrients, apart from pH and soil organic carbon, was considerably lower to non-existent (Fig. 1). For practical reasons, we ultimately decided to focus on using existing Landsat products 20 and the Sentinel-2 bands B02 (Blue), B04 (Red), B8A (Narrow NIR), B09 (Water vapour), B11 (SWIR1) and B12 (SWIR2) as the major new environmental covariates, while the Sentinel-1 products were not utilized to produce final predictions.</p>
<p>The combined variable importance plots derived using Random Forest with all 250 m and 30 m covariates used together (Fig. 2) reveal that, on average, climatic images such as SM2RAIN monthly rainfall estimates and CHELSA bioclimatic images (3, 7, 4), are the most important covariates to inform mapping of soil properties and nutrients in Africa. This result is consistent with our previous global results 21 , where soil chemical properties were primarily correlated with climate images, and soil physical properties with a combination of landform parameters, parent material and climatic images. At 30 m resolution, however, Sentinel-2 B11, B09 and B12, DTM vertical depth and Landsat SWIR1 are overall the most important for mapping soil properties and nutrients. Although these covariates appear lower on the full list of the most important variables than climatic images, this is an important discovery and clearly indicates that Sentinel and Landsat seasonal and/or long-term composites merit utilization as covariates for this current, and future, predictive soil mapping campaigns.</p>
<p>When the importance measures for all variables are ordered based on the mean relative importance (absolute variable importance divided by the highest variable importance), the results show that overall the most important variables for mapping soil properties in Africa are (1) sampling depth (Figs. 2 and3), (2) Isothermality (quantifies how large the day-to-night temperatures oscillate relative to the summer-to-winter annual oscillations) and (3) mean annual rainfall. Here Isothermality seems to be especially important for modeling log ext.-K, log ext.-Mg and log ext.-S, and mean annual rainfall for modeling organic carbon, organic N, soil pH, log ext.-Mg and log ext.-P (see also Supplementary material).</p>
<p>The newly added USGS surficial lithology map of Africa 22 did not help improve predictions, however ln-eCEC values were significantly correlated with the class "Volcanic-Ash, Tuff, Mudflow". Classes "Extrusive Volcanic" and "Aeolian Sediments" seem to marginally help improve predictions of sand and clay. The surprisingly low correlation between the surficial geology map classes and soil nutrients is most likely due to the overly coarse scale of the geological map.</p>
<p>of fivefold spatial cross-validation for all variables of interest. The average R-square ranges from the best performing soil pH (CCC = 0.90) and ext.-Al (CCC = 0.937), to the worst performing ext.-P (CCC = 0.654), ext.-S (CCC = 0.708) and depth to bedrock (CCC = 0.725). Also note from Table 1 that some variables are predicted using considerably smaller training pools: especially bulk density, depth to bedrock, ext.-S and ext.-Zn have about 2-3× fewer observations for training than e.g. soil pH or similar. The models for bulk density, depth to bedrock, ext.-S and ext.-Zn are hence, in general, less representative of all landscape combinations in Africa and should be used with caution.</p>
<p>The spatial Cross-Validation accuracy assessment results (Fig. 4) show that a combination of feature selection and 2-scale modeling results in substantial improvements in prediction performance when compared to the previous work 17 . Improvements in accuracy are especially substantial for ext.-K, ext.-Fe, ext.-P and ext.-Ca, i.e. all variables where 30 m covariates can explain up to 30% of additional variation in the target variables.</p>
<p>The model performance and individual variable importance lists can be also tracked via the https ://zenod o.org repositories for iSDAsoil.</p>
<p>In summary, in comparison to our previous work 17 , these accuracy results suggest an average improvement in the R-square value from 0.6 (250 m predictions) to 0.8 (30 m predictions), probably primarily attributable to the addition of higher resolution remote sensing images and Digital Terrain parameters, but also by the adoption of methodological improvements in hyper-parameter tuning, feature selection and ensembling of models using the Super Learner algorithm. Note also that, thanks to the AfSIS project, most of the points used for training have been geo-located with high accuracy (&lt;50 m location error) and this probably also plays an important role in making the fine-resolution imagery useful for predictive mapping.</p>
<p>Importance of Sentinel-2 data for preparing field-scale nutrient maps. A visual comparison of the new predictions with the previous maps we produced in 2017 17 indicates that the new predictions better match spatial patterns in the field (Fig. 5). This is especially evident for variables such as soil pH, ext.-Ca, ext.-Mg and sand content, where Sentinel-2 mosaics and AW3D DTM derivatives are identified as being among the most important covariates.</p>
<p>Using a two-scale model was necessary to help us optimize computing when using about 350 covariate layers available at 250 m resolution-mainly climatic/atmospheric images-and some 60 layers-mainly EO data and DTM derivatives-at 30 m. This partitioning helped to speed up processing so that production time remained comparable to e.g. producing the global predictions at 250 m 21 .</p>
<p>The results overall indicate that the additional investment in the preparation of the EO data has proven to be worth the effort. High resolution satellite data has helped us achieve an increase in predictive ability, such that soil properties can now be predicted at 30m resolution, resulting in a Figure 2. Relative covariate importance for selected target soil variables ordered based on mean importance of all 250 m and 30 m resolution covariates. In this instance, the covariate "sampling depth" is the overall most important covariate, while Sentinel-2 B11 and Landsat SWIR images are revealed as the highest ranked covariates at 30 m resolution (see further Table 1 and Supplementary materials). highly detailed dataset of roughly 24 billion pixels per layer. Note we expended about 25% of the budget only to process the Sentinel-2 images (about 100 TB of data to derive 25% percentile and interquertile range) to produce the cloud-free Sentinel-2 soil-mapping-ready products for Africa.</p>
<p>Because multiple soil properties were shown to correlate well with continuous EO products such as Sentinel bands (especially B4, B8A, B10, B11 and B12), rainfall images (SM2RAIN), and Land Surface Temperature images (MODIS LST), this opens up possibilities for monitoring changes in soil properties such as soil carbon or soil pH in the future, as Landsat, Sentinel, MODIS and SM2RAIN missions are all expected to continue into the foreseeable future. This could be especially important for monitoring, for example, soil organic carbon changes 27 and/or soil degradation related to soil erosion, salinization, soil compaction or sealing. It remains to</p>
<p>Mapping soil properties at 30 m and three depths with uncertainties is heavily computational and requires substantial resources. Specifically, derivation of prediction errors can increase production costs considerably, consequently these might need to be estimated using simplified procedures in the future. Also our main rationale for using multiscale models vs one individual model was to try to decrease production costs without experiencing a significant loss of accuracy. The results indicate that the 2-scale EML is especially attractive for reducing computing costs which otherwise would have been about 5-10 times greater if we had tried to downscale ALL of the covariates from 250 to the finest 30 m resolution.</p>
<p>We did not estimate the area of applicability for Machine Learning for Africa per soil variable following the method of Meyer and Pebesma 29 , but our uncertainty maps do clearly reveal areas where the models extrapolate or perform poorly: usually these are densely vegetated tropical areas (Congo basin) or semi-arid parts of Somalia and Sudan. Next-generation soil sampling projects in Africa such as https ://www.soils 4afri ca-h2020 .eu/ might benefit from using our prediction uncertainty maps to identify new sampling locations e.g. by focusing on the areas that are most difficult to model i.e. that have widest prediction error intervals.</p>
<p>In principle, 2-scale ensembling can be considered to provide a generic framework for predictive soil mapping. It can be extended to consider multiple scales although, for practical purposes, we currently recommend using a minimum of two and a maximum of three scales to avoid increasing the computational complexity unnecessarily. In practice, one could also begin by evaluating multiple scales, then select statistically significant scales, then do ensembling of predictions for only scales identified as significant.</p>
<p>Value of the maps produced for local and/or field based agronomy needs to be evaluated "on the ground" and by landowners/farmers. In the first few weeks of testing iSDAsoil app (see Fig. 6), we have already received considerable feedback from experts in Europe and Africa. The main criticisms so far have focused on the low accuracy of the SOC predictions, particularly for peatland areas, on sampling locations over-representing croplands, and on problems with downloading and using these large datasets. The diversity of African soils and the under-representation of specific areas remains a challenge. We note especially that the following aspects can be considered as requiring more and better training/point data:</p>
<p>• Peatlands in Rwanda, Congo basin and similar remain heavily under-represented, as are all inaccessible tropical jungles or similar remote areas. • Nutrients P and S and micronutrients Cu, B remain difficult to map using current EO data and or any other type of data available for use in this study. There seems to be no simple solution for this problem and possibly not even 2× more point data for model training than we had here could guarantee success. • Application (fertilizers), crop history, and similar data from field trials is generally lacking and available only for limited locations e.g. via the Optimizing Fertilizer Recommendations for Africa (OFRA) database 30 .</p>
<p>While there have been criticisms of the absolute accuracy of the iSDAsoil maps, it is important to consider this in the context of real-world applications of the resource, for example in the generation of site-specific fertiliser recommendations. In this case, additional data collection would be required such as land use history, previous fertiliser applications and historic yields. However, we see this resource as a low cost alternative to lab-based soil test that has value in reducing uncertainty around soil properties compared to having no information, which is especially relevant in a smallholder agriculture context 31 .</p>
<p>Our initial predictions are not likely to be correct enough to support informed management at the farm scale immediately. We can, however, propose our initial predictions as being relevant as a starting point, or base, that drives and informs additional new sampling, for each specific parcel of interest. In that sense, our maps provide a uniform and relevant base from which to start building individually relevant predictions for specific parcels of agricultural land. Promotion of first steps for basic improved crop management does not perhaps demand an exceptionally high accuracy of soil data. For example, a good estimate of soil pH can already help to inform which crops may be most suitable to grow/ to not grow or if liming may be needed before any other agrochemicals are used.</p>
<p>Collecting and adding point data from countries such as Democratic Republic of the Congo, Sudan and/or Somalia remains a challenge as there are many serious security challenges for any soil sampling effort. Some recent reports from the Congo have shown that tropical peatlands are probably heavily under-estimated in previous soil maps of Africa 10,32 . Even in relatively safe Tanzania, multiple human casualties occurred during the AfSIS field data collection program, due to unclear land access permission and local militia problems. We anticipate, nevertheless, that a large amount of publicly funded point samples and observations remain unavailable and therefore unused 33 . These could be easily added to modeling and help improve predictions, and the iSDAsoil system has been designed to easily created new versions of the maps based upon additional data.</p>
<p>Another data source that could help improve predictions in the future is the upcoming EU Copernicus Sentinel satellites including the CHIME (Copernicus Hyperspectral Imaging Mission for the Environment), LSTM (Land Surface Temperature Monitoring) and CIMR (Copernicus Imaging Microwave Radiometer) 34 . Here we anticipate that, considering that the MODIS LST images have often proven to be among the most important explanatory variables, the LSTM mission especially could potentially improve the accuracy of soil predictions.</p>
<p>Next-generation soil and/or nutrient modeling in space and time could also probably profit from incorporating EO data that directly measures soil moisture status and Net Primary Productivity (kg ha -1 year -1 ). Adding extra training points, adding dynamic EO data products (time-series of images), improving the prediction accuracy for specific soil properties/nutrients will likely result in substantial improvements. For many soil properties (soil texture fractions, depth to bedrock, organic carbon etc) it is difficult to detect meaningful changes in them over time intervals of less than several years (unless some extreme event occurs), nevertheless, soils are a dynamic medium, and mapping and monitoring gradual and abrupt changes, especially in the chemical and biological soil properties will likely become the next frontier of research in Africa.</p>
<p>For the majority of soil properties, excluding depth to bedrock, we also use soil depth as one of the covariates so that the final models for the two scales are in the form 5 :</p>
<p>where y is the target variable, d is the soil sampling depth, φθ are geographical coordinates (northing and east- ing), and X p are the covariates. Adding soil depth as a covariate allows for directly producing 3D predictions 35 , which is our preferred approach as prediction can be then produced at any depth within the standard depth interval (e.g. 0-50 cm).</p>
<p>The predictions in the Ensemble models described in Fig. 7 are in principle based on using the following five Machine Learning libraries common for many soil mapping projects 5 .</p>
<p>scales can be traced back to the work of McBratney 42 . In a multiscale model, soil variation can be considered a composite signal (Fig. 8):</p>
<p>where S 4 is the value of the target variable estimated at the coarsest scale, S 3 , S 2 and S 1 are the higher order com- ponents, s B is the location or block of land, and ε is the residual soil variation i.e. pure noise.</p>
<p>In this work we used a somewhat simplified version of Eq. ( 2) with only two scale-components: coarse ( S 2 ; 250 m) and fine ( S 1 ; 30 m). We produce the coarse-scale and fine-scale predictions independently, then merge using a weighted average 43 : where ŷ(s B ) is the ensemble prediction, w i is the model weight and σ 2 i,CV is the model squared prediction error obtained using cross-validation. This is an example of Ensemble Models fitted for coarse-scale model for soil pH:</p>
<p>For the majority of lognormal distributed (right-skewed) variables we model and predict the ln-transformed values ( e (x + 1) ), then provide back-transformed predictions ( e x -1 ) to users via iSDAsoil. Note that also pH is a log-transformed variable of the hydrogen ion concentrations.</p>
<p>Although ln-transformation is not required for non-linear models such as Random Forest or Gradient Boosting, we decided to apply it to give proportionally higher weights to lower values. This is, in principle, a biased decision by us the modelers as our interest is in improving predictions of critical values for agriculture i.e. producing maps of nutrient deficiencies and similar (hence focus on smaller values). If the objective of mapping was to produce soil organic carbon of peatlands or similar, then the ln-transformation could have decreased the overall accuracy, although with Machine Learning models sometimes it is impossible to predict effects as they are highly non-linear.</p>
<p>Derivation of prediction errors. We also provide per-pixel uncertainty in terms of prediction errors or prediction intervals (e.g. 50%, 68% and/or 90% probability intervals) 45 . Because stacking of learners is based on repeated resampling, the prediction errors (per pixel) can be determined using either:</p>
<p>1. Quantile Regression Random Forest 46 , in our case by using the 4-5 base learners, 2. Simplified procedure using Bootstraping, then deriving prediction errors as standard deviation from multiple independently fitted learners 1 .</p>
<p>Both are non-parametric techniques and the prediction errors do not require any assumptions or initial parameters, but come at a cost of extra computing. By default, we provide prediction errors with a probability of 67%, which is the 1 standard deviation upper and lower prediction interval. Prediction errors indicate extrapolation areas and should help users minimize risks of taking decisions.</p>
<p>For derivation of prediction interval via either Quantile Regression RF or bootstrapping, it is important to note that the individual learners must be derived using randomized subsets of data (e.g. fivefold) which are spatially separated using block Cross-Validation or similar, otherwise the results might be over-optimistic and prediction errors too narrow.</p>
<p>Further, the pooled variance ( σE ) from the two independent models (250 m and 100 m scales in Fig. 7) can be derived using 47 : where σ 2 j is the prediction error for the independent components, μj is the predicted value, and w are the weights per predicted component (need to sum up to 1). If the two independent models (250 m and 30 m) produce very similar predictions so that μ250 ≈ μ30 , then the pooled variance approaches the geometric mean of the two variances; if the independent predictions are different ( μ250 -μ30 &gt; 0 ) than the pooled variances increase proportionally to this additional difference (Fig. 9).</p>
<p>Accuracy assessment of final maps. We report overall average accuracy in Table 1 and Fig. 4 using spatial fivefold Cross-Validation with model refitting 1,48 . For each variable we then compute the following three metrics: (1) Root Mean Square Error, (2) R-square from the meta-learner, and (3) Concordance Correlation Coefficient (Fig. 4), which is derived using 49 : where ŷ are the predicted values and y are actual values at cross-validation points, µ ŷ and µ y are predicted and observed means and ρ is the correlation coefficient between predicted and observed values. CCC is the most appropriate performance criteria when it comes to measuring agreement between predictions and observations.</p>
<p>For Cross-validation we use the spatial tile ID produced in the equal-area projection system for Africa (Lambert Azimuthal EPSG:42106) as the blocking parameter in the training function in mlr. This ensures that points falling in close proximity (&lt;30 km) are either used for training or for validation, which ultimately provides a more objective measure of accuracy for the whole of the continent 48 .</p>
<p>Training points. For model training we used a compilation of existing data previously produced by the AfSIS project and/or other publicly available soils data (Fig. 7). The important training point datasets include:</p>
<p>• AfSIS I and II soil samples for Tanzania, Uganda, Nigeria, Ghana: ca. 40,000 sampling locations, based upon spectral and wet chemistry data (available from: https ://regis try.opend ata.aws/afsis /). AfSIS I dataset was prepared by ICRAF using a systematic sampling procedure 50,51 , • ISRIC Africa Soil Profile Database: ca. 13,000 legacy profiles collected across Africa and collated by ISRIC as part of the AfSIS project 13 , • LandPKS: ca. 12,000 soil profile observations, crowd sourced and collected via the LandPKS mobile app 52 , • IFDC: ca. 9,000 soil sampling locations across Ghana, Uganda, Rwanda and Burundi collected from various projects, • AfricaRice and TAMASA: ca. 3,000 soil sampling locations across Africa generated from field trials/surveys by AfricaRice 53 and Taking Maize Agronomy to Scale in Africa (TAMASA).</p>
<p>In total this consists of more than 100,000 soil sites (unique locations) from over 20 datasets, measured using wet chemistry and dry spectroscopy 54 . The final training dataset includes between ca. 30,000-150,000 cleaned and standardized training samples depending on the variable (see Table 1).</p>
<p>iSDA was supported by ICRAF to leverage their extensive spectral calibration libraries in order to generate accurate and inexpensive soil property predictions from spectral data 55 . Analytical methods used for soil variables included the laser diffraction method for clay and sand fractions, the Mehlich3 extraction for extractable nutrients, pH was determined in 1:2 deionised water, eCEC was determined with the Cobalthexamine method and thermal oxidation and subtraction of inorganic carbon was used for soil organic carbon. We paid special attention to filtering out artifacts in the input points, filling in gaps in the point data, and leveraging expert agronomy rules. A full harmonization of different laboratory methods used in different data sets was not conducted but we ensured that only data from comparable methods with a similar range of results were used. Different extraction or analysis methods that can easily depart from each other by factors of 2-10. For example, different ex-P methods. For this reasons we have rather opted to splitting some variables into groups and/or omitting measurements that are incompatible with the majority of measurements.</p>
<p>The training points from the LandPKS project are, in fact, non-laboratory variables i.e. quick estimates of texture by hand. To convert the values from e.g. clay-loam texture class to clay, silt and sand fractions we use the texture triangle centroids 5 e.g. the class "clay" is converted to 20% sand, 18% silt and 63% clay and similar. The results of converting the values are thus visible as groupings in the observed data in the accuracy plots (Fig. 4) for sand, silt, clay and coarse fragments (CF)/stone content.</p>
<p>Part of the training datasets used for model building, and import and standardization rules are listed via a public repository at https ://gitla b.com/openl andma p/compi led-ess-point -data-sets/. For an up-to-date overview of training point datasets used, please refer to https ://isda-afric a.com/isdas oil.</p>
<p>We use an extensive stack of covariates that includes up-to-date MODIS, PROBA-V, cloud free Sentinel 2 mosaics, Landsat data, digital terrain parameters and climactic variables. The 250 m resolution covariates include (see Supplementary material for a complete list with file names):</p>
<p>• Digital Terrain Model DTM-derived surfaces-slope, profile curvature, Multiresolution Index of Valley Bot- tom Flatness (VBF), deviation from Mean Value, valley depth, negative and positive Topographic Openness and SAGA Wetness Index-all based on the MERIT-DEM 56 and computed using the SAGA GIS 57 using varying spatial resolutions (250 m, 1 km, 2 km); • CHELSA Bioclimatic images 58 • USGS Africa Surface Lithology map at 250 m resolution 22 .</p>
<p>CHELSA bioclimatic images include: (Bio1) annual mean temperature, (Bio2) mean diurnal temperature range, (Bio3) isothermality (day-to-night temperature oscillations relative to the summer-to-winter oscillations), (Bio4) temperature seasonality (standard deviation of monthly temperature averages), (Bio5) maximum temperature of warmest month, (Bio6) minimum temperature of coldest month, (Bio7) temperature annual range, (Bio10) mean temperature of warmest quarter, (Bio11) mean temperature of coldest quarter, (Bio12) annual precipitation amount, (Bio13) precipitation of wettest month, (Bio14) precipitation of driest month, (Bio16) precipitation of wettest quarter, (Bio17) precipitation of driest quarter. All layers were processed in the native resolution then, if necessary, downscaled to the same grid using bicubic splines resampling in GDAL 64 . The USGS Africa Surface Lithology map units were converted to indicators with some units being excluded for having too few ( &lt; 5 ) training points.</p>
<p>The 30 m resolution covariates include:</p>
<p>• Digital Terrain Model DTM-derived surfaces derived using the AW3D digital elevation model 65 downloaded from https ://www.eorc.jaxa.jp/ALOS/en/aw3d3 0/data/, and combined with the NASA DEM 30 m resolution product downloaded from https ://lpdaa c.usgs.gov/produ cts/nasad em_hgtv0 01/; • Sentinel-2 L2A cloud-free mosaics of bands B02, B04, B8A, B09, B10, B11 and B12 derived as 25%, 75% percentiles and inter-quantile ranges (IQR) processed via the AWS Open Registry (https ://regis try.opend ata.aws/senti nel-2/). Mosaics are computed for two seasons for years 2018 and 2019 (Fig. 7); • Existing Landsat cloud-free products with NIR and SWIR images based on the Global Forest Change project 20 and downloaded from https ://earth engin epart ners.appsp ot.com/scien ce-2013-globa l-fores t; • Global Surface Water long-term probability images based on Pekel et al. 66 and downloaded from https :// globa l-surfa ce-water .appsp ot.com.</p>
<p>We have pre-selected the 30 m resolution EO data for mapping soil nutrients over Africa, to still stay within the project budget by using the following procedure (Fig. 7):</p>
<p>The Sentinel-2 cloud-free images were produced using the Scene Classification Mask (SCL band) for two seasons (S1 = months 1, 2, 3, 7, 8, 9, and S2 = 4, 5, 6, 10, 11, 12) combined through 2018 and 2019 year, to minimize number of pixels with clouds. We processed a total of 852,738 Sentinel-2 L2A scenes, or about 200TB of raw data. Scenes were processed by splitting the African continent into 8721 tiles (2000×2000 pixels or 60×60 km). For processing these large volumes of data we used the AWS EC2 Spot Instances (Auto Scaling Groups) with 3GB of RAM per vCPU and few TB of ephemeral (temporary) storage for satellite images. The total processing time to produce all Sentinel-2 products took ca. 100,000 h of computing. Average time required to produce one cloud-free tile per tile/band/season ranged between 90 min for B02, B04 and 50 min for B8A, B09, B11, B12.</p>
<p>For predictive mapping we use a fully-optimized High Performance Computing system (3× Scan 3XS servers) using the Intel Xeon Gold chip-set with 40 CPU cores/80 treads.</p>
<p>Variable</p>
<p>Unit Training samples R-square RMSE CCC be verified if similar relations between soil organic carbon and 250 m resolution and 30 m resolution EO data is also applicable on other continents.</p>
<p>Scientific Reports | (2021) 11:6130 | https://doi.org/10.1038/s41598-021-85639-y</p>
<p>Scientific Reports | (2021) 11:6130 | https://doi.org/10.1038/s41598-021-85639-y</p>
<p>The AfSIS (Africa Soil Information Service) was funded by the Bill and Melinda Gates Foundation (BMGF) and the Alliance for a Green Revolution in Africa (AGRA). iSDA (Innovative Solutions for Decision Agriculture Ltd) is a social enterprise with a mission to improve smallholder farmer profitability across Africa. We are grateful for the outputs generated by all former AfSIS project partners: Ethiopian Soil Information Service (EthioSIS), Ghana Soil Information Service (GhaSIS), Nigeria Soil Information Service (NiSIS), Tanzania Soil Information Service (TanSIS), Columbia University, Rothamsted Research, World Agroforestry (ICRAF), Quantitative Engineering Design (QED), ISRIC-World Soil Information, and International Institute of Tropical Agriculture (IITA).</p>
<p>The iSDAsoil dataset is available under the Creative Commons Attribution 4.0 (CC-BY) International license and can be accessed via https ://isda-afric a.com/isdas oil. Cloud-optimized GeoTIFFs can be downloaded via https ://zenod o.org/searc h?q=iSDAs oil.</p>
<p>T.H., I.W. designed experiment(s), programmed and implemented computing, performed predictive modeling and statistical analysis, and coordinated the paper writing, T.H., M.E.A.M., K.D.S., A.D., J.C., J.C. quality controlled training point datasets, processed data licenses, analysed the results and coordinated project, J.K., L.P., M.S., processed the Sentinel data and programmed derivation of EO products, K.D.S., A.S. prepared, calibrated soil spectral library for Africa, and quality controlled the AfSIS training point datasets, M.E.A.M., M.K., O.A., L.G. implemented back-end and front-end solutions for the iSDAsoil, A.D., S.M.H., S.P.M., G.E.A. prepared, quality-controlled various training point datasets, and provided harmonization rules, K.S., J-M.J., J.C., F.B.T.S., M.Y., J.W. prepared and quality-controlled various national training point datasets, T.H., M.E.A.M., A.D., S.M.H., S.P.M., J.C., R.A.M., I.W., J.C. wrote the paper, T.H., M.E.A.M., J.K., A.S., M.K., O.A., L.G., L.P., contributed equally to processing the input data, developing the back-end and front-end solutions All authors reviewed the manuscript.</p>
<p>The authors declare no competing interests.</p>
<p>The online version contains supplementary material available at https ://doi. org/10.1038/s4159 8-021-85639 -y.</p>
<p>Correspondence and requests for materials should be addressed to T.H.</p>
<p>Reprints and permissions information is available at www.nature.com/reprints. Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f481284541"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:42+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>ultiple studies have assessed the real-world effectiveness of different Coronavirus 2019 (COVID-19) vaccination programs in the general population, in healthcare and other frontline workers and in care home residents 1 . Studies generally showed high effectiveness of the BNT162b2 mRNA vaccine (Pfizer-BioNTech) and the Oxford-AstraZeneca adenovirus vector vaccine, ChAdOx1 nCoV-19 (termed here ChAdOx1), against the Alpha (B.1.1.7) and preceding variants. More limited real-world effectiveness data are available for the mRNA-1273 (Moderna) vaccine 2-4 . Continued emergence of new SARS-CoV-2 variants potentially threatens the success of vaccination programs, particularly as in vitro experiments suggest reduced neutralization activity of vaccine-elicited antibodies against emerging variants 5,6 . Of particular concern is the Delta variant (B.1.617.2), which has caused sharp rises in infections in many countries, including some with relatively high vaccination coverage, such as the United Kingdom (UK). In England, B.1.617.2 quickly became dominant after being classified as a variant of concern on 28 April 2021, reaching 61% of sequenced positives from the English symptomatic testing program in the week commencing on 17 May (https://assets.publishing.service.</p>
<p>B.1.617.2 versus B.1.1.7, leaving it unclear to what extent the results for infection might be attributable to bias due to test-seeking behavior being influenced by vaccination status 8 . A further contributor might be waning immunity, with two recent studies from Israel finding higher infection rates in those vaccinated earliest 10,11 .</p>
<p>We, therefore, assessed the effectiveness of the BNT162b2, ChAdOx1 and mRNA-1273 vaccines against new SARS-CoV-2 PCR-positive cases using the Office for National Statistics (ONS) COVID-19 Infection Survey (CIS), a large, community-based survey of individuals living in randomly selected private households across the UK, where RT-PCR tests were performed after a pre-determined schedule, irrespective of symptoms, vaccination and prior infection 12,13 . Besides avoiding bias from test-seeking behavior changing after receipt of particular vaccines, other advantages over existing studies [7][8][9][10]14,15 include the ability to adjust for prior infection status and a wider range of potential confounders, including working in patient-facing healthcare, care homes or social care, household characteristics and (in)direct contact with hospitals or care homes.</p>
<p>We assessed VE based on overall RT-PCR positivity and split according to self-reported symptoms, cycle threshold (Ct) value (&lt;30 versus ≥30) as a surrogate for viral load, from 1 December 2020 (start of vaccination rollout) to 16 May 2021, when B.1.1.7 dominated, and from 17 May 2021 to 1 August 2021, when B.1.1.7 was replaced by B.1.617.2 (Extended Data Fig. 1), using calendar time as an instrumental variable for variant. In addition, in this B.1.617.2-dominant period, we investigated variation in vaccine effectiveness by time from second vaccination, long-term health conditions, age and prior infection. Given concerns that recent reduced effectiveness of BNT162b2 against (severe) infection in Israel could be due to the short interval between first and second vaccinations (vast majority, 3 weeks 16 ), we also investigated the dosing interval for BNT162b2. In addition, we assessed viral burden in new PCR-positive cases occurring ≥14 d after second vaccination using Ct values.</p>
<p>Visits and new PCR-positive cases included in analysis. During the B.1.1.7-dominant period, from 1 December 2020 to 16 May 2021 (Extended Data Fig. 1), nose and throat RT-PCR results were obtained from 384,543 individuals aged 18 years or older (221,909 households) at 2,580,021 visits (median (interquartile range (IQR)) 7 (6-8)), of which 16,538 (0.6%) were the first PCR-positive cases in a new infection episode. During the B.1.617.2-dominant period, from 17 May to 1 August 2021, results were obtained from 358,983 individuals (213,825 households) at 811,624 visits (median (IQR) 2 (2,3), 3,123 (0.4%)) being the first PCR-positive cases. Characteristics at included visits are shown in Supplementary Table 1.</p>
<p>We classified each visit according to vaccination status and prior infection, as previously reported 13 (Supplementary Table 2), considering individuals not yet vaccinated or &gt;21 d before vaccination without evidence of prior infection as the reference group. The vast majority of post-vaccination visits were with individuals who received BNT162b2 or ChAdOx1; there were only sufficient data to provide conclusive estimates after the first mRNA-1273 dose (Extended Data Figs. 2 and3 and Supplementary Table 3). The median (IQR) time since first vaccination for visits ≥21 d after the first vaccination but before the second was 47 (34-61), 43 (31-58) and 41 (31-52) for ChAdOx1, BNT162b2 and mRNA-1273, respectively (taking 21 d as the time when protection from the first vaccination might be reasonably achieved 17 ). The median (IQR) time from second vaccination for visits ≥14 d after the second vaccination was 41 (27-57) d for ChAdOx1 and 59 (35-86) d for BNT162b2, respectively (taking 14 d as the time when protection from the second 13 (Table 1 and Supplementary Table 4). In the B.1.617.2-dominant period, in individuals aged ≥18 years, there was evidence of reduced effectiveness compared to the B.1.1.7-dominant period ≥21 d after the first ChAdOx1 vaccination but not ≥14 d after the second (heterogeneity P = 0.004 and P = 0.23, respectively). There was no evidence of reduced effectiveness in the B.1.617.2-dominant period for BNT162b2 against all new PCR-positive cases (heterogeneity P = 0.60 and P = 0.23, respectively) (Table 1, Fig. 1 and Supplementary Table 4).</p>
<p>However, a decreasing number of visits remained in the unvaccinated reference group over time, particularly for individuals aged 65 years or over (Extended Data Figs. 2 and3). In particular, in the B.1.617.2-dominant period, less than 1% of visits of individuals aged 65 years or over were in the unvaccinated reference group, making estimates of VE against this group challenging to interpret. Although reasonable numbers of individuals aged 18-64 years remained in the unvaccinated reference group in the B.1.617.2-dominant period, comparisons with the B.1.1.7-dominant period were not possible in this age group owing to low numbers of individuals having received two vaccinations before 17 May 2021; however, VE estimates in the B.1.617.2-dominant period were similar to all adults for both vaccines (Fig. 1, Tables 1 and2 and Supplementary Table 4). To investigate VE in the B.1.617.2-dominant period further, we, therefore, focused on this younger age group.</p>
<p>In the B.1.617.2-dominant period, VE against new PCR-positive cases of individuals aged 18-64 years was significantly lower for ChAdOx1 versus BNT162b2 ≥21 d after one vaccination and ≥14 d after two vaccinations (heterogeneity P = 0.001 and P &lt; 0.0001, respectively; Table 2 and Supplementary Table 5). For both vaccines, having received two doses ≥14 d previously still provided significantly more protection than one dose ≥21 d previously (P &lt; 0.0001). There was no evidence that the effectiveness of two ChAdOx1 vaccinations ≥14 d previously differed from the protection afforded by previous natural infection without vaccination 1 and2 for ≥18 years and 18-64 years, respectively.</p>
<p>(heterogeneity P = 0.33), whereas two BNT162b2 vaccinations afforded greater protection (P = 0.04). Results were similar for individuals ≥18 years of age (Table 1). Effectiveness of a single dose of mRNA-1273 in individuals aged 18-64 years was at least as high as a single dose of BNT162b2 or ChAdOx1 (Supplementary Table 3 and Table 2). Apparent greater effectiveness of a single mRNA-1273 dose could potentially be driven by age, as individuals receiving mRNA-1273 were younger on average, and effectiveness appeared greater in younger individuals (Supplementary Table 6). There were insufficient data to estimate VE after a second mRNA-1273 dose (Extended Data Figs. 2 and3).</p>
<p>Effect of time from second vaccination and subgroups. In the B.1.617.2-dominant period, in individuals 18-64 years of age, VE of BNT162b2 against new PCR-positive cases reduced over time (P = 0.007; Fig. 2 and Table 3). Reductions were numerically smaller 3 for estimates of decline. See Supplementary Table 6 for estimates of VE within subgroups 14 d after second vaccination (intercept on panels below). lthc, self-reporting a long-term health condition.</p>
<p>for ChAdOx1, but there was no formal evidence of heterogeneity (P = 0.14).</p>
<p>Approximately 10% of visits in the B.1.617.2-dominant period occurred in vaccinated individuals with evidence of prior SARS-CoV-2 infection (Supplementary Table 2). Protection against new PCR-positive cases was significantly higher for vaccinated individuals with prior infection than vaccinated individuals without prior infection for both ChAdOx1 and BNT162b2 (heterogeneity P &lt; 0.0001 and P = 0.006, respectively; Supplementary Table 6).</p>
<p>VE was also higher in individuals aged 18-34 years than in individuals aged 35-64 years for both ChAdOx1 and BNT162b2 (heterogeneity P = 0.002 and P = 0.001, respectively). However, there was no evidence of differences between individuals reporting versus not reporting long-term health conditions or between &lt;6 versus ≥6 weeks (median (IQR) 25 (21-34) versus 72 (63-77) d) between the first and second BNT162b2 vaccination (heterogeneity P = 0.18; Supplementary Table 6).</p>
<p>Restricting new PCR-positive cases to those with Ct &lt;30 (higher viral burden) or with symptoms, attenuations in VE in individuals aged ≥18 years in the B.1.617.2-dominant versus the B.1.1.7-dominant period were more pronounced than against all new PCR-positive cases (Table 1 and Supplementary Table 4). Notably, attenuations in the B.1.617.2-dominant period now reached statistical significance for BNT162b2 as well as ChAdOx1 (for example, heterogeneity P &lt; 0.0001 ≥14 d post-second dose for both Ct &lt;30 and symptomatic infections). In the B.1.617.2-dominant period, one or two BNT162b2 vaccinations still provided greater VE than ChAdOx1 against PCR-positive cases with Ct &lt;30 or with symptoms in individuals aged ≥18 years (Table 1; P &lt; 0.003) and 18-64 years (Fig. 1, Table 2 and Supplementary Table 5; P &lt; 0.001). In the B.1.617.2-dominant period, VE against PCR-positive cases with Ct ≥30 (lower viral burden) or without self-reported symptoms was still lower than against PCR-positive cases with Ct &lt;30 or with symptoms for all three vaccines (Table 2).</p>
<p>There was now formal evidence that the effectiveness of BNT162b2 against PCR-positive cases with Ct &lt;30 or with symptoms declined faster ≥14 d after second vaccinations than for ChAdOx1 (heterogeneity P = 0.003 for both outcomes; Table 3, and Extended Data Figs. 4 and5). Extrapolating declines beyond the observed follow-up, both vaccines would be equally effective 7). Ct values were highest in individuals ≥14 d after second vaccination-significantly higher than in individuals who were unvaccinated and not previously PCR/antibody positive but with no evidence that they differed from individuals who were unvaccinated but previously PCR/antibody positive (age/ sex-adjusted P = 0.02 and P = 0.72, respectively).</p>
<p>From 14 June 2021, after which more than 92% of PCR-positive cases with Ct &lt;30 were B.1.617.2 compatible (Extended Data Fig. 1), differences in Ct values between individuals who were unvaccinated and individuals ≥14 d after second vaccination had attenuated substantially (age/sex-adjusted P = 0.35, heterogeneity versus B.1.1.7-dominant period P = 0.01), as had differences with individuals who were unvaccinated but previously PCR/antibody positive. Mirroring the attenuation in Ct values, the difference between individuals who were unvaccinated and individuals ≥14 d after second vaccination in the percentages of PCR-positive cases reporting any or well-recognized COVID-19 symptoms (cough, fever or loss of taste/smell) significantly attenuated after 14 June 2021 (heterogeneity P &lt; 0.0001 and P = 0.008 respectively; Extended Data Fig. 6). However, this was likely driven by lower Ct values, as the association between Ct and symptom reporting remained broadly similar after B.1.617.2 (Extended Data Fig. 7).</p>
<p>Considering all 1,736 PCR-positive cases ≥14 d after two ChAdOx2 or BNT162b2 vaccinations from 1 December 2020 through 1 August 2021 (1,415 (82%), of whom had ≥1 prior negative swabs after their second vaccination), Ct values came from a mixture of two subpopulations (Fig. 3b). The low subpopulation had a mean Ct of 21.7 (95% confidence interval (CI), 21.2-22.2), and the high subpopulation had a mean Ct of 32.7 (95% CI, 32.5-33.0), consistent with either mild or late identified infection. The relative percentage of new PCR-positive cases falling into these two subpopulations varied strongly over time (P &lt; 0.0001; Fig. 3c), with the percentage in the low Ct (high viral burden) subpopulation vaccinations than two ChAdOx1 vaccinations (adjusted odds ratio (aOR) = 0.33 (95% CI, 0.16-0.67), P = 0.002), but this likelihood increased significantly over time from second vaccination (aOR per month = 1.43 (95% CI, 1.07-1.91), P = 0.01; unadjusted in Fig. 3d; Supplementary Table 7 and Extended Data Fig. 8). In contrast, there was no evidence of changing likelihood over time for ChAdOx1 (aOR per month = 0.97 (95% CI, 0.79-1. 19), P = 0.78; heterogeneity P = 0.02). Overall, therefore, by around 3 months after second vaccination, the probability of being in the low-Ct subpopulation was similar for both BNT162b2 and ChAdOx1. Vaccine type and time from second vaccination had similar effects on the mean Ct within the low-Ct subpopulation, with higher Ct values in new PCR-positive cases 14 d after second BNT162b2 vaccination (P = 0.003), which then dropped significantly faster with time from second vaccination than for ChAdOx1 (interaction P = 0.01), leading to similar Ct values with both vaccines by around 3 months (Extended Data Fig. 8b). Individuals who were previously PCR/antibody positive were less likely to belong to the low-Ct subpopulation compared to individuals without evidence of previous infection (P &lt; 0.0001), while individuals who reported having long-term health conditions were also associated with a lower probability of belonging to the low-Ct subpopulation (P = 0.006), potentially reflecting protection in the former and longer duration of PCR positivity in the latter, leading to late infections being more likely to be identified through the fixed testing schedule. There were no additional effects of sex, age (unadjusted in Extended Data Fig. 8b) or ethnicity on the probability of belonging to the low-Ct subpopulation (P &gt; 0.15).</p>
<p>Anti-trimeric spike antibody (IgG) levels were measured in a subset of individuals, selected at random or based on longest study participation or prior swab positivity (Methods). A prior result was available for 846/1,736 (49%) new PCR-positive cases ≥14 d after two ChAdOx2 or BNT162b2 vaccinations, of which 795 (94%) were above the 42 ng ml -1 positivity threshold (Extended Data Fig. 9c) (median, 215 ng ml -1 ) (IQR 126-454). However, independently of factors in Supplementary Table 7, every doubling in IgG was associated with 22% lower odds of a new PCR-positive case belonging to the low-Ct subpopulation (aOR = 0.78 (95% CI, 0.66-0.93), P = 0.007), with no evidence that this varied by vaccine type (heterogeneity P = 0.31). There was no evidence of association between IgG and mean Ct values within either subpopulation (P &gt; 0.14). Most individuals with antibody measurements after a new PCR-positive test ≥14 d after second vaccination increased antibody levels after their new PCR-positive test, suggesting a boosting effect of new infections after vaccination (Extended Data Fig. 10).</p>
<p>Our results suggest that vaccination with two doses of BNT162b2 or ChAdOx1 still substantially reduces the risk of new PCR-positive SARS-CoV-2 infections. However, whereas the two vaccines provided similar benefits when B.1.1.7 was dominant, benefits from two ChAdOx1 doses are reduced more with B.1.617.2 than for two BNT162b2 doses, although two ChAdOx1 doses still provide similar protection as that from previous natural infection. Benefits from both vaccines are numerically greater against PCR-positive cases in patients with versus without self-reported symptoms and in patients with high-versus low-viral-burden PCR-positive cases, but the difference in effectiveness is smaller with B.1.617.2 for both vaccines.</p>
<p>The dynamics of protection varied over time from second vaccination and by vaccine type, with initially larger effectiveness with BNT162b2 than ChAdOx1, which then become more similar by ~4-5 months due to more rapid waning of effectiveness with BNT162b2, particularly against infections with Ct &lt;30 or symptoms. Notably, there was no evidence that effectiveness depended on the interval between first and second BNT162b2 vaccinations (&lt;6 weeks versus ≥6 weeks). Protection against new PCR-positive cases was significantly larger in vaccinated individuals with evidence of prior infection than in vaccinated individuals without prior infection.</p>
<p>We also found greater effectiveness in individuals 18-34 years old than individuals 35-64 years old, although we were not able to jointly assess the degree to which this could have been caused by higher rates of previous infection in this group. We were unable to estimate VE in individuals 65 years of age and older in the B.1.617.2-dominant period, as very few individuals remained unvaccinated in the reference group; moreover, such individuals are unlikely to be representative. This challenge of diminishing and increasingly unrepresentative control groups also applies to other designs, such as test-negative case-control, and will increasingly hinder assessment of VE at younger ages with increasing rollout (Extended Data Fig. 3). Few studies have assessed VE during periods where the B.1.617.2 variant dominated. A test-negative case-control study from the English symptomatic testing program suggested that the effectiveness after one dose of either BNT162b2 or ChAdOx1 was lower against symptomatic infection with B.1.617.2 than B.1.1.7 (31% versus 49%, respectively), with smaller differences after two doses (BNT162b2, 88% versus 94%, respectively; ChAdOx1, 67% versus 75%, respectively) 7 . There is little alternative to using observational data to assess VE against new variants, because additional placebo-controlled randomized trials would be unethical (although active comparator trials could still be performed). However, there are many biases in observational analyses 18 , particularly if symptomatic testing is non-random and related to perceived efficacy 8 . Potential bias due to such health-seeking behavior is likely particularly pronounced for mild symptoms, included in many VE studies using routine symptomatic testing program data. This might be exacerbated by the generic nature of many symptoms prompting testing, which might be incidental, and misclassification due to individuals reporting symptoms when they want to get a test. As we demonstrated substantially lower VE against infections with high Ct or no reported symptoms, this would bias estimates toward lower effects, potentially differentially between vaccines.</p>
<p>Such bias is substantially reduced when testing schedules are fixed independent of symptom or vaccination status, as in our survey, or when using objective severe disease endpoints, such as hospital admissions and deaths. A recent study from Scotland 9 found no statistical evidence of differential effectiveness against hospital admissions with B.1.617.2 and B.1.1.7 (62% versus 72% in PCR-positive cases), although power was relatively limited. BNT162b2 effectiveness against hospitalizations remained high when B.1.617.2 dominated in Israel (88%, https://www.gov.il/BlobFolder/reports/ vaccine-efficacy-safety-follow-up-committee/he/files_publications_ corona_two-dose-vaccination-data.pdf), despite lower effectiveness against self-reported symptomatic SARS-CoV-2 infection (41% versus 97% previously) 19 .</p>
<p>Although testing behavior bias could contribute to these differences, we also found a stronger protective effect against infections with higher viral burden and/or symptoms from BNT162b2 and ChAdOx1 vaccines, although to a lesser degree than against B.1.1.7. One explanation could be differential effects of vaccination on mucosal and systemic immunity 20 . In theory, the former is more important for preventing carriage, transmission and infection becoming established, whereas the latter is more important for preventing severe disease once infected 21 . Studies in rhesus macaques showed greater reductions in SARS-CoV-2 viral load in the lungs and prevention of pneumonia, without reducing viral loads in the upper respiratory tract with intramuscular ChAdOx1 (ref. 22 ), and protection against viral replication at much lower concentrations in the lower respiratory tract than in the upper respiratory tract with intramuscular mRNA-1273 (ref. 23 ). In mice, an experimental adenovirus vaccine induced strong systemic adaptive immune responses against SARS-CoV-2 and reduced infection in the lungs but minimal mucosal immune responses when administered intramuscularly 24 . Another explanation for differences in VE against infections with B.1.617.2 versus B.1.1.7 is that the former might have a replication advantage in airway human epithelial cells; increased infectivity at mucosal surfaces could facilitate antibody evasion 25 . A final explanation could be varying protection by time since second vaccination in the B.1.617.2-dominant period, which also differed between BNT162b2 and ChAdOx1. When such time-dependent effects are present, studies with different follow-up will inevitably get different 'average' results, and studies when B.1.1.7 dominated might predominantly reflect early effects. Regardless of explanation, although protection against hospitalization and death is maintained, 'booster' vaccinations might not be needed, particularly because infection after vaccination might provide a natural antibody boost. However, declines in immunity against infection show that this needs to be monitored closely.</p>
<p>In addition to reduced VE, we found a substantial shift in viral burden in individuals who were infected despite two vaccinations with BNT162b2 or ChAdOx1 in the B.1.617.2-dominant period, with similar average Ct values to individuals infected without vaccination, and much more similar percentages reporting symptoms, driven by Ct. Although, with B.1.1.7, we 13 and others [26][27][28] found that vaccinated individuals had lower viral burden (higher Ct values) than unvaccinated individuals, the greater number of new PCR-positive cases (1,736 ≥14d after second vaccination) allowed us to show that there are two different types of such infections: a low-viral-burden group that dominated early in 2021 and a high-viral-burden group that increased in frequency with B.1.617.2. Individuals receiving ChAdOx1 were more likely to fall into the latter group after their second vaccination, as were an increasing percentage of new PCR-positive individuals with increasing time from second BNT162b2 vaccination, mirroring changes in protection against new PCR positivity. Peak viral load, therefore, now appears similar in infected vaccinated and unvaccinated individuals, with potential implications for onward transmission risk, given the strong association between peak Ct and infectivity 29 . However, the degree to which this might translate into new infections is unclear; a greater percentage of virus might be non-viable in individuals who are vaccinated, and/or their viral loads might also decline faster, as suggested by a recent study of patients hospitalized with B.1.617.2 (ref. 26 ) (supported by associations between higher Ct and higher antibody levels here and in ref. 30 ), leading to shorter periods 'at risk' for onwards transmission. Nevertheless, there might be implications for any policies that assume a low risk of onward transmission from vaccinated individuals (for example, relating to self-isolation and travel), despite vaccines both still protecting against infection, thereby still reducing transmission overall. This might be particularly important when vaccinated individuals are not aware of their infection status or perceive that their risk of transmission is low. Notably, individuals infected after second vaccination appeared to gain an antibody boost, and higher prior antibody levels were independently associated with lower viral burden.</p>
<p>The main study strength is its size and design including participants from randomly selected private residential households in the community, tested following a fixed schedule, independent of symptoms and vaccination status, thereby avoiding bias due to test-seeking behavior that potentially affects many other studies assessing VE against SARS-CoV-2 infections 8 . Furthermore, we are able to adjust for risk factors that also affect vaccination but are typically not available in electronic health records, such as patient-facing healthcare work and long-term health conditions, and also adjusted for background 'force of infection' using flexible models for background infection rates varying by age, calendar time and geographical region. This should lead to less residual confounding than studies relying on routine electronic healthcare data.</p>
<p>Our study has several limitations. Although we included a broad set of potential confounders, results might still be biased by unknown confounders or misclassification of prior infection status-for example, due to having antibody measurements on only a subset. Participants are tested initially at weekly and then monthly visits, meaning that, when rates are increasing, as when B.1.617.2 came to dominate, we expect to identify infected individuals earlier in their infection episode 31,32 , as shown and adjusted for in our Ct analysis. Late detection of older infections on the fixed visit schedule means that some positives could be classified as having occurred shortly after vaccination, whereas the infection might actually have been acquired before vaccination, potentially diluting VE estimates. However, most infections ≥14 d after second vaccination had a preceding negative after second vaccination. To avoid misclassification bias from erroneously classifying higher Ct positives where only ORF1ab + N genes were detected as B.1.1.7, our comparisons treated calendar periods as an instrumental variable, according to whether B.1.1.7 or B.1.617.2 was dominant, but this will likely lead to a small amount of bias in our VE estimates. In particular, it is expected to result in a small dilution bias when estimating the effect of the B.1.617.2 variant. We did not have information on severe outcomes, against which VE might remain high as hospitalization and death rates have increased by only small amounts in the UK, despite large increases in the number of people testing positive (https:// coronavirus.data.gov.uk/).</p>
<p>In summary, with B.1.617.2, BNT162b2 and ChAdOx1 remain protective against any new PCR-positive cases and infections with higher viral burden or symptoms, but VE against these outcomes is reduced, with evidence of significantly different dynamics of immunity against infections with Ct &lt;30 or symptoms after second doses of the two vaccines. With B.1.617.2, those infections occurring despite either vaccine have similar peak viral burden to those in unvaccinated individuals. The effect on infectivity to others is unknown but requires urgent investigation. It further argues for vaccinating as many of the population as possible, because unvaccinated individuals might not be protected by as substantial reductions in transmission among the immunized population as seen other infections, making herd immunity likely unachievable for emerging variants and requiring efforts to protect individuals themselves. Although the current preservation of VE against severe outcomes in other studies suggests that allowing ongoing virus transmission and nasopharyngeal viral presence might have limited consequences, the success of this strategy will ultimately rely on universal vaccination (currently not available to most worldwide); uniform protection induced by vaccines, including in older individuals; optimization of vaccine strategies to induce higher levels of mucosal and systemic immunity; and an absence of novel variants that might compromise VE against severe infection.</p>
<p>Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
<p>Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons. org/licenses/by/4.0/.</p>
<p>The survey methods are the same as those described previously 13 but are also described in detail below.</p>
<p>The ONS CIS is a large household survey with longitudinal follow-up (ISRCTN21086382, https://www.ndm.ox.ac.uk/covid-19/covid-19infection-survey/protocol-and-information-sheets) (details in refs. 12,13 ). The study received ethical approval from the South Central Berkshire B Research Ethics Committee (20/SC/0195). Private households are randomly selected on a continuous basis from address lists and previous surveys to provide a representative sample across the UK. After verbal agreement to participate, a study worker visited each selected household to take written informed consent for individuals aged 2 years and over. Parents or carers provided consent for those aged 2-15 years; those aged 10-15 years also provided written assent. For the current analysis, we included only individuals aged 16 years and older who were potentially eligible for vaccination.</p>
<p>Blood samples were couriered directly to the University of Oxford where they were tested for the SARS-CoV-2 antibody using an ELISA detecting anti-trimeric spike IgG 33 . Before 26 February 2021, the assay used fluorescence detection (positivity threshold, 8 million units) 33 . After this, it used a commercialized CE-marked version of the assay-the Thermo Fisher OmniPATH 384 Combi SARS-CoV-2 IgG ELISA (Thermo Fisher Scientific)-with the same antigen and a colorimetric detection system (positivity threshold, 42 ng ml -1 monoclonal antibody unit equivalents, determined from 3,840 samples run in parallel). From 27 February 2021, samples were also tested using a Thermo Fisher Scientific N antibody.</p>
<p>Inclusion and exclusion criteria. This analysis included individuals aged 18 years or older (that is, those who were eligible for vaccination) and all visits with positive or negative swab results</p>
<p>Individuals were asked about their vaccination status at visits, including type, number of doses and date(s). Individuals from England were also linked to administrative records from the National Immunisation Management Service (NIMS). We used records from NIMS where available; otherwise, we used records from the survey, because linkage was periodic, and NIMS does not contain information about vaccinations received abroad or in Northern Ireland, Scotland and Wales. Where records were available in both, agreement on type was 98%, and agreement on dates was 95% within ±7 d. A small number of visits after reported vaccination with either unknown or vaccines other than ChAdOx1, BNT162b2 or mRNA-1273 were excluded as these were too few to provide reliable estimates (for mRNA-1273, we included only the first dose and the period ≥17 May because numbers were also too few before 17 May and for second doses (Extended Data Fig. 3)).</p>
<p>SARS-CoV-2-positive cases. PCR-positive results might be obtained at multiple visits after infection, so we grouped positive tests into episodes (cases). Whole genome sequencing is available on only a subset of positives, and only a subsample provides monthly blood samples for antibody status, so positive episodes were defined using study PCR results. We previously found that defining episodes based on 90 d, as suggested by the World Health Organisation (https://www.paho.org/ en/documents/interim-guidelines-detecting-cases-reinfection-sars-cov-2), led to higher than plausible risk of a new episode between 90 and 120 d, particularly for high-Ct infections 13 , suggesting that intermittent long-term PCR positivity could be contributing. Here, we, therefore, defined the start of a new 'positive case' as the date of ( 1 We chose these vaccination status categories empirically based on previous findings 13 . Exposure group ii (Not vaccinated, not previously positive, 1-21 d before vaccination) was included because there is inevitably a degree of transient reverse causality where vaccination appointments have to be rescheduled if someone tests positive in the weeks before the scheduled visit. Prior infection status was based on multiple sources, including previous PCR-positive episodes in the study, positive tests from the national testing program in England, positive S-antibody measurements before vaccination and N-antibody measurements. All participants were swabbed from enrollment and onwards, allowing assessment of prior infection status via this route. Everyone living in England (83% of the study population) was eligible to get tested via the national testing program if they experienced symptoms or this was required for workplace or school attendance. In total, 19% of participants had an S-antibody measurement before vaccination, and 32% of participants had at least two N-antibody measurements. We defined prior positivity as having either a previous PCR-positive episode or a positive S-antibody measurement more than 90 d before the visit or two consecutive positive N-antibody measurements more than 42 d before the visit. The choice of 90 d and 42 d was arbitrary but designed to exclude ongoing infections acquired previously being misattributed to current visits. Visits from vaccinated individuals (groups (iii)-(xii)) were defined irrespective of previous positivity (Supplementary Table 2) to reflect the effect of vaccination as being implemented in the UK (without regard to prior infection). However, in sensitivity analysis, we analyzed the effect of vaccination by prior infection status. Visits from the same participant were classified in different groups depending on their status at each visit.</p>
<p>Outcomes. Analysis was based on visits, because these occur independently of symptoms and are, therefore, unbiased. Only the first test-positive visit in each new PCR-positive infection episode starting after 1 December 2020 was used, dropping all subsequent visits in the same infection episode and all negative visits before the first time that a participant could be considered 'at risk' for a subsequent new positive episode (as defined above), to avoid misattributing ongoing PCR positivity to visit characteristics and immortal time bias, respectively. Primary analysis included all new PCR-positive episodes. Secondary analyses considered infection severity, by classifying positives by Ct value (&lt;30 or ≥30) and self-reported symptoms. The threshold Ct value of 30 is somewhat arbitrary but corresponds to ~150 copies per ml 29 and is consistently used in the UK for many purposes, including algorithms for review of low-level positives at the laboratories where the PCR tests were performed and a threshold for attempting whole genome sequencing. For each positive test, a single Ct was calculated as the arithmetic mean across detected genes (Spearman correlation &gt;0.98), and then the minimum value was taken across positives in the infection episode to reflect the greatest measured viral burden within an episode. To allow for pre-symptomatic positives being identified in the survey, any self-reported symptoms at any visit within 0-35 d after the index positive in each infection episode were included (questions elicit symptoms in the last 7 d at each visit). Statistical analysis. Associations among the different exposure groups and outcome (first positive test in an infection episode versus test negative) were evaluated with generalized linear models with a logit link. Robust standard errors were used to account for multiple visits per participant. To adjust for substantial confounding by calendar time and age, with non-linear effects of age, which are also different by region, we included both as restricted cubic splines and interactions between these splines and region/country (regions for England and country for Northern Ireland, Scotland and Wales). Furthermore, given previous observations of different positivity rates by age over time 12 , we added a tensor spline to model the interaction between age and calendar time with the restriction that the interaction is not doubly non-linear 34 . The primary analysis considered effect modification of each vaccine exposure group by time period (before 17 May 2021 (B.1.1.7 dominant) or after 17 May 2021 (B.1.617.2 dominant)) in those aged ≥18 years. Secondary analyses considered variation over time from second vaccination (linear on the log-odds scale, truncating at the 95th percentile of observed days from second vaccination separately for each vaccine) and effect modification by long-term health conditions, dosing interval and prior infection status in the B.1.617.2-dominant period only in those aged 18-64 years. Pairwise comparisons of the exposure groups were performed unadjusted. Analysis was based on complete cases (&gt;99% of observations).</p>
<p>For all infections, comparisons of Ct values by vaccine exposure groups used quantile (median) regression adjusted for age and sex. Associations between factors and Ct values in 'breakthrough' infections occurring ≥14 d after second vaccinations were assessed using mixture normal linear regression models with two component subpopulations (Bayesian Information Criterion 499.4 lower than single population). For these analyses of Ct values, we conducted backwards elimination (exit P = 0.05) for associations between factors and the latent class probabilities and separately with the Ct values in each subpopulation for the 12 variables shown in Supplementary Table 7. We included interactions with vaccine in either part of the model type where these had interaction P &lt; 0.05. We considered three knot-restricted natural cubic splines in continuous factors (calendar date of positive, age, interval between first and second vaccination and time since second vaccination) (knots at the 10th, 50th and 95th percentiles) if there was evidence of non-linearity at P &lt; 0.01. To reduce the influence of outliers, we truncated the interval between first and second vaccination at 3 and 14 weeks and the time from second vaccination at the 95th percentile (118 d, 3.9 months).</p>
<p>Reporting Summary. Further information on research design is available in the Nature Research Reporting Summary linked to this article.</p>
<p>a Re-infection will be a variable amount of time previously, but it was not possible to split this owing to low numbers. Note: All estimates (VE = 100% × (1 odds ratio)) were obtained from a generalized linear model with a logit link comparing to the reference category of 'Not vaccinated, not previously positive and ≥21 d before vaccination' and using clustered robust standard errors. Heterogeneity P values were obtained using the two-sided Wald test without adjustment for multiple comparisons. Calendar time was split into two epochs when most cases detected in the survey were ORF1ab + N positive (B.1.1.7 compatible) and then when triple positives became dominant (B.1.617.2 compatible) (Extended Data Fig.</p>
<p>1</p>
<p>). Estimates from the former are similar to those from individuals aged ≥16 years previously published on data to 8 May 2021 but with slightly wider 95% CIs due to splitting time after the second dose at 14 d in this analysis. See Supplementary Table</p>
<p>4</p>
<p>for unadjusted heterogeneity P values. VE post-second doses changes over time from vaccination (see Fig.</p>
<p>2</p>
<p>and Extended Data Figs.</p>
<p>4 and 5</p>
<p>for changes in individuals aged 18-64 years), so estimates in this table are an average over follow-up included in this analysis.</p>
<p>NATURE MEDICINE | www.nature.com/naturemedicine</p>
<p>Articles</p>
<p>NATURE MEDICINE</p>
<p>vaccination might be reasonably achieved). The median (IQR) dosing interval between first and second vaccination was 76 (68-78) d and 74 (62-77) d, respectively.</p>
<p>Effect of vaccination on new PCR-positive cases. Adjusting for multiple potential confounders (details in Supplementary</p>
<p>a Re-infection NATURE MEDICINE | www.nature.com/naturemedicine averaging 16%, 34% and 72% through 16 May 2021, 17 May-13 June and 14 June onwards, respectively. Independently of this effect of calendar time (reflecting B.1.1.7 versus B.1.617.2 dominance), new PCR-positive cases were less likely to be in the low Ct subpopulation 14 d after two BNT162b2</p>
<p>a When initial effectiveness NATURE MEDICINE | www.nature.com/naturemedicine</p>
<p>This study is funded by the Department of Health and Social Care, with in-kind support from the Welsh Government, the Department of Health on behalf of the Northern Ireland Government and the Scottish Government. E.P., K.B.P., A.S.W., T.E.A.P., N.S. and D.E. are supported by the National Institute for Health Research Health Protection Research Unit (NIHR HPRU) in Healthcare Associated Infections and Antimicrobial Resistance at the University of Oxford, in partnership with Public Health England (PHE) (NIHR200915). A.S.W. and T.E.A.P. are also supported by the NIHR Oxford Biomedical Research Centre. E.P. and K.B.P. are also supported by the Huo Family Foundation. A.S.W. is also supported by core support from the Medical Research Council (MRC) UK to the MRC Clinical Trials Unit (MC_UU_12023/22A) and is an NIHR Senior Investigator. P.C.M. is funded by Wellcome (intermediate fellowship, grant no. 110110/Z/15/Z) and holds an NIHR Oxford BRC Senior Fellowship award. D.W.E. is supported by a Robertson Fellowship and an NIHR Oxford BRC Senior Fellowship. The views expressed are those of the authors and are not necessarily those of the National Health Service, the NIHR, the Department of Health or PHE. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript. All authors had full access to all data analysis outputs (reports and tables) and take responsibility for their integrity and accuracy. We are grateful for the support of all COVID-19 Infection Survey participants and the COVID-19 Infection Survey team: Office for National Statistics: I. Diamond, E. Rourke, R. Studley, T. Thomas, D. Cook, D. Ayoubkhani, R. Black, A. Felton, M. Crees, J. Jones, L. Lloyd and E. Sutherland; University of Oxford, Nuffield Department of Medicine: A. S. Walker, D. Crook, P. C. Matthews, T. Peto, E. Pritchard, N. Stoesser, K.-D. Vihta, J. Wei, A. Howarth, G. Doherty, J. Kavanagh, K. K. Chau, S. B. Hatch, D. Ebner, L. Martins Ferreira, T. Christott, B. D. Marsden, W. Dejnirattisai, J. Mongkolsapaya, S. Cameron, P. Tamblin-Hopper, M. Wolna, R. Brown, S. Hoosdally, R. Cornall, D. I. Stuart and G. Screaton; University of Oxford, Nuffield Department of Population Health: K. Pouwels; University of Oxford, Big Data Institute: D. W. Eyre, K. Lythgoe, D. Bonsall, T. Golubchik and H. Fryer; University of Oxford, Radcliffe Department of Medicine: J. Bell; Oxford University Hospitals NHS Foundation Trust: S. Cox, K. Paddon and T. James; University of Manchester: T. House; Wellcome Trust: J. Farrar; Public Health England: J. Newton, J. Robotham and P. Birrell; IQVIA: H. Jordan, T. Sheppard, G. Athey, D. Moody, L. Curry and P. Brereton; National Biocentre: I. Jarvis, A. Godsmark, G. Morris, B. Mallick and P. Eeles; Glasgow Lighthouse Laboratory: J. Hay and H. VanSteenhouse; Department of Health and Social Care: J. Lee; Welsh Government: S. White, T. Evans and L. Bloemberg; Scottish Government: K. Allison, A. Pandya and S. Davis; Public Health Scotland: D. I. Conway, M. MacLeod and C. Cunningham.</p>
<p>gov.uk/government/uploads/system/uploads/attachment_data/ file/991343/Variants_of_Concern_VOC_Technical_Briefing_14. pdf) and 99% from 27 June onwards (https://assets.publishing. service.gov.uk/government/uploads/system/uploads/attach ment_data/file/1001358/Variants_of_Concern_VOC_Technical_ Briefing_18.pdf).</p>
<p>The following potential confounders were adjusted for in all models for VE as potential risk factors for acquiring SARS-CoV-2 infection (without variable selection): geographic area and age in years (see below), sex, ethnicity (white versus non-white as small numbers), index of multiple deprivation (percentile, calculated separately for each country in the UK; https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019; https://gov.wales/welsh-index-multiple-deprivation-full-index-update-ranks-2019; https://www.gov.scot/collections/scottish-index-of-multiple-deprivation-2020/; https://www.nisra.gov.uk/statistics/deprivation/northern-ireland-multipledeprivation-measure-2017-nimdm2017), working in a care home, having a patient-facing role in health or social care, presence of long-term health conditions, household size, multigenerational household, rural-urban classification (https:// www.nisra.gov.uk/support/geography/urban-rural-classification; https://www.gov. uk/government/collections/rural-urban-classification; https://www.ons.gov.uk/ methodology/geography/geographicalproducts/ruralurbanclassifications; https:// www.gov.scot/publications/scottish-government-urban-rural-classification-2016/ pages/2/), direct or indirect contact with a hospital or care home, smoking status and visit frequency. Details are shown in Supplementary Table 1.</p>
<p>Data are still being collected for the COVID-19 Infection Survey. De-identified study data are available for access by accredited researchers in the ONS Secure Research Service (SRS) for accredited research purposes under part 5, chapter 5 of the Digital Economy Act 2017. For further information about accreditation, contact research.support@ons.gov.uk or visit the SRS website.</p>
<p>Any methods, additional references, Nature Research reporting summaries, source data, extended data, supplementary information, acknowledgements, peer review information; details of author contributions and competing interests; and statements of data and code availability are available at https://doi.org/10.1038/ s41591-021-01548-7.</p>
<p>This study was designed and planned by A.S.W., J.F., J.B., J.N., I.D. and K.B.P. and is being conducted by A.S.W., R.S., D.C. and E.R. The specific analysis was designed by A.S.W. and K.B.P. K.B.P. and A.S.W. contributed to the statistical analysis of the survey data. J.H. conducted analysis of the RT-PCR data. A.S.W. and K.B.P. drafted the manuscript. All authors contributed to interpretation of the study results and revised and approved</p>
<p>the manuscript for intellectual content. K.B.P. and A.S.W. are the guarantors and accept full responsibility for the work and conduct of the study, had access to the data and controlled the decision to publish. The corresponding author (K.B.P.) attests that all listed authors meet authorship criteria and that no others meeting the criteria have been omitted.</p>
<p>All authors have completed the International Committee of Medical Journal Editors uniform disclosure form at www.icmje.org/coi_disclore.pdf. D.W.E. declares lecture fees from Gilead, outside the submitted work. E.P., P.C.M., N.S., D.W.E., J.I.B., D.C., T.E.A.P., A.S.W. and K.B.P. are employees of the University of Oxford but were not involved in the development or production of the vaccine. J.I.B. acts as an unpaid advisor to Her Majesty's Government on COVID but does not sit on the vaccine task force and is not involved in procurement decisions. J.I.B. also sits on the Board of the Oxford Sciences Innovation, which has an investment in Vaccitech, which has a royalty from the ChAdOx1 vaccine when, if ever, it makes a profit. A.S.W., in addition to the funding mentioned above, received grants from the Medical Research Council UK during the conduct of the study. P.C.M. received funding from the Wellcome Trust. The remaining authors declare no competing interests.</p>
<p>Extended data is available for this paper at https://doi.org/10.1038/s41591-021-01548-7.</p>
<p>The online version contains supplementary material available at https://doi.org/10.1038/s41591-021-01548-7.</p>
<p>Correspondence and requests for materials should be addressed to Koen B. Pouwels.</p>
<p>Peer review information Nature Medicine thanks the anonymous reviewers for their contribution to the peer review of this work. Editor recognition statement Joao Monteiro was the primary editor on this article and managed its editorial process and peer review in collaboration with the rest of the editorial team.</p>
<p>Extended Data Fig. 5 | Protection against PCR-positives with reported symptoms. Note: data restricted to those aged 18-64 years old and the B.1.617.2-dominant period; lthc=self-reporting a long term health condition. All estimates (Vaccine effectiveness = 100% * (1-odds ratio)) were obtained from a generalised linear model with a logit link comparing to the reference category of 'Not vaccinated, not previously positive and ≥21 days before vaccination' and using clustered robust standard errors. The error bars represent 95% CIs. See Fig. 2 for effects on all PCR-positive episodes. See Table 3 for estimates of overall decline over time. See Supplementary Table 6 for estimates of VE within subgroups 14 days after second vaccination (intercept on panels below).</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f358466133"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Structural biologists have traditionally approached cellular complexity in a reductionist manner in which the cellular molecular components are fractionated and purified before being studied individually. This 'divide and conquer' approach has been highly successful. However, awareness has grown in recent years that biological functions can rarely be attributed to individual macromolecules. Most cellular functions arise from their concerted action, and there is thus a need for methods enabling structural studies performed in situ, ideally in unperturbed cellular environments. Cryo-electron tomography (Cryo-ET) combines the power of 3D molecular-level imaging with the best structural preservation that is physically possible to achieve. Thus, it has a unique potential to reveal the supramolecular architecture or 'molecular sociology' of cells and to discover the unexpected. Here, we review state-of-theart Cryo-ET workflows, provide examples of biological applications, and discuss what is needed to realize the full potential of Cryo-ET.</p>
<p>structural biology; correlative light-electron microscopy; cryo-electron tomography; image processing workflow; sample preparation workflows; structural biology in situ A comprehensive understanding of the inner workings of cells needs more than knowledge of their molecular inventories or the sum of individual molecular structures [1,2]. When cells are taken apart and molecules are released from their functional environment, all information about their interactions and context is irrecoverably lost. It is common belief now that cellular functions are not the result of random collisions of individual molecules; they rather require the concerted actions of functional modules [3,4]. Many of these exist only transiently, while others, being more stable, may be so deeply rooted in their cellular environment that they cannot be isolated without violation of their structural integrity. Hence, there is a compelling need for methods that allow visualizing the molecular architecture of cells in situ [5].</p>
<p>There is no single method that could give us the whole picture; it rather requires an 'imaging across scales' approach and the integration of data covering different length scales (Fig. 1). At one end of the spectrum are the methods providing high-resolution structures of isolated and purified molecules, such as X-ray crystallography, nuclear magnetic resonance spectroscopy (NMR), and cryo-electron microscopy (cryo-EM) single-particle analysis. In recent years, the latter method has emerged as the most versatile method unrivalled in particular when it comes to large and flexible macromolecular assemblies [6]. At the other end of the spectrum are methods allowing the visualization of whole cells and their dynamics such as super-resolution light microscopy. When combined with ion-beam block face scanning electron microscopy (FIB-SEM), striking multimodal views of large volumes can be obtained [7]. Cryo-electron tomography (cryo-ET) provides a crucial link between wholecell imaging and high-resolution structure determination. It provides molecular resolution 3D images of cellular landscapes, but is restricted in volume because larger samples must be thinned to &lt; 1 lm to render them electron transparent [8]. Otherwise, the only preparation step is vitrification by rapid freezing, yielding pristinely preserved samples. Chemical fixation and staining which bear the risk of altering the macromolecular organization of cells are avoided altogether.</p>
<p>Small objects such as viruses [9][10][11][12], isolated organelles [13], cell appendages [14][15][16], small bacteria [17], or minicells [18] can be studied in toto. For cellular structural studies, cells are grown on grids which must be non-cytotoxic. To have some control over where cells grow, avoiding, for example, areas obstructed by grid bars, micropatterning methods can be used [19] (Fig. 2). Vitrification of single cells not exceeding a thickness of ~5 lm can be achieved by plunge freezing [20]. For thicker objects, high-pressure freezing is indispensable to avoid ice-crystal formation and its deleterious consequences for cellular ultrastructure [21,22].</p>
<p>After vitrification most cells require thinning to render them electron transparent. Serial sections can be cut with a cryo-microtome, but compression artifacts and poor reproducibility have limited the use of this method [23]. Focused-ion beam (FIB)-milling has become the method of choice for compression-free specimen thinning [24,25]. By controlling the stream of Ga + ions, different thinning geometries (lamellae, wedges) can be realized. In combination with cryocompatible micromanipulators, slabs of high-pressure frozen samples can be lifted out and placed on EM grids for further thinning. This cryo-FIB lift-out method expands the range of samples that can be studied by cryo-ET to eukaryotic cells, multicellular organisms, and tissues [26]. Imaging across scales aims at a detailed and comprehensive description of the cellular space. This can be achieved by the integration of high-resolution structures into large volume data. In situ cryo-ET provides a crucial link by bridging the resolution gap (dotted region) between ex situ high-resolution structures and low-resolution large volume data. Boxes of the structural methods below the scale bar indicate the attainable resolutions (left) and scales over which information can be obtained (right). The volume of the box corresponds to a typical volume of a single tomogram. It is populated with imaginary particles of sizes typical for the various high-resolution methods (red NMR, green X-ray crystallography, blue single-particle analysis). In this scheme, the occupancy of the cellular space is underrepresented (2,3%). In reality, cells are much more crowded (occupancy 20-30% of the volume). Fig. 2. Cryo-ET workflow from sample preparation to tomogram acquisition. Sample thickness determines the vitrification method and the subsequent processing steps, producing samples with thicknesses (&lt; 0.5 µm) allowing electron imaging. Cryo-ET can be applied to a broad range of samples from isolated macromolecules to multicellular organisms. Arrows indicate possible workflow directions for different sample groups. For adhesive cells, the use of lasers for drawing patterns (micropatterning) provides control over where cells attach and can induce different morphologies. Vitrification is mostly achieved under atmospheric pressure either by plunge freezing, where samples are applied to EM grids, blotted, and plunged into a cryogen kept close to À196 °C, or microfluidic vitrification, where a rapid temperature drop is achieved by switching off the heater element between the sample and the heat sink. Thicker specimens need to be vitrified by highpressure freezing (2045 bar) and may need the addition of cryoprotectants. Micromanipulation (box) includes optional steps that can be combined depending on experimental requirements. CLEM utilizes cryo-FM to identify regions of interest and enables targeted thinning of samples using FIB-milling. Cryo-FIB lift-out allows examining parts of bulky specimens. Cryo-electron microscopy of vitreous sections (CEMOVIS) can be used for initial trimming of bulky specimens. Finally, specimens are imaged using an electron beam in a fashion similar to computer-aided tomography. The main difference is that projections of different views are obtained by rotating the sample in the beam instead of rotating the beam around the sample. Correlative light-electron microscopy (CLEM) allows for the identification and localization of features or events of interest in large cellular landscapes, and their precise targeting for FIB-milling [27][28][29][30]. Cryogenic super-resolution optical fluctuation imaging (cryo-SOFI) further improves the localization precision of fluorescently labeled proteins beyond the diffraction limit [31]. However, the signal localization precision of live cell imaging suffers from a time delay, between imaging and vitrification, on the scale of seconds. Recently, microfluidics cryofixation devices have been used to address this issue. They are able to arrest a particular cellular state within milliseconds by enabling vitrification on the imaging stage [32].</p>
<p>To obtain a tomogram of the area of interest a series of projection images is recorded, while tilting the sample in the microscope. After refining the eucentric height over the recording position, four steps need to be repeated for each tilt in the series: tilting, centering, focusing, and recording. The angular increments can be either equally spaced or closer together as the tilt angle increases [33]. The tilt series range is usually limited to AE 60°. Different mono-and bidirectional tilt schemes are used to distribute the electron dose in a preferred sequence. The now widely used dose-symmetric tilt scheme changes the tilt direction for every step, starting at 0°and climbing its way up to the maximum tilt [34,35]. The main advantage of starting data collection at low angles, where the path of the electrons through the sample is shortest, is the preservation of high-resolution information before the onset of serious radiation damage. In addition, almost symmetrical distribution of the electron dose minimizes alignment jumps notorious for bidirectional tilt schemes.</p>
<p>Because of the radiation sensitivity of frozen-hydrated biological material, the exposure to the electron beam must be minimized. Optimal exposure is dependent on both the sample sensitivity to ionizing radiation and the resolution aimed at. At exposures around 160 eÁ A À2 , gas bubbles develop causing severe structural damage [36]. Distributing the total allowable electron dose over a tilt series leads to low signal-tonoise ratios (SNR) of the individual images. In addition, for higher tilt angles the path electrons traverse through the slab-shaped samples increases, resulting in multiple electron scattering further reducing the SNR. Moreover, obtaining views over the whole 180°angular range is not possible due to the physical design of the specimen holder that obstructs the beam path at higher tilt angles. The limited angular sampling range of projections results in the 'missing wedge' of information in Fourier space that causes elongation artifacts in reconstructed tomograms parallel to the electron beam direction [37]. In transmission electron microscopes (TEM) with a dual-axis stage, a tilt series can be recorded in two directions, reducing the missing information to a missing pyramid yielding a more isotropic resolution [38].</p>
<p>An additional factor to consider when recording a tomogram is magnification, which determines the theoretically achievable maximum resolution according to the Nyquist-Shannon sampling theorem [39]. Here, one has to keep in mind that when magnification is increased the intensity of the beam needs to be increased as well, in order that the number of electrons per pixel stays the same and that frame and tilt series alignment are not compromised. Therefore, the electron exposure of the specimen, measured in electrons/ A 2 , increases quadratically with magnification; that is for a 2-fold increase in magnification, the electron exposure of the sample increases 4-fold. Selecting optimal recording parameters needs to reconcile the optimization of sampling with the need to limit the cumulative exposure.</p>
<p>The aligned tilt series data are then computationally reconstructed into a tomogram (Fig. 3) by any of the available reconstruction methods. Most commonly, weighted back-projection (WBP) [51,52] is used for its speed and preservation of high-resolution information, although direct Fourier inversion methods have certain advantages [44]. Iterative reconstruction methods yield improved contrast compared to WBP [53] and have been shown to reduce the distortions caused by the 'missing wedge' [54][55][56]. These characteristics are useful for visual tomogram interpretation and for sub-tomogram alignment [53]; however, for sub-tomogram averaging, unlike WBP, high-frequency information may be lost [53]. Recently, improved iterative methods outperformed the WBP method in the 2-3 nm resolution range [56][57][58].</p>
<p>Interpretation of structural features from reconstructed tomograms is especially challenging for crowded cellular systems and low SNR datasets. Denoising filters enhance structural features by suppressing noise, while preserving most of the signal. For example, non-linear anisotropic diffusion enhances edges [59,60], whereas more specialized filters are used to track filaments or to segment membranes [61,62]. Recently, convolutional neural networks have taken advantage of the fast detector readout to train a noise model on the basis of frames [63].</p>
<p>Denoising filters greatly facilitate segmentation. Image segmentation not only aids visual interpretation but also enables quantitative analysis, such as distance-based analysis of specific protein populations to segmented membranes [64,65]. Macromolecules can be located using templates derived from already known structures [66,67]. However, finding different molecular species in complex systems relies on the availability of large template libraries and the computationally demanding template search is usually limited to a few molecular species. Constraining the search space, where prior knowledge is available, can greatly facilitate the speed and accuracy of template matching. For example, the search space for membrane-embedded molecular complexes can be constrained to segmented membranes. Several software packages augment the labor-intensive manual segmentation [68,69]. Convolutional neural networks can be trained on segmented data [70] or to extract features automatically, in an unsupervised fashion [71]. While automation reduces user bias and increases throughput, some manual intervention is still required to set boundary conditions.</p>
<p>To avoid bias and enable detection of novel complexes, it is desirable to develop methods that are not relying on predefined templates, but rather use the tomogram data for pattern mining. Recently, a template-free detection method was developed and successfully applied to membrane-bound complexes [72] and a multi-pattern pursuit method for automated detection of frequently occurring structural features in tomograms [73].</p>
<p>When tomograms contain repetitive features, resolution can be improved by averaging multiple copies of structures of interest using methods akin to those being used in single-particle analysis. Extracted sub-tomograms are iteratively aligned and averaged to increase their SNR and resolution. For every iteration, the relative rotations and shifts between sub-tomograms and the reference structure are determined by a cross-correlation similarity metric [53]. Applying these orientations yields a new reference, which is used to refine the sub-tomogram orientations in the subsequent iteration round. Refinement is repeated until convergence or a specified iteration number has been reached. To avoid overfitting, the reference structure is filtered between iteration rounds to its estimated resolution by comparing resolution shells of two independently reconstructed volumes obtained by splitting the dataset into two halves [74]. In addition, maximum likelihood methods further reduce the risk of overfitting by allowing each sub-tomogram to simultaneously contribute to different orientations in a weighted manner [75]. To reduce the compositional and conformational heterogeneity and to further improve the averaging results, it is necessary to classify the sub-tomograms into more homogenous subsets. Different averaging and classification methods have co-evolved and among other features consider the missing wedge by performing constrained cross-correlations [67,76], provide speed improvements [77,78], and employ different classification strategies [72,[79][80][81]. Instead of finding subpopulations by global comparison, masks can be applied to specific areas for focused classification. To reduce bias, masks can be automatically generated from the local variance between sub-tomogram averages generated from subsets of the whole dataset [82]. In this way, different assembly, functional, and binding states of in situ 26S proteasomes have been successfully identified as well as two distinct oligomeric forms of tripeptidyl peptidase II [64,83,84].</p>
<p>Cryo-ET has provided insights into the structure and function of viruses [9-12,92-97], nuclear pore complexes [64,[98][99][100], ribosomes [101][102][103], coated vesicles [104][105][106][107][108][109], nucleosome arrangement in chromatin [110], cytoskeletal elements [111][112][113], bacterial secretion systems [114][115][116][117], chemotaxis [118,119], flagellar motors [120], and S-layers [121]. Obtaining information about the spatial arrangement of proteins by cryo-ET has also found use in assessing protein denaturation at the air-buffer interface for single-particle analysis [122]. To illustrate its broad applicability, examples are discussed that utilize different parts of the cryo-ET workflow, reveal insights at different length scales, and enable integration with other structural determination methods.</p>
<p>Structural studies of viruses have been driving methods developments in 3D EM since the early days [123]. Sub-tomogram averaging has been used widely for studies of pleomorphic viruses. Examples include the murine leukemia retrovirus [92,93], rubella virus [94], herpes simplex virus type I [9,95], and the severe acute respiratory syndrome coronavirus 2 [96,97]. Sub-tomogram averaging of viral lattices with high local order resulted in the first sub-nanometer resolutions for the ex situ Ebola nuclear capsid [10] and fullerene-like HIV-1 capsid [11]. For the well-behaved immature HIV-1 capsid, near-atomic 3.9</p>
<p>A resolution was achieved [12]. This was further improved to 3. 4 A by applying 3D CTF correction [50], and more recently to 3.1</p>
<p>Application of these developments has resulted in the first 4.8</p>
<p>A in situ cryo-ET structure of Caulobacter crescentus surface layer [121] (Fig. 4A). S-layers are 2D arrays of proteins that provide protection and structural support to many bacteria and archaea. Using an integrative approach combining cryo-ET, single-particle averaging, and native mass spectrometry (MS), a high-resolution structural model of the S-layer was generated. This provided insights into the S-layer lattice organization, its interaction with surface lipopolysaccharides and dependence on calcium ions, and exemplifies the progress EM has made in the past three decades, since the first electron crystallography structure of C. crescentus S-layer [124].</p>
<p>Coat protein complex I (COPI) has been extensively studied ex situ and in situ. COPI-coated vesicles transport cargo within the Golgi network and in the retrograde direction to the endoplasmic reticulum. These heteroheptameric complexes assemble on the surface of the cis Golgi cisternae where they are recruited by Arf1 to facilitate the formation of membrane buds for transport. Cryo-ET of ex situ assembled COPI vesicles from mouse proteins revealed flexibly linked trimeric assemblies as the basic modules covering the vesicle surface [104]. At 13 A the basic molecular architecture of the COPI was established [105] (Fig. 4B). Taking advantage of improved data acquisition schemes and local alignment, resolution was further improved to 9</p>
<p>A. This allowed refinement of the COPI architecture and provided insights into the coatomer formation and disassembly [106].</p>
<p>In situ studies by cryo-ET FIB-milled lamellae from Chlamydomonas reinhardtii provided the native COPI structure at 20</p>
<p>A [107]. Comparison of the independently reconstructed in situ COPI structure showed high similarity to the ex situ COPI structure, confirming that reconstitution faithfully recapitulated the in situ scenario. In contrast to the empty ex situ vesicles, however, the luminal side of native COPI contained additional density indicating bound cargo or cargo receptors. Interpretation of the COPI in the context of their native environment provided insights into the COPI morphology and apparent half-life in the cell. As the COPI progress from the cis to trans Golgi, each time they bud off, uncoat, and fuse with the next cisterna their morphology is altered. The vesicle diameter, membrane thickness, cargo, all reflect the characteristics of the parent Golgi membrane, whereas the vesicle coat itself remains structurally unchanged. These insights could not have been obtained from a reconstituted system alone. On the other hand, understanding the COPI architecture at the secondary-structure level was only possible from the ex situ COPI data and the integration of atomic details provided by crystallographic methods. This example illustrates how different levels of information can be meaningfully integrated to provide a comprehensive picture of a complex system.</p>
<p>In situ cryo-ET of poly-Gly-Ala aggregates associated with amyotrophic lateral sclerosis and frontotemporal dementia provide an example of how alteration of the intracellular environment affects the local concentration of other molecular species [125]. CLEM was used to locate fluorescently tagged poly-Gly-Ala aggregates in transfected rat neurons and to target them for FIBmilling. Cryo-ET revealed networks of poly-Gly-Ala composed of polymorphic ribbons (Fig. 4C). The aggregates are densely populated with a single molecular species, the 26S proteasome. Compared with the surrounding cytosol, the concentration within the aggregate is increased ~30-fold. Given the local abundance of proteasomes, sub-tomograms with a resolution of ~10</p>
<p>A could be generated and classification allowed to distinguish between conformations corresponding to the basic functional states: the ground state and the substrate-processing state [126]. Mapping these two conformations back into the tomograms of the segmented aggregate material showed that the proteasomes identified as being engaged with substrate are invariably in close contact with the poly-Gly-Ala ribbons. This suggests that they are engaged with the substrate, but fail to degrade it. Becoming stalled upon interaction with the aggregate material severely compromises the cellular protein quality control system.</p>
<p>The transition from electron tomography of resin-embedded and metal-stained cellular samples to low-dose imaging of vitrified specimens was enabled by automation of the data acquisition [127][128][129]. Since demonstrating the feasibility of cryo-ET [130], a workflow has been established that enables structural studies in situ to be performed with a wide range of cellular systems. However, throughput is still a limitation when large datasets are needed for quantitative analyses and for sub-tomogram classification and averaging. In single-particle analysis, purification of the molecules of interest results in a massive increase in concentration and the number of particles is almost never a limitation. In in situ cryo-ET, the natural abundance of a molecule in the cell determines the copy numbers per tomogram. Moreover, in situ a higher degree of heterogeneity may be encountered, as different functional and conformational states often coexist. Imaging of cellular samples has a considerable discovery potential for mapping macromolecular interactions, but often requires collecting more data than for purified specimens. For example, to perform the structural analysis of the COPI vesicles, 61 and 60 tomograms were collected for both ex situ and in situ datasets. However, the in situ dataset contained four times fewer copies of COPI, despite recording over an area twice as large. Another factor reducing the yield of in situ cryo-ET is often the lack of high-contrast intracellular fiducial markers. As a result, half of the in situ COPI tomograms had to be discarded due to unacceptable alignment errors resulting from variations in sample quality. To achieve a comparable in situ dataset would require the acquisition of ~250 tomograms even in a scenario where every tomogram would contain at least one Golgi apparatus. This requires preparation of numerous lamellae using Ga + FIB-milling, which is currently a time-consuming manual process. For thicker specimens, the milling time scales in proportion with the amount of material that needs to be ablated. At the current throughput of typically 5-10 lamellae per day, the sample preparation is slower than the recording capabilities of TEMs. Many steps of the milling process are repetitive and have been automated in the material sciences; this is not yet common in cryo-FIB-milling [131]. All steps of the workflow, from data acquisition to data analysis will benefit from task automation wherever this is possible. While automation would provide some remedy, Ga + FIB-milling is intrinsically limited by low beam currents. Xe + plasma FIB offers faster sputtering rates and two orders of magnitude higher beam currents [132] and is a promising alternative. Together with an automated milling procedure preparation of up to 5 lamellae/ hour is now possible [133].</p>
<p>Thicker samples present additional challenges. First, vitrification of ~5 µm samples or beyond cannot be achieved by plunge freezing. High-pressure freezing devices are limited to ~150 µm thickness of material or alternatively up to a few hundred µm with doublesided cooling devices [22]. With microfluidic freezing platforms, the sample thickness is given by the channel depth of 20 µm [32]. Freezing of bulk specimens has not seen substantial improvements in the past two or three decades and would need revisiting, to make tissue vitrification routine. Second, finding the region of interest in the block of ice and trimming it down requires a combination of cryo-fluorescence microscopy (FM), FIB-milling, and FIB lift-out. To enable precise 3D targeting of features of interest in an automated manner, such an approach requires the development of suitable models to incorporate the image information into deep learning approaches [134]. Correlating fluorescence and electron microscopy is relatively straightforward with thin samples. Correlation is aided by fiducial markers on the sample surface [135] and has recently become integrated into an automated workflow [131,136]. But this approach would need some adaptation for correlating features in larger frozen volumes.</p>
<p>Currently, the CLEM workflow requires the transfer of samples between specialized equipment for FM, FIB-milling, and finally TEM. Ice contamination is difficult to avoid during sample transfer. While being acceptable in the early sample preparation steps, after preparation of lamellae it should be avoided; even minor contaminations can affect data quality, while ice crystals obstruct the beam and reduce areas suitable for tomogram acquisition. Moreover, any sample deformations after FM affect the signal correlation. This can be problematic during the final stages of FIB-milling where bending of lamellae is not uncommon and often requires to stop the thinning process prematurely. Tension buildup resulting from large temperature changes during vitrification of materials with different expansion coefficients (carbon supports on metal grids) can be reduced by milling micro-expansion joints next to cells, but this can lead to displacement of the specimen and interfere with correlation [137]. Alternatively, all-gold supports do not suffer from different expansion coefficients, but their mechanical stability is much lower [138].</p>
<p>At the current resolution, FM is mainly used for targeting areas of interest and not for correlative interpretation. However, super-resolution FM correlative approaches have the potential to contribute to molecular identification. Increased fluorophore photostability at cryogenic temperatures can provide the needed photon counts for their precise localization also in samples considered too thick for EM. Recently, imaging inside a He-cooled cryostat enabled correlative super-resolution FIB-SEM to reveal identities of 100-200 nm large vesicles inside whole cells [7]. To fully harness the identification power of super-resolution methods it would be advantageous to close the resolution gap down to ~30 nm or below, which is already possible for fixated cells with interferometric photoactivated localization microscopy imaging [139]. For vitrified specimens localizing microtubule bundles inside human bone osteosarcoma epithelial cells (U2OS) is a recent achievement that required addressing the increased drift of cryostages and devitrification induced by the excitation laser [140].</p>
<p>Integrating FM and FIB-milling into one instrument would facilitate switching between different imaging modalities over different scales and eliminate the risk of contamination during sample transfer. Such an instrument would not only open up new possibilities for workflow optimization but would also help develop new strategies for dealing with thick specimens.</p>
<p>The acquisition of tomographic data is considerably slower than data acquisition for single-particle cryo-EM. To acquire a tomogram with 41 projections around 32 min are required using the dose-symmetric tilt scheme [35], whereas anywhere between 100 and 200 micrographs can be recorded in the same time for single-particle analysis. Overhead time is spent on accurate focusing and tracking to compensate the movement of the stage between tilting steps. In addition, the requirements for precise tracking and stage settling increase with magnification, leading to even longer acquisition times. New single-tilt axis holders reduce the stage settling time practically to zero and obviate the need for tracking. This considerably speeds up acquisition of a dose-symmetric tilt series to under 5 min, but the effect on high-resolution sub-tomogram averaging still needs further investigation [141]. Alternatively, piezoelectric-driven stages provide superior precision (14 pm) and ultra-low drift (11 pmÁs À1 ), but they are not yet available commercially and would require some redesign of the current grids [142].</p>
<p>Setting up acquisition areas will also require automation to keep up with faster tomogram recording rates. Automated data acquisition of in situ samples is challenging, because of the high variability of lamellae content and could benefit from machine learning approaches. For ex situ samples the task is simpler, since the grid support raster can be used to target areas, similar to single-particle acquisition.</p>
<p>Identification of molecular complexes in complex in situ environments is challenging, because the inventory of molecular species spans several orders of magnitude in size and abundance. For example, a commonly cultured human cell line is populated with over 10 000 different proteins ranging in copy numbers from anywhere below 500 to over 20 million copies per cell [143]. Attempting to find molecular complexes in a template-based approach would require the availability of comprehensive template libraries, but often templates do not exist. For an approach toward building a functional model of the whole cell, the number of available structural and homology models with a high sequence coverage was recently estimated for the pancreatic b-cell [144]. The estimates show that structures exist for 28% of the 11 700 estimated protein species and while these numbers may be discouraging for a template-based approach they suggest that there is considerable potential for template-free approaches. To achieve a complete structural and spatial representation of the cell's proteome, that is the goal of visual proteomics [145], further developments of pattern mining methods will be necessary [72,73,146]. However, with decreasing size of molecular species, it becomes increasingly difficult to detect particles in noisy tomograms and to reliably align and classify them. Thus, smaller and less abundant complexes may escape detection and analysis. The same applies to single-particle cryo-EM, which relies heavily on averaging to improve the resolution and SNR, just as sub-tomogram averaging does. In practice, however, single-particle cryo-EM reconstructions of &lt; 100 kDa proteins are possible [147], while molecular complexes smaller than 500 kDa are currently considered small for subtomogram averaging. To assess the detection rate of template matching by a scoring function, cryo-ET has been used in combination with quantitative MS in Leptospira interrogans [148].</p>
<p>One way to extend the lower-end size-limit in cryo-ET is to use a phase plate for contrast enhancement. Positioned at the diffraction plane, a phase plate converts the information imprinted on the phase of the electron wave into detectable amplitude modulation, by inducing a p/2 phase shift between the unscattered electron wave relative to the scattered electron waves. This enables data collection close to focus and provides substantial contrast transfer at low spatial frequencies, which is advantageous for recognizing and aligning smaller objects. Despite the success of the Zernike phase plate (ZPP) in light microscopy, the precision required to manufacture analogous devices for TEM delayed the realization of early proposals by decades [149]. Higher contrast and similar resolution to conventional TEM were obtained with the thin-film ZPP [150]. However, the ZPP was impractical for routine use, because of its short lifespan, it required precise centering of the hole, and automated data acquisition was not achieved [151]. Moreover, the central hole where the direct beam passes unaffected caused fringes in the images and its diameter determined the onset of the phase shift (cut-on periodicity). These problems were overcome with the Volta phase plate (VPP), which also uses a thin amorphous carbon film, but relies on the electron beam to induce the phase shift and offers a practical solution to many shortcomings of earlier designs [151,152]. Since there is no hole, the need for centering is obviated and the only requirement is the precise tuning of the TEM. The VPP regenerates over time and has a lifespan of years, if handled appropriately. More importantly, the VPP is compatible with automated data acquisition, and with software advances that included CTF phase fitting and correction, larger datasets could be acquired close to focus. This resulted in reconstructions of 20S proteasomes at 2.4</p>
<p>A and enabled reconstructions of hemoglobin (64 kDa) at 3.2 A [153,154]. At the theoretical lower-end size-limit for single-particle analysis, images and 2D class averages of myoglobin (17 kDa) showed the stunning improvement in contrast the VPP provides [154]. Recently, using the VPP in cryo-ET the 52 kDa streptavidin became visible, although no sub-tomogram averaging was attempted [155]. However, a problem of using the VPP for lamellae is charge buildup that causes local differences in phase contrast and limits its usability. An additional thin metal coating mitigates this problem and has provided impressive views of the nuclear periphery [156]. For Dictyostelium cells milled using a wedge geometry, beam-induced charging was not an issue. VPP imaging over the resulting thickness gradient revealed the detailed structure of actin networks and enabled tracing of branch structures within the actin waves also in ~300 nm thick regions [157]. The boost in contrast from the VPP can be a decisive advantage to resolve features of cellular structures that require imaging in thicker areas. However, for extensive sub-tomogram averaging aiming for achieving high resolution, the use of VPP brings additional challenges. For tomography tilt series acquired close to focus, VPP images render CTF fitting and correction difficult, limiting the attainable resolution to the first CTF zero. Nevertheless, the contrast enhancement is advantageous and often the only way to visualize small non-repetitive features in tomograms.</p>
<p>In a novel promising approach, phase shift can be generated by sufficiently strong laser fields, taking advantage of the ponderomotive force [158]. The laser phase plate does not suffer from signal loss inherent to thin-film phase plates and provides a stable phase shift that is tunable on-demand. However, at the moment the laser field strength is able to induce a p/2 phase shift of 80 keV electrons and further developments are needed before its use can be tested on 300 keV electrons commonly used in cryo-ET [159].</p>
<p>Distortions resulting from the missing information at higher tilts beyond 60°are a fundamental problem in cryo-ET [37]. One way to approach this is to fill the frequency space by averaging sub-tomograms of objects in different orientations [160]. Another possibility is to optimize the information content in one tomogram. Computationally it is possible to infer what the missing wedge data would be, but it is not possible to recover unobserved data [161]. Obtaining tomograms over the full angular range has been successful for small bacteria trapped in glass capillaries [162]. To extend the angular range, circular FIB-milling patterns could be used to make cylindrical specimens at the expense of a much reduced volume. However, to precisely align cylindrical specimens for tilt series acquisition would be challenging and might render this approach impractical.</p>
<p>Another challenge in cryo-ET is the low SNR of the recorded images resulting from the electron dose restrictions. In light of recent technological improvements in electron detection and software analysis, Peet et al. [163] set out to accurately estimate the optimal electron energy per induced radiation damage for cryo-EM. Their results confirm that the elastic crosssection contributing to signal in the TEM images increases proportionately faster than the inelastic cross-section contributing to radiation damage, and accurate measurements suggest that for thinner samples of up to 600 A using lower energy electrons (100 keV) would result in up to 25% improvement in information extraction, if appropriate detectors existed. For tomography the ability to image thicker samples would be desirable, but there is a limited advantage of increasing the acceleration voltage. The gain in penetration depth from 100 to 300 kV is 2fold, but increases only an additional 1.5-fold from 300 kV to 1.2 MV as it goes along with a steep increase in the equipment costs and a higher likelihood of knock-on damage [164]. Nevertheless, the suggested direction is interesting, because it challenges the paradigm, that the sample thickness should be adjusted for TEM imaging. With automated tuning of microscopes, it would become possible to switch between different acceleration voltages and adjust the microscope to the specimen thickness to achieve optimal information transfer. The same authors also discuss the benefit of chromatic aberration (Cc) correction that would render inelastically scattered electrons usable for phase contrast and enable an overall increase in the SNR.</p>
<p>An idea put forward by Danev et al. [165] is to use defocus modulations to optimally extract sample information. Inserting a small electrostatic lens at the back focal plane would allow control and fast tuning of the defocus parameter during acquisition, which can be used as an optical dose-dependent filter that follows the gradual demise of high-resolution structural features. For tomography this would allow to more evenly fill the frequency space by combining close-tofocus high-resolution information with high-defocus information for more reliable CTF determination and tilt series alignment within one movie frame sequence.</p>
<p>Cryo-ET has the unique potential to bridge the gap between the cellular and molecular worlds. Ideally, it would provide structural information over large cellular volumes. But the quest for high-resolution cryo-ET is incompatible with imaged volume. Imaging at high magnifications comes at the cost of reducing the field of view and imaging thick samples results low-quality data. Considering that optimal specimen thickness for 300 keV electrons is around 100 nm [163], such tomograms show a small fraction of the cellular volume. For example, a 100 nm thin lamella of a typical baker's yeast with a diameter of 5 µm would contain ~0.22% of its total volume, if imaged at 2.5</p>
<p>A/pixel on a 4 k detector. Large assemblies, such as nuclear pore complexes or vesicles, might not even fit in their entirety into 100 nm thick slabs, compromising the benefits. Depending on the biological question being addressed, often a compromise to record over a larger volume and to accommodate the features of interest at the cost of resolution is advantageous. To ensure highresolution snapshots of the cell's interior are representative of the cell's state and to avoid missing rare events of interest, requires acquisition of many tomograms. Considering the increasing throughput in tomogram acquisition it is not unreasonable to consider covering large areas in a tessellated cryo-ET approach, where tomograms would be in silico stitched together to represent the entire volume of thinned specimens. This means a 100-fold increase of the imaged area compared to a single tomogram for a 12 by 12 µm lamella, using the same imaging conditions as above. While beam-induced structural changes will present a challenge for implementing this approach to cryo-ET, such approaches were already successfully applied to plastic-embedded sections of, for example, U2OS cells [166]. Although overlapping regions will have higher electron exposures, the central parts of tomograms would retain the high-resolution information for subtomogram averaging.</p>
<p>While such ideas are exciting in theory, practical solutions have to be found.</p>
<p>Cryo-ET has made great progress over the last decade, which is reflected by the increasing number of successful applications. It has provided accurate views of unperturbed cellular landscapes, revealing their native molecular organization. For a long time, studying isolated molecular complexes was the only possible way of obtaining structural information for a mechanistic understanding of their functions. However, technology advances in cryo-ET now enable in situ structural studies at 3-4 nm resolution and, when applying averaging methods, sub-nanometer resolutions can be achieved. We are just beginning to realize the potential of cryo-ET as a tool for studying macromolecular crowding. Phase transitions in lipid droplets can be already detected and attributed to different cellular states [167], but the information contained in tomograms, when properly calibrated, could be used for measuring systematically local density fluctuations inside cells. This holds the potential to detect phase separation phenomena and map regions that define membraneless organelles [168]. While in favorable cases cryo-ET can provide near-atomic resolution, even at nanometer resolution, the cellular environment offers a tremendous potential to discover unexpected scenarios. An increasing number of reports have revealed that macromolecules are organized into functional microcompartments at the nuclear pore basket [64] or the endoplasmic reticulum [65], highlighting the importance of in situ studies. However, the difficulty of in situ cryo-ET lies in mining the rich information contained in the tomograms. Cellular complexity presents a challenge to identify macromolecules when sub-tomogram averaging fails to provide the resolution for unambiguous identification. Integrative approaches have shown success where individual methods could not provide the full picture and helped generate pseudoatomic models of large assemblies such as the 26S proteasome [169] or the nuclear pore complex [170]. In proximity to the already mapped assemblies, interacting smaller proteins could be modeled based on distance constraints provided by cross-linking MS data. There is no reason to believe that the integrative modeling approach could not be expanded to tomograms. In fact, a tomogram spanning ~1 µm 2 and up to a few hundred nm in thickness can provide a structural framework to integrate functional data and for docking high-resolution atomic structures into their cellular context. In addition, integrating MS data allows crossvalidating tomographic results. Quantitative MS has the possibility to provide the ground truth of protein copy numbers, which could be used to assess the number of detected complexes and those that escaped detection. On a larger scale, cryo-ET can itself be integrated into larger volumes provided by FIB-SEM to provide pictures of whole cells. There is still a lot of potential to improve the workflow of sample preservation, data recording, information extraction, quantitative interpretation, and finally data integration with other methods. Developments in instrumentation and image analysis will undoubtedly continue to push the boundaries forward. They will help advance our understanding of known structures and lead to the discovery of new structural patterns orchestrating cellular functions.</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>FEBS Letters 594 (2020) 3243-3261 ª 2020 The Authors. FEBS Letters published by John Wiley &amp; Sons Ltd on behalf of Federation of European Biochemical Societies</p>
<p>We thank Vladan Lu ci c for valuable discussions and critical reading of the manuscript. We are grateful to Miroslava Schaffer for the cryo-FIB lift-out image, and to Ben Engel and Qiang Guo for providing the in situ tomography images. Open access funding enabled and organized by Projekt DEAL.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f555917018"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>80% for moderate tooth wear, leading to the conclusion that these are common conditions in the Dutch adult population. Severe tooth wear (prevalence 6%) may however be characterized as rare. A tendency was found for there to be more tooth wear in older age groups, in men as compared with women, in persons with lower SES, and in the present survey as compared with the previous one.</p>
<p>, due to the growing consumption of acidic drinks and food. Nevertheless, both mechanical and chemical wear should be taken into account when studying tooth wear.</p>
<p>It is important to distinguish between the qualifying and quantifying aspects of the assessment of tooth wear. Many grading scales are available for the clinical quantification of hard tissue loss [Ganss and Lussi, 2014]. Unfortunately, some grading scales incorporate information about the etiology, such as attrition, abrasion, and erosion. As a result, the quantifying and qualifying aspects of the assessment process may be confused. A list of clinical appearances that can be used to qualify tooth wear -that is, to indicate which types of tooth wear are present -has been proposed by Gandara and Truelove [1999].</p>
<p>Large-scale cross-sectional surveys of oral health among Dutch adults were performed in 2007 and in 2013, where tooth wear was one of the factors assessed. Both the 2007 survey [Schuller et al., 2009] and the 2013 survey [Schuller et al., 2014] made use of a grading scale that is suitable for quantifying all types of tooth wear, though it may be noted that different scales were used in the two surveys.</p>
<p>The results of the various studies in this field are difficult to compare because of the large number of different grading scales in use [Margaritis and Nunn, 2014]. Moreover, most studies have been performed on children, adolescents, and young adults [Jaeggi and Lussi, 2014]. According to the last-mentioned authors, it is nevertheless true that tooth wear is a common condition and there is evidence that its prevalence is growing steadily, especially in younger age groups. They go on to cite reports that males show more tooth wear than females, and that there is a tendency for older people to show more lesions.</p>
<p>The aim of the present study was to assess the prevalence of tooth wear in the Dutch adult population in different age groups, for both genders, in different socioeconomic classes, and for different types of teeth. These results were compared with the outcomes of the above-mentioned 2007 study.</p>
<p>Data were collected from April 2013 to November 2013 as part of a large survey of oral health and preventive behavior among Dutch adults (divided for the purpose of the study into 5 age groups: 25-34, 35-44, 45-54, 55-64, and 65-74 years). The survey was performed in 's-Hertogenbosch, a medium-sized city in the southern Netherlands that can be considered to be representative of the general Dutch population in terms of sociodemographic in-dicators [Truin et al., 1987]. Health insurance companies were asked [under the authority of the National Health Care Institute (Zorginstituut Nederland)] to provide the names and addresses of their clients. A total of 87,075 names and addresses was provided. A stratified sample of 6,904 people (including edentulous individuals) was selected. All those eligible to participate in the study were invited to visit a mobile dental examination facility temporarily located in their city of residence. Eighty-two percent of those invited to participate (5,661 individuals) stated that they did not wish to take part (51% of this group were male, 36% had higher education, 77% indicated that they did not have enough time or interest to participate, and 10% were afraid of dental treatment). Individuals without any teeth at all (n = 118) were the only ones excluded from the study. This left a study population of 1,125 adults (56% of whom were female). This study was judged by the Central Committee on Research Involving Human Subjects not to fall under the provisions of the Medical Research Involving Human Subjects Act. It was furthermore decided that the study met all requirements of the Personal Data Protection Act (Approval No. m1501261).</p>
<p>All participants filled in a questionnaire giving details of their sociodemographic and dental status, and their dietary and oral hygiene behavior, and underwent an oral health assessment in a dental chair, performed with the aid of halogen light, a mirror, a blunt probe, and compressed air. To make the examination less demanding for the participants, tooth wear was scored only on all elements of the first quadrant (the molars, premolars, cuspids, and incisors on the right side of the maxilla) and the third quadrant (all teeth on the left side of the mandible), or only in the second quadrants (all teeth on the left side of the maxilla) and the fourth quadrant (all teeth on the right side of the mandible). The first and third quadrants were examined in participants whose serial number (assigned at random to each participant) was odd, while participants with an even serial number had their second and fourth quadrants examined. Wisdom teeth were excluded from the survey. The examinations were performed by experienced, calibrated dentists, and internal validity was assessed by performing a second measurement on 133 participants (8.3%) [Schuller et al., 2014].</p>
<p>The above-mentioned 2007 study was performed in a comparable population sample, also in 's-Hertogenbosch [Schuller et al., 2009]. A 5-point ordinal occlusal/incisal grading scale was used there (0 = no loss of enamel surface characteristics; 1 = loss of enamel surface characteristics; 2 = loss of enamel, exposing dentin over less than one third of the surface; 3 = loss of enamel, exposing dentin over more than one third of the surface; 4 = complete loss of enamel) [Smith and Knight, 1984]. In the present survey, tooth wear was measured on another 5-point ordinal occlusal/incisal grading scale (0 = no wear; 1 = wear confined to enamel; 2 = wear into dentin &lt;1/3 of crown height; 3 = wear into dentin &gt;1/3 but &lt;2/3 of crown height; 4 = wear into dentin &gt;2/3 of crown height [Lobbezoo and Naeije, 2011]; fig. 1 ). These grades were given the following descriptive names: grade 1 = mild, grade 2 = moderate, grade 3 = severe, and grade 4 = extreme. In order to be able to compare the results of these two surveys, all tooth wear grades were converted into a 'skeleton index', as proposed by Van't Spijker et al. [2009]</p>
<p>In both surveys (2007 and 2013), participants were stratified in 2 groups on the basis of socioeconomic status (high-SES and low-SES) and in 5 age groups (25-34, 35-44, 45-54, 55-64, and 65-74 years). Education level was used as a proxy for SES and was divided into 'low' (up to secondary vocational education) and 'high' (higher than secondary vocational education).</p>
<p>In 2013, a total of 1,125 respondents from the original stratified sample of 6,904 persons invited to participate in the survey filled in the questionnaire and underwent the clinical examination; this corresponds to a response rate of 16.3%. The response rate in 2007 was 15.5% (1,018 out of an initial sample of 6,560). Female respondents made up 56.4% of the study population in 2013, and 56.0% in 2007. The percentages of respondents with low SES in the age groups 25-34, 35-44, 45-54, 55-64, and 65-74 years were 27, 38, 47, 58, and 54%, respectively, in 2013, and 38, 52, 46, 61, and 70% in 2007.</p>
<p>Mean tooth wear scores increased with age, from 1.67 in the youngest age group (25-34) to 2.07 in the oldest age group (65-74; table 1 ). The mean score for the entire population was 1.90 ( table 1 ). Higher individual scores were found in older age groups (χ 2 = 152.0, p &lt; 0.001). Further analysis of the data showed that this observation applied to all types of teeth: molars (χ 2 = 12.57, p = 0.014), premolars (χ 2 = 87.34, p &lt; 0.001), cuspids (χ 2 = 140.39, p &lt; 0.001), and incisors (χ 2 = 131.37, p &lt; 0.001).</p>
<p>The mean tooth wear scores were 2.00 for men and 1.81 for women (Z = 7.20, p &lt; 0.001; table 2 ). A similar difference was found in all age groups; only in the 45-to 54-year age group was this difference not significant. The higher tooth wear scores in men were observed in all types of teeth (molars: Z = 2.76, p = 0.006; premolars: Z = 4.54, p &lt; 0.001; cuspids: Z = 9.91, p &lt; 0.001; incisors: Z = 7.15, p &lt; 0.001).</p>
<p>There is a tendency for low-SES participants to have higher mean tooth wear scores, especially in the age groups 55-65 and 65-74 years; in the youngest age group (25-34 years), low-SES participants actually show slightly lower tooth wear ( table 1 ). However, this difference was only statistically significant for the study population as a whole (Z = 3.52, p &lt; 0.001). Further analysis of the data revealed that the difference between SES groups could be observed in molars (Z = 2.47, p = 0.014), cuspids (Z = 4.65, p &lt; 0.001), and incisors (Z = 2.60, p = 0.001). No significant differences were found in premolars (Z = 0.93, p = 0.35).</p>
<p>Tooth wear data from the 2007 and 2013 surveys are presented in table 3 . It will be seen that mean tooth wear scores were higher in 2013 than in 2007 for all types of teeth. This difference was found in molars (Z = 9.89, p &lt; 0.001), cuspids (Z = 19.25, p &lt; 0.001), and incisors (Z = 14.25, p = 0.007), and in all age groups.</p>
<p>The aim of the present study was to assess the prevalence of tooth wear in the Dutch adult population as a function of various factors. More tooth wear was found in older age groups than in younger age groups (for all types of teeth); men showed more tooth wear than women (again, for all types of teeth), and low-SES participants showed higher tooth wear scores than high-SES participants, especially above the age of 55 (for all types of teeth, except premolars). In addition, mild and moderate tooth wear turned out to be common conditions, with prevalences of 13 and 80%, respectively, while severe tooth wear (with a prevalence of 6%) was rare. Comparison of the outcomes of the 2007 and 2013 surveys, which were performed in similar populations, showed higher scores in all age groups for molars, cuspids, and incisors in 2013.</p>
<p>One limitation of these two surveys is that all participants were recruited from a single Dutch city ('s-Hertogenbosch), which may restrict the external validity of the tooth wear prevalence data obtained. However, 's-Hertogenbosch was found to be representative of the Netherlands as a whole in 1987 [Truin et al., 1987]. Since the demographics of the city (such as age distribution, percentage of migrants, and percentage composition of households) are still comparable with those for the Netherlands as a whole [as may be seen by consulting Statline (Statistics Netherlands) and Eurostat], it is reasonable to assume that 's-Hertogenbosch is still quite representative of the country as a whole. Of course, it remains true that there may be some regional differences concerning such matters as SES, levels of oral health, and accessibility of oral health professionals.</p>
<p>There are only relatively few epidemiological studies on tooth wear that examine tooth wear in older age Fares et al., 2009], influence of SES not determined), and a survey in the USA (Okunseri et al. [2015], 3,773 participants, 6 age groups, modified TWI). Factors deter-mining the choice of grading scale, the effect of gender and SES on observed tooth wear, and observed prevalence over time will be discussed below.</p>
<p>As mentioned above, many different grading scales have been used in the various studies of tooth wear, which renders an unequivocal comparison of these studies difficult [Margaritis and Nunn, 2014]. Each of these grading systems has its own advantages, disadvantages, and limitations. There is a strong need for a merged, widely used grading system. A group of experts [Bartlett et al., 2008] recently designed the BEWE, which has the potential to become such a widely used grading system. However, it was decided not to use the BEWE in the present survey, because we wanted to assess tooth wear as a whole and not only erosive tooth wear. Furthermore, it was decided to gather separate information on different types of teeth (molars, premolars, cuspids, and incisors) and not to sum the scores over each sextant as is done in the BEWE. In addition, it may be impossible to calculate the BEWE in elderly people because of missing teeth in one or more sextants. Finally, the Lobbezoo and Naeije grading scale is widely used in the Netherlands, and the clinicians who performed the examination in our 2013 survey were already familiar with it, so this is the one we ultimately decided to use. The 2007 survey in 's-Hertogenbosch used the tooth wear index (TWI), a scale that grades the amount of surface area in the horizontal plane involved in the wear. This allows the grading of wear in the early stages, but grading of loss of clinical crown height (in the vertical plane) is essential for further differentiation of the ongoing progress of tooth surface loss. This has already been mentioned by other investigators studying tooth wear in elderly people [Donachie andWalls, 1995, 1996] and was the reason why the scale used in the 2013 survey also grades tooth surface loss in a vertical direction [Lobbezoo and Naeije, 2001]. This allows more stages of clinical crown height loss to be differentiated, which was deemed essential since it was expected that tooth wear would be severer in the older age groups.</p>
<p>No matter what grading scale was used, all studies concluded that tooth wear increases with age. Since tooth wear is an irreversible process, this finding was to be expected and is in line with a review of the prevalence of tooth wear in adults [ Van't Spijker et al., 2009].</p>
<p>It was also a common finding in all studies that men show more tooth wear than women; no explanation for this has yet been given in the literature. There is no evidence that the tooth structure differs between men and women, or that there are any differences in the composition of saliva. Concerning the diet, there is evidence that men consume more acidic drinks than females, both in adolescents [Hasselkvist et al., 2016], and in adults [Heuer et al., 2015], resulting in more (chemical) tooth wear. In addition, it might be hypothesized that men's masticatory muscles exert higher forces (for a review, see Van der Glas et al. [1996]), leading to more mechanical tooth wear.</p>
<p>Studies that considered the effect of SES on tooth wear showed equivocal findings. Some reported higher tooth wear scores in low-SES groups [Donachie and Walls, 1995;Okunseri et al., 2015], which is largely in line with the present findings, while others reported no difference [Kelly at al., 2000;Steele et al., 2011;Vered et al., 2014]. It could be hypothesized that people belonging to the lower-SES groups know less about the health aspects of their diet [Sichert-Hellert et al., 2011] and may therefore tend to eat more erosive food.</p>
<p>Striking variations were reported in the observed prevalence of tooth wear found in different studies. Some researchers came to the conclusion that as many as 75% [Kitasako et al., 2015], or at least half of the population studied [Vered et al., 2014], did not show erosive tooth wear, while others stated that mild and moderate tooth wears are common conditions but that severe tooth wear is rare [Hugoson et al., 1988;Smith and Robb, 1996;Kelly et al., 2000;Steele et al., 2011;Okunseri et al., 2015]. This latter view is in line with the present study as well as with that expressed in a recent review, in which the authors concluded that tooth wear is a common clinical finding [ Van't Spijker et al., 2009]. The observed differences in the prevalence of tooth wear can perhaps be explained by the distinction drawn between erosive (chemical) tooth wear and mechanical tooth wear, in addition to the fact that the reliance on dentin exposure to indicate the extent or severity of tooth wear is not reliable [Holbrook and Ganss, 2008] together with the difficulty of diagnosing exposed dentin [Ganss et al., 2006].</p>
<p>A further aim of this study was to estimate the variation of the prevalence of tooth wear with time, which was done by comparing the results of the 2007 and 2013 surveys. This led to the conclusion that mean tooth wear scores increased between 2007 and 2013 for all types of teeth that were included in both surveys. In fact, the present study may have underestimated this increase, since the percentage of individuals with low SES was lower in 2013 than in 2007, and the present study indicates a slight negative correlation of SES with tooth wear.</p>
<p>To our knowledge, the only comparison of the prevalence of tooth wear in a comparable survey over a considerable time span was performed in the UK. A 2009 survey [Steele and O'Sullivan, 2011] reported a higher prevalence of tooth wear than a 1998 survey [Kelly et al., 2000]. The prevalence of any wear had increased to 77% in 2009, and that of moderate tooth wear to 15%, while severe wear remained rare (2% in 2009) [Kelly et al., 2000;Steele and O'Sullivan, 2011]. The two Dutch surveys of 2007 and 2013 represent the second time that such a comparison has been made. The prevalence of mild tooth wear found here had increased to 13% and that of moderate tooth wear to 80%, while severe tooth wear remained rare (6%). It is difficult to compare the UK surveys with the Dutch ones, since the UK studies only recorded the observed wear of the 6 upper front teeth and the most affected surface of each of the 6 lower anterior teeth, while the Dutch surveys examined the occlusal/incisal surfaces of a variety of different types of teeth.</p>
<p>The two Dutch surveys showed that tooth wear in molars, cuspids and incisors had increased between 2007 and 2013 in all age groups. It can be hypothesized that the overall higher tooth wear scores were due to greater chemical wear [Johansson et al., 2012]. Unfortunately, the oral health survey of which the tooth wear study formed a part did not allow the collection of detailed information on the diet of the participants or the possibility that some of them might be suffering from gastroesophageal reflux disease. Hence, it was impossible to as-certain whether these extrinsic or intrinsic causes or erosive tooth wear played a role in determining the findings of this survey. The same is true of possible etiological factors for mechanical tooth wear, like parafunctional activities.</p>
<p>Prevalence data show that mild and moderate tooth wear is a common condition in the Dutch adult population, while severe or extreme tooth wear is rare. The prevalence of tooth wear in the Dutch adult population has increased between 2007 and 2013. More tooth wear was found in older age groups (for all types of teeth), and in men as compared with women (for all types of teeth). Persons with lower SES showed more tooth wear than those with a high SES.</p>
<p>Caries Res 2016;50:543-550 DOI: 10.1159/000447020</p>
<p>This research was financed by the Dutch National Health Care Institute (ZIN).</p>
<p>P.W., E.J.H.V., F.L., and A.A.S. conceived and designed the study. E.J.H.V. and A.A.S. performed the clinical examination. P.W., E.J.H.V., C.M.V., and A.A.S. analyzed the data. P.W. and E.J.H.V. wrote the paper. C.M.V., F.L., and A.A.S. subjected the main intellectual content of the manuscript to critical review. All authors read and approved the final manuscript.</p>
<p>The authors declare no conflicts of interest.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f207643625"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:26+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Mitochondrial dysfunction is associated with a spectrum of human disorders, ranging from rare, inborn errors of metabolism to common, age-associated diseases such as neurodegeneration. How these lesions give rise to diverse pathology is not well understood, partly because their proximal consequences have not been well-studied in mammalian cells. Here we provide two lines of evidence that mitochondrial respiratory chain dysfunction leads to alterations in one-carbon metabolism pathways. First, using hypothesis-generating metabolic, proteomic, and transcriptional profiling, followed by confirmatory experiments, we report that mitochondrial DNA depletion leads to an ATF4-mediated increase in serine biosynthesis and transsulfuration. Second, we show that lesioning the respiratory chain impairs mitochondrial production of formate from serine, and that in some cells, respiratory chain inhibition leads to growth defects upon serine withdrawal that are rescuable with purine or formate supplementation. Our work underscores the connection between the respiratory chain and one-carbon metabolism with implications for understanding mitochondrial pathogenesis.</p>
<p>Damaged mitochondrial respiratory chains play a key role in the pathogenesis of rare congenital metabolic disorders, as well as in a number of age-associated disorders such as diabetes (Szendroedi et al., 2012), neurodegenerative disease (Schapira et al., 1989), and aging. Mitochondrial respiratory chain components are encoded by two genomes; respiratory chain proteins encoded by mitochondrial DNA (mtDNA) are expressed in all tissues, yet inherited lesions within mtDNA can lead to varying tissue pathology (Koopman et al., 2012;Vafai and Mootha, 2012), suggesting a complex interplay between the primary respiratory chain dysfunction and the compensatory adaptations to that dysfunction. Improved understanding of cellular responses to respiratory chain dysfunction promises to deepen our understanding of mitochondrial disease pathogenesis, nominate new biomarkers (Suomalainen et al., 2011), and motivate new therapeutic strategies (Zhang et al., 2013).</p>
<p>Cellular responses to respiratory chain dysfunction, collectively known as the mitochondrial retrograde response, have been studied in a number of organisms (Haynes et al., 2013;Liu and Butow, 2006). In yeast, early application of genomic profiling and genetic studies identified a transcriptional program (Liu and Butow, 2006) that senses respiratory chain dysfunction, rewires metabolism to bypass a congested tricarboxylic acid (TCA) cycle, and promotes cellular survival. In worms, errors in mitochondrial biosynthesis trigger the mitochondrial unfolded protein response (UPR mt ) to activate transcription of mitochondrial proteases and chaperones, proteins that reduce oxidative stress, and glycolytic enzymes (Nargund et al., 2012). In flies, respiratory chain dysfunction signals to the nucleus and cytosol via reactive oxygen species (ROS) and altered energetics to JNK and AMPK, respectively, to place a checkpoint on cell division (Owusu-Ansah et al., 2008). Induction of a mitochondrial retrograde response in flies has recently been shown to suppress age-dependent degradation of mitochondria (Owusu-Ansah et al., 2013).</p>
<p>Studies of mammalian cells have identified a small collection of cellular responses to respiratory chain dysfunction. Classic studies showed that loss of mtDNA gives rise to uridine and pyruvate dependency (King and Attardi, 1989). Altered mitochondrial calcium uptake stemming from collapse of the mitochondrial membrane potential triggers metabolic alterations (Amuthan et al., 2001). Loss of the mtDNA induces expression of mitochondrial chaperones (Martinus et al., 1996).</p>
<p>Recently, a mouse model of mitochondrial respiratory chain disease has been shown to mount an ATF4-mediated, starvation-like transcriptional response (Tyynismaa et al., 2010), though the functional relevance of this response remains unclear. At present, a systematic picture of how mammalian cells respond to respiratory chain dysfunction at the levels of both gene expression and metabolism is lacking; such a picture could help to unify the above observations, while also pointing to novel responsive and adaptive pathways.</p>
<p>We modeled mitochondrial respiratory chain dysfunction in human HEK-293 cells by depleting them of mtDNA. In human cells, mtDNA is required for expression of 13 structural subunits of the oxidative phosphorylation (OXPHOS) complexes that make up the respiratory chain; human patients with mtDNA depletion exhibit severe multicomplex respiratory chain deficiency (Shoffner, 2005). To generate hypotheses about pathways remodeling in respons to mitochondrial dysfunction, we systematically characterized the response of HEK-293 cells to mtDNA depletion using complementary metabolite, RNA, and protein profiling.</p>
<p>eLife digest Mitochondria are found within virtually all of our body's cells and are best known as their power plants. Damaged mitochondria cause many diseases in humans -from rare, inherited metabolic disorders that cause symptoms including muscle weakness and developmental problems, to age-related diseases such as diabetes and Parkinson's disease.</p>
<p>How does mitochondrial damage lead to such a variety of symptoms and conditions? To answer this question, researchers must understand how cells respond to and compensate for such damage.</p>
<p>To mimic mitochondrial failure, Bao et al. reduced the amount of DNA in the mitochondria of human cells and observed that this caused the cells to accumulate more of an amino acid called serine. Further investigation showed that this accumulation comes in part from cells producing more serine, and that a protein called Activating Transcription Factor 4 is responsible for increasing the expression of the genes needed to produce serine in the cells.</p>
<p>Bao et al. also found that damaged mitochondria are less able to consume serine to produce a compound called formate, which is a precursor for DNA building blocks. If cells cannot acquire enough extra serine to compensate for this inefficiency, they cannot produce some of the building blocks required to make DNA and other critical compounds in the cell. Supplementing the cells with formate or the DNA building blocks enabled the cells to recover, which suggests that formate supplements may help to treat some mitochondrial disorders.</p>
<p>At a higher level, these results suggest that the mitochondrion's role as a major chemical factory in the cell, and not just as the power plant, may also contribute to disease when the mitochondria are broken. Further work is now needed to investigate how cells know to turn on Activating Transcription Factor 4 when their mitochondria are damaged. It also remains to be discovered whether this reduces or exacerbates the symptoms of mitochondrial disease.</p>
<p>Integrated analysis of the profiles raised the hypothesis that one carbon metabolism, especially serine biosynthesis and transsulfuration, remodels in response to mitochondrial dysfunction. We confirmed this hypothesis with mechanistic follow-up experiments. We then explored alterations in serine metabolism in greater detail, and discovered that cells experience impairment of mitochondrial one-carbon synthesis upon respiratory chain dysfunction. In some cell lines, this leads to dependence on exogenously provided serine in the presence of mitochondrial dysfunction. Thus, our study identifies a new metabolic vulnerability of cells facing mitochondrial stress, with implications for our understanding and treatment of human mitochondrial disorders.</p>
<p>We stably transfected T-REx-293 cells, a HEK-293-derived cell line expressing the tet repressor, with a plasmid that expresses a dominant-negative mutant of DNA polymerase gamma (POLGdn) (Jazayeri et al., 2003) under tet repressor control. Doxycycline-triggered expression of POLGdn halts replication of mtDNA, which is then diluted as cells continue to divide (Figure 1a). mtDNAencoded OXPHOS complex components become depleted (Figure 1a) (Jazayeri et al., 2003), cellular respiratory capacity becomes compromised (Figure 1 days, cell growth also slows. Removal of doxycycline allows recovery of mtDNA content and cell growth (Figure 1-figure supplement 1). Some of the recovery could be due to selection of cells that lose tet-inducible POLGdn expression (see Materials and methods), so we repeated these experiments using 100 ng/ml ethidium bromide treatment. Ethidium bromide directly inhibits mitochondrial DNA replication, and gave similar results as POLGdn expression (Figure 1-figure supplement 1).</p>
<p>To generate hypotheses as to what biochemical changes arise from POLGdn-induced mtDNA depletion, we performed initial studies using three profiling modalities. We performed metabolite profiling using targeted mass spectrometry (control and days 2 and 3; Figure 1-figure supplement 3; Figure 1-figure supplement 4; and Supplementary file 1), transcriptional profiling using microarrays (selected days between 1 and 25, with two untreated controls; Figure 1-figure supplement 5 and Supplementary file 2), and protein profiling using mass spectrometry (control and days 2 and 5; Figure 1-figure supplement 6 and Supplementary file 3).</p>
<p>We stress that these experiments were performed with limited numbers of replicates: one transcriptional profiling replicate for each of 18 time points; one protein profiling replicate for each of 3 time points; and two metabolite profiling replicates for each of 3 time points and 2 different sample types. The paucity of replicates prevents us from drawing definitive conclusions from the individual profiles. Any hypotheses posed by analyzing these profiles must be considered preliminary and subject to confirmation and validation.</p>
<p>When jointly analyzed, the profiling methodologies suggest increases in transsulfuration and serine biosynthesis (Figure 1b and Figure 1c). Serine itself is the most strongly increased metabolite in all of our analyses, and the serine biosynthesis enzymes are among the most strongly upregulated proteins in our proteomic data. Transcriptional profiling reveals elevation of the entire serine biosynthetic pathway and two high-affinity human serine transporters (SLC1A4 and SLC1A5; Supplementary Table 2a). While our metabolite profiling did not measure cysteine, we did find that the precursor for transsulfuration, homocysteine, was the most strongly decreased metabolite in all of our analysis. Further, we observed increased taurine, a known product of cysteine breakdown, and increased a-hydroxybutyrate, a byproduct of transsulfuration, in metabolite profiling of spent media (Figure 1-figure supplement 3). Finally, we observed transcriptional activation of transsulfuration genes as well as SLC7A11, the dominant cystine transporter of the plasma membrane.</p>
<p>We next performed experiments to confirm the hypothesis that serine metabolism and transsulfuration are altered upon mtDNA depletion, and to understand the molecular basis of these alterations.</p>
<p>To discover cis-regulatory motifs and factors that might be responsible for our observed transcriptional changes, we performed motifADE analysis (Mootha et al., 2004) on our transcriptional profiles. motifADE scores evolutionarily conserved cis-motifs for their relative enrichment within the vicinity of the transcription start sites of genes that are differentially expressed. Among all possible 6, 7, 8-mer, and gapped 9-mer motifs (Figure 2a, Supplementary file 2), the highest-scoring motif was the 8-mer 5'-TGATGCAA-3' (p » 1.8Â10 4 , Mann-Whitney U test, adjusted for number of motifs tested), which is strikingly similar to consensus ATF4-C/EBP binding site TGATGHAAH (Kilberg et al., 2009). Indeed 26 of the 50 genes (52%) most upregulated in response to mtDNA depletion contain this consensus ATF4-C/EBP binding site near their transcription start sites (Supplementary file 2), representing a strong enrichment over the 14% seen across the genome (p&lt;10 -9 , binomial test).</p>
<p>We confirmed ATF4 involvement in mtDNA depletion-elicited transcriptional changes by overexpressing an N terminally truncated GADD34 protein (GADD344N), which inhibits ATF4 activation (Novoa et al., 2001), in the parent T-REx-293 cell line. We tested four genes that were among the most highly up-regulated in our microarray dataset. We confirmed that these genes were also highly upregulated upon mtDNA depletion with EtBr, and that GADD344N overexpression inhibits this upregulation (Figure 2b).</p>
<p>We performed a similar analysis of serine and cysteine biosynthesis genes. In the preliminary transcriptional profiling dataset, five of these genes were upregulated in nearly all the early mtDNA depletion time points (Figure 2c). GADD344N overexpression blunted activation of all five genes in response to EtBr-induced mtDNA depletion (Figure 2d). ATF4 has previously been shown to activate expression of serine biosynthesis genes (Ye et al., 2012) and transsulfuration genes (Dickhout et al., 2012). Furthermore, chromatin immunoprecipitation experiments have shown direct ATF4 protein binding to the promoter regions of PHGDH, PSAT1, and CTH (Han et al., 2013).</p>
<p>We used a series of mitochondrial inhibitors to determine what bioenergetic parameters might be upstream of ATF4 activation (Figure 2e). Inhibition of OXPHOS complexes III and V using antimycin and oligomycin, respectively, gives the strongest activation of genes shown above to be ATF4responsive. Inhibition of complex I using rotenone gives subtle activation. Membrane potential dissipation using the uncoupler carbonyl cyanide m-chlorophenyl hydrazone (CCCP) fails to elicit activation of these genes, and indeed partially reversed ATF4 activation from mtDNA depletion. These results suggest that mtDNA depletion-triggered activation of ATF4 arises from redox stress due to a stalled respiratory chain, and not from defects in ATP synthesis or membrane depolarization.</p>
<p>To further investigate redox effects on ATF4 activation, we manipulated NAD+/NADH in cells by growing them in media with either 1 mM pyruvate or 1 mM lactate. Pyruvate and lactate are known to freely cross the plasma membrane, and altering the extracellular pyruvate:lactate ratio allows control over the cytoplasmic NAD+/NADH ratio through the action of lactate dehydrogenase (Bu ¨cher et al., 1972;Williamson et al., 1967). Cells grown in media for 24 hrs with 1 mM lactate showed significantly higher expression of ATF4 target genes than with 1 mM pyruvate (Figure 2f). However, the magnitude of the changes is modest compared to those seen with either antimycin treatment or with mtDNA depletion. Therefore, while altered cellular redox balance appears to contribute to ATF4 activation, other factors, such as oxidative stress from stalling of the respiratory chain, may also be important when mtDNA is depleted.</p>
<p>Because doxycycline can itself inhibit mitochondrial translation (Ugalde et al., 2004;Wang et al., 2015), we wondered whether direct doxycycline toxicity, and not doxycycline-induced POLGdn, was responsible for the transcriptional effects we observe in our profiling experiments. We used microarrays to measure the effect of 6 d doxycycline treatment on T-REx-293 cells that did not express POLGdn. ATF4 target genes showed much lower activation in doxycycline-treated T-REx-293 cells than in cells with POLGdn induction (Figure 2-figure supplement 1a). When we performed moti-fADE on the doxycycline control data and considered Bonferroni corrected p-values, the ATF4 motif TTGCATCA was not significant (Figure 2-figure supplement 1b).</p>
<p>Transsulfuration is important for generating H 2 S, an emerging gaseous signaling molecule important for many aspects of mammalian physiology (Kabil et al., 2014). Given our transcriptional and metabolic profiles suggest an activation of transsulfuration, we wondered if mtDNA depletion could also increase H 2 S production.</p>
<p>To confirm that mtDNA depletion leads to decreased homocysteine abundance, we performed focused measurements of homocysteine levels in T-Rex-293 cells depleted of mtDNA using ethidium bromide (Figure 3a). Next, we used two different methods to detect H 2 S. First, we reacted cell extracts with monobromobimane (MBB) and detected H 2 S adducts using HPLC (Tokuda et al., 2012). Second, we detected sulfane sulfur species in cell extracts using SSP4, a fluorescent probe (Marutani et al., 2014). H 2 S degradation requires a functioning respiratory chain (Hildebrandt and Grieshaber, 2008), so we used acute antimycin A treatment as a control for changes in H 2 S degradation rate. Both methods revealed increased H 2 S accumulation as a consequence of mtDNA depletion, greater than the amount induced by acute treatment with antimycin A (Figure 3b). These data support the notion that transcriptional changes elicited by mtDNA depletion have the effect of increasing cellular H 2 S production.</p>
<p>We confirmed alterations in serine using EtBr-treated T-Rex-293 cells, ruling out possible side effects due to doxycycline toxicity as well as statistical anomalies arising from the small sample size used in the initial metabolite profiling (Figure 4a).</p>
<p>In the initial metabolite profiling data, serine was the most strongly consumed metabolite, by fold change compared to base media, in untreated cells (Figure 1-figure supplement 4). Therefore, increased endpoint serine in the spent media atop mtDNA-depleted cells could reflect either increased synthesis or decreased consumption. To determine the contribution of serine biosynthesis to our observed increase in serine abundance, we performed isotopic tracer analysis using 13 C labeled glucose (Chaneton et al., 2012). To avoid product inhibition of serine biosynthesis (Fell and Snell, 1988), we used a low (50 mM) concentration of unlabeled serine in the labeled glucose media. The analysis (Figure 4b) shows that in response to mtDNA depletion, cells both produce more serine from glucose and take up less serine from the media. We estimate that the cell volume is at least 1000 fold smaller than the media volume in our experiments. Therefore, decreased serine uptake implies decreased overall serine consumption and not simply decreased serine accumulation in the cytoplasm.</p>
<p>To explain why serine consumption decreases, we considered the metabolic roles of serine in mammalian cells. In addition to its role in protein synthesis, serine is also a precursor for phospholipid biosynthesis and a major source of one-carbon (1C) units in folate metabolism, which supports purine and thymidylate synthesis as well as cellular methylation reactions (Tibbetts and Appling, 2010). Serine can allosterically activate PKM2 (Chaneton et al., 2012) and thereby regulate the exit of carbons from glycolysis (Ye et al., 2012). Serine is also a precursor for cysteine and glutathione biosynthesis via transsulfuration, and HCT116 cells lacking p53 exhibit serine dependency that is rescuable with glutathione supplementation (Maddocks et al., 2013).</p>
<p>We became interested in the role of serine in 1C metabolism because mitochondria are the source of most of the 1C units used in cellular biosynthesis, and because consumption of serine for 1C metabolism involves an oxidation step that requires an NAD+ cofactor (Tibbetts and Appling, 2010). Thus, loss of NAD+ reoxidation due to the loss of the mitochondrial respiratory chain could conceivably lead to impairment of mitochondrial 1C metabolism, as theorized previously (Desler et al., 2010).</p>
<p>To test this model of 1C metabolism blockade in intact cells, we note that the NAD+-dependent step in mitochondrial metabolism is the oxidation of methylene-THF to formyl-THF by MTHFD2. Our model thus predicts an increase in abundance of methylene-THF. We inferred increased methylene-THF abundance by determining rates of serine isotopic scrambling (Figure 4-figure supplement 1). Briefly, 13 C 3 -labeled serine generates 13 C 2 -glycine and a 13 C labeled methylene-THF in mitochondria by the action of SHMT2. This labeled methylene-THF can recombine with an unlabeled glycine - which is present in excess -by the reverse action of SHMT2 to generate 13 C 1 -serine. The rate of emergence of 13 C 1 -serine thus reads out methylene THF abundance. We performed these experiments in SHMT1 knockout cells (see below) to avoid interference from cytoplasmic folate reactions, and found increased emergence of 13 C 1 -serine upon mtDNA depletion (Figure 4c). We observed similarly increased serine scrambling by treatment with rotenone, which directly inhibits NADH reoxidation through respiratory complex I. Measurement of cellular NAD+:NADH ratios confirms that these are altered with both mtDNA depletion and rotenone treatment (Figure 4-figure supplement 2). Therefore, inhibition of mitochondrial respiration likely shifts the redox state of the mitochondrial folate pool in favor of reduced species such as methylene-THF.</p>
<p>To determine whether the shift in the mitochondrial redox state could inhibit mitochondrial 1C metabolism, we performed formate synthesis assays on isolated mitochondria treated with respiratory chain poisons. As shown in Figure 4d, both rotenone and antimycin A partially inhibit mitochondrial synthesis of formate from serine. Garcı ´a-Martı ´nez and Appling performed similar experiments with mitochondria isolated from rat liver (Garcı ´a-Martı ´nez and Appling, 1993), and also observed partial inhibition of formate synthesis with rotenone treatment.</p>
<p>Elevations in homocysteine often signify insufficient one carbon pools. Hence, an important question is the degree to which mitochondrial 1C compromise is compatible with our observation of decreased homocysteine (Figure 1b). In mammals, homocysteine has two major fates: conversion to cysteine via transsulfuration, and conversion to methionine via remethylation; the latter process consumes cytoplasmic 1C units. Our hypothesized mitochondrial 1C compromise might therefore lead to increased homocysteine abundance and be in direct conflict with the strong observed decrease in homocysteine levels in both spent media and cell extract.</p>
<p>To examine this issue more closely, we performed deuterium tracer experiments to determine the extent of homocysteine remethylation in T-REx-293 cells. As shown in Figure 4-figure supplement 4, homocysteine remethylation using exogenously supplied, deuterated formate was nearly 1000-fold slower than synthesis of serine from deuterated formate. We conclude that remethylation is not a major fate for homocysteine in T-REx-293 cells, regardless of 1C availability. The observation of decreased homocysteine in our experiments, which we attribute to increased transsulfuraton, is therefore compatible with our model of mitochondrial 1C impairment.</p>
<p>1C units are required for cellular biosynthesis, but treating T-REx-293 cells with either rotenone or antimycin, both of which impair mitochondrial 1C generation (Figure 5a), only gave subtle growth rates changes. To test the robustness of 1C metabolism in T-REx-293 cells undergoing mitochondrial dysfunction, we withdrew serine from cells treated with inhibitors. Antimycin-or rotenone-treated cells, but not control DMSO-treated cells, showed strongly impaired growth when serine was withdrawn (Figure 5a, Figure 5-figure supplement 1a). We observed a similar effect with serine withdrawal in cells depleted of mtDNA using EtBr (Figure 5b). A serine dose-response curve in the presence of antimycin (Figure 5-figure supplement 1c) shows optimal cell growth above about 100 mM serine in the media.</p>
<p>We note that this phenomenon is not a true auxotrophy, since cells are still able to synthesize serine. Indeed, if cells with mitochondrial dysfunction were truly serine auxotrophs, they would show increased serine consumption. Instead, we observed the opposite (Figure 4b). We surmise that these cells can overcome blockade of mitochondrial serine metabolism by mass action, but only at high cytoplasmic serine concentrations. Such a bypass mechanism would give rise to serine dependency if cells lose the cytoplasmic serine that they synthesize by diffusion to the media when exogenous serine is withheld, as has been observed for many cell types (Eagle and Piez, 1962).</p>
<p>We also observed serine dependency with oligomycin (Figure 5-figure supplement 1a), which others (Maddocks et al., 2013) have reported in HCT116 cells and attributed to serine involvement in energy metabolism. To distinguish the two models of serine dependency, we tested the effect of the mitochondrial uncoupler CCCP, which impairs energy production (Figure 5-figure supplement 1b) but increases NADH oxidation (Figure 4-figure supplement 2). CCCP did not give rise to serine dependency, and indeed a low dose of CCCP could rescue both the growth defect and the serine dependency arising from oligomycin treatment (Figure 5-figure supplement 1a). These data suggest that the mitochondrial dysfunction-induced serine dependency that we observe is related to the redox state of NAD cofactors, and not to energy impairment.</p>
<p>To further implicate 1C metabolism in serine dependency, we rescued this dependency using 1C related metabolites. Knockouts of MTHFD2 and MTHFD1L, two enzymes involved in mitochondrial formate synthesis, are embryonic lethal in mammals (Di Pietro et al., 2002;Momb et al., 2013), but some knockout phenotypes are rescuable with formate or hypoxanthine supplementation (Momb et al., 2013;Patel et al., 2003). Exogenous formate bypasses the need for its mitochondrial synthesis, and hypoxanthine is an alternate source of purines, the de novo synthesis of which requires 1C units. Experiments on OXPHOS-inhibited T-REx-293 cells with serine withdrawal showed near-complete rescue of growth when media was supplement with either 30 mM hypoxanthine or 3 mM sodium formate (Figure 5a). These concentrations of hypoxanthine and formate also gave strong rescue of growth defects in the absence of serine in mtDNA-depleted cells (Figure 5b). These data further support the notion that serine dependence in the face of mitochondrial dysfunction is related to 1C metabolism. Exploring compartment specificity using SHMT knockouts Parallel folate pathways exist in the cytoplasm and the mitochondria (Tibbetts and Appling, 2010).</p>
<p>To further determine the compartment specificity of serine fluxes, we used CRISPR/Cas9 (Ran et al., 2013) to knock out serine hydroxymethyltransferase (SHMT) genes in T-REx-293 cells (Figure 5-figure supplement 2). SHMT catalyzes the first step in folate-mediated production of formate from serine. Two isoforms exist in mammals: SHMT1, which is exclusively cytoplasmic, and SHMT2, which is mostly mitochondrial but has a cytoplasmic splice variant (Anderson and Stover, 2009). As expected, knockout of SHMT2, but not SHMT1, abolished formate synthesis from serine in isolated mitochondria (Figure 5-figure supplement 2c). In the presence of serine, neither SHMT1 KO nor SHMT2 KO cell lines required formate or hypoxanthine for growth, indicating that serine can be used to generate 1C units in either compartment. Without serine in the culturing media, SHMT2 KO cells showed strongly suppressed growth that could be rescued with formate, similarly to cells treated with RC inhibitors (Figure 5c), whereas SHMT1 KO cells did not. We hypothesize that high levels of exogenous serine are required to drive conversion of serine to formyl-THF in the cytoplasm via SHMT1, likely because MTHFD1, the cytoplasmic enzyme that makes formate, is coupled to NADPH and thus favors formyl-THF consumption rather than generation (Tibbetts and Appling, 2010). This provides a possible explanation for why high levels of serine can rescue 1C synthesis in T-REx-293 cells with compromised RC function.</p>
<p>Mammalian cells can also derive 1C units from breakdown of choline and glycine, which could in principle support growth in the absence of serine (Tibbetts and Appling, 2010). To investigate the roles of these other 1C precursors, we generated T-REx-293 cells with simultaneous knockout of both SHMT1 and SHMT2 genes. Supplementation with hypoxanthine and thymidine (HT) is required for cell growth in the absence of 1C metabolism (Hakala, 1957), since 1C units are used for the synthesis of purines and of thymidylate (Tibbetts and Appling, 2010). Therefore, we supplemented media with HT when we generated these double-KO (DKO) clones. DKO cells so generated were unable to grow on unsupplemented media, whereas most single knockouts and WT cells were able to grow (Figure 5-figure supplement 2a). In all cases, formate (3 mM) could replace HT to support DKO cell growth (not shown). We conclude from this that other sources of 1C are unable to completely replace serine-derived 1C units. Interestingly, hypoxanthine alone was also able to partially rescue DKO cell growth (Figure 5-figure supplement 2e), suggesting that an alternative pathway might be sufficient to supply 1C for thymidylate synthesis. Finally, DKO cells, when rescued using either formate or hypoxanthine, were no longer serine dependent even with antimycin treatment (Figure 5-figure supplement 2f), indicating that no other functions of serine account for its requirement in cells undergoing RC inhibition.</p>
<p>We performed serine scrambling assays in five cell lines -T-Rex293, 293T, HeLa, C2C12, and MCH58 -to determine whether mtDNA depletion could induce 1C deficits in each of them. Instead of using SHMT1 knockout cells, we sought to suppress cytoplasmic SHMT activity by using lower concentrations of serine in the labeling media. Except with MCH58 cells, where high variance in the untreated samples prevented us from reaching any conclusions, we consistently observed increased ratios of 13 C 1 -serine to 13 C 3 -serine, with at least one time point showing a statistically significant increase for all the other cell lines tested (Figure 4-figure supplement 3).</p>
<p>However, impairment of 1C metabolism only led to serine dependence, manifesting as a proliferation defect upon serine withdrawal, in a small handful of cell lines: besides T-Rex293, we only observed similar results in 293MSR and U251 cells (Figure 5-figure supplement 3); a recent report (Maddocks et al., 2013) additionally shows serine dependence of HCT116 cells treated with oligomycin. We failed to observe serine dependence in many other cell lines, including 293T cells which, like T-Rex293 and 293MSR cells, are derived from HEK-293 cells. We surmise that expression of the large or small T antigen in 293T cells enables them to better cope with respiratory chain dysfunction-induced 1C compromise.</p>
<p>Although few mammalian cells demonstrate serine dependence in the presence of respiratory chain inhibition, we have observed similar phenomena in S. cerevisiae grown in nonfermentable media with sub-lethal doses of antimycin: serine withdrawal exacerbates antimycin-induced growth defects in a manner rescuable with purine supplementation (Figure 5d).</p>
<p>Classic inborn errors of metabolism are due to lesions within linear pathways, leading to accumulation of upstream substrates (that can be toxic) or depletion of essential downstream molecules. Therapeutic strategies for these diseases are often aimed at limiting substrate accumulation or replenishing of downstream factors. In respiratory chain dysfunction, however, the resultant metabolic derangements are manifold because of the numerous mitochondrial and cytoplasmic processes that are intimately coupled to the respiratory chain (Vafai and Mootha, 2012). Well-known metabolic alterations associated with mitochondrial disease include increased reliance on glycolysis as a source of ATP (Robinson et al., 1992), dependence on pyruvate to support aspartate biosynthesis (Sullivan et al., 2015;Birsoy et al., 2015;Cardaci et al., 2015), and inability to synthesize pyrimidines (King and Attardi, 1989).</p>
<p>In this paper, we offer two lines of evidence to support the idea that cellular 1C metabolism is also altered upon respiratory chain dysfunction. First, generating hypotheses with metabolic, proteomic, and transcriptional profiling and following these observations up with focused validation experiments, we report that cells activate serine biosynthesis and transsulfuration in response to mtDNA depletion. Second, we show in separate experiments that lesioning the respiratory chain impairs mitochondrial production of formate from serine. In a small number of cell types, this leads to growth defects upon serine withdrawal that is rescuable with purine or formate supplementation.</p>
<p>An important question is the degree to which our observations of one-carbon metabolism remodeling in proliferating cells are relevant to in vivo mitochondrial disease, which mostly affects postproliferative tissue.</p>
<p>We note that our observation of ATF4 activation and alterations in serine metabolism and transsulfuration is richly supported by recent studies of mitochondrial disease. These have shown ATF4 activation by mitochondrial dysfunction in human cells lines (Martı ´nez-Reyes et al., 2012;Silva et al., 2009), rodent models (Tyynismaa et al., 2010), and humans (Crimi et al., 2005). Increased transsulfuration has been observed following ATF4 activation in general (Dickhout et al., 2012), and mitochondrial dysfunction in particular (Krug et al., 2014). One of the byproducts of transsulfuration, a-hydroxybutyrate, has been recently identified as a promising biomarker for mitochondrial disease in humans (Thompson Legault et al., 2015) and mice (Jain et al., 2016). ATF4 is known to activate serine biosynthesis (Ye et al., 2012), and increased serine has been observed in a number of mitochondrial disease settings, albeit with less consistency. Muscle from male mice (but not female ones) with mitochondrial myopathy show increased serine levels (Tyynismaa et al., 2010). Serine was found to be highly elevated in urine from mitochondrial disease patients (Smuts et al., 2013) and proposed as a component of a novel biosignature for mitochondrial disease, but not found to be increased in the blood of a different cohort of mitochondrial disease patients (Clarke et al., 2013). Serine levels are increased in a mitochondrial Parkinson's disease model in Drosophila (Tufi et al., 2014), but not in C. elegans genetic models of mitochondrial disease (Falk et al., 2008;Morgan et al., 2015).</p>
<p>Furthermore, while serine dependency appears to be cell type specific, 1C compromise as evidenced by altered serine scrambling appears to be more general. We note that a recent report on the effect of mitochondrial inhibitors showed impaired serine uptake and formate release in differentiated C2C12 myotubes (Xu et al., 2011). Therefore, 1C compromise does not appear to be limited to proliferating cells. More recently, studies of mouse mitochondrial disease models have also noted imbalanced nucleotide pools and altered 1C-related metabolites (Nikkanen et al., 2016). Taken together, these data suggest that 1C metabolism is more efficient in the presence of a functioning respiratory chain in a variety of in vivo and in vitro contexts, and argues that the 1C compromise seen with respiratory chain dysfunction might be generalizable to whole body metabolism.</p>
<p>Whether the ATF4 response is adaptive in this context has not been clear. Our study shows ATF4-dependent activation of serine synthesis (Ye et al., 2012) following respiratory chain blockade, and poses the hypothesis that the serine synthesis-activating aspect of ATF4 might be adaptive by helping maintain cellular 1C availability. Indeed, ATF4 has recently been shown to mediate purine synthesis induction by mTORC1 (Ben-Sahra et al., 2016). Transsulfuration constitutes another potentially adaptive element of the ATF4 response program, since it supports synthesis of glutathione, a key cellular ROS scavenger. However, we have so far failed to observe deleterious effects of ablating the ATF4 response in T-REx-293 cells. Since the ATF4 integrated stress response program encompasses a number of different genes and functions, we hypothesize that it contains both adaptive and maladaptive components. In support of this notion, a recent paper showed that inhibition of ATF4 activation is protective in rodent models of intracerebral hemorrhage (Karuppagounder et al., 2016).</p>
<p>Our work may provide mechanistic insights into the folate deficiency in mitochondrial disease, with therapeutic implications. Mitochondrial disorders are occasionally associated with cerebral folate deficiency (CFD), and some of these patients are known to respond to treatment with folinic acid (Garcia-Cazorla et al., 2008). No proven mechanism yet connects mitochondrial disease to CFD, but given that brain expresses very little SHMT1 (Girgis et al., 1998), our results pose the hypothesis that CFD may result from impaired mitochondrial formate synthesis (Figure 4). Formate supplementation has been shown to ameliorate defects associated with 1C gene knockout (Momb et al., 2013), and a recent report demonstrated that the bioenergetics defects of a fly model of Parkinson's disease could be reversed with supplementation of nucleotides (Tufi et al., 2014). Mitochondrial disease patients are commonly given folic acid as part of the 'mito cocktail,' with no proven efficacy. Our results suggests that these patients might lack the 1C units that are bound by the folate cofactors, and not the co-factors themselves. Our work raises the hypothesis that formate or nucleotide supplementation may be of benefit in some of respiratory chain diseases.</p>
<p>One of the most puzzling characteristics of mitochondrial diseases is their phenotypic heterogeneity and tissue-specific pathology (Vafai and Mootha, 2012). Our identification of 1C metabolism and transsulfuration as metabolic alterations associated with mitochondrial disease presents a new set of hypotheses that could help explain this heterogeneity. Different organs in the body differ in which 1C donors they utilize, in their ability to metabolize those 1C units (Yoshida and Kikuchi, 1973), and in their transsulfuration activity (Mudd et al., 1965). Because many of these one-carbon pathways are coupled to the respiratory chain, a lesion within the mitochondrion could in principle ripple out to 1C defects that could manifest in many different ways depending on the tissue and cell state. Rapidly proliferating cells might be unable to replicate their DNA due to nucleotide imbalances, whereas metabolically active cells in the liver and kidney might be deprived of essential purinecontaining cofactors such as NAD+. Tissue-specific variations in 1C metabolism may contribute to the remarkable phenotypic variation of mitochondrial disease.</p>
<p>T-REx-293 cells were obtained from Thermo Fisher (Waltham, MA). POLGdn cells were generated as in Jazayeri et al. (2003). U251 cells were obtained from the National Cancer Institute. 293T, HeLa, and C2C12 were obtained from ATCC. MCH58 cells were a generous gift from Eric Shoubridge. We did not authenticate cell lines. However, we were able to differentiate C2C12 myoblasts into myotubes, and were able to PCR the SV40 small and large T antigens from 293T cell genomic DNA. All cells were cultured with DMEM (11995, Thermo Fisher) supplemented with 10% FBS (F6178, Sigma-Aldrich, St. Louis, MO) and grown at 37 ˚C with 5% CO 2 . DMEM without serine or glycine, but with 1 mM pyruvate and in every other respect identical to the DMEM obtained from Thermo Fisher, was custom-made (U.S. Biological, Salem, MA) and supplemented with 10% dialyzed serum (F0392, Sigma-Aldrich). All cell cultures were tested for mycoplasma contamination monthly and confirmed to be free of mycoplasma.</p>
<p>DNA was extracted from cells and analyzed by multiplex real time quantitative PCR as in Baughman (2011). Briefly, samples of 5Â10 4 cells were pelleted, aspirated, and suspended in 50 ml lysis buffer (25 mM NaOH, 0.2 mM EDTA). Cell lysate was heated to 95 ˚C for 15 min to hydrolyze protein and RNA, and neutralized with addition of 50 ml neutralization buffer (40 mM Tris-HCl). 5 ml of 1:50 diluted neutralized cell lysate was analyzed using multiplexed TaqMan real-time quantitative PCR in 20 ml reactions, with a custom-synthesized assay for the AluYb8 repeat element to quantitate nuclear DNA copy number and a custom-synthesized assay for MT-ND2 to quantitate mitochondrial DNA copy number. The custom-synthesized AluYb8 Taqman assay consisted of the forward primer 5'-C TTGCAGTGAGCCGAGATT-3', the reverse primer 5'-GAGACGGAGTC-TCGCTCTGTC-3', and the probe 5'-VIC-ACTGCAGTCCGCAGTCCGGCCT-MGBNFQ-3'. The custom-synthesized MT-ND2 assay consisted of the forward primer 5'-TGTTGGTTATACCCTTCCCGTACTA-3', the reverse primer 5'-CCTGCAAAG-ATGGTAGAGTAGATGA-3', and the probe 5'-6FAM-CCCTGGCCCAACCC-MGBNFQ-3'. To calibrate MT-ND2 PCR Ct values, we used dilution ladders of a chemically synthesized primer corresponding to the target of the quantitative PCR assay. To calibrate AluYb8 PCR Ct values, we used dilution ladders of total DNA extracted from human cells.</p>
<p>PolGdn cells were split every 3 d. On each split, two 10 cm plates were seeded with 2.0, 1.0, and 0.5 M each for RNA and protein collection after 1, 2, and 3 d. RNA was extracted from cell plates using RNeasy columns (Qiagen, Germany) with DNase treatment to remove DNA contamination. For protein collection, cells were first trypsinized, suspended, and counted. Counts derived from protein collection were used for growth curve computation. 5Â10 4 cell were used for mtDNA analysis. The remaining cells were then pelleted and lysed using RIPA buffer with cOmplete protease inhibitor (Roche, Switzerland). Ethidium bromide growth curves were generated in similar fashion, without plates for RNA samples. We note that continuous doxycycline treatment also gave rise to mtDNA repletion, albeit more slowly than when doxycycline was removed, raising the possibility that the strong selective pressure against POLGdn expression could yield mutant cells that lost POLGdn expression.</p>
<p>Oxygen consumption measurements were performed in a Seahorse XF24 Analyzer (Agilent, Santa Clara, CA). Untreated and mtDNA-depleted POLGdn-expressing cells, suspended by trypsinization, were seeded at 10 5 per well into Seahorse cell plates pre-treated with Cell-Tak (Becton Dickinson, Santa Clara, CA) according to manufacturer's recommendations. Cells were incubated in DMEM in Seahorse cell plates for 1 hr before oxygen consumption measurement.</p>
<p>PolGdn-expressing cells were seeded to twelve 6-cm plates at 5Â10 5 ea in 3 ml DMEM + 10% FBS. Four of these plates had 1 mg/ml doxycycline, and another four had 1 mg/ml doxycycline added 1 d after seeding. 3 d after seeding, media was collected from plates. Plates were washed once with icecold PBS and aspirated. Polar metabolites were extracted from two plates of each condition using 1 ml -80 ˚C 80% methanol:20% water. Nonpolar metabolites were extracted from two plates of each condition using 1 ml -80 ˚C isopropanol.</p>
<p>A combination of three liquid chromatography tandem mass spectrometry (LC-MS) methoda was used to measure metabolites in cell extracts and spent media as described previously (Townsend et al., 2013). Briefly, polar metabolites were profiled using a 4000 QTRAP triple quadrupole mass spectrometer (SCIEX; Framingham, MA) coupled to a 1200 Series pump (Agilent Technologies; Santa Clara, CA) and an HTS PAL autosampler (Leap Technologies; Carrboro, NC). Media samples (10 mL) were extracted using 90 mL of 74.9:24.9:0.2 v/v/v acetonitrile/methanol/formic acid containing stable isotope-labeled internal standards (valine-d8, Isotec; and phenylalanine-d8, Cambridge Isotope Laboratories; Andover, MA) and centrifuged (10 min, 9000 x g, 4 ˚C). Cell extracts and media extraction supernatants (10 mL) were injected directly onto a 150 x 2 mm Atlantis HILIC column (Waters; Milford, MA). The column was eluted isocratically at a flow rate of 250 mL/min with 5% mobile phase A (10 mM ammonium formate and 0.1% formic acid in water) for 1 min followed by a linear gradient to 40% mobile phase B (acetonitrile with 0.1% formic acid) over 10 min. MS analyses were carried out using electrospray ionization and selective multiple reaction monitoring scans in the positive ion mode. Declustering potentials and collision energies were optimized for each metabolite by infusion of reference standards before sample analyses. The ion spray voltage was 4.5 kV and the source temperature was 450 ˚C. Polar metabolite were profiling in the negative ion mode using a 5500 QTRAP triple quadrupole mass spectrometer (SCIEX; Framingham, MA) coupled to an ACQUITY UPLC (Waters; Milford, MA). Media samples (30 mL) were extracted using 120 mL of 80% methanol containing inosine-15 N4, thymine-d4 and glycocholate-d4 internal standards (Cambridge Isotope Laboratories; Andover, MA) and were centrifuged (10 min, 9000 x g, 4 ˚C). Cell and media extract supernatents (10 mL) were injected directly onto a 150 x 2.0 mm Luna NH2 column (Phenomenex; Torrance, CA) that was eluted at a flow rate of 400 mL/min with initial conditions of 10% mobile phase A (20 mM ammonium acetate and 20 mM ammonium hydroxide in water) and 90% mobile phase B (10 mM ammonium hydroxide in 75:25 v/v acetonitrile/methanol) followed by a 10 min linear gradient to 100% mobile phase A. The ion spray voltage was -4.5 kV and the source temperature was 500 ˚C. Lipid profiling was performed in the positive ion mode using a 4000 QTRAP triple quadrupole mass spectrometer (SCIEX; Framingham, MA) coupled to a 1100 Series pump (Agilent Technologies; Santa Clara, CA) and an HTS PAL autosampler (Leap Technologies; Carrboro, NC). Lipids were extracted from media (10 mL) using 190 mL of isopropanol containing 1-dodecanoyl-2-tridecanoyl-sn-glycero-3-phosphocholine (Avanti Polar Lipids; Alabaster, AL). Cell and media extracts (10 mL) were injected directly onto a 150 x 3.0 mm Prosphere HP C4 column (Grace, Columbia, MD). The column was eluted isocratically with 80% mobile phase A (95:5:0.1 vol/vol/vol 10 mM ammonium acetate/methanol/acetic acid) for 2 min followed by a linear gradient to 80% mobilephase B (99.9:0.1 vol/vol methanol/acetic acid) over 1 min, a linear gradient to 100% mobile phase B over 12 min, then 10 min at 100% mobile-phase B. MS analyses were carried out using electrospray ionization and Q1 scans in the positive ion mode. Ion spray voltage was 5.0 kV and source temperature was 400 ˚C. For each lipid analyte, the first number denotes the total number of carbons in the lipid acyl chain(s) and the second number (after the colon) denotes the total number of double bonds in the lipid acyl chain(s).</p>
<p>Cell extract metabolite abundances were normalized to sample geometric means to adjust for cell number differences. We used a multi-step protocol to adjust spent media metabolite abundances. First, we measured a media volume change of 12.0% in 6 cm plates with 3 ml media over the course of 3 d, and re-scaled media metabolite measurements accordingly. Then, we used the log mean cell extract metabolite differences between the different samples to estimate the per-day growth rate difference due to doxycycline treatment. We then used the growth rate difference to estimate changes in the area-under-the-curve (AUC) exposure of media to cells and adjusted accordingly. While this adjustment entailed straightforward flux multiplication in the case of metabolites released to the media, metabolites strongly absorbed from the media were more difficult to treat because multiplication would give rise to cells absorbing more metabolite than was present in the base media. We therefore used an ad-hoc adjustment function for uptaken metabolites that satisfied three criteria: (1) its value and slope would match that for released metabolites at the zero flux boundary case; (2) it would be continuous for all uptake fluxes; (3) measurements of near-100% uptake would adjust to yield near-100% uptake. Our final adjustment function was</p>
<p>where R is the evaporation-adjusted abundance ratio compared to base media, a the AUC adjustment factor, and R adj the growth-adjusted metabolite abundance ratio used in</p>
<p>RNA from 18 time points (n = 1 for each time point) were analyzed using Affymetrix (Santa Clara, CA) Human Genome U133 Plus 2.0 arrays. RNA sample processing, hybridization to Affymetrix U133 Plus 2.0 microarrays, and microarray imaging were performed according to manufacturer's recommendations. Raw microarray data were analyzed using the RMA algorithm with manufacturer-provided probeset definitions. Probesets were filtered in an ad-hoc manner according to three criteria: (a) probeset standard deviation across all the timepoint samples were required to be at least 7.5% of the probeset mean, to remove unchanging probesets; (b) maximum values for probesets were required to be at least 50, to remove probesets with insufficient signal; (c) total power in the second through sixth coefficients of the Fourier transform of the data were required to be at least as strong as the total power in the seventh through twelfth, to remove probesets with high frequency noise that we considered unlikely to be informative. Probesets that did not survive these filters were not considered for any downstream analysis. To estimate the number of transcripts with significant changes at day 6, we pooled data from days 5-7 and compared these to data from one and zero days prior to initiation of doxycycyline treatment.</p>
<p>Sulfane sulfur levels in T-REx-293 cells were measured using a sulfane sulfur-specific fluorescent probe SSP4 (generous from Dr. Ming Xian, Washington State University) as reported previously (Marutani et al., 2014). Briefly, cells were washed with ice-cold Tris-HCl (100 mM, pH 9.5, 0.1 mM DTPA) buffer, scraped, transfered to an eppendorf tube, and centrifuged to obtain the supernatant.</p>
<p>The supernatant was transferred into a 96 well-plate, incubated with SSP4 at 20 mM at 37 ˚C for 30 min, and fluorescent intensity was read by a microplate reader (SpectraMax M5 Microplate reader, Molecular Devices, Sunnyvalem CA).</p>
<p>PolGdn cells, treated for 0, 3, and 6 d with doxycycline to induce mtDNA depletion, were in triplicate 35 mm plates at approximately 2Â10 6 cells per plate. Each plate was washed with warm PBS and aspirated. To each plate was then added 1 ml of warm 13 C glucose media, which was glucoseand serine-free DMEM + 10% dialyzed FBS, supplemented with 25 mM [U-13 C]glucose (Cambridge Isotope Labs) and 50 mM unlabeled serine (Sigma). We used this lower concentration of serine (DMEM normally contains 400 mM) to avoid potential product-inhibition of serine synthesis (Fell and Snell, 1988). Cells were incubated with labeling media at 37 ˚C for 30 min, after which labeling media was removed, pelleted at 2000 g for 20 s, and supernatant taken for LC-MS/MS quantitaton (see below). The cell pellet and cells on plates were trypsinized, pooled, resuspended, and counted to adjust serine fluxes for cell number.</p>
<p>Cell medium samples (previous paragraph) were prepared using nine volumes (1:9 v/v) of extraction solution containing 75% acetonitrile, 25% methanol, and 0.2% formic acid, and vortexed. Samples were then centrifuged at 11,000 rpm at 4ºC for 8 min, and the supernatant was injected into LC-MS/ MS. A series of 12 C serine (BioUltra 99.5%, Sigma) and 13 C serine ( 13 C 3 , 99%, Cambridge Isotope Labs) standard solutions at concentrations of 0.1, 0.5, 1, 5, 10, 50 mM were prepared in serine-free base medium to generate a calibration curve. An Agilent 1260 HPLC system coupled with Q Exactive (Thermo Fisher) was used perform LC-MS/MS quantitation. LC Column was Atlantis HILIC Silica 2.1 Â 150 mm column and particle size was 3 m m. Mobile Phase A was 0.1% formic acid, 10 mM ammonium formate. Mobile Phase B was 0.1% formic acid in acetonitrile. Column was at room temperature. 10 uL volume of samples was injected into LC-MS/MS. The flow rate was 0.25 mL/min. The LC gradient was as follows: 95% B was held from 0 to 0.5 min, then from 0.5 to 10.5 min, 95% B was linearly changed to 40%. From 10.5 to 15 min, 40% B was held. From 15 min to 17 min 40% B was changed to 95%. From 17 to 32 min, 95% B was held to equilibrate the column. Serine was quantified using the targeted MS2 method. For 12 C serine, the precursor ion was 106.0506 and the fragment ion 60.0454 was used for extraction ion chromatogram. For 13 C serine, the parent ion was 109.0606 and the fragment ion 62.0521 was used for extraction ion chromatogram. The extraction ion mass window was 10 ppm. The NCE was 20.</p>
<p>To confirm that mtDNA depletion from EtBr treatment could also give rise to increased serine and decreased homocysteine, we seeded T-REx-293 cells to 6-cm plates at 5Â10 5 ea in 3 ml DMEM + 10% FBS, with and without 100 ng/ml EtBr, and collected spent media samples after 3 d incubation.</p>
<p>To measure total homocysteine (i.e., both oxidized and reduced), 200 ml spent media was reduced (Magera et al., 1999) by addition of 40 ml DTT (0.5 M), vortexed, centrifuged at 2000Âg for 1 min to remove any cell debris, and the supernatant incubated at room temperature for 15 min. 120 ml of the supernatant was extracted by adding 200 ml 0.1% formic acid in ACN, vortexing for 15 s, incubating on ice for 30 min, and centrifuging at 13000Âg for 20 min. The resulting supernatant was analyzed by LC-MS for homocysteine abundance as above. Homocysteine signal was acquired in SIM mode.</p>
<p>To measure serine, 200 ml spent media was pelleted at 2000Âg for 1 min to remove cell debris, and 100 ml the supernatant extracted by adding 900 ml 0.1% formic acid in 75% ACN: 25% methanol, vortexing for 15 s, incubating on ice for 30 min, and centrifuging at 13000Âg for 20 min. The resulting supernatant was analyzed by LC-MS for serine abundance as above. Serine signal was acquired in full scan mode.</p>
<p>For single SHMT knockouts, 6Â10 5 T-Rex293 cells in 6-wells were transfected with 300 ng U6-sgRNA PCR product (Ran et al., 2013) and 1 mg pCas9_GFP (Addgene #44719) using Roche X-tremeGENE 9. We used the guide sequence CATCTGCAATCTTCCGTAGC for SHMT1 and GCAACCTCAC-GACCGGATCA for SHMT2. 2-3 d after transfection, single cells from the top 5% of GFP expressors were deposited by FACS into 96-wells containing 50% spent media and 50% fresh media, supplemented with 200 mM serine and 1:500 normocin (InvivoGen). Single cell colonies were analyzed for SHMT1 and SHMT2 expression by Western blotting; SHMT1 antibodies were Cell Signaling Tech (Danvers, MA) #12612, and SHMT2 antibodies were Thermo Scientific #PA5-32228. Double SHMT knockouts were generated likewise, except transfections were with 225 ng of each U6-sgRNA PCR product, and FACS sorted cells were grown in media further supplemented with 1x HT (100x solution from Thermo Fisher; 16 mM thymidine and 100 mM hypoxanthine final). We also repeated SHMT1 and SHMT2 single knockout generation with 1x HT supplementation, and none of the knockout lines so generated were hypoxanthine or formate auxotrophs.</p>
<p>Untreated and EtBr-treated SHMT1 KO T-REx-293 cells were seeded in 35 mm plates at 10 6 and allowed to attach for 1 d. They were then washed with warm PBS and treated with labeling media (DMEM with 400 uM 13 C 3 -serine, 10% dialyzed FBS) for 1 hr. Cells were then washed with ice-cold PBS, and metabolites extracted using 750 ul 80% acetonitrile: 20% water. 13 C 3 -serine and 13 C 1 -serine were quantitated using the same procedure as for serine synthesis determination.</p>
<p>In follow-up studies, we used 50 uM 13 C 3 -serine on wild type cells. T-REx-293, 293T, and HeLa cells were seeded at 10 6 ; C2C12 cells at 2.5Â10 5 ; MCH58 at 5Â10 5 .</p>
<p>Cellular NAD+ and NADH content were determined as previously described (Sullivan et al., 2015).</p>
<p>We used a hybrid cavitation chamber (Kristia ´n et al., 2006) / homogenizer (Mootha et al., 1997) technique to disrupt cells, followed by differential centrifugation to isolate mitochondria (Mootha et al., 1997). All steps for mitochondrial isolation were performed at 4 ˚C. Briefly, 2-4 confluent 15 cm plates of T-REx-293 cells were washed with PBS (room temp) and scraped into a conical tube. These were pelleted at 600g for 10 min, aspirated, and resuspended in 11 ml IB c (200 mM sucrose, 10 mM Tris/MOPS, 1 mM EGTA/Tris, Roche cOmplete protease inhibitor, pH 7.4) (Frezza et al., 2007). The cell suspension was pressurized to 800 psi with nitrogen in a pre-chilled cavitation chamber (Parr Instruments, Moline, IL) for 15 min, and rapidly decompressed into a Potter-Elvehjem homogenizer. The cell suspension was then homogenized with 5 strokes at 1000 rpm. This lysate was centrifuged at 600 g to remove nuclei and intact cells. Mitochondria in the supernatant were then pelleted at 8000 g, and the supertatant aspirated. Mitochondria were resuspended in IB c , and the differential centrifugation procedure repeated. After the second round, mitochondria were suspended in 300-400 ml IB c , and quantitated by BCA assay (Thermo Fisher). Mitochondria were then pelleted and resuspended to 5.71 mg/ml in experiment buffer EB (137 mM KCl, 2.5 mM MgCl 2 , 10 mM HEPES, 1 mg/ml BSA, pH 7.4). Formate production assays were performed in 105 ml of EB with 150 mg mitochondria, 3 mM Pi, 1 mM serine, and 1 mM ADP, at 37 ˚C for 20 min. Formate production was stopped by centrifuging the mixture at 8000 g for 10 min (4 ˚C) and removal of supernatant. Replicate wells of 40 ul supernatant were analyzed using a formate assay kit (Sigma), where one well did not contain enzyme and was used as a background NAD(P)H control. Antimycin and rotenone were used at 1 mM, and the corresponding vehicle control was 0.1% (w/v) DMSO.</p>
<p>When drug treatment was used, mitochondria were incubated with drugs for 2 min at 37 ˚C prior to addition of serine, Pi, and ADP.</p>
<p>For each experimental condition, T-Rex293 cells were seeded in triplicate, either at 1.5Â10 5 /well in 12-well plates or at 3Â10 5 /well in 6-well plates, in DMEM + 10% dialyzed FBS, and split at 2 d or 3d intervals. Ethidium bromide was applied at 100 ng/ml, antimycin at 500 nM, rotenone at 100 nM, and oligomycin at 500 nM. CCCP was used at 5 mM when alone and 3 mM to rescue oligomycin treatment. On each split, cells were trypsinized, counted, and re-seeded to the original density. We used the cell counts to compute growth curves. Growth rates shown in Figure 5-figure supplement 1a and Figure 5-figure supplement 1c were computed by performing least-squares line fits to individual log-transformed growth traces from days 2-6. We omitted growth between days 0 and 2 because the drug-induced growth effects did not appear fully developed before day 2. 293MSR cells were grown identically. U251 cells were grown in triplicate in 6-cm plates at 1.2Â10 5 per plate, and rotenone treatment on U251 was at 50 nM. U251 cells were split at 2 d intervals, and the growth rates shown in Figure 5-figure supplement 3 are from days 2-10 in the U251 growth curves and days 0-6 in the 293MSR growth curves.</p>
<p>To revive the S. cerevisiae BY4741 strain, cells were plated onto YPD (rich medium) plates from frozen glycerol stocks. After 2 days, cells were taken from plates, re-suspended into liquid YPD, and counted. Next, an appropriate amount of cells were taken to inoculate a 3 mL culture of SD +2% Dextrose (Sunrise Science, San Diego, CA) at 1x10 6 cells/ml. The resulting 3 mL culture was placed in a New Brunswick Scientific (Edison, NJ) model TC-7 roller drum on the fastest rotation until saturated (16 hr). The cells were then counted and diluted back to 1x10 6 cells/ml in SD-serine-adenine+2% glycerol+2% ethanol with 5 nm Antimycin A. For the serine and adenine additions, 1X corresponds to 85.6 mg/L and 21 mg/L, respectively. To monitor growth in each condition, 150 uL of culture was placed in the wells of a 96-well plate and growth curves were done using the Bio Tek (Winooski, VT) Synergy H1 multi-mode plate reader. The growth conditions were 30 ˚C with continuous low shaking. OD 600 was measured every 15 min for 48 hr.</p>
<p>The following datasets were generated:</p>
<p>Bao et al. eLife 2016;5:e10575. DOI: 10.7554/eLife.10575</p>
<p>We thank Josh Baughman, Hany Girgis, Sarah Calvo, Denis Titov, Eran Mick, and other members of the Mootha lab for helpful discussions and technical assistance. We thank the MGH CRM Flow Cytometry Core and the DFCI Microarray Core for technical services, and David Thorburn, Vipin Suri, and Michael Baym for helpful discussions. This work was supported by NIH grant R01DK081457. VKM is an Investigator of the Howard Hughes Medical Institute.</p>
<p>Grant reference number</p>
<p>All significance values were computed using Student's t-test (two-tailed) unless otherwise specified. All error bars shown in figures denote standard errors of the mean. n values denote biological replicates, i.e. measurements performed on independent biological samples. The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. . Supplementary file 1. Metabolite profiling data, showing raw mass spectrometry counts as well as adjusted abundance ratios (see Materials and methods). DOI: 10.7554/eLife.10575.022</p>
<p>. Supplementary file 2. Analysis of microarray data. (a) 100 most upregulated genes. Filtered probesets (see Materials and methods) were sorted according to mean upregulation between days 1 and</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f269308191"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:49+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>In this paper we examine how the talk of the facilitator shapes group workshop interactions by using the conversational object 'formulation'. The data consist of video recordings of a corpus of four facilitated workshops held with management and development teams. By adopting an exploratory video-based investigation using conversational analysis to examine our data, we highlight the significance of three distinct set of formulations used by facilitators in workshops. Specifically, our findings show how formulations that encourage reflection or facilitate action, together with those collaboratively produced, enable sense making and the achievement of a temporal conversational order among participants. This research contributes to the study of facilitated workshops by offering a more nuanced approach to the understanding of the craftsmanship of doing facilitation, its effects on the workshop process and, ultimately, workshop outcomes.</p>
<p>organisations increasingly rely on groups to produce novel responses to the demands imposed by these challenges. One presumed benefit of using groups is that they are able to tackle a problem more effectively than would be possible had the problem been left to any single individual. Despite their presumed benefits, however, there is substantial research evidence suggesting that groups often find working together difficult due to limited capabilities, competing interests or negative group dynamics (Kerr and Tindale 2004). The practice of facilitated workshops is one accepted and well-established approach to overcome such difficulties.</p>
<p>Facilitated workshops are designed to help groups engage in productive discussions that challenge shared assumptions and develop new perspectives. If effective, the work of facilitators can enable a range of group process outputs, including a full exchange and shared understanding of different views on the issues being discussed, effective communication of information from several sources, and the development of a sense of common purpose and commitment to action (Phillips and Phillips 1993). To this end, facilitators use a variety of strategies to support the group process while remaining neutral to the content of group discussions (Kaner 2007;Schuman 2005;Schwartz 2002). The question is: How does the facilitator do this? What does 'doing facilitation' look like in practice? While there is an extensive literature that characterizes facilitation in terms of the skills and knowledge required to design interventions and manage groups (e.g. Eden and Ackermann 2010;Franco and Montibeller 2010;Schuman 2005), there is a dearth of studies that draw on observations of actual facilitation practice. At the same time, there is an increasing recognition of the need to develop an in-depth understanding of the microprocesses of group decision support practice, including facilitation practice (e.g. Franco and Greiffenhagen 2018;Tavella and Franco 2015). This paper contributes to this emerging trend by realizing the opportunities afforded by video-based research based on conversation analysis to capture how facilitators go about their craft. Specifically, we show how, as group discussions proceed, facilitators 'formulate' what it is workshop participants have been saying, in order to facilitate sense making and achieve, albeit temporally, conversational order. We contend that an examination of how facilitators deploy formulations in situ is likely to produce a more nuanced understanding of how facilitation affects participants' interactions within a workshop environment, and with what conversational effects. Furthermore, we posit that such a nuanced understanding can be fed back to practice, and thus enable facilitators to become more aware of the ways in which their formulations affect the workshop process and, ultimately, the workshop outputs.</p>
<p>The rest of the paper is structured as follows. In the next section, we briefly review the relevant literature on facilitation and formulations. We then describe our research methodology, including our approach to data collection and analysis. After this, the results of our analysis are presented and discussed, using the presentational format that is typical of conversation analytic studies. Given the exploratory nature of this research, it is worth noting that our main concern here is with showing the significance of only a small set of formulations drawn from our data. We end the paper with some conclusions and directions for future research.</p>
<p>The study of facilitation is inextricably tied to the notion of a work group. Phillips and Phillips (1993) define a facilitated work group as "a small collection of people who share a goal and perform various tasks, with the help of a facilitator, to accomplish their objectives. " (p. 535). From this perspective facilitation is then seen as "process in which a person whose selection is acceptable to all member of the group, is substantively neutral, and has no substantive decision-making authority diagnoses and intervenes to help a group improve how it identifies and solves problems and makes decisions, to increase the group's effectiveness" (Schwartz 2005: 21). Facilitators can be internal or external to the organization in which the work group operates, have no decision making authority, and are formally recognized by group members to assist them with the completion of their task (Wardale 2013).</p>
<p>The group facilitation literature has provided a plethora of frameworks that characterize the work of facilitators in terms of either competences (e.g. Azadegan and Kolfschoten 2012;Gregory and Romm 2001;Hunter and Thorpe 2005;Kaner 2007;Lieberman Baker and Fraser 2005;Schein 1999), or intervention design (e.g. Kolfschoten et al. 2007;McFadzean and Nelson 1998;Wardale 2013). Although useful, this type of frameworks gloss over the complex interactional processes by which facilitated group work is actually achieved. This is because such frameworks are mostly based on practitioners' (and academics') reflective accounts of their experience of facilitation, rather than on empirical evidence obtained from direct observation of the 'doing' of facilitation. What is lacking are in situ descriptions of facilitators doing their work. One exception within the group decision and negotiation literature are recent studies of 'facilitated group modelling', a process by which a facilitator helps a group to build a 'model' that captures a situation they are concerned with, engage in modelsupported discussions to explore the situation, and reach agreements on how to address it (Franco and Montibeller 2010;2011). Studies in this area show the interactional and dynamic nature of facilitated modelling practices. For example, Tavella and Franco (2015) explore two sets of distinct practices, generative and calculative. The former involved communicative behaviours such as inviting, clarifying, building, affirming, and gently introducing expertise, and was associated with sharing or the creation of new knowledge by the group; the latter, on the other hand, consisted of behaviours such as challenging, reiterating and deploying authority, and it was associated with the reproduction of existing knowledge by the group. Tavella and Papadopoulos (2015) compare the work of expert and novice facilitators and, contrary to expectations, found that common facilitation practices were present in the behaviour of both experts and novices. Outside the group decision and negotiation literature, studies of facilitated workshop interactions 'as they happen' on the ground are also rare, with few exceptions. For example, Cooren et al. (2006) identify strategies used by facilitators for selecting who or what is exercising agency in an interaction sequence. Nielsen (2012) shows how a facilitator organises workshop activities, manages group-talk, and draws each group member out to participate actively in shaping a local community of practice.</p>
<p>Overall, these works make a contribution to further our understanding of the machinery for doing facilitation in workshops. An important part of this machinery that has received less attention in facilitated workshop studies is the use of formulations by facilitators. A formulation is defined as a candidate understanding of what participants have said earlier in the conversation (Garfinkel and Sacks 1970;Heritage and Watson 1979). Through the use of formulations, elements of prior talk are reintroduced, summarized, or extracting the general meaning of in a short and precise form in order to achieve confirmation, make a point, or mark what is to be seen as essential (Heritage and Watson 1979). Formulations may be used to pinpoint something, invite the interlocutor to participate in a new, shared focus and negotiate 'what we are talking about'. They often have a 'double duty' of working to achieve mutual understanding and at the same time carry out specific activities (Heritage and Watson 1979). For example, formulations are typically used in business meetings to offer 'candidate pre-closings' enabling the conclusion of a topic or the transition to new topics (Barnes 2007). In therapy and counselling, formulations are used as understanding checks or to elicit the client's personal narrative by asking questions in order to make a diagnosis (Antaki et al. 2005;Hutchby 2005;Kurri and Wahlström 2007). Formulations are also commonly used in negotiations and mediations to summarize, suggest common ground, propose solutions and conclude (Drew 2003). In summary, formulations are of special interest because, as Clifton (2009) persuasively argues, they can shape the way in which workshop participants are able to negotiate their past, present, and future interactions.</p>
<p>It is anticipated that formulations will be widely used in facilitated workshops. Their ability to clarify, summarize, or articulate prior talk and select elements for further treatment by the workshop participants make these conversational objects highly relevant and useful. Formulations are particularly useful during long workshops since they may serve as a vehicle to reintroduce talk that was produced earlier in the workshop and make it locally relevant (Heritage 1985). Furthermore, formulations may serve to preserve the intended neutrality of the facilitator (Eden 1990;Phillips and Phillips 1993) since they may represent a cautious response to prior talk, compared to other locally relevant responses such as assessments (Pomerantz 1984) or agreements/disagreements (Sacks 1987(Sacks /1973)). Finally, formulations may serve to draw inference and test hypotheses (Heritage 1985) during a workshop by means of developing prior talk in order to have it confirmed or disconfirmed by the speaker (e.g. by verbalizing something tacit, presupposed or indicated in the prior talk). The use of formulations have been studied in a variety of different institutional settings (e.g. Drew 2003). However, to our knowledge, the use of formulations has not been previously examined in facilitated workshops. In what follows we conduct a fine-grained examination of the use of formulations in facilitated workshops, with a view to develop a more nuanced understanding of the actual 'doing' of facilitation as an interactional practice.</p>
<p>The data for this exploratory study was drawn from a corpus of four facilitated workshops held with management and development teams. The workshops were sponsored by senior managers of the organizations involved, and concerned with a range of issues involving strategy, innovation, or change. All workshops were videotaped and audio-recorded, which roughly translated into a total of 30 h of facilitated workshop interactions that were initially transcribed verbatim. General information about the workshops can be found in Table 1.</p>
<p>From this larger pool of data, and for reasons of clarity and space limitations, we will be showing in the findings section extracts from one setting only (Workshop 1). This was a six-hour facilitated workshop commissioned by the corporate development division of a British university in the Midlands region,1 and was held as part of the division's strategic review of external income generation. The aim of the division is to coordinate the generation of external income for the university through consultancy, knowledge transfer partnerships, and training. In 2007, the division was facing the challenge of meeting aspirational targets regarding the university's external income. A facilitation team of two people was brought into run the workshop. The workshop participants included the head of the division and six business development managers. The overall purpose of the workshop was to achieve a shared understanding of the key strategic issues that the division was facing at the time concerning the generation of external income.</p>
<p>The workshop process was divided into six planned group activities undertaken in a linear sequence and guided by the facilitation team: (1) gathering issues; (2) linking and exploring issues; (3) articulating the system of goals implied by the issues; (4) prioritizing the issues; (5) developing options to address the issues; and (6) prioritizing options and reaching agreements about action. In what follows we present three inter-action segments from this workshop to illustrate the different types of formulations observed in our data. Names of the organization, persons and activities/work areas, which may convey or reveal any specific identities, have all been rendered anonymous.</p>
<p>Data analysis followed an iterative-inductive approach that required cycling back and forth between theory and data (Orton 1997). First, we watched and listened to the recorded data with the extra benefit of having verbatim transcripts, and noted instances of any potentially interesting conversational exchanges between the facilitator and the participants in the sequential conduct of the workshops. One noticing was the range of formulations that facilitators regularly used to open, manage, and close defined workshop activities such as gathering, structuring, or evaluating participants' contributions. To make the process of identifying formulations systematic, we followed Heritage and Watson's (1979) distinction between formulations that extract the general meaning of the preceding talk (or 'gist'), and formulations that draw out its relevant implication (or 'upshot'). The basic format embodied by these formulations is that of a conversational adjacency pair, with the first part involving a preface (e.g. 'so…') or syntactic frame (e.g. 'are you saying that…'), and the second part showing confirmation or disconfirmation. Next, we selected shorter segments containing these formulations, so that their nature and constitutive features could be examined closely. These shorter segments were then re-transcribed according to the Jefferson's notation system (Jefferson 2004).</p>
<p>Finally, we analyzed the data from a multimodal conversation analytic perspective, incorporating the participants' use of a range of resources from different semiotic fields in order to produce social actions and create meaning (Goodwin 1981(Goodwin , 1994(Goodwin , 2003(Goodwin , 2007;;Goodwin and Goodwin 1996;Sidnell 2005;Stivers and Sidnell 2005;Streeck 1993). Specifically, our analysis drew on a range of analytical concepts from conversation analysis and linguistics. For example, the notion that linguistic interactions are used by interlocutors to accomplish new social orders is a core concept (e.g. Antaki and Widdicombe 1998;Atkinson and Heritage 1984). To illustrate, a participant may suggest the need for "attracting external funding", and the action of suggestion produces a turn-at-talk local identity for the participants as 'suggester of attracting external funding'. Moreover, it creates reciprocal identities for co-participants as 'receivers of suggestions', or 'evaluators of suggestions' or even 'participants in need of attracting external funding'. Another core concept is intersubjectivity, which in conversation analytic terms refers to the interactional practices used by participants to show each other their local understandings of what is going on in the conversation (Schegloff 1992;Schegloff and Sacks 1973). By responding to a turn-at-talk, a next speaker shows the first speaker how she/he perceived the prior turn (e.g., if the suggestion of a new theme is welcomed or treated as a distraction). Moreover, by responding to the response, the first speaker shows his/her understanding of the second turn, and if the second turn evidences a correct hearing of the first turn. This intersubjectivity also serves to show the researcher if the speakers share tacit as-sump-tions or if they initiate repair (Sche-gloff 1991;Schegloff et al. 1977). Therefore, this next-turn-proof-procedure (Drew 1992), and the ability to presuppose what is implied in the talk (Harder 1980;Vagle et al. 1994), make it possible to identify partici-pant orientations towards norms and values, as well as non-questionable, acceptable actions.</p>
<p>In this section we present the three types of formulations identified within our dataset: formulations that encourage reflection; formulations that facilitate action; and collaboratively-produced formulations. These formulations correspond highly with previous studies of formulations in other institutional settings (e.g. Drew 2003). Furthermore, the three types of formulations identified were relevant to particular stages of a workshop. Typically, workshops have three identifiable stages: an opening stage where expectations are set and a roadmap of the workshop process is introduced; a middle stage of sorting something out which is related to the purpose of the workshop (e.g., decision making, idea development); and a closing stage. This staged structure is in accordance with studies of other institutional settings (e.g. Hutchby 1996;Ten Have 1999). Specific workshops designs may consist of multiple stages, but comparable are the basic three-part structure of opening, sorting out and closing. Our findings relate to last two stages of a workshop.</p>
<p>The type of formulation presented here was regularly seen in the 'sorting' stage of a workshop, where we see lots of clarifications, hypotheses and challenges made in order to explore mutual understandings and seek common ground. Below we show a formulation used by the facilitator (Sandro) to encourage the group to reflect further on the basis of the preceding talk, as illustrated below. In the following segment, the participants have been talking extensively about the problem of getting researchers to work harder at attracting external funding to the university. (For an explanation of the symbols used in the transcribed examples, see the appendix) (Figs. 2, 3 and4). The facilitator's formulation "↓ye:s so is that (0.3) Joe when you say this balan↓cing portfolio (.) of ↓ac↑tivities is an issue (0.5) which (0.5) will achieve higher margins (0.7) ↑how does that ↓relate to the previous materi↓al" (lines 1-25) has the so-prefaced design 'so when you say X how does that relate to Y'. He selects Joe as next speaker by his gaze (lines 2, 9, 16, 23, 25), accomplishes using the screen as a mutual point of reference (lines 5, 7, 13, 21). At possible completion points in constructing the turn, he gets a confirmation from Joe (lines 11, 19). Joe does not respond at the transition relevant place (line 25), instead there is a pause (line 27), and that leads Sandro to extend his turn by producing an account (line 28) and produce a new response point. Joe still does not respond, and a pause occurs (line 29). Then Sandro produces an incremental turn (lines 30-34) and there is a very long pause (line 35). Sandro produces yet another response point (line 37) and there is yet another pause (line 40). Matt now self-selects (line 41) but drops out, and after another pause (line 46) Sandro begins a turn that may be designed to resolve the matter by suggesting something (line 47). At that point Stanley first, and then Joe, respond; the latter with a suggestion of a link (line 49), designed as a tentative proposal. Sandro follows up on Joe's suggestion by asking for clarification (line 52) and receives a confirmation from Callum and Joe (lines 53, 54).</p>
<p>The function of the formulation in the above segment (lines 1-25) is to identify the gist of prior talk, focus on something new and encourage the participants to reflect further. By continuously producing new response points and enduring several pauses, he forces the group to come up with something. The turn is left hanging in the air, and a particular participant is left with the floor until somebody else comes into rescue him. He addresses a particular participant and narrows the invited contribution down to a very specific point to make, connecting a prior turn of his (lines 6-8) to something hitherto left hanging (line 25).</p>
<p>Our second category consists of formulations that are commonly observed in the closing stage of the workshop, and which are used for reaching a conclusion or proposing a solution. In the segment below, we see the participants as a group committing to future actions that will be executed after the workshop. After a in which has highlighted the attractiveness of the proposal to engage with academics in the exploration of their areas of interest, Jean confirms quietly while nodding (line 2), and Joe seems to be saying something along the lines of "we're getting around to an understanding", but his turn is almost inaudible. At this point, the (second) facilitator Alfie asks for confirmation ("So you're saying you'll do it?" line 4) while especially looking to Jean for uptake. This is yet another formulation, here formulating other's future actions as an upshot of the preceding talk. Jean now gazes back at Alfie and confirms "yeah &gt; well that's what &lt; I: put down" the action in question (lines 7-9). Alfie recycles his attempt to achieve confirmation (line 11), again addressing Jean with his gaze, and getting her to confirm it (line 12). After that exchange, Alfie points to Jean and says "We ↑have an ↑action" (lines 15-16). Alfie is pointing to Jean (with a large wave shaped movement ending in a downward pointing direction) while insistently gazing at the other facilitator (Sandro), as if to say "you should make a record of that". By means of that gesture he is making Jean accountable for the commitment to future action and at the same time telling Sandro to make a record of it. Sandro recycles the action formulation with an almost identical repetition ("Have an action yeah?" line 19), which Jean confirms with a smile (line 23) and modifies (line 27) to something that she'll "would hope to do" (line 28) even if "a bit ↑scared" is her description of the situation. The action formulation in line 16 serves to announce an outcome, and the formulation in line 19 seeks confirmation of that announcement. This sequence of formulating the conclusion as an upshot (lines 4, 11), achieving agreement or confirmation (lines 7-9, 12, 23 27, 28), and confirming the agreement with another action formulation (line 19) is similar to exchanges seen in other institutional settings, such as general practice consultations where the doctor orients to confirming the patient's agreement with the recommended action (Gafaranga and Britten 2004).</p>
<p>The phenomenon of one speaker completing another speaker's turn in progress is termed 'collaborative completion' (Sacks 1992) or 'co-participant completion' (Lerner 1991). By means of this practice the speaker may propose a candidate understanding of the turn in progress. We have identified this type of phenomenon across both the sorting out and the closing stages of a workshop, in what we called 'collaboratively produced formulations'. It can be a formulation used the facilitator present a hypothesis as an upshot of the group's preceding talk, which is a very common use of formulations in workshops, but this variant is designed to be collaboratively completed by workshop participants. This is illustrated in the following segment.</p>
<p>Example 3: "An issue which is…" The facilitator begins his turn by marking it not as an uptake to the immediately preceding talk (lines 1-8) but something that he wants to say in spite of that. He marks his contribution as an addition to a known concept ("that concept" line 9), which he specifies verbally (line 11) and non-verbally (line 12). Stanley confirms the relevance of the topic by nodding and uttering a stressed and prolonged "No:" (line 13) that is linking to Sandro's negative utterance design ("might not apply" line 11), which is an almost identical repetition of a previous turn produced by Stanley. Then he eagerly produces an account for making the contribution (note the gesture and gaze, lines 17, 19). There is a lot of preparation done by Sandro : misplacement marking, redesigning and accounting twice (lines 1-19). Then Gerald comes in with the punch line "We're not he:re for ↓that" (line 22), which Sandro confirms (line 25). The facilitator is by means of the formulation presenting a hypothesis that is designed as building on preceding talk ("that concept about") and marked as an attempt to "capture" an "issue" from their preceding discussion. The formulation "that concept about (0.3) it might not apply to e:very academic (.) it but it is an issue that I want to capture which i:s eh (0.3) We're not he:re for ↓that" is collaboratively produced by Sandro and Gerald.</p>
<p>Note, that Gerald's collaborative completion is not unwarranted. Sandro makes an effort to produce talk that the participants will confirm or collaboratively complete; his turn is designedly incomplete, making a completion of it a relevant action for coparticipants. Besides the mentioned work, he also stretches the sound on "is", adds a hesitation marker and pauses (lines 20, 21). He is creating the optimal conditions for a participant to come in with the climax of his turn, leaving himself a response turn in the next turn, confirming what he has been fishing for. Collaboratively completed formulations may be considered extreme versions of formulations aimed at achieving confirmations from co-participants.</p>
<p>The exploratory video-based investigation reported in this paper provides a complimentary departure from the mainstream group facilitation literature that has emphasized the use of facilitator competences and intervention design frameworks to study and guide the practice of facilitation. For example, prescriptions such as 'active listening', 'maintain a task orientation' or 'handing back contritions in changed form' (Ackermann 1996;Franco and Montibeller 2010;Phillips and Phillips 1993) do not take into account the different ways in which such actions can be enacted in workshops. Similarly, workshop 'scripts' (e.g. Ackermann et al. 2011;Hovmand et al. 2012) or 'ThinkLets' (e.g. Azadegan and Kolfschoten 2012;Kolfschoten et al. 2007) that provide detailed instructions to facilitators on what to say to the group in order to achieve intended workshop outputs, do not consider the different ways in which such instructions can be applied in interaction. By contrast, our exploratory study shows how formulations are used to achieve some of the complex interactional work involved in enacting and sustaining these general and more specific prescriptions.</p>
<p>When the facilitator produces a formulation by presenting a hypothesis, projecting an action, or proposing a conclusion, a significant amount of interactional work is involved to achieve a confirmation from the participants. Specifically, the facilitator is putting forward to the group something that they need to make sense of, either looking backwards, as in the clarification of previous talk; or looking forward, as in thinking further, building on previous talk. Furthermore, we note that facilitators use what is known as 'so-prefacing' 1985) to mark the beginning of a formulation turn design. By using such 'so'-prefaced upshots facilitators make evident what action is due, and from whom it is due (cf. Raymond 2004).</p>
<p>We see formulations being produced by the facilitator throughout the whole workshop. Typically, a facilitator's question may lead to further questions or a discussion, after which the facilitator produces a formulation in order to make sense of prior talk co-produced by multiple participants. A facilitator's formulation is mainly designed to achieve a confirmation from the participants, but it can also revitalize the discussion leading to the facilitator recycling and/or producing a new formulation until a sequence of formulation-confirmation is achieved. Therefore, formulations both serve as a tool in the process of ongoing talk and as an aid in achieving the goal of the interaction.</p>
<p>A key requirement of effective facilitation is to support a group process without influencing the content of group discussions (Kaner 2007;Schuman 2005;Schwartz 2002). Our findings show how facilitators use formulations to draw out the participants' contributions on their behalf without influencing content. By using formulations, facilitators draw out contributions from different participants, one at a time, or leave the floor open for all. Furthermore, they decide when to deliver contributions on behalf of the group and when to foster the group to deliver their own contributions (e.g. "we are not here for that", Example 3, line 22).</p>
<p>Formulations, however, are not to be seen as verbal phenomena alone. As our empirical material demonstrates, formulations are also embodied social actions. For example, the evidence suggests that the physical act of pointing may be doing similar interactional work as the use of 'so' as a preface to a formulation, the embodied 'soprefacing'. To illustrate, when the second facilitator, Alfie, points to the participant, Jean, and says "we have an action" (Example 2, line 16), we see his bodily movement of pointing as an embodied equivalent to 'so-prefacing'. Pointing gestures are embodied actions that may be used by participants to point to something, somewhere or someone, and are typically described to be a referential gesture that cannot be understood when looked upon in isolation (Auer and Bauer 2011;Clark 2003;Haviland 2000;Klippi 2015;Streeck 2009). Gestures like pointing are not separate actions, but a situated interactive activity, which may establish a particular physical space as a shared focus for the organization of cognition and action (Goodwin 2003).</p>
<p>By adopting a conversation analytic approach to examine our video recordings, we were able to provide a fine-grained analysis of the use and interactional impacts of three different types of formulations used by the facilitator. First, our analysis shows that formulations encouraging participants' reflections require a significant amount of interactional work on the part of the facilitator, who puts forward to the group something that they need to make sense of, either by looking backwards, as in the clarification of previous talk; or by looking forward, as in thinking further, building on previous talk. Second, we show how in collaboratively produced formulations the facilitator actively directs the group talk, taking and redesigning his turns so that the participants can both predict where he is going, and able to produce the completion by themselves. Third, our findings suggest that action formulations can either project participants' future activities (e.g. "you're saying you'll do it?"), or announce participants' commitment to a particular course of action (e.g. "we have an action plan"). In both cases we see action formulations as an upshot of the preceding talk. In addition, the empirical material presented here demonstrates formulations produced in situ are embodied social actions in which body movements may be doing similar interactional work as verbal communication. Taken together, our fine-grained analysis offers a more nuanced approach to the understanding of the embodied craftsmanship of doing facilitation.</p>
<p>Our research has at least two obvious limitations. Firstly, to develop an in-depth understanding of the significance of formulations in situ, we had to focus on only a small set of formulations. Secondly, while we did not distinguish between the facilitators for analytical purposes, we do acknowledge that the personality and style of the facilitator can play a significant in workshop interactions. Notwithstanding these limitations, there is considerable potential for further research into the practice of facilitated workshops using the conversation analytic perspective adopted here. One possible direction would be to undertake further fine-grained analysis of our data, with a view to identify formulations that might be distinct from those discussed in this paper. Another possible avenue for further research would be to study if facilitators use more tendentious formulations in processes where they were hired to pursue a specific agenda. An additional, and potentially useful, future study might involve comparing different facilitation tasks and workshop protocols with the actual, interactional practices of the facilitators when supporting the group process.</p>
<p>Finally, our study also has practical implications for the work of facilitation practitioners. Specifically, our findings can contribute towards the development of a 'tool kit' of formulations available for doing facilitation. Indeed a more detailed understanding of the use of different formulations and their interactional consequences would be a useful part of any repertoire of facilitation skills. Furthermore, the development of training materials based on actual use of formulations such as those identified in this research, rather than on the use of role plays or workshop design 'scripts' (e.g. Andersen and Richardson 1997;Hovmand et al. 2012) and 'ThinkLets' (e.g. Kolfschoten et al. 2006Kolfschoten et al. , 2011) ) in a simulated environment, could offer would-be or practicing facilitators the opportunity to rehearse the interactions that would comprise an actual workshop episode and to assess what participants would do in the situation (e.g. Stokoe 2013). However, this development would require a larger sample of facilitated workshops from which to develop such training materials.</p>
<p>The name of the university and the identities of workshop participants have all been disguised for confidentiality purposes.</p>
<p>Acknowledgments Thanks are due to our workshop participants without whom this study would not have been possible.</p>
<p>Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f79093084"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T07:03+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>We apply an online optimization process based on machine learning to the production of Bose-Einstein condensates (BEC). BEC is typically created with an exponential evaporation ramp that is optimal for ergodic dynamics with two-body s-wave interactions and no other loss rates, but likely sub-optimal for real experiments. Through repeated machine-controlled scientific experimentation and observations our 'learner' discovers an optimal evaporation ramp for BEC production. In contrast to previous work, our learner uses a Gaussian process to develop a statistical model of the relationship between the parameters it controls and the quality of the BEC produced. We demonstrate that the Gaussian process machine learner is able to discover a ramp that produces high quality BECs in 10 times fewer iterations than a previously used online optimization technique. Furthermore, we show the internal model developed can be used to determine which parameters are essential in BEC creation and which are unimportant, providing insight into the optimization process of the system.</p>
<p>Experimental research into quantum phenomena often requires the optimization of resources or processes in the face of complex underlying dynamics and shifting environments. For example, creating large Bose-Einstein condensates (BECs) with short duty cycles is one of the keys to improving the sensitivity of cold-atom based sensors 1 or for performing scientific investigation into condensed matter phases 2 , many-body physics 3 and non-equilibrium dynamics 4 . The standard process of BEC production is evaporative cooling 5 . Microscopic semi-classical theory exists to describe this process 6 , but it can oversimplify the dynamics and miss more complex and effective methods of performing evaporation. For example, Shobu et al. 7 found circumventing higher order inelastic collisions can produce large condensates. 'Tricks' like this are likely to exist for other species with complicated scattering processes 8 , but discovery is only possible by experimentation. We automate this process of discovery with machine-learning online optimization (MLOO). What distinguishes our approach from previous methods for optimization is that we seek to develop a statistical model of the relationship between parameters and the outcome of the experiment. We demonstrate that MLOO can discover condensation with less experiments than a competing optimization method and provide insight into which parameters are important in achieving condensation.</p>
<p>Online optimization (OO), with mostly genetic [9][10][11][12][13][14][15][16][17][18][19][20][21][22] but also gradient 23 and hybrid solvers 24,25 , has been used to enhance a variety of quantum experiments. Here we use online to mean optimization that is performed in real time with the experiment. What distinguishes our approach is that it does not only seek to optimize the experiment, but also creates an internal model that is able to predict the performance of future experiments given any set of parameters. This is achieved by modeling the experiment using a Gaussian process (GP) 26 . Our algorithm both fits the model to previous observations, and chooses to do future experiments that will best refine its model, making it an automation of scientific method. Online machine learning (OML) with GPs [26][27][28][29][30] has been applied in a variety of areas including robotics 31,32 , vision 33 , industrial chemistry 34,35 and biochemistry 36 . However, in all of these cases, the focus was not on optimization. Rather, the goal was the development of an accurate model. We combine the advantages of OML with the motivation of OO. The resultant MLOO algorithm has the following advantages: every experimental observation is used to improve the GP model, and uncertainties in the measurements are correctly accounted for; our algorithm will find global minima, but exploration is not random, new parameters are picked with knowledge of where the learner is most uncertain; the learner provides a visualization of the resource's quality as function of the parameters that can inform experimentalists on how to best develop future optimization experiments.</p>
<p>Experiment. The experimental apparatus is described in detail in 37 . Initially 87 Rb atoms are cooled in a combined 2D and 3D MOT system and subsequently cooled further by RF (radio frequency) evaporation. The cloud is then loaded into a cross beam optical dipole trap for the final evaporation stage. It is this stage that is the subject of the optimization process. At this point, the sample contains 4 × 10 7 atoms at a temperature of ~5 μK with a phase space density of ~0.05. The cross dipole trap is formed from two intersecting 1090 nm and 1064 nm lasers with approximate waists of 350 μm and 300 μm respectively producing a trap with frequencies 185 × 185 × 40 Hz. The depth of the cross trap is determined by the intensity of the two beams and is found to be approximately 70 μK. The 1064 nm beam is controlled by varying the current to the laser, while the 1090 nm beam is controlled using the current and a waveplate rotation stage combined with a polarizing beamsplitter to provide additional power attenuation while maintaining mode stability. A diagram of the experimental set up is shown in Fig. 1. Normally the power to these beams is ramped down over time, thereby lowering the walls of the trap and allowing the higher energy atoms to leak out. The remaining atoms rethermalize to a lower temperature, enabling cooling. Once the gas has been cooled to temperatures on the order of nK, a phase transition occurs, and a macroscopic number of atoms start to occupy the same quantum state. This transition is called Bose-Einstein condensation 38 . We hand over control of these ramps to the MLOO. We consider two parameterizations: one simple, where we only control the start and end points of a linear interpolation; and one complex, where we add variable quadratic, cubic and quartic corrections to the simple case (see Supplemental Equations).</p>
<p>Performance Measure. The approach we propose is a form of supervised learning, meaning that we provide the learner with a number that quantifies the quality of the resource produced or in optimization terminology a cost that must be minimized. Naïvely one might try to use a measure based on temperature and particle number. However determining these quantities accurately near condensation is difficult when constrained to very few runs per parameter set. Instead, a technique was created to measure the width of the edges of the cloud. For thermal clouds this edge is broad, but as the sample cools and condenses these edges become sharper. To quantify this, an absorption image of the final state of the quantum gas is taken after a 30 ms expansion of the cloud, with the image providing the optical depth as a function of space. This absorption image is taken at resonance, resulting in saturation of the image (see Fig. 2). Whilst this makes determining peak density difficult, it ensures that the edges of the cloud are accurately determined. The cost is then calculated from all data between a lower and upper threshold optical depth. The lower threshold is determined by the noise in the system. The upper threshold is set slightly lower than the saturation level of the image. Only data from between the bounds is used and the cost is simply the average of these values. In practice this means the sharper the edges of the cloud, the lower the cost. Indeed, low quality thermal clouds have broad edges, whereas the ideal BEC has much sharper edges. Each parameter set is tested twice with the average of the two runs used for the cost. Tests of the variation in cost for a set of parameters run-to-run indicate they obey a Gaussian distribution. As such we are able to estimate the uncertainty from two runs as twice the range. In doing so, the chance we have underestimated the uncertainty will be 27%. We therefore also apply bounds to the uncertainty to eliminate outliers overly affecting the modeling process. The cost function can be evaluated as long as some atoms are present at the end of the evaporation run. In cases where the evaporation parameters produced no cloud twice for a set of parameters, we set the cost to a default high value.</p>
<p>Algorithm. We treat the experiment as a stochastic process X ( )</p>
<p>which is dependent on the parameters X = (x 1 ,… , x M ). When we make a measurement and determine a cost, we interpret this as a sample of this process C(X) with some associated uncertainty U(X). We define the set of all parameters, costs and uncertainty previously measured as =  X X ( , ) , )</p>
<p>respectively and collectively refer to these sets as our observations O X C U = ( , , ). The aim of OO is to use previous observations  to plan future experiments in order to find a set of parameters that minimize the mean cost of the stochastic process M X ( )  . Unique to the MLOO approach, we first make an estimate of the stochastic process given our observations C O  X ( ), which is then used to determine what parameters to try next. We model X ( )  as a GP-a distribution over functions-with constant mean function and covariance defined by a squared exponential correlation function</p>
<p>where H = (h 1 , … , h M ) is a set of correlation lengths for each of the parameters. The mean function conditional on the observations  and correlation lengths H of our GP is:</p>
<p>, which is evaluated through a set of matrix operations 26 (see Supplemental Equations). As we are using a GP, we can also get the variance of the functions conditioned on  and H: σ X H ( , ) O C 26 . Both of these estimates depend on the correlation lengths H, normally referred to as the hyperparameters of our estimate. We assume that H is not known a priori and needs to be fitted online.</p>
<p>The correlation lengths H control the sensitivity of the model to each of the parameters, and relates to how much a parameter needs to be changed before it has a significant effect on the cost (see Fig. 1). A standard approach to fit H is maximum likelihood estimation 26 . Here, the hyperparameters are globally optimized over the likelihood of the parameters H given our observations , or L H ( )  26 (see Supplemental Equations). However, when the data set is small there will often be multiple local optima for the hyperparameters whose likelihoods are comparable to the maximum. We term these hyperparameters the hypothesis set =  H H ( , , )</p>
<p>. To produce our final estimates for the mean function and variance we treat each hypothesis as a particle 30 , and perform a weighted average over . The weighted mean function is now defined as</p>
<p>and weighted variance of the functions is</p>
<p>, where</p>
<p>are the relative weights for the hyperparameters. Now that we have our final estimate for C O H X ( , ), we need to determine an optimization strategy for picking the next set of parameters to test.</p>
<p>Consider the following two strategies: We could always test parameters that are predicted to minimize M X ( )  , making our learner act as an 'optimizer' . But this learner could get trapped in local minima and re-enforce its ignorance; Or we could test parameters that maximize Σ ^X ( ) 2  (i.e. where we are most uncertain), this would provide us with experimental data that helps us best refine our model and discriminate between the hypotheses, making our learner act like a 'scientist' . But this learner may require a large number of trials to map the space and would not prioritize refinement of the global minima. We chose to implement a balanced strategy that repeatably sweeps between these two extremes by minimizing a biased cost function:</p>
<p>, where the value for b is linearly increased from 0 to 1 in a cycle of length Q. During testing with synthetic data, we found sweeping the learner between acting like a 'scientist' (b = 0) and an 'optimizer' (b = 1) was more robust and efficient than fixing the learner to one strategy. When we minimized B X ( )</p>
<p>we also put bounds, set to 20% of the parameters maximum-minimum values, on the search relative to the last best measured X. We call these bounds a leash, as it restricts how fast the learner could change the parameters but did not stop it from exploring the full space (similar to trust-regions 39,40 ). This was a technical requirement for our experiment: when a set of parameters was tested that was very different from the last set, the experiment almost always produced no atoms, meaning we had to assign a default cost that did not provide meaningful gradient information to the learner. Once the next set of parameters is determined they are sent to the experiment to be tested. After the resultant cost is measured this is then added to the observation set  with N → N + 1 and the entire process is repeated.</p>
<p>As a benchmark for comparison, we also performed OO using a Nelder-Mead solver 41 , which has previously been used to optimize quantum gates 25 .</p>
<p>We demonstrate the performance of machine learning online optimization in comparison to the Nelder-Mead optimizer in Fig. 2. Here we used the complex parameterization for all 3 ramps, and added an extra parameter that controlled the total time of the ramps, resulting in 16 parameters. If we were to perform a brute force search and optimize the parameters to within a 10% accuracy of the parameters maximum-minimum bounds, the number of runs required would be 10 16 . The Nelder-Mead algorithm is able to find BEC much faster than this, in only 145 runs. The machine learning algorithm, on the other hand, is much faster. After the first 20 training runs, where the machine learning and Nelder-Mead algorithm use a common set of parameters, the machine learning algorithm converges in only 10 experiments.</p>
<p>The learner used in Fig. 2 only used the best hypothesis set when picking the next parameters, in other words we set P = 1. Evaluating multiple GPs is computationally expensive with so many parameters, so to save time we made this restriction. In spite of this, the learner discovered ramps that produced BEC in very few iterations. This is because the learner consistently fitted the correlation lengths of the 3 most important parameters-the end points of the ramps-very quickly. However, we found the other correlation lengths were not estimated well and would not converge, even after a BEC was found. This meant that we were unable to make useful predictions about the cost landscape and we could not reliably determine what parameters were least important. The final optimized parameters produced a condensate with 5 × 10 5 atoms.</p>
<p>Gramacy et al. 30 have suggested that making good online estimation of the GP correlation lengths requires multiple particles. We considered achieving this goal in a different experiment as shown in Fig. 3. Here we used a learner with many particles P = 16, but had to use the simple parameterization for the ramps to save computational time. This resulted in a total of 7 parameters. We can see again the overall trend for the machine learner is still faster than Nelder-Mead, but less pronounced. More carefully estimating the correlation lengths has hindered the convergence rate compared to the 16 parameter case. Nevertheless, as we now have a more reliable estimate of the correlation lengths we can take advantage of a different feature of the learner.</p>
<p>In Fig. 4(a) we show estimates of the cost landscape as 1D cross sections about the best measured point. We plot the two most sensitive parameters and the least. We can see the least sensitive parameter appears to have no effect on the production of a BEC. This parameter corresponds to an intentionally added 7th parameter of the system that controls nothing in the experiment. Figure 4(a) shows the learner successfully identified this, even with such a small data set. After making this observation we can then reconsider the design of the optimization process and eliminate this parameter from the experiment.</p>
<p>In Fig. 3 we plot the machine learner optimization run with P = 16 but now with only 6 parameters. We can see the learner converges more rapidly than the 7 parameter case, and even produces a higher quality BEC. As the learner no longer takes extra runs to determine the importance of the useless 7 th parameter, it achieves BEC rapidly. We plot a 2D cross section of the landscape against the two most sensitive parameters in Fig. 4(b) generated from the 6 parameter machine learning run. We can see there is a very sharp transition to BEC, as it exists in a very deep valley of the landscape.</p>
<p>The optimum values for each parameter of the 16 parameter MLOO run are shown in a table in the supplementary material. Plots of the optimal ramps for each of the five optimization runs discussed are also shown and display cases where the optimum ramp is non-monotonically decreasing. The experimental controls adjust the shape of the trapping beams in a non-trivial manner, so this does not ensure that the trap depth experienced by the BEC was also non-monotonically decreasing. A key strength of the MLOO process is that we were able to find the ramps for the control that maximized the BEC without performing a lengthy characterization of relationship between the controls and the potential. Instead, the MLOO directly characterizes the relationship between the controls and the quality of the outcome. This significantly decreases the system identification and analysis overhead when optimizing an experiment.</p>
<p>The topology of optimization landscapes has been suggested as an explanation for the profound discrepancy between the number of experiments required to do a brute force search, and the number of experiments required in practice when using OO. Specifically, in laser-aided quantum chemistry, under the assumption of controllability it has been proven that landscapes are 'trap-free' 42 (there has been further refinement [43][44][45][46][47] and debate [48][49][50] on the generality of the result). In our experiment we observed Nelder-Mead always found condensation, albeit slower than MLOO, even though it is a local solver susceptible to being trapped. This suggests our landscape is also 'trap-free' , and perhaps there is a universal principle for all quantum OO systems.</p>
<p>The MLOO algorithm we developed is available online 51 (it uses 52 to evaluate the GPs); it can be immediately applied to experiments that have previously used OO: quantum chemistry 9 , femtosecond physics 13 , and quantum computing 25 . Indeed, any automated experiment with a resource of measurable quality can be enhanced using MLOO. In (a) the predicted cost is shown as a function of the end of the polarization ramp (red), the end of the dipole beam ramp (green) and the unconnected parameter (blue). The learner correctly identifies that the unconnected parameter does not have a significant effect on the production of BEC. In (b) a cross section of the 2 most sensitive parameters are plotted against cost.</p>
<p>Scientific RepoRts | 6:25890 | DOI: 10.1038/srep25890</p>
<p>M.R.H. acknowledges funding from an Australian Research Council (ARC) Discovery Project (project number DP140101779). J.J.H. acknowledges support of an ARC Future Fellowship (FT120100291). A.N.L would like to thank the South Australian Government through the Premier's Science and Research Fund for supporting this work. I.R.P acknowledges support of an ARC Laureate Fellowship FL110100020.</p>
<p>Supplementary information accompanies this paper at http://www.nature.com/srep Competing financial interests: The authors declare no competing financial interests.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f207522207"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T08:17+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Background: Survey research in healthcare is an important tool to collect information about healthcare delivery, service use and overall issues relating to quality of care. Unfortunately, physicians are often a group with low survey response rates and little research has looked at response rates among physician specialists. For these reasons, the purpose of this project was to explore survey response rates among physician specialists in a large metropolitan Canadian city. Methods: As part of a larger project to look at physician payment plans, an online survey about medical billing practices was distributed to 904 physicians from various medical specialties. The primary method for physicians to complete the survey was via the Internet using a well-known and established survey company (www.surveymonkey.com). Multiple methods were used to encourage survey response such as individual personalized email invitations, multiple reminders, and a draw for three gift certificate prizes were used to increase response rate. Descriptive statistics were used to assess response rates and reasons for non-response. Results: Overall survey response rate was 35.0%. Response rates varied by specialty: Neurology/neurosurgery (46.6%); internal medicine (42.9%); general surgery (29.6%); pediatrics (29.2%); and psychiatry (27.1%). Non-respondents listed lack of time/survey burden as the main reason for not responding to our survey. Conclusions: Our survey results provide a look into the challenges of collecting healthcare research where response rates to surveys are often low. The findings presented here should help researchers in planning future survey based studies. Findings from this study and others suggest smaller monetary incentives for each individual may be a more appropriate way to increase response rates.</p>
<p>With the rise of the Internet and email in recent decades, online and web-based tools offer promising advances for healthcare survey research methods [1,2]. Immediate survey delivery, real-time data tracking and inexpensive costs are selling points of email or webbased surveys [2]. Electronic surveys may also increase response rates through ease of access, as well as greater individual anonymity compared to face-to-face or telephone interviews [2,3]. Despite the increased use of web-based surveys, considerable debate about the success and usefulness of this type of survey mode exists [4][5][6]. Studies using both email and mail paper surveys demonstrate conflicting evidence as to whether email surpasses mail as a delivery modality [6]. Survey response rates have also in general been on the decline for the past decade in the field of health related research [1,[6][7][8].</p>
<p>Despite the declining use of survey research methods, this type of research remains an important way of research to gather information about physicians' knowledge, attitudes, and to evaluate the impact of clinical research on practice [9]. Soliciting physician input is also essential when existing healthcare policies are being updated or to inform new policies [10]. Unfortunately, physicians are a professional group with low survey response rates in general [11,12]. While family doctors have typically had low survey response rates [12,13], specialist physicians historically have demonstrated variability in response rates [14][15][16][17]. Kellerman and Herold [8] reviewed the variability of demographic characteristics on physician responses to surveys and found that medical specialty type was not associated with response rates. There is a clear dispute in the literature as to whether survey recruitment methods that are successful with general practitioners are also successful with other physician specialties. Also it is actually uncommon in the survey methodology literature to see surveys conducted across multiple physician specialties. Our study allowed us to look at variations in response rate across multiple specialties and in addition, our recruitment methodology was unique in that individualized/personalized emails were sent to each physician. As survey research with specialist physician groups is on the rise [18][19][20], more survey research involving physician specialists is needed in order to understand the reasons for differences in response rates within this medical group. Specifically, identifying new recruitment methods that may be uniquely related to the physician specialist groups is needed.</p>
<p>Differential effects by medical specialty may be the result of several factors including preference for survey mode, survey design, survey length and potential confounding factors such as the gender of respondents [6,8,21]. For example, in one survey study of family and specialist physicians, pediatricians not only had higher response rates overall and within the promised-incentive group but were also the least sensitive to the timing of the incentive. One possible reason for this is that the response rate may be confounded by gender; women may be more likely to respond to surveys than men and women make up a larger proportion of pediatricians [21].</p>
<p>Response rate can be further affected by the survey topics. When the topic is of high interest to respondents, potential respondents are more likely to respond to the survey [6,[22][23][24]. In addition, whether survey topics are sensitive or non-sensitive or concern attitude or fact is likely to affect response rates in web surveys [6,22,24]. For example, obtaining data on physicians' billing practices is often challenging due to the sensitive nature of the topic [25]. Only a handful of studies have examined and compared survey response rates among physician specialists, in whom different survey methodologies may be necessary to achieve acceptable response rate [14,26].</p>
<p>As part of a larger project assessing the impact of physician billing practices on the completeness of administrative data, we sought to examine response rates to a web-based survey developed for medical and surgical specialists. The survey was designed to gather demographic and billing information from physician specialists in Fee-for-Service (FFS) and Alternative Payment Plans (APP). The recent introduction of Alternative Payment Plans across Canada has changed the way that many physicians are reimbursed and subsequently the process of physician billing [27]. Physicians on APPs are encouraged to submit claims for the services they provide called "shadow bills", for administrative purposes. Unfortunately, with these new APPs, they are not compensated for the time spent recording the services they deliver (i.e. shadow billing).</p>
<p>The objective of our study was to assess billing practices amongst a large group of medical and surgical specialists using a modified version of the Dillman method [23,28]. Our hypothesis was that the response rate to our web-based survey would be low due to the sensitive nature of the topic under investigation (i.e. physician billing practices). Here we discuss the results from our study findings including survey methodology and response rates, and we explore reasons for non-response.</p>
<p>Survey design: The initial three-page survey was reviewed and refined for content validity by a working group of eight senior researchers and practicing physicians from the various relevant specialties [i.e. intensive care unit (ICU), internal medicine, neurology and neurosurgery, pediatrics, psychiatry and general surgery]. The refinement process included a content review from all stakeholders listed as co-investigators for the project.</p>
<p>The final survey gathered information regarding physicians' billing status (FFS versus APP), whether they are obligated to shadow bill as part of their APP contract (if applicable), whether incentives are provided to them to shadow bill (if applicable) and demographic information. The email survey design and layout included two pages of questions. The primary method of accessing and completing the survey was via the Internet using a well-known and established survey company (www.surveymonkey.com). The survey company hosted and collected the survey data and only participants who were sent the email could connect to the hyperlink and respond to the questionnaire. However, if physicians had trouble accessing or completing the online survey, a paper version could be requested by mail or fax. Ethical approval for the study was obtained from the Office of Medical Bioethics at the University where the study took place out of.</p>
<p>Survey participants: The following physician specialties were targeted: ICU, internal medicine, neurology and neurosurgery, pediatrics, psychiatry and general surgery. We restricted our sample to these specialties as they were established APP and FFS programs and their specialty is a potential confounding factor for shadow billing behaviour and these specialty groups had a large number of registered physicians in a large Canadian city where the study took place.</p>
<p>Inclusion criteria were: 1) physicians employed and practicing in 2009; 2) on an APP or FFS payment plan and; 3) physicians providing inpatient or outpatient (i.e. clinic) services based at one of the four acute care hospitals in the city where the study took place. Exclusion criteria were: 1) general practitioners (as the majority are remunerated by FFS system and did not fit into the scope or budget of our study) and; 2) medical trainees (i.e. medical students, residents, and fellows) as the majority of them do not submit billings.</p>
<p>Respondent Sampling: The survey sampling frame was generated using a list of physicians from the 2008 Canadian Medical Directory. The original list included 1012 physicians, their clinic/hospital appointment, specialty, as well as contact information. Because the contact information on the list is not updated regularly, the information (i.e. phone, address, email) and specialty was further verified through the latest faculty/ department contact lists, and physician contact directories posted on websites of Alberta Health Services, hospitals and the College of Physicians of Alberta website. After the verification of contact information, 108 physicians were excluded due to incorrect contact information or unavailable contact information. The final population of physicians targeted included 904 physicians (324 internists, 58 neurologists/neurosurgeons, 171 pediatricians, 118 psychiatrists and 233 general surgeons).</p>
<p>Survey promotion and process: Figure 1 outlines the survey invitation process and timeline. A website containing the project information, investigators' contact information, and a link to the survey was developed. Meetings were held with department heads for each medical/ surgical group to discuss the study and obtain letters of support. Meetings and presentations promoting the survey were also organized with the various medical departments. All the initial email invitations contained a link to the study website which provided further information regarding the study and research team, and a link to access the survey. Additionally, all emails contained the eligibility criteria for participating physicians, the opening and closing dates for access to the survey, and a unique identification number for each participant.</p>
<p>The main strategy to promote the website and survey was to involve key individuals (i.e. influential physicians from each medical group included in the study) to facilitate, encourage, and support their colleagues, department heads, and other physicians to complete the survey. The emails were addressed and sent individually to each physician by name, thereby avoiding any issues with confidentiality which can be a challenge with mass emailing lists. Emails were also sent using personalized subject headings. The key physicians who were supporting the promotion of the survey authorized their names to be used in the subject heading (i.e. Dr. X is asking for your help). Supporting physicians' names used in the subject heading were representative of all the medical departments/specialties involved in the study. The goal of using a familiar physician's name to personalize the invitation was to add peer influence and to increase the likelihood of physicians' reading the email and consenting to participate. A generic subject heading listing the funding body (i.e. xxx funded research project) was also used in cases where the use of an individual physician's name was not deemed appropriate. All responding inquiries or comments were directed primarily to the lead research coordinator and physician co-investigators. Physicians were given the opportunity to submit their unique study ID number with the submission of their survey, and by doing so their names were entered into a one-time draw for three $200.00 (Canadian) gift certificates to a local bookstore.</p>
<p>Finally, after the allotted time period passed to respond to the initial survey invite, a secondary survey was sent to all eligible non-respondents asking them to identify the reasons for not participating in the original survey. The actual question that was sent via email was "In a few words or sentences, please indicate why you were unable or unwilling to complete the survey." Physician specialist responses were gathered qualitatively.</p>
<p>Of the 904 eligible physicians contacted, 317 eligible physicians responded to the survey, for an overall response rate of 35.0%. Table 1 outlines the baseline demographic characteristics of the survey respondents. The majority of respondents were male (55.1%) between the ages of 40 and 59 (51%). A large proportion of physicians had been in practice for more than 15 years (44.6%), with only 18.3% in practice less than 5 years. The majority of physicians (47.7%) were remunerated on a full-time APP plan and 38.1% were paid on a FFS plan (see Table 1).</p>
<p>Table 2 outlines the characteristics of physician survey respondents by type of payment plan. Internal medicine specialists on a full-time APP plan were most likely to respond (54%), followed by internal medicine specialists on a part-time APP plan (38.6%) and surgery (35.3%) and internal medicine (35.3%) specialists on a FFS plan. Psychiatrists on both full-time APP (8.7%) and FFS (9.2%) plans were least likely to respond to the survey. Physician specialists aged 40-59 years on both APP part-time (63.3%) and full-time (51%) plans were more likely to respond to the survey. FFS physicians (46.2%) in the 40-59 years of age category were also more likely to respond than other age categories. Male physician specialists had statistically significant higher levels of response across all payment plans (APP full 51.7%; APP part 54.5%; FFS 59.7%) compared to their female counterparts. Finally, those physician specialists with more than 15 years in practicing medicine were more likely to respond. Part-time APP physicians (50%) with the highest response rate followed by FFS (47%) and full-time APP physicians (41%).</p>
<p>The response rates by timing of reminders for the medical specialty groups are shown in Table 3. Internal medicine (33.6%) and neurology/neurosurgery (34.5%) had the highest response rates following the Of the physicians who responded to the initial survey, 82.6% (262/317) provided their unique identification number to be entered into the lottery draw.</p>
<p>Sixty-three physicians responded to the secondary survey aimed at exploring reasons for non-response, for a response rate of 11.8% (n = 63/533). Of those who responded to the follow-up survey (n = 63), 70.5% were males and 29.5% were females. Respondents for this follow-up survey were from the following specialties: Internal medicine (34.2%), general surgery (27.8%), neurology/neurosurgery (0.03%), pediatrics (18.2%) and psychiatry (16.9%). Reasons for non-response were survey burden, with 60.3% of respondents reporting that there were too many survey requests and they lacked the time to complete them; 15.9% believed they were not eligible; 12.7% had no interest or saw no benefit to completing the survey; 7.9% felt the survey was asking information which was too private; and, 3.2% did not know their billing mechanism in order to complete the survey. It should be noted that in the current study, a handful of physicians (n = 5) responded unfavorably to the offer of a lottery draw incentive, finding it offensive and unethical.</p>
<p>We conducted an online survey using a personalized invitation email strategy (with web-based survey) in addition to various other recruitment methods (multiple follow-up/reminders, lottery draw). These strategies have been used in prior survey studies to increase physician response rates [29,30]. The 35.0% response rate for our own survey was lower than anticipated, but in view of the sensitive nature of the topic under investigation, it was not unexpected. Our response rate is still higher or comparable to similar studies using email as a distribution mode among physician specialists [31,32].</p>
<p>The sensitive nature of our topic (i.e. physician billing practices) and the time-period during which our survey was conducted most likely contributed to a lower response rate. Survey research shows that survey topics which are sensitive or non-sensitive or concern attitude or fact is likely to affect response rates in web surveys [6,24]. According to several meta-analyses, the salience of a topic is one of the most important factors that influence response rates in both mail and web surveys [6,22,23,33,34]. The contract renewal period for all physicians' on APPs occurred during the months in which our survey opened. This may have affected response rates, as physicians may have been cautious about consenting to have their billing practices reviewed for the purposes of our study, as the contract renewal process directly examined the quality of physician's billing submissions. Despite this challenge, many of the responding physicians contacted us to ask questions about our study after the initial survey invitation, indicating they were interested in our study topic and requested having the results sent to them. In one case, a face-to-face interview was set up with a physician to discuss the details of the study. Given our project resources, email was the most efficient, inexpensive and timely manner of contacting survey participants. Tracking, managing, and organizing the incoming data was simple and was ideal for the short project timeframe.</p>
<p>Results from studies of previous web-based surveys indicate similar trends in response rates to the current study. In one meta-analyses, the mean response rate for 68 web-based surveys reported in 49 studies was 39.6% [22], similar to our current findings. In Kellerman et al.</p>
<p>[8], the response rates for general practitioners and specialists were 40.1% (186/464) and 49.6% (235/474), respectively. Response rates among specialist physicians vary within the literature [21]. In one study, a mail survey, pediatricians had higher response rates compared to general practitioners, internists and obstetricsgynecology physicians and were also the least sensitive to the timing of the incentive [21]. In the current study, neurologists and internists had the highest levels of response. This may also be due to gender differences in that a large proportion of women in those specialties responded to the questionnaire compared to the other specialties. Our findings are in concordance with previous literature which suggests women physicians may be more likely to respond to surveys than male physicians [6,21]. Additionally in the current study, internal medicine and pediatrics had some of the most longstanding Alternative Payment Programs (i.e. established in [2003][2004][2005], which may have lessened the concern of physicians in responding to a survey about billing behaviors making them more likely to respond compared to the other specialties. Among published studies involving physician as respondents, survey response rates seem to be most influenced by the use of individual monetary incentives [35][36][37]. For example, a US study found that the provision of a small ($2.00) monetary incentive sent to each physician invited to participate, yielded a substantially greater response rate (56.0% vs. 44.0 %) than the lottery draw of a larger, one-time, cash incentive [38]. It has been proposed that in order to achieve the response rates needed to validate health care policy-related research using survey methodology, the offer of monetary incentives may become a necessary part of the research process [39,40]. A recent Canadian study examining the use of a substantial monetary lottery incentive among physicians did not find that financial incentives improved response rate. In fact, response rates were lower in the following year (35.9% in 2004, 31.6% in 2007) [41]. In a study examining prepaid incentives to physician specialists, the response rate was 52.1% for physicians who received a $20 check versus 67.8% for physicians who received a $50 check (P &lt; 0.001) [42]. As physicians become increasingly burdened with surveys, studies suggest larger incentives may be necessary to engage potential respondents and thus maximize response rate [42].</p>
<p>Based on these findings and from our own survey findings, individual smaller financial incentives for each respondent may increase initial buy-in from participants, and may be superior to large, one-time lottery draws. However since we did not include a comparison group of individual small financial incentives, this conclusion is somewhat limited. Additionally it is important to note, that a handful of physicians (n = 5) responded to the offer of a lottery draw incentive unfavorably. Similar studies have found negative responses to incentives [26,43], although not the point of withdrawing from the study. In the case of the current study, the physicians declined to participate as a result of being offered a personal incentive.</p>
<p>The timing of follow up reminders has also been shown to increase response rates. However, recommendations regarding the timing of follow up and frequency of follow up reminders vary substantially in the literature [13]. Our study was associated with an increase in response rates by medical or surgical specialty after each follow-up/reminder; however, no clear pattern surfaced as to which timeframe (1 st week, 3 rd week) is most ideal to increase response rates. Our results suggest that at least one follow-up reminder may prove beneficial in increasing response rates [4,44]. More recently, research suggests too many reminders may be viewed as possible harassment of potential respondents [45]. Future research should focus on the ideal number and nature of reminders and specifically, how much is too much.</p>
<p>Researchers must always explore and address the bias associated with non-response. Physicians who responded to our follow up survey (11.8%) displayed similar patterns or characteristics of response across gender and specialty. However, beyond these two characteristics, we were not able to compare or contrast other factors that may have influenced certain physicians to respond versus non-respondents. Kellerman and Herold [8] outline the reasons why responding and non-responding physicians tend to share similar characteristics. Physicians as a group are more homogeneous regarding knowledge, training, attitudes, and behavior and variations that do exist among physicians may not be as associated with willingness to respond or survey content [8].</p>
<p>In the current study, it is important to recognize that non-respondents may differ from participating physicians in ways we were unable to assess and is noted as a possible response bias issue. The main reason for initial non-response in our study was survey burden, with a lack of time to complete them (60.3%). Physicians commonly acknowledge that too many survey requests and growing constraints on their time limit their ability to participate in multiple, concurrent survey-based studies [46] . Given the demands on their time, survey topic or salience must be relevant and the survey must present a benefit to physicians in order for them to participate. Studies show physicians are interested in endorsing certain aspects of research where the opportunity to enact quality improvement and contribute to clinical knowledge is evident [47].</p>
<p>It was hypothesized that using personalized email subject headings with the names of key physicians who were supporting the promotion of the survey (i.e. Dr. X is asking for your help) would help bolster participation. As with mail surveys, previous literature indicates using personalized correspondence is apparently associated with higher response rates for electronic survey [22]. However this also may have led to response bias in the likelihood of increased participation of physicians in certain specialties (i.e. if the respondent was familiar with the physician who was promoting study). However, a generic subject heading listing the funding body (i.e. xxx funded research project) was also used in cases where the use of an individual physician's name was not deemed appropriate. The authors feel this bias would not have affected the results in a significant fashion, especially given the low response rate.</p>
<p>It is important to discuss the limitations of our study. First, 108 physicians were excluded due to incorrect contact information or unavailable contact information, resulting in possible selection bias. Second, there is always the possibility that an email will be identified as "spam mail" when using email as a contact method, possibly further reducing the response rate. Third, we only used one survey mode (i.e. email) which may have limited our response rate. Other limitations included the lack of a comparison group to establish whether our personal survey method enhanced response rates. As there were no controlled groups to compare various interventions that may be associated with improved response rate, it is not possible to firmly establish definite drivers of the degree of response observed in this study. However, we attempted to explore the different reasons for non-responses among physicians in our survey. Finally, the survey was limited to one large metropolitan city in Canada; thus, the findings may not be generalizable to other geographical locations, or to general practitioners or physicians in training.</p>
<p>In conclusion, our online survey response rate of 35.0% remains comparable to response rates from previously published physician specialist survey-based studies. Variations across medical specialties may have been influenced by gender as woman in certain specialties (i.e. internal medicine and neurology) were more likely to respond than their male counterparts. The response rate in the current study was likely influenced by the sensitive survey topic, but it is likely that specialties (i.e. pediatrics and internal medicine) with longstanding APP programs were more likely to respond as they had more experience with billing within that program. Future survey studies are needed to determine the ideal methodology based on survey topics for physician specialists. This study shares some of the challenges and successes of conducting survey research among multiple physician specialties, where advancement in successful survey recruitment methods is necessary.</p>
<p>*Note: Alternative Payment Program (APP), Fee-For-Service Payment Program (FFS). *Age percentage calculated among individuals with non-missing data; 54 individuals (17.3% of total sample) did not provide information. *Sex percentage calculated among individuals with non-missing data; 54 individuals (17.3% of total sample) did not provide information.</p>
<p>*</p>
<p>Data used in the analysis was collected through a project funded by the Canadian Institutes of Health Research (CIHR). H. Quan, N. Jetté, and W. A. Ghali are supported by Alberta Innovates Health Solutions (AIHS) Population Health Investigators Salary Awards. N. Jetté and W. A. Ghali are Canada Research Chair Tier 2 holders. Lindsay L. Sykes was funded by a Summer Studentship from AIHS.</p>
<p>Abbreviations APP: Alternative Payment Plans; FFS: Fee-for-Service; ICU: Intensive Care Unit.</p>
<p>The authors declare that they have no competing interests.</p>
<p>Please note that all authors have agreed to the conditions noted on the authorship agreement form and take full responsibility for this data, the analyses and interpretation. HQ and NJ conceived of the study idea and HQ, BH, TN, CAB, ED, SS, WAG and NJ secured funding for the project through writing and application of the grant. CTC, HQ, BH, TN, CAB, ED, SS, WAG, LLS and NJ all took part in the development and refinement of the questionnaire. CTC, HQ and NJ carried out the survey and CTC and LLS gathered and analyzed results. CTC, HQ, BH, TN, CAB, ED, SS, WAG, LLS and NJ all took part in the development and editing of the manuscript. All authors read and approved the final manuscript.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f567416075"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:41+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>In the context of survival analysis, calibration refers to the agreement between predicted probabilities and observed event rates or frequencies of the outcome within a given duration of time. We aimed to describe and evaluate methods for graphically assessing the calibration of survival models. We focus on hazard regression models and restricted cubic splines in conjunction with a Cox proportional hazards model. We also describe modifications of the Integrated Calibration Index, of E50 and of E90. In this context, this is the average (respectively, median or 90th percentile) absolute difference between predicted survival probabilities and smoothed survival frequencies. We conducted a series of Monte Carlo simulations to evaluate the performance of these calibration measures when the underlying model has been correctly specified and under different types of model mis-specification. We illustrate the utility of calibration curves and the three calibration metrics by using them to compare the calibration of a Cox proportional hazards regression model with that of a random survival forest for predicting mortality in patients hospitalized with heart failure. Under a correctly specified regression model, differences between the two methods for constructing calibration curves were minimal, although the performance of the method based on restricted cubic splines tended to be slightly better. In contrast, under a mis-specified model, the smoothed calibration curved constructed using hazard regression tended to be closer to the true calibration curve. The use of calibration curves and of these numeric calibration metrics permits for a comprehensive comparison of the calibration of competing survival models.</p>
<p>Assessing calibration is an important component of deriving and validating clinical prediction models. Calibration refers to the agreement between predicted and observed risk. 1,2 Time-to-event outcomes are common in prognostic research. Common examples include time to death or time to disease occurrence. While methods for evaluating the calibration of prediction models for binary outcomes (eg, logistic regression models) have been well-described, [1][2][3][4] there is less information on methods to assess the calibration of models for time-to-event outcomes. When outcomes are time-to-event in nature, the objective of prognostic models is frequently focused on estimating the probability of the occurrence of the outcome within a specified duration of time. A classic example is one of the Framingham Risk Scores which uses a survival model to estimate the probability of developing coronary heart disease within 10 years. 5 When discussing the calibration of models for time-to-event outcomes we are referring to assessing the agreement between the observed and the estimated probability of the event occurring within a specified duration of time. Thus, calibration in this setting is assessing observed and predicted probabilities at specific points in time. Thus, in the context of the Framingham Risk Score, calibration would refer to comparing the observed and predicted probabilities of developing coronary heart disease within 10 years.</p>
<p>The objective of this article is to describe and evaluate the performance of methods for assessing the calibration of predicted probabilities derived from models for time-to-event outcomes. The article is structured as follows: In Section 2, we summarize common methods for assessing calibration for binary outcomes and describe extensions to assessing calibration of predicted probabilities derived from models for time-to-event outcomes. In Section 3, we describe methods to compute smoothed calibration curves for time-to-event models. We describe two methods, one based on a flexible adaptive hazard regression model and the other based on the use of restricted cubic splines with a Cox proportional hazards model. We also describe how to compute numeric metrics for summarizing calibration. In Section 4, we describe a series of Monte Carlo simulations to evaluate the performance of these methods. In Section 5, we report the results of these simulations. In Section 6, we present a case study illustrating the application of these methods when comparing the calibration of a Cox proportional hazards model for predicting mortality after hospitalization for heart failure with that of a random survival forest. Finally, in Section 7, we summarize our findings and place them in the context of the literature.</p>
<p>When outcomes are binary, calibration refers to the agreement between observed and estimated probabilities of the occurrence of the event or outcome. A variety of methods have been proposed to assess calibration in this setting. First, subjects can be divided into strata based on the predicted probability of the outcome (eg, dividing subjects into 10 equally sized groups using the deciles of the predicted probabilities). Then, within each stratum, the mean predicted probability is computed as is the empirically estimated probability of the outcome (ie, the crude estimated probability of the outcome amongst all subjects in the given stratum). The mean predicted probability of the outcome can then be compared with the empirically estimated probability of the outcome across strata. These can be compared graphically, with deviations from a diagonal line indicating lack of calibration. While this approach is simple to implement, a limitation is the potential loss of information resulting from binning subjects into strata based on predicted risk. Second, rather than dividing subjects into strata based on the predicted probability of the outcome, smooth calibration curves based on loess regression smoothers or flexible nonlinear models can be produced. [1][2][3] This approach allows for an assessment of the agreement between observed and predicted risk across the spectrum of predicted risk. Third, summary numeric measures of calibration, such as the Integrated Calibration Index (ICI), E50, E90, and E max can be reported. 1,6 The ICI is the weighted difference between smoothed observed proportions and predicted probabilities, in which observations are weighted by the empirical density function of the predicted probabilities. The ICI is equivalent to the mean difference between predicted probabilities and observed probabilities derived from a smoothed calibration curve. E50 and E90 denote the median and 90th percentile of the absolute difference between observed and predicted probabilities. E max denotes the maximum absolute difference between observed and predicted probabilities of the outcome.</p>
<p>When outcomes are time-to-event in nature, calibration refers to the agreement between observed and estimated probabilities of the occurrence of the event or outcome within specified durations of time. Assessing calibration of predicted probabilities derived from models for time-to-event outcomes is complicated by two issues. First, calibration is typically assessed for time-to-event outcomes by comparing observed vs predicted probabilities of the outcome occurring within a specified time t. Thus, if multiple time points are of interest clinically, one would need to assess calibration at each of these time points. Second, when assessing calibration at time t, one observes for a given subject, not the probability of the outcome, but a time-to-event outcome. The most commonly used approach appears to be a modification of the stratification-based approach described above for use with binary outcomes. 1 Subjects are divided into strata based on the predicted probability of the occurrence of the event by time t. Within each stratum, the mean predicted probability of the occurrence of the event by time t is computed. Then, within each stratum, the observed probability of the occurrence of the event by time t is computed by fitting a Kaplan-Meier survival function to the subjects in that stratum. The mean predicted and observed probabilities can then be compared across strata, possibly using a scatter plot and superimposing a diagonal line on the resultant plot. Harrell suggests that a limitation of this approach is that, in addition to the risk categories being arbitrary, the categorization of predicted risk can lead to a loss of precision. 1(p506) He suggested that smoothed calibration curves be constructed using the flexible adaptive hazard regression model described by Kooperberg. 7 This approach allows for estimating the relationship between the observed outcome and predicted survival probabilities, which permit construction of smoothed calibration curves for time-to-event outcomes without assuming a parametric form or proportional hazards. While Kooperberg's article on hazard regression has been cited 178 times as of September 18, 2019 (Source: Web of Science), the large majority of these citations were by articles in the statistical and methodological literature. There is little evidence that hazard regression-based methods are commonly used to assess the calibration of time-to-event models. This approach, and a related-approach, will be described in greater detail in the following section. Crowson described a set of methods for assessing the calibration of Cox proportional hazards regression models based on fitting Poisson regression models. 8 Modifications of these methods allow for the production of smoothed calibration curves, similar to those advocated by Harrell.</p>
<p>The use of the Cox proportional hazards regression model is ubiquitous in modern medical research. 9 However, unlike parametric accelerated failure time models, the Cox regression model does not directly provide an estimate of the probability of the occurrence of the event within a specified duration of time. Obtaining an estimate of the baseline cumulative hazard function (eg, using the Breslow or Nelson-Aalen estimator) allows the analyst to estimate these probabilities. 10</p>
<p>In this section we describe methods for constructing smoothed calibration plots for survival outcomes and how numerical calibration metrics can be derived from these smoothed calibration curves.</p>
<p>Let F(t 0 | X) denote a model for estimating the probability of the occurrence of an event prior to time t 0 for a subject with covariate vector X. F(t 0 | X) could be a commonly used method such as a Cox proportional hazard regression model or it could be a method from the machine learning literature, such as a random survival forest. 11 For each subject, let Pt 0 = F(t 0 |X) denote the predicted probability of the occurrence of the outcome prior to time t 0 . Kooperberg et al described a family of flexible adaptive hazard regression models that use linear splines and tensor products to estimate the logarithm of the conditional hazard function. 7 This family of hazard regression models contains the proportional hazards models as a subclass. Hazard regression can be used to estimate a calibration curve for time-to-event outcomes. Given the observed time-to-event outcome for each subject (T), one can fit a hazard regression model: log(h(t)) = g(log(-log(1 -Pt 0 )), t), in which the log-hazard of the outcome is modeled as a function of the complementary log-log transformation of the predicted probability of the outcome occurring prior to time t 0 (this predicted probability was obtained using the model fit in the previous paragraph, whose calibration one now wants to assess). Note that we use Pt 0 in the preceding function, to highlight that calibration is being assessed at time t 0 , with Pt 0 denoting the predicted probability of an event occurring prior to time t 0 . Based on the fitted hazard model, an estimated probability of the occurrence of the outcome prior to time t 0 conditional on Pt 0 can be obtained. Note that while the model regressed the hazard of the outcome on the complementary log-log transformation of the predicted probability, we report results on the probability scale for greater interpretability. For each observed value of Pt 0 , the estimated probability of the occurrence of the outcome occurring prior to time t 0 is obtained. These are displayed graphically to produce a calibration plot for time t 0 .</p>
<p>An alternative to the use of a flexible adaptive hazard regression model is to use a conventional Cox proportional hazards model with restricted cubic splines to model the relationship between log(-log(1 -Pt 0 )) and the log-hazard of the outcome. Based on the fitted model, an estimated probability of the occurrence of the outcome prior to time t 0 can be estimated for each value of Pt 0 . From these estimated probabilities, a calibration curve can be constructed. While this second approach can be implemented easily using standard statistical software, a disadvantage is having to assume proportional hazards.</p>
<p>Note that in both approaches we have used the complementary log-log transformation for the predicted probabilities rather than the probabilities themselves. In the experience of one of the authors, there are two advantages to this approach. First, this transformation likely lessens the number of knots needed when using restricted cubic splines. Second, it may increase the likelihood of a linear relationship between the probability of the outcome and the linear predictor. The simplification of the fit is a result of not needing to impose any constraints in the regression space.</p>
<p>Software for implementing both methods using the R statistical programming language is provided in Appendices A and B.</p>
<p>Once a smoothed calibration curve has been constructed, one can compute the following numerical calibration metrics: ICI, E50, and E90. For each subject we have a predicted probability of the outcome occurring within time t. Then, using the smoothed calibration curve, one can determine an estimate of the smoothed observed probability of the outcome occurring within time t. The ICI is computed as the mean absolute difference between observed and predicted probabilities across the sample. This is equivalent to the weighted absolute difference between the calibration curve and the diagonal line of best fit, where the difference is weighted by the distribution of predicted probabilities. 6 E50 is the median absolute difference between observed and predicted probabilities, while E90 is the 90th percentile of the absolute difference between observed and predicted probabilities. Let Pt 0 denote the predicted probability of the occurrence of the outcome prior to time t 0 and let Pc</p>
<p>We conducted a series of Monte Carlo simulations to examine the ability of the methods described above to assess the calibration of survival models. We examined three different scenarios: (i) the fitted model was correctly specified; (ii) the fitted model omitted a quadratic term; (iii) the fitted model omitted an interaction. Our first set of simulations examined the choice of number of knots when using restricted cubic splines to construct a calibration curve.</p>
<p>The number of knots used in the restricted cubic splines when modeling the relationship between the hazard of the outcome and the predicted probability of the outcome within a given duration of time can be thought of as a hyper-parameter. We conducted a series of simulations to determine the optimal value of this hyper-parameter when the underlying regression model was correctly specified. We simulated data for a large super-population consisting of 1 000 000 subjects. For each subject we simulated a continuous covariate x from a standard normal distribution: x∼N(0, 1). While frequently the focus will be on assessing the calibration of a multivariable model, one can think of the single continuous covariate as a linear predictor or risk score that summarizes the multivariable contribution of a set of predictor variables. We then simulated a time-to-event outcome for each subject so that outcomes followed a Cox-Weibull model, using methods described by Bender et al. 12 We simulated event times as follows: T =</p>
<p>, where U is a random uniform number between 0 and 1, 𝛽 = log(1.5), 𝜆 = 0.0000227, and 𝜈 = 1.75. Thus, a one unit increase in x (equivalent to a one standard deviation (SD) increase) was associated with a 50% increase in the hazard of the outcome, the median event time was approximately 1 year in the super-population and the maximum observed event time was approximately 10 years. We determined the 10th, 25th, 50th, 75th, and 90th percentiles of event times in this large super-population. We refer to these times as t 10 , t 25 , t 50 , t 75 , and t 90 , respectively.</p>
<p>From the large super-population, we draw a random sample of size N. In this sample we used a Cox proportional hazards model to regress the hazard of the outcome on the single covariate X. The calibration of the fitted Cox model was assessed using restricted cubic splines with k knots, as described in the previous section. We evaluated the calibration of the fitted model at the five times: t 10 , t 25 , t 50 , t 75 , and t 90 . Graphical smoothed calibration curves, ICI, E50, and E90 were computed. This process was repeated 1000 times and the mean calibration curve was estimated across the 1000 simulation replicates (the values of each of the 1000 calibration curves were evaluated along the same grid; for each value on that grid, we determined the mean value across the 1000 calibration curves). Similarly, ICI, E50, and E90 were averaged across the 1000 simulation replicates. We allowed one factor to vary in these simulations: the number of knots. We considered three different values for this factor: 3, 4, and 5. The size of the random samples (N) was fixed at 1000 subjects.</p>
<p>These simulations were similar to those described above with four exceptions. First, we used both restricted cubic splines and hazard regression to assess model calibration. Second, we fixed the number of knots for the restricted cubic spline model at three, based on the results from the previous set of simulations. Third, we allowed one factor to vary in this set of simulations: the size of the random samples. We considered three different values for this factor: 500, 1000, and 10 000. Fourth, we introduced the presence of censoring and allowed the proportion of subjects who were censored to vary across scenarios. We allowed the proportion of subjects that were censored to range from 0 to 0.60 in increments of 0.10.</p>
<p>In order to incorporate censoring, we modified the data-generating process so that for each subject we simulated an event time (using methods identical to those described above) and a censoring time. Censoring times were simulated from an exponential distribution. For each subject, the observed survival time was the minimum of the simulated event time and the simulated censoring time. Subjects were considered as censored observations if the censoring time was less than the event time. A bisection approach was used to determine the rate parameter for the exponential distribution so that the proportion of censored subjects in the super-population was equal to the desired value. Due to the presence of censoring, we evaluated calibration at the specified quantiles of the observed survival time in the large super-population, rather than at the specified quantiles of event times.</p>
<p>The simulations described above evaluated the performance of the graphical calibration methods when the survival model was correctly specified. This set of simulations was similar to those described in Section 4.2, with the following modifications. First, event times were simulated as follows:</p>
<p>,</p>
<p>where 𝛽 1 = log (1.5) and 𝛽 2 = log (1.25). Thus, the log-hazard of the outcome has a quadratic relationship with the continuous covariate x. In each random sample of size N, a mis-specified Cox proportional hazards model was fit. The model incorporated only a linear term for x and omitted the x 2 term. We did not incorporate censoring in this set of simulations for two reasons: (i) censoring was shown to have no effect in the previous set of simulations; (ii) to simplify the presentation of the results.</p>
<p>This set of simulations explored the use of graphical calibration methods when an interaction term was omitted from the fitted model. This set of simulations was similar to those described in Section 4.2, with the following modifications. First, two covariates were simulated for each subject. As above, the first covariate was simulated from a standard normal distribution: x 1 ∼N(0, 1). However, the second covariate was simulated from a Bernoulli distribution with parameter 0.5: x 2 ∼Be(0.5). Second, event times were simulated as follows:</p>
<p>, where 𝛽 1 = log(1) = 0 and 𝛽 2 = log(2)log(1) = log (2). Thus, among subjects for whom x 2 = 0, there was no association between x 1 and the hazard of the outcome (hazard ratio = 1), while in subjects for whom x 2 = 1, a one unit increase in x 1 (equivalent to a one SD increase) was associated with a 100% increase in the hazard of the outcome (hazard ratio = 2). In each random sample of size N, a mis-specified Cox proportional hazards model was fit. The fitted model incorporated two variables: x 1 and x 2 and omitted the interaction between these two variables. As in the previous section, we did not incorporate censoring in this set of simulations for two reasons: (i) censoring was shown to have no effect in the simulations in Section 4.2; (ii) to simplify the presentation of the results.</p>
<p>The mean estimated calibration curves across the 1000 simulation replicates are described in Figure 1. The figure consists of five panels, one for each of the five times points at which calibration was assessed (t 10 , t 25 , t 50 , t 75 , and t 90 ). Each panel displays the mean calibration curve for each of the three values of the number of knots (3, 4, and 5 knots). For each value on the grid of predicted probabilities along which the mean calibration curve was estimated (see above), we also estimated the 2.5th and 97.5th percentiles of the observed probabilities across the 1000 sampled datasets. Using these estimated percentiles, we have superimposed lines for each of the three values of the number of knots reflecting the variability in the estimated calibration curve across the 1000 simulation replicates. On each panel we have also superimposed a non-parametric estimate of the density function of the predicted probabilities in the large super-population (right vertical axis). Across the five times at which we assessed calibration, the use of three knots tended to result in calibration curves that were closer to the diagonal line of perfect calibration. For each of the five times, the use of three knots resulted in calibration curves that were, on average, indistinguishable from the line of perfect calibration. Furthermore, the estimated calibration curves displayed increasing variability across simulation replicates as the number of knots increased from three to five.</p>
<p>The mean estimated values of the ICI, E50, and E90, along with their SD across the 1000 simulated samples are reported in Figure 2 (the standard errors of the different calibration metrics are reported as error bars). For all combinations of time points (t 10 , t 25 , t 50 , t 75 , and t 90 ) and metrics (ICI, E50, and E90), mean calibration was better when three knots were used than when four or five knots were used. ICI was closer to zero when using three knots compared to when using four knots in at least 77% of the simulated datasets across the five different percentiles of event time. ICI was closer to zero when using three knots compared to when using five knots in at least 89% of the simulated datasets across the five different percentiles of event time. E50 was closer to zero when using three knots compared to when using four knots in at least 66% of the simulated datasets across the five different percentiles of event time. E50 was closer to zero when using three knots compared to when using five knots in at least 78% of the simulated datasets across the five different percentiles of event time. E90 was closer to zero when using three knots compared to when using four knots in at least 74% of the simulated datasets across the five different percentiles of event time. E90 was closer to zero when using three knots compared to when using five knots in at least 86% of the simulated datasets across the five different percentiles of event time.</p>
<p>Based on the results of these simulations, we concluded that the use of three knots is preferable to the use of four or five knots when using restricted cubic splines to compute calibration curves. Accordingly, this value was used in all subsequent simulations.</p>
<p>The mean estimated calibration curves across the 1000 simulation replicates are described in Figures 345678. There is one figure for combination of sample size (500/1000/10 000) and method of constructing calibration curves (restrictive cubic splines vs hazard regression). Due to the incorporation of different degrees of censoring, results from the different methods could not be superimposed on the same figure and retain their readability. Each calibration curve is restricted to a range of predicted probabilities ranging from the first to the 99th percentiles of risk in the population. Each figure consists of five panels, one for each of the five time points at which calibration was assessed (t 10 , t 25 , t 50 , t 75 , and t 90 ). Each panel depicts the mean calibration curve for the given method of constructing calibration curves, along with lines denoting the 2.5th and 97.5th percentiles of the calibration curves across the 1000 simulation replicates. This pair of curves provides an assessment of the variability of the calibration curves across simulation replicates. There is one set of curves for each of the different degrees of censoring. On each panel we have superimposed a diagonal line denoting perfect calibration.</p>
<p>On each panel we have also superimposed non-parametric estimates of the density of the predicted probabilities in the large super-population (right vertical axis). Note that there is a separate density function for each of the different degrees of censoring.</p>
<p>Regardless of the degree of censoring, both methods tended to result in calibration curves that were close to the diagonal line of perfect calibration over the range of predicted probabilities in which most subjects lay. When the sample size was low, both methods resulted in calibration curves that displayed moderate to large variability in the region in which predicted probabilities had low density. When the sample size was 500, differences between the two approaches were, at most, minor. However, the method based on restricted cubic splines always resulted in a mean calibration curve that coincided with the diagonal line denoting perfect calibration. When the sample size was 1000 or 10 000, then both methods produced calibration curves that were, on average, essentially indistinguishable from the diagonal line of perfect calibration. Furthermore, when the sample size was 10 000, there was very little variation in the estimated calibration curves across simulation replicates.</p>
<p>The mean estimated values of calibration metrics are reported in Figure 9 (ICI), Figure 10, (E50), and Figure 11 (E90). In each figure there are five panels, one for each of the times at which calibration is assessed. Since the fitted model was correctly specified, we want the values of the calibration metrics to be close to zero. For both methods (restricted cubic splines and hazard regression), ICI tended to be close to zero for most settings and times at which calibration was assessed. For each estimation method, ICI tended to decrease towards zero as the sample size increased. For a given sample size and degree of censoring, the use of restricted cubic splines tended to result in an estimated ICI that was closer to zero than did the use of hazard regression. For both methods (restricted cubic splines and hazard regression). When assessing calibration at a higher percentile of survival time (75th and 90th percentiles), the estimated ICI tended to increase as the proportion of subjects that were censored increased when restricted cubic splines were used. The converse was true for lower percentiles of survival time. Similar results were observed for E50 and E90.</p>
<p>The mean estimated calibration curves across the 1000 simulation replicates are described in Figure 12 (sample size = 500), Figure 13 (sample sizes = 1000), and Figure 14 (sample size = 10 000). The figures have a similar structure to those of Figures 345678, except that there are no calibration curves in the presence of censoring. In all three figures the mean calibration curves differed from the diagonal line of perfect calibration. The mean calibration curves tended to have an approximately quadratic shape, providing evidence that a quadratic term had been omitted from the model. The variation displayed by the calibration curves decreased with increasing sample size.</p>
<p>On each panel we have superimposed the true calibration curve (green curve) (which is defined differently from the diagonal line of perfect calibration). This curve was estimated using the large super-population. We applied the true (correctly specified) model and the mis-specified model to the super-population to estimate the true probability of the outcome and the mis-specified probability of the outcome for each subject in the super-population. We then plotted the true probability of the outcome against the mis-specified probability of the outcome using a solid green curve, to denote the true calibration curve. In general, the smoothed calibration curve estimated using hazard regression tended to be closer to the true calibration curve, compared with the calibration curve estimated using restricted cubic splines. When making predictions at the 10th, 25th, and 50th percentiles of event time, differences between the two approaches were minimal; however, the hazard regression-based approach tended to be slightly closer to the true calibration curve.</p>
<p>The mean estimated values of the ICI, E50, and E90 are reported in the top section of Table 1. Since a mis-specified model had been fit, we want the values of the calibration metrics to be different from zero, indicating that the models are miscalibrated. The values of the calibration metrics reported in Table 1 are larger than those reported when a correctly specified model was fit (Figures 9-11). For a given setting, the values of ICI, E50, and E90 obtained when using restricted cubic splines tended to be equal to or larger than those obtained when using hazard regression. The bottom section of Table 1 reports the ICI, E50, and E90 when comparing differences between predicted probabilities and the true calibration curve described above (note that since the true calibration curve is estimated in the full super-population, there are not separate values of the calibrations metrics for different sample sizes). Ideally, we want the estimated values of these metrics to be close to the true values. The values of ICI, E50, and E90 produced using hazard regression tended to be modestly closer to the "true" values of ICI, E50, and E90 than are the values produced using restricted cubic splines.</p>
<p>The mean estimated calibration curves across the 1000 simulation replicates are described in Figure 15 (sample size = 500), Figure 16 (sample sizes = 1000), and Figure 17 (sample size = 10 000). The figures have a similar structure to the previous sets of figures. These figures suggest that despite the omission of an interaction, the resultant models were, in general, well-calibrated. When assessing calibration at all five time points, both methods resulted in mean calibration curves that were close to the diagonal line that denotes perfect calibration in the range of predicted probabilities with the highest density.</p>
<p>On each panel we have superimposed the true calibration curve (green curve). The true calibration curve is different from the diagonal line denoting perfect calibration. When making predictions at the 90th percentiles of event time, the smoothed calibration curve estimated using hazard regression tended to be closer to the true calibration curve compared with the smoothed calibration curve estimated using restricted cubic splines. When making predictions at the 10th, 25th, 50th , and 75th percentiles of event time, neither approach resulted in smoothed calibration curves that coincided with the true calibration curve over its entire range. Furthermore, neither approach resulted in a smoothed calibration curve that was noticeably closer to the true calibration curve than that produced by the other method. The mean estimated values of the ICI, E50, and E90 are reported in the top section of Table 2. The values of the three calibration metrics when an interaction was omitted were not meaningfully different from when the correct model had been specified (Figures 9-11). In the majority of the 15 settings, the values of ICI, E50, and E90 were marginally larger when hazard regression was used compared with when restricted cubic splines were used. However, the small values for these metrics suggest that they cannot be used reliably to identify the omission of an interaction.</p>
<p>The bottom section of Table 2 reports the ICI, E50, and E90 when comparing differences between predicted probabilities and the true calibration curve described above (since the true calibration curve is estimated in the full super-population, there are not separate values of the calibrations metrics for different sample sizes). The estimated values of ICI, E50, and E90 obtained using hazard regression (top section of table) tended to be closer to "true" values of ICI, E50, and E90 (bottom section of table) than were the estimated values of ICI, E50, and E90 obtained using restricted cubic splines (top section of table). In general, the estimated values of ICI, E50, and E90 obtained using hazard regression were close to the "true" values of these metrics.</p>
<p>We provide a case study to illustrate the utility of graphical methods for assessing the calibration of survival models. We compare the calibration of a Cox proportional hazard model with that of a random survival forest for modeling the hazard of mortality within 5 years of hospitalization for heart failure. We assess the calibration of predictions of the probability of death within 1, 2, 3, 4, and 5 years using each approach.</p>
<p>The Enhanced Feedback for Effective Cardiac Treatment (EFFECT) Study was an initiative to improve the quality of care for patients with cardiovascular disease in Ontario. 13 During the first phase, detailed clinical data were collected on patients hospitalized with congestive heart failure (CHF) between April 1, 1999 and March 31, 2001 at 86 hospital corporations in Ontario, Canada. During the second phase, data were abstracted on patients hospitalized with this condition between April 1, 2004 and March 31, 2005 at 81 Ontario hospital corporations. Data on patient demographics, vital signs and physical examination at presentation, medical history, and results of laboratory tests were collected for these two samples. The first phase of the EFFECT sample will be used for model derivation, while the second phase will be used as an independent validation sample from a different temporal period. Data were available on 9945 and 8339 patients hospitalized with a diagnosis of CHF during the first and second phases of the study, respectively. After excluding subjects with missing data on any of the variables that will be included in our prediction models, 8240 and 7608 subjects were available from the first and second phases, respectively, for inclusion in the current study.</p>
<p>The outcome for the current case study was time from hospital admission to death, with subjects censored after 5 years of follow-up if death had not yet occurred. Data on both in-hospital and out-of-hospital mortality were available.</p>
<p>The candidate predictor variables considered in this case study were: age, sex, systolic blood pressure, heart rate, respiratory rate, neck vein distension, S3, S4, rales &gt;50% of lung field, pulmonary edema, cardiomegaly, diabetes, cerebrovascular disease/transient ischemic attack, previous acute myocardial infarction, atrial fibrillation, peripheral vascular disease, chronic obstructive pulmonary disease, dementia, cirrhosis, cancer, left bundle branch block, hemoglobin, white blood count, sodium, potassium, glucose, urea, and creatinine. We fit a Cox proportional hazard regression model in the derivation sample (EFFECT phase 1) in which the hazard of mortality was regressed on all the variables listed above. The fitted model was then applied to the independent validation sample (EFFECT phase 2). We also fit a random survival forest in the derivation sample, in which the hazard of mortality was modeled using the covariates listed above. 11 For the random survival forest, 1000 survival trees were grown. Fivefold cross-validation was used in the derivation sample to determine the optimal number of predictor variables to be selected at each node for consideration for use in splitting that node. The optimal number of predictor variables to select was 21, when using ICI in the derivation sample as the optimization criterion. The fitted survival forest was then applied to the independent validation sample. We evaluated the calibration of these two methods in the validation sample at 1, 2, 3, 4, and 5 years post-admission. Graphical calibration curves were computed, as were ICI, E50, and E90.</p>
<p>Calibration curves for the Cox proportional hazard model and the random survival forest when RCS was used to construct the calibration curves. There is one curve for each of the two models. The diagonal line denotes the line of perfect calibration. The density function denotes a non-parametric estimate of the distribution of predicted risk across the sample (right axis) [Colour figure can be viewed at wileyonlinelibrary.com]</p>
<p>The calibration plots for the two methods are described in Figures 18 (restricted cubic splines approach) and Figure 19 (hazard regression approach). Each figure consists of five panels, one each for assessing calibration at 1, 2, 3, 4, and 5 years post-admission. As in the previous figures, we have assessed calibration over an interval ranging from the first percentile of predicted probabilities to the 99th percentile of predicted probabilities.</p>
<p>On each panel we superimposed the density function for the predicted probabilities of death within the given interval as derived from the Cox proportional hazards model. The estimated ICI, E50, and E90 are reported in Table 3.</p>
<p>In examining Figure 18, one observes that the Cox regression model and the random survival forests tended to have comparable calibration. The one exception was when predicting the probability of death within 5 years of hospital admission, where the random forest displayed better calibration in subjects with high predicted probabilities of mortality. With one exception, for each of the three calibration metrics (ICI, E50, and E90) and at each of the five time points (1, 2, 3, 4, and 5 years), calibration was better for the Cox proportional hazards regression model than for the random survival forest (the exception was predicting survival at 1 year and assessing calibration using the ICI). Qualitatively similar results were observed when using hazard regression to assess calibration of the two methods.</p>
<p>We described two methods for constructing smoothed calibration curves for assessing the calibration of models for time-to-event outcomes. From these smoothed calibration curves, three different numerical calibration metrics can be derived that quantify differences between predicted and observed probabilities. The use of graphical calibration curves allows for an assessment of the calibration of survival models. Furthermore, the numeric calibration metrics will facilitate the comparison of the calibration of different models for survival data. We compared the use of flexible adaptive hazard regression with that of a Cox model using restricted cubic splines and found that they had comparable performance for constructing calibration curves. In most instances, differences between the two approaches tended to be negligible.</p>
<p>There is an extensive literature on assessing calibration of models for binary outcomes. [1][2][3][4]14 In clinical and epidemiological research, time-to-event outcomes are also common. Methods for assessing the calibration of models for time-to-event outcomes have received less attention. The purpose of the current study was 3-fold. First, to describe methods for graphically assessing the calibration of predicted probabilities of the occurrence of an event within a given duration of time. Second, to describe numerical calibration metrics for summarizing the calibration of models for time-to-event outcomes. Third, to conduct a series of Monte Carlo simulations to evaluate the performance of these methods in a wide range of settings. The current study is, to the best of our knowledge, the most comprehensive study on methods for assessing the calibration of models for time-to-event outcomes.</p>
<p>We have described three different numeric metrics for assessing the calibration of survival models. We suggest that the greatest utility of these metrics will be for comparing the relative calibration of different prediction models. This was illustrated in the case study, in which, when relying on graphical calibration curves, it was difficult to assess which method had superior calibration. However, the calibration metrics were able to quantify that the Cox proportional hazards model had superior calibration compared to the random survival forest. Given that there is no reference value for what constitutes an acceptable value of ICI, E50, or E90, these metrics will have limited utility when attention is restricted to a single model. However, these metrics can serve an important function when developing a prediction model. When the prediction method includes tuning parameters (as do random survival forests), the value of these metrics can be evaluated at different values of the tuning parameter and the value that optimizes calibration can be selected. This was done in our case study.</p>
<p>As noted in the above, Crowson et al suggested that a set of three Poisson regression models could be used to assess the calibration of a Cox proportional hazards model. 8 The first model allows for assessing calibration-in-the large, which quantifies the ratio of the number of observed events in the validation sample to the number of events predicted by the regression model. The second model allows for estimation of the calibration slope, while the third permits a comparison of observed and expected frequencies within risk strata. While the primary focus of that article was on assessing calibration using strata defined by grouping subjects with a similar predicted risk of the outcome, they note that the latter approach can be modified using regression smoothers to produce smoothed calibration plots. The current article provides several novel contributions. First, we used simulations to examine the relative performance of two different approaches to construct smoothed calibration curves. While Crowson and colleagues suggest that smoothing splines can be employed, we considered the relative performance of two different methods of producing smoothed calibration curves (RCS vs hazard regression). Second, we examined the performance of these methods in the face of model mis-specification. Third, we described numerical calibration metrics (ICI, E50, and E90) that can be derived from smoothed calibration plots. These metrics, which were originally proposed for assessing the calibration of models for binary outcomes, have not previously been extended for use with time-to-event outcomes. Fourth, our simulations allowed for an assessment of the sampling variability of both smoothed calibration curves and of the numerical calibration metrics.</p>
<p>In the current study, we have focused on graphical and numerical assessments of calibration. We have not focused on formal goodness-of-fit tests. The Hosmer-Lemeshow test is a commonly used statistical test for formally assessing the fit of a model for predicting the probability of binary outcomes. 15,16 This test is based on comparing observed vs predicted probabilities of the outcome across strata of predicted risk. Gronnesby and Borgan developed an extension of the Hosmer-Lemeshow test for use with survival data under the assumption of proportional hazards. 17 D'Agostino and Nam developed a formal test for assessing the goodness-of-fit of survival models that was motivated by the Hosmer-Lemeshow test, while Demler et al modified this test to improve its type I error rate when the proportion of subjects who were censored was high. 18,19 Similarly, May and Hosmer described goodness-of-fit tests for the Cox proportional hazards model that are motivated by the Hosmer-Lemeshow test. 20 While these tests provide a formal testing of the hypothesis of model goodness-of-fit, they do not provide information on the magnitude of mis-calibration or whether lack of calibration is only evident within a specific range of predicted risk. The methods described in the current article provide for both a qualitative (graphical) and numeric (ICI, E50, and E90) assessment of calibration.</p>
<p>In our final set of simulations, we observed that, despite the omission of an interaction term, the resultant mis-specified fitted model displayed good calibration. We note that under omnibus statistical tests such as general goodness-of-fit assessments (eg, calibration curve departure from line of identity, Hosmer-Lemeshow test, assessment of residuals, and Q-Q plots), specific model inadequacies (eg, omitted predictors, failure to account for nonlinearity, and omission of interactions) may not be readily apparent. Furthermore, the analyst may have difficulty tracing the lack of fit back to the root cause. Omnibus tests in general will have less power than directed tests. So, while we greatly value the importance of calibration plots, we note that their primary purpose is to assess overall model accuracy (calibration-in-the-small) and not principally to detect specific model structural problems. It is important to note that the omission of a variable can result in a mis-specified model that still displays good calibration.</p>
<p>There are certain limitations to the current study. Our evaluation of graphical calibration curves and calibration metrics was based on Monte Carlo simulations. Due to computational limitations and constraints on manuscript length, we were only able to examine a limited number of scenarios. These simulations were not intended to be comprehensive. Instead, we illustrated that the calibration curves performed as intended when the model was correctly specified. Furthermore, we showed that these metrics identified some forms of model mis-specification (eg, omission of a quadratic term) but not other forms of model mis-specification (eg, omission of an interaction). This latter set of simulations demonstrated that a model can display adequate calibration despite being mis-specified.</p>
<p>In summary, we have described and evaluated methods for constructing calibration curves of models for time-to-event outcomes and numerical calibration metrics. The use of graphical calibration curves allows for an assessment of the calibration of survival models. The numeric calibration metrics will facilitate the comparison of the calibration of different models for survival data. (cox.1yr.cll,3),x=T, data=effect2.df) calibrate.forest &lt;-coxph(Surv(survtime,mort5yr) ∼ rcs (forest.1yr.cll,3),x=T, data=effect2.df) predict.grid.cox &lt;-seq(quantile(effect2.df$cox.1yr,probs=0.01), quantile(effect2.df$cox.1yr,probs=0.99),length=100) predict.grid.cox.cll &lt;-log(-log(1-predict.grid.cox)) E90.1yr.forest &lt;-quantile(abs(effect2.df$forest.1yr -predict.calibrate.forest),probs=0.9) cat (1,ICI.1yr.cox,ICI.1yr.forest,E50.1yr.cox,E50.1yr.forest, E90.1yr.cox,E90.1yr.forest,</p>
<p>predict.cox &lt;-1 -predictSurvProb(cox1,newdata=effect2.df,times=365*(1:5)) # Predicted probability of death within 1,2,3,4,5 years. effect2.df$cox.1yr &lt;-predict.cox[,1]</p>
<p>effect2</p>
<p>predict</p>
<p>effect2.df$cox.1yr.cll &lt;-log(-log(1-effect2.df$cox.1yr))</p>
<p>This study was supported by ICES, which is funded by an annual grant from the Ontario Ministry of Health and Long-Term Care (MOHLTC). The opinions, results and conclusions reported in this article are those of the authors and are independent from the funding sources. No endorsement by ICES or the Ontario MOHLTC is intended or should be inferred. This research was supported by operating grant from the Canadian Institutes of Health Research (CIHR) (MOP 86508). Dr. Austin is supported in part by a Mid-Career Investigator award from the Heart and Stroke Foundation of Ontario. The Enhanced Feedback for Effective Cardiac Treatment (EFFECT) data used in the study was funded by a CIHR Team Grant in Cardiovascular Outcomes Research (Grant numbers CTP79847 and CRT43823). Dr. van Klaveren is supported by the Patient-Centered Outcomes Research Institute (grant ME-1606-35555). The work was supported by CTSA award No. UL1 TR002243 from the National Center for Advancing Translational Sciences to the Vanderbilt Institute for Clinical and Translational Research. Its contents are solely the responsibility of the authors and do not necessarily represent official views of the National Center for Advancing Translational Sciences or the National Institutes of Health.</p>
<p>Canadian Institutes of Health Research, Grant/Award Numbers: CRT43823, CTP79847, MOP 86508; Heart and Stroke Foundation of Canada; National Center for Advancing Translational Sciences, Grant/Award Number: UL1 TR002243; Patient-Centered Outcomes Research Institute, Grant/Award Number: ME-1606-35555; Ontario Ministry of Health and Long-Term Care; ICES</p>
<p>The data sets used for this study were held securely in a linked, de-identified form and analysed at ICES. While data sharing agreements prohibit ICES from making the data set publicly available, access may be granted to those who meet pre-specified criteria for confidential access, available at www.ices.on.ca/DAS.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f81778269"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Human languages evolve by a process of descent with modification in which parent languages give rise to daughter languages over time and in a manner that mimics the evolution of biological species. Descent with modification is just one of many parallels between biological and linguistic evolution that, taken together, offer up a Darwinian perspective on how languages evolve. Combined with statistical methods borrowed from evolutionary biology, this Darwinian perspective has brought new opportunities to the study of the evolution of human languages. These include the statistical inference of phylogenetic trees of languages, the study of how linguistic traits evolve over thousands of years of language change, the reconstruction of ancestral or proto-languages, and using language change to date historical events. Keywords Languages . Evolution . Darwin . Phylogeny Writing in his Descent of Man (1871), 11 years after the publication of the Origin of Species (1859), Darwin observed that Bthe formation of different languages and of distinct species, and the proofs that both have been developed through a gradual process, are curiously the same^(Darwin, 1871, p. 59; the German linguist Schleicher had made the same point in 1863, eight years before Darwin). As usual, Darwin (and Schleicher) was on to something, because it turns out that the transmission and evolution of genes and languages share a number of striking parallels (see Table 1).</p>
<p>Indeed, the transmission of linguistic information is not merely analogous to the transmission of genetic information: At a mathematical level, the two can be seen as formally equivalent, given certain simplifying assumptions. Both genes and languages can be represented as digital systems of inheritance, built on the transmission of discrete chunks of information-genes in the case of biological organisms, and words in the case of language. Genes in turn comprise combinations of the four bases or nucleotides (A, C, G, T) whereas words can be modelled as comprising combinations of discrete sounds or phones (in fact, phones or sounds vary in a continuous space, but languages are commonly represented as expressing a particular set of discrete phonemes).</p>
<p>The similarities between these two systems of inheritance raises the possibility that we can import to the study of languages ideas, approaches, and methodologies originally developed to investigate genetic systems-a prospect that has been fulfilled: In recent years a field of phylogenetic and comparative studies of how languages evolve has grown up around ideas and methodologies adapted from evolutionary biology and statistics (Pagel, 2009). I will describe some of these in this article, attempting to show how a Darwinian perspective has allowed researchers to use languages to test questions of human history as well to test questions of how languages themselves evolve.</p>
<p>Linguists have known from at least the late 18th century (Jones, 1824) that languages evolve from earlier ancestral languages, eventually giving rise to family trees or what biologists call phylogenies of related contemporary languages.</p>
<p>A phylogenetic tree is a hypothesis about the specific sequence of historical branching events leading from a common ancestor forwards in time to the contemporary groupings, be they biological species or languages. One of the best studied linguistic phylogenies is that defined by the Indo-European (I-E) language family, a highly simplified form of which is shown in Fig. 1a.</p>
<p>Figure 1a depicts what is sometimes known as the Anatolian origin of the Indo-European languages, which scholars date to around 7,500 years ago (Bouckaert et al., 2012(Bouckaert et al., , 2013)). Others (e.g., Chang, Cathcart, Hall, &amp; Garrett, 2015) prefer a more recent origin of the I-E languages-closer to 6,000 years ago-and not in Anatolia but somewhere in the Russian steppes. Either way, the descendant languages of this family are now spoken widely across western Eurasia and the Indian subcontinent. Some of these modern descendants include the Celtic, Germanic, and Romance languages of western Europe, the Slavic languages of Russia and much of the Balkans, and the Indo-Iranian languages including Persian, Sanskrit, and many of the languages of the Indian subcontinent.</p>
<p>Phylogenies can seldom be observed directly because the ancestors that are inferred to have existed at the base or origin of the tree and then at its internal nodes or branching points (see Fig. 1a) no longer exist, having typically been replaced by their descendants over time. Even when ancient samples exist-possibly as fossils or as ancient texts-it is not always obvious precisely where on the tree they would be placed. For these reasons, phylogenies must be inferred, and this is usually accomplished by using information available in contemporary species or languages. Where biologists use the similarities and differences in genes among a group of species to infer biological phylogenies, linguistic phylogenies can be inferred from similarities and differences in lists (e.g., Swadesh, 1952) of common vocabulary words, or in patterns of shared sounds and sound use (Hruschka et al., 2015).</p>
<p>Modern phylogenetic studies rely on statistical models of evolution based on the principle of likelihood to guide the inference of phylogenetic trees (Edwards, 1972;Felsenstein, 2004;Pagel, 1999Pagel, , 2000Pagel, , 2009)). The likelihood is defined as the probability of the data (the patterns of similarity and differences in genes or words) given a tree or phylogeny and a model of evolution that contains assumptions about how words evolve. The likelihood is conventionally written as</p>
<p>where L is the likelihood, D stands for the data, M is the model of evolution, and T is the phylogenetic tree. The model of evolution M is, in a linguistic setting, a mathematical-statistical statement about the rate at which new forms arise and change. If words are the raw data, then the model estimates the rate at which new unrelated words arise. If the raw data are the phonemes or sounds that make up the words, then the model estimates the rate at which these sounds change from one to the other (e.g., Hruschka et al., 2015).</p>
<p>Given a list of words shared among the various languages (e.g., Fig. 1b), the goal is to find the phylogenetic tree (including its branching patterns, the lengths of the branches of the tree, and the relative timings of events in the tree) that makes the data (the word lists) most likely or probable given the model of evolution. The assumption is that change is rare or slow, and so contemporary forms that are more similar are probably more closely related than forms with less in common. The statistical nature of the likelihood means that alternative hypotheses (alternative trees) can be tested against the Bbest^or most probable tree by comparing their likelihoods, allowing researchers to support some descriptions of history over others. Statistical likelihood models have been used to reconstruct phylogenies of the Austronesian languages (Gray, Drummond, &amp; Greenhill, 2009), the Indo-European languages (e.g., Bouckaert et al., 2012;Chang et al., 2015;Gray &amp; Atkinson, 2003;Pagel, 2000), the Turkic languages (Hruschka et al., 2015), the Semitic languages (Kitchen, Ehret, Assefa, &amp; Mulligan, 2009), Japonic (Lee &amp; Hasegawa, 2011), Bantu (Grollemund, Branford, Meade, Venditti, &amp; Pagel, 2015), and Arawak (Walker, Robert, &amp; Ribeiro, 2011).</p>
<p>In addition to supplying descriptions of the history of a group of languages, language trees might be especially well suited to investigating questions of relatively recent human history, especially those of human migration. Gene evolution can be too slow to resolve recent events, and often there has been migration or intermarrying between groups that has diluted genetic differences even while cultural differences have been maintained. For instance, language trees have been used to study the timing and causes of the spread of Indo-European languages (e.g., Bouckaert et al., 2012;Chang et al., 2015;Gray &amp; Atkinson, 2003), the pace of occupation of the Pacific by the Austronesian people (Gray et al., 2009), and the migration routes of the Bantu-speaking people through Africa (Currie, Meade, Guillon, &amp; Mace, 2013;Grollemund et al., 2015).</p>
<p>Linguistic phylogenies are also routinely used to investigate questions of human cultural evolution. Here, language trees have been used to study the rise and spread of farming (Gray &amp; Atkinson, 2003), the movement of ancient horseman from the Russian steppes (Chang et al., 2015;Haak et al., 2015), the evolution and spread of dairying (Holden &amp; Mace, 2003, 2009;Mace, Jordan, &amp; Holden, 2003), relationships between religious and political practices (Watts et al., 2015), changing political structures (Currie, Greenhill, Gray, Hasegawa, &amp; Mace, 2010), and even the age of fairy tales (da Silva &amp; Tehrani, 2016).</p>
<p>Linguists define two words as cognate if they descend from a common ancestral word, just as biologists define two genes as homologous if they descend from a common ancestral gene (see Table 1 and Fig. 1b). An intriguing feature of human languages is that the words for some meanings get replaced over the course of evolution by new unrelated or noncognate words far more frequently than the words for other meanings. For instance, the words used to denote the concept of two of something are cognate among all of the Indo-European languages whereas the words for bird or drink change more often (see Fig. 1b).</p>
<p>A phylogenetic perspective on this question immediately tells us that the related sounds for two trace their ancestry far farther back in time than the sounds for bird. But, if a word is just a sound that conveys a meaning, why is it that some meanings retain their words far longer than others? It is not</p>
<p>Proto-I.E. the words themselves: Bird would be a perfectly fine sound to convey the idea of two objects, and two a perfectly fine sound to describe egg-laying, feathered animals that fly.</p>
<p>If words are coded as cognate or not among various languages, and this information is arrayed on a phylogenetic tree, as in Fig. 1b, it is possible to estimate the rates at which new cognate classes arise per unit time for different words. Applying statistical likelihood models comparable to those used for inferring phylogenies reveals a 100-fold difference in this rate in the Indo-European languages (Pagel, Atkinson, &amp; Meade, 2007). Numeral words and pronouns (I, you, who, two, three, five) tend to be among the slowest evolving (Pagel et al., 2007;Vejdemo &amp; Hörberg, 2016) whereas many adjectives and verbs (e.g., dirty, rotten, wet, smell, squeeze) have high rates of change. Nouns (e.g., ear, foot, salt, egg, star) often fall somewhere in the middle.</p>
<p>The differences in the rates of change among the various categories of words in Indo-European languages are replicated across many of the world's languages (Pagel, 2009), suggesting a common cause. It turns out that the single best predictor of how long a word will last before being replaced by a new noncognate form is the frequency with which it is used in common everyday speech: Words that are used frequently tend to be replaced at a slower pace than those that are infrequently used (Pagel et al., 2007), and the frequency with which specific meanings are used seems to be much the same around the world (Calude &amp; Pagel, 2011).</p>
<p>Armed with knowledge of the rates at which words change, it should be possible to perform what could be called linguistic archaeology-namely, to plumb what the past might have been like or to estimate when certain events occurred. In this way, languages can be used to ask and test questions about human history.</p>
<p>Ancient languages seldom leave a fossil trace, and so historical linguists often attempt to reconstruct past or protolanguages from the information in a set of related contemporary languages (e.g., Bomhard, 2008;Crowley &amp; Bowern, 2010). The success of this endeavor depends directly on rates of change: Words that change slowly over long periods of time, such as the numeral words, might provide a clear signal of their past or ancestral states. For instance, the proto-Indo-European (see Fig. 1a,b) word for two might have been duo, and tria might have been the proto-Indo-European word for three, stretching back perhaps 7,500 years (Bouckaert et al., 2013).</p>
<p>We (Pagel et al., 2007, and above) were interested to see if we could go back even further in time by studying words with exceptionally slow rates of change. If these Bultra-conserved' words exist more widely than in the Indo-European languages that we originally studied, cognate forms of them will be found today in a diverse range of languages that are the descendants of an even older common ancestor.</p>
<p>We found evidence for around 20 such ultra-conserved words, related forms of which can indeed be found today in languages from all over Eurasia (Pagel, Atkinson, Calude, &amp; Meade, 2013). Among the ultra-conserved words were thou (you), I, we, who, what, mother, bark (of a tree), ashes and fire. As expected, the ultra-conserved words tended to correspond to meanings that are used at high frequency, or at least might have been in our distant past. By taking into account the rate of change of these words, we were able to posit the existence of an ancestral language that would have been spoken around 15, 000 years ago, a time shortly after the last Ice Age, when all human groups were still hunter-gatherers.</p>
<p>Words can also be used to date historical events, an endeavor that Swadesh (1952) referred to as glottochronology. The Homeric epics are among some of the greatest masterpieces of literature. The Iliad is set during the Trojan War, the 10-year siege of the city of Troy (Ilium) by a coalition of Greek states, and so it must have been written sometime after the 12th century BCE-if indeed the wars were ever fought. But how much later? Was Homer effectively a Bwar reporter,^writing an account of events soon after they happened, or was he an historian?</p>
<p>Herodotus, writing in the Histories, Book II.53 around 450 BCE, remarked that Homer Blived, as I believe, not more than 400 years ago.^Many modern classicists and historians prefer a more recent, mid-8th century date for the Iliad. We (Altschuler, Calude, Meade, &amp; Pagel, 2013) decided to try to estimate a date for the Iliad by investigating patterns of cognacy among the 200 words of Swadesh's (1952) fundamental vocabulary in three languages: Modern Greek, Homeric Greek from Homer's Iliad, and Hittite, a language distantly related to both modern and Homeric Greek.</p>
<p>We first recorded whether each word in the Swadesh list was cognate or not between pairs of the three languages. Then, we solved for the date in history that was the most likely for the Iliad, given our knowledge of the rates of change of the words and the patterns of cognacy we observed. Our calculation suggested that the original text of the Iliad was released in approximately 762 BCE. This date is in close agreement with classicists' and historians' beliefs arrived at independently by studying historical references and the nature of Homeric Greek as expressed in the Iliad.</p>
<p>One way linguists classify languages is by their structural properties of syntax, grammar, and word morphology (e.g., Longobardi &amp; Guardiano's, 2009, study of syntax). A wellknown structural feature of a language is the order of the words in its sentences. The sentence BI kicked the ball,^for example, is SVO, or subject (S), verb (V), object (O). Of the six possible orderings of subjects, verbs, and objects in a sentence, two-SVO and SOV-dominate the world's languages; two others-VSO and VOS-account for ~10 % of languages; and the remaining two-OSV and OVS-are rare (Dryer &amp; Haspelmath, 2013;Gell-Mann &amp; Ruhlen, 2011;Greenberg, 1963).</p>
<p>A phylogenetic-statistical perspective makes it possible to trace the history of this important structural feature of languages, including inference of the most probable ancestral or founding word order for a group of languages. First, each of a number of related languages must be evaluated for its word order, and these are then arrayed on a phylogeny of the languages, as in Fig. 1b. With this combination of data and phylogenetic tree, it is then possible to study the evolution of the changing word orders in much the same way as I described in a previous section for studying rates of evolution of cognate classes.</p>
<p>Applying this statistical approach to the Indo-European languages suggests that SOV (BI the ball kicked^) was the most probable word order of the ancestral or proto-Indo-European languages (Dunn, Greenhill, Levinson, &amp; Gray, 2011;Pagel, 2009), and SOV is also inferred to be the likely ancestral state of many other language families (Gell-Mann &amp; Ruhlen, 2011; Maurits &amp; Griffiths, 2014).</p>
<p>Happily, the phylogenetic-statistical inference of the ancestral word order agrees with earlier conclusions from linguists (e.g., Lehmann, 1981). But we might then ask what the phylogeneticstatistical perspective brings or adds in this situation. Two answers might be given. One is that an approach using phylogenetic information can lead to different conclusions from those that fail to account for the relatedness among languages. Imagine, for example, that one investigated the languages of Fig. 1b without regard to their phylogeny. A simple count that ignores any information on the relatedness of the languages might suggest that SVO was the ancestral word order.</p>
<p>A second reason to use the phylogenetic-statistical approach is that it can locate on the tree the timings and placement of specific changes, and it can estimate both the dominant directions and the rates at which various transitions occur (see Maurits &amp; Griffiths, 2014;Pagel, 2009). Pagel (2009), for instance, found that SOV routinely gave rise to SVO word orders, and SVO to VSO, but that reverse transitions were rare or nonexistent.</p>
<p>Darwin's quote at the outset of this article is often used to illustrate his attachment to a gradual or smooth view of evolutionary changes. But two phenomena-punctuational change and concerted evolution-give slightly different perspectives on this gradual mode of evolution.</p>
<p>Phylogenetic trees for Austronesian, Bantu, and Indo-European languages all show that languages with a rich history of language-splitting events have diverged more from their ancestral languages than extant languages with fewer splitting events in their pasts (Atkinson, Meade, Venditti, Greenhill, &amp; Pagel, 2008). It is as if in Fig. 1a we would expect more linguistic change to have occurred along the path from the root of the tree up to the Celtic or Romance languages than we would along the path from the root to the Anatolian, Indo-Iranian, Slavic, or Germanic languages. The amount of time is the same in every case, but they differ in the number of splitting events (this example is hypothetical because the tree in Fig. 1a and b only incudes a few of the languages along each path). We observed a similar pattern for genetic evolution among biological species (Pagel, Venditti, &amp; Meade, 2006).</p>
<p>The explanation for the increased amounts of evolution along branches with more splitting events seems to be that at times of Bspeciation^and of Blineage splitting^-when new languages or species form-a short episode or punctuational burst of evolution occurs. Elsewhere, we have suggested that speciation and cultural splitting are special times of evolution when multiple factors can come into play that accelerate the pace of change (Venditti &amp; Pagel, 2010, 2014). Anthropological accounts of indigenous societies suggest that at times of cultural change, new groups will often actively change their language to distinguish themselves from their neighbors (Pagel, 2012).</p>
<p>Evolutionary biologists use the term concerted evolution to describe the strange phenomenon of a nucleotide replacement (one nucleotide being substituted for another) at a specific site in one gene, being quickly followed by the same nucleotide replacement at the same site in other, typically related, genes. A form of concerted evolution known as regular sound change is also observed in languages, where a specific phoneme or sound changes to the same other phoneme in many words in the lexicon (Crowley &amp; Bowern, 2010;Hruschka et al., 2015). A well-known example is the p→f sound change in the Germanic languages, where an older Indo-European p sound was replaced by an f sound, such as in pater→father, or pes, pedis→ foot.</p>
<p>As with punctuational episodes of change, concerted evolution is not what we normally associate with the gradual, even plodding, pace of evolution. On the other hand, neither punctuational nor concerted change violates a Darwinian view of evolution. Both are simply instances in which the pace of evolutionary change increases, sometimes dramatically, for short periods of time.</p>
<p>Where biological bodies are the temporary repositories of genes, human minds are the temporary repositories of words.</p>
<p>Both genes and words increase their probability of being transmitted-one into a new body, the other into a new mind-by adopting forms that are fitter than their competitors. The last 50 years or so of evolutionary studies has documented countless instances of the adaptation of genes. Now, in the last 10 to 20 years, the increasing use of evolutionary perspectives in combination with phylogenetic-statistical methods is documenting patterns in the evolution of languages, words and sound systems that are consistent with language adapting to the minds and habits of its speakers (Christiansen &amp; Chater, 2008). These new methods bring an explicit hypothesis testing rigor and make possible inferences, analyses, and tests not available to traditional studies.</p>
<p>Most of the preceding discussion has referred to patterns of evolution observed among languages. It is also possible to identify adaptive evolution occurring within single languages, that is, within a population of speakers. For instance, it is well known that frequently used words are shorter-the easier to say-conforming to Zipf's principle of least effort (Zipf, 1949). Rates of linguistic change also appear to be faster in larger populations (Bromham, Huaa, Fitzpatrick, &amp; Greenhill, 2015), confirming a key prediction of adaptive evolution: In larger populations, selection is better able to overcome the effects of random drift.</p>
<p>Where the transmission of genes has been responsible for the diversity of organismic life over the last 3.5 billion years, the transmission of sounds and words has been responsible for the diversity of languages over the approximately 160,000 to 200,000 year history of our species. But in that relative blink of an eye, the transmission of linguistic information-a feature confined to human society-has been far more influential on the recent history of the world than have genes. It could even be said that language's role in the transmission of the information that makes our societies possible-the development and continued improvement of nearly all of our artefacts and technologies-means that genes have now been superseded by this new but powerful Darwinian replicator.</p>
<p>Psychon Bull Rev (2017) 24:151-157</p>
<p>Psychon Bull Rev (2017) 24:151-157</p>
<p>Acknowledgments Advanced Investigator Award 268744 to M. Pagel from the European Research Council supported this research.</p>
<p>Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http:// creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f491166651"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:46+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The SARS-CoV-2 delta (B.1.617.2) variant is highly transmissible and spreading globally, including in populations with high vaccination rates. We aimed to investigate transmission and viral load kinetics in vaccinated and unvaccinated individuals with mild delta variant infection in the community.</p>
<p>Between Sept 13, 2020, and Sept 15, 2021, 602 community contacts (identified via the UK contract-tracing system) of 471 UK COVID-19 index cases were recruited to the Assessment of Transmission and Contagiousness of COVID-19 in Contacts cohort study and contributed 8145 upper respiratory tract samples from daily sampling for up to 20 days. Household and non-household exposed contacts aged 5 years or older were eligible for recruitment if they could provide informed consent and agree to self-swabbing of the upper respiratory tract. We analysed transmission risk by vaccination status for 231 contacts exposed to 162 epidemiologically linked delta variant-infected index cases. We compared viral load trajectories from fully vaccinated individuals with delta infection (n=29) with unvaccinated individuals with delta (n=16), alpha (B.1.1.7; n=39), and pre-alpha (n=49) infections. Primary outcomes for the epidemiological analysis were to assess the secondary attack rate (SAR) in household contacts stratified by contact vaccination status and the index cases' vaccination status. Primary outcomes for the viral load kinetics analysis were to detect differences in the peak viral load, viral growth rate, and viral decline rate between participants according to SARS-CoV-2 variant and vaccination status. Findings The SAR in household contacts exposed to the delta variant was 25% (95% CI 18-33) for fully vaccinated individuals compared with 38% (24-53) in unvaccinated individuals. The median time between second vaccine dose and study recruitment in fully vaccinated contacts was longer for infected individuals (median 101 days [IQR 74-120]) than for uninfected individuals (64 days [32-97], p=0•001). SAR among household contacts exposed to fully vaccinated index cases was similar to household contacts exposed to unvaccinated index cases (25% [95% CI 15-35] for vaccinated vs 23% [15-31] for unvaccinated). 12 (39%) of 31 infections in fully vaccinated household contacts arose from fully vaccinated epidemiologically linked index cases, further confirmed by genomic and virological analysis in three index case-contact pairs. Although peak viral load did not differ by vaccination status or variant type, it increased modestly with age (difference of 0•39 [95% credible interval -0•03 to 0•79] in peak log 10 viral load per mL between those aged 10 years and 50 years). Fully vaccinated individuals with delta variant infection had a faster (posterior probability &gt;0•84) mean rate of viral load decline (0•95 log 10 copies per mL per day) than did unvaccinated individuals with pre-alpha (0•69), alpha (0•82), or delta (0•79) variant infections. Within individuals, faster viral load growth was correlated with higher peak viral load (correlation 0•42 [95% credible interval 0•13 to 0•65]) and slower decline (-0•44 [-0•67 to -0•18]). Interpretation Vaccination reduces the risk of delta variant infection and accelerates viral clearance. Nonetheless, fully vaccinated individuals with breakthrough infections have peak viral load similar to unvaccinated cases and can efficiently transmit infection in household settings, including to fully vaccinated contacts. Host-virus interactions early in infection may shape the entire viral trajectory.</p>
<p>While the primary aim of vaccination is to protect individuals against severe COVID-19 disease and its consequences, the extent to which vaccines reduce onward transmission of SARS-CoV-2 is key to containing the pandemic. This outcome depends on the ability of continues to cause a high burden of cases even in countries with high vaccination coverage. Data are scarce on the risk of community transmission of delta from vaccinated individuals with mild infections.</p>
<p>Here, we report data from a UK community-based study, the Assessment of Transmission and Contagiousness of COVID-19 in Contacts (ATACCC) study, in which ambulatory close contacts of confirmed COVID-19 cases underwent daily, longitudinal URT sampling, with collection of associated clinical and epidemiological data. We aimed to quantify household transmission of the delta variant and assess the effect of vaccination status on contacts' risk of infection and index cases' infectiousness, including (1) households with unvaccinated contacts and index cases and (2) households with fully vaccinated contacts and fully vacci nated index cases. We also compared sequentially sampled</p>
<p>Evidence before this study The SARS-CoV-2 delta variant is spreading globally, including in populations with high vaccination coverage. While vaccination remains highly effective at attenuating disease severity and preventing death, vaccine effectiveness against infection is reduced for delta. Determining the extent of transmission from vaccinated delta-infected individuals to their vaccinated contacts is a public health priority. Comparing the upper respiratory tract (URT) viral load kinetics of delta infections with those of other variants gives insight into potential mechanisms for its increased transmissibility. We searched PubMed and medRxiv for articles published between database inception and Sept 20, 2021, using search terms describing "SARS-CoV-2, delta variant, viral load, and transmission". Two studies longitudinally sampled the URT in vaccinated and unvaccinated delta variant-infected individuals to compare viral load kinetics. In a retrospective study of a cohort of hospitalised patients in Singapore, more rapid viral load decline was found in vaccinated individuals than unvaccinated cases. However, the unvaccinated cases in this study had moderate-to-severe infection, which is known to be associated with prolonged shedding. The second study longitudinally sampled professional USA sports players. Again, clearance of delta viral RNA in vaccinated cases was faster than in unvaccinated cases, but only 8% of unvaccinated cases had delta variant infection, complicating interpretation. Lastly, a report of a single-source nosocomial outbreak of a distinct delta sub-lineage in Vietnamese health-care workers plotted viral load kinetics (without comparison with unvaccinated delta infections) and demonstrated transmission between fully vaccinated health-care workers in the nosocomial setting. The findings might therefore not be generalisable beyond the particular setting and distinct viral sub-lineage investigated.</p>
<p>The majority of SARS-CoV-2 transmission occurs in households, but transmission between fully vaccinated individuals in this setting has not been shown to date. To ascertain secondary transmission with high sensitivity, we longitudinally followed index cases and their contacts (regardless of symptoms) in the community early after exposure to the delta variant of SARS-CoV-2, performing daily quantitative RT-PCR on URT samples for 14-20 days. We found that the secondary attack rate in fully vaccinated household contacts was high at 25%, but this value was lower than that of unvaccinated contacts (38%). Risk of infection increased with time in the 2-3 months since the second dose of vaccine. The proportion of infected contacts was similar regardless of the index cases' vaccination status. We observed transmission of the delta variant between fully vaccinated index cases and their fully vaccinated contacts in several households, confirmed by whole-genome sequencing. Peak viral load did not differ by vaccination status or variant type but did increase modestly with age. Vaccinated delta cases experienced faster viral load decline than did unvaccinated alpha or delta cases. Across study participants, faster viral load growth was correlated with higher peak viral load and slower decline, suggesting that host-virus interactions early in infection shape the entire viral trajectory. Since our findings are derived from community household contacts in a real-life setting, they are probably generalisable to the general population.</p>
<p>Although vaccines remain highly effective at preventing severe disease and deaths from COVID-19, our findings suggest that vaccination is not sufficient to prevent transmission of the delta variant in household settings with prolonged exposures. Our findings highlight the importance of community studies to characterise the epidemiological phenotype of new SARS-CoV-2 variants in increasingly highly vaccinated populations. Continued public health and social measures to curb transmission of the delta variant remain important, even in vaccinated individuals.</p>
<p>See Online for appendix URT viral RNA trajectories from individuals with nonsevere delta, alpha, and pre-alpha SARS-CoV-2 infections to infer the effects of SARS-CoV-2 variant status-and, for delta infections, vaccination status-on transmission potential.</p>
<p>ATACCC is an observational longitudinal cohort study of community contacts of SARS-CoV-2 cases. Contacts of symptomatic PCR-confirmed index cases notified to the UK contact-tracing system (National Health Service Test and Trace) were asked if they would be willing to be contacted by Public Health England to discuss participation in the study. All contacts notified within 5 days of index case symptom onset were selected to be contacted within our recruitment capacity. Household and non-household contacts aged 5 years or older were eligible for recruitment if they could provide written informed consent and agree to self-swabbing of the URT. Further details on URT sampling are given in the appendix (p 13).</p>
<p>The ATACCC study is separated into two study arms, ATACCC1 and ATACCC2, which were designed to capture different waves of the SARS-CoV-2 pandemic. In ATACCC1, which investigated alpha variant and pre-alpha cases in Greater London, only contacts were recruited between Sept 13, 2020, and March 13, 2021. ATACCC1 included a pre-alpha wave (September to November, 2020) and an alpha wave (December, 2020, to March, 2021). In ATACCC2, the study was relaunched specifically to investigate delta variant cases in Greater London and Bolton, and both index cases and contacts were recruited between May 25, and Sept 15, 2021. Early re cruitment was focused in West London and Bolton because UK incidence of the delta variant was highest in these areas. 10 Based on national and regional surveillance data, community transmission was moderate-to-high throughout most of our recruitment period.</p>
<p>This study was approved by the Health Research Authority. Written informed consent was obtained from all participants before enrolment. Parents and caregivers gave consent for children.</p>
<p>Demographic information was collected by the study team on enrolment. The date of exposure for non-household contacts was obtained from Public Health England. COVID-19 vaccination history was determined from the UK National Immunisation Management System, general practitioner records, and self-reporting by study participants. We defined a participant as unvaccinated if they had not received a single dose of a COVID-19 vaccine at least 7 days before enrolment, partially vaccinated if they had received one vaccine dose at least 7 days before study enrolment, and fully vaccinated if they had received two doses of a COVID-19 vaccine at least 7 days before study enrolment. Previous literature was used to determine the 7-day threshold for defining vaccination status. [11][12][13] We also did sensitivity analyses using a 14-day threshold. The time interval between vaccination and study recruitment was calculated. We used WHO criteria 14 to define symptomatic status up to the day of study recruitment. Symptomatic status for incident casesparticipants who were PCR-negative at enrolment and subsequently tested positive-was defined from the day of the first PCR-positive result.</p>
<p>SARS-CoV-2 quantitative RT-PCR, conversion of ORF1ab and envelope (E-gene) cycle threshold values to viral genome copies, whole-genome sequencing, and lineage assignments are described in the appendix (pp 13-14).</p>
<p>Primary outcomes for the epidemiological analysis were to assess the secondary attack rate (SAR) in household contacts stratified by contact vaccination status and the index cases' vaccination status. Primary outcomes for the viral load kinetics analysis were to detect differences in the peak viral load, viral growth rate, and viral decline rate between participants infected with pre-alpha versus alpha versus delta variants and between unvaccinated delta-infected participants and vaccinated delta-infected participants.</p>
<p>We assessed vaccine effectiveness and susceptibility to SARS-CoV-2 infection stratified by time elapsed since receipt of second vaccination as exploratory analyses.</p>
<p>To model viral kinetics, we used a simple pheno menological model of viral titre 15 during disease pathogenesis. Viral kinetic parameters were estimated on a participantspecific basis using a Bayesian hierarchical model to fit this model to the entire dataset of sequential cycle threshold values measured for all participants. For the 19 participants who were non-household contacts of index cases and had a unique date of exposure, the cycle threshold data were supplemented by a pseudo-absence data point (ie, undetectable virus) on the date of exposure. Test accuracy and model misspecification were modelled with a mixture model by assuming there was a probability p of a test giving an observation drawn from a (normal) error distribution and probability 1 -p of it being drawn from the true distribution.</p>
<p>The hierarchical structure was represented by grouping participants based on the infecting variant and their vaccination status. A single-group model was fitted, which implicitly assumes that viral kinetic parameters vary by individual but not by variant or vaccination status. A four-group model was also explored, where groups 1, 2, 3, and 4 represent pre-alpha, alpha, unvaccinated delta, and fully vaccinated delta, respectively. We fitted a correlation matrix between participant-specific kinetic parameters to allow us to examine whether there is within-group correlation between peak viral titre, viral growth rate, and viral decline rate. Our initial model selection, using leave-oneout cross-validation, selected a four-group hierarchical model with fitted correlation coefficients between individual-level parameters deter mining peak viral load and viral load growth and decline rates (appendix p 5). However, resulting participant-specific estimates of peak viral load (but not growth and decline rates) showed a marked and significant correlation with age in the exploratory analysis, which motivated examination of models where mean peak viral load could vary with age. The most predictive model overall allowed mean viral 1) and transmission assessment (table 2). NHS=National Health Service. *All index cases were from ATACCC2. †All contacts. ‡The two earliest PCR-positive cases from the ATACCC2 cohort (one index case and one contact) were confirmed as having the alpha variant on whole-genome sequencing (recruited on May 28, 2021). This alpha variant-exposed, PCR-positive contact is excluded from figure 1B. §One PCR-negative contact had no vaccination status data available and one PCR-negative contact's index case had no vaccination data available. ¶Vaccination data were available for 138 index cases of 163. ||The contacts of these 15 index cases are included within the 232 total contacts. **These three index cases without contacts are only included in the viral load kinetics analysis (figure 3) and are not included in tables 1 and2 load growth and decline rates to vary across the four groups, with mean peak viral load common to all groups but assumed to vary linearly with the logarithm of age (appendix p 5). We present peak viral loads for the reference age of 50 years with 95% credible intervals (95% CrIs). 50 years was chosen as the reference age as it is typical of the ages of the cases in the whole dataset and the choice of reference age made no difference in the model fits or judgment of differences between the groups.</p>
<p>We computed group-level population means and within-sample group means of log peak viral titre, viral growth rate, and viral decline rate. Since posterior estimates of each of these variables are correlated across groups, overlap in the credible intervals of an estimate for one group with that for another group does not necessarily indicate no significant difference between those groups. We, therefore, computed posterior probabilities, pp, that these variables were larger for one group than another. For our model, Bayes factors can be computed as pp/(1-pp). We only report population (group-level) posterior probabilities greater than 0•75 (corresponding to Bayes factors &gt;3) as indicating at least moderate evidence of a difference.</p>
<p>For vaccine effectiveness, we defined the estimated effectiveness at preventing infection, regardless of symptoms, with delta in the household setting as 1 -SAR (fully vaccinated) / SAR (unvaccinated).</p>
<p>The funder of the study had no role in study design, data collection, data analysis, data interpretation, or writing of the report.</p>
<p>Between Sept 13, 2020, and Sept 15, 2021, 621 communitybased participants (602 contacts and 19 index cases) from 471 index notifications were prospectively enrolled in the ATACCC1 and ATACCC2 studies, and contributed 8145 URT samples. Of these, ATACCC1 enrolled 369 contacts (arising from 308 index notifications), and ATACCC2 enrolled 233 contacts (arising from 163 index notifications) and 19 index cases. SARS-CoV-2 RNA was detected in 163 (26%) of the 621 participants. Wholegenome sequencing of PCR-positive cases confirmed that 71 participants had delta variant infection (18 index cases and 53 contacts), 42 had alpha variant infection (one index case and 41 contacts), and 50 had pre-alpha variant infection (all contacts; figure 1A).</p>
<p>Of 163 PCR-positive participants, 89 (55%) were female and 133 (82%) were White. Median age was 36 years (IQR 26-50). Sex, age, ethnicity, body-mass index (BMI) distribution, and the frequency of comorbidities were similar among those with delta, alpha, and pre-alpha infection, and for vaccinated and unvaccinated delta-infected participants, except for age and sex (appendix pp 2-3). There were fewer unvaccinated females than males (p=0•04) and, as expected from the age-prioritisation of the UK vaccine roll-out, unvaccinated participants infected with the delta variant were significantly younger (p&lt;0•001; appendix p 3). Median time between exposure to the index case and study enrolment was 4 days (IQR 4-5). All participants had non-severe ambulatory illness or were asymptomatic. The proportion of asymptomatic cases did not differ among fully vaccinated, partially vaccinated, and unvaccinated delta groups (appendix p 3).</p>
<p>No pre-alpha-infected and only one alpha-infected participant had received a COVID-19 vaccine before study enrolment. Of 71 delta-infected participants (of whom 18 were index cases), 23 (32%) were unvaccinated, ten (14%) were partially vaccinated, and 38 (54%) were fully vaccinated (figure 1A; appendix p 3). Of the 38 fully vaccinated delta-infected participants, 14 had received the BNT162b2 mRNA vaccine (Pfizer-BioNTech), 23 the ChAdOx1 nCoV-19 adenovirus vector vaccine (Oxford-AstraZeneca), and one the CoronaVac inactivated wholevirion vaccine (Sinovac).</p>
<p>It is highly probable that all but one of the 233 ATACCC2 contacts were exposed to the delta variant because they were recruited when the regional prevalence of delta was at least 90%, and mostly 95-99% (figure 1B). 10 Of these, 206 (89%) were household contacts (in 127 households), and 26 (11%) were non-household contacts. Distributions of age, ethnicity, BMI, smoking status, and comorbidities were similar between PCR-positive and PCR-negative contacts (appendix p 4). The median time between second vaccine dose and study recruitment in fully vaccinated contacts with delta variant infection was 74 days (IQR 35-105; range 16-201), and this was significantly longer in PCR-positive contacts than in PCR-negative contacts (101 days [IQR 74-120] vs 64 days [32-97], respectively, p=0•001; appendix p 4). All 53 PCR-positive contacts were exposed in household settings and the SAR for all delta variant-exposed household contacts was 26% (95% CI 20-32). SAR was 1). We estimated vaccine effectiveness at preventing infection (regardless of symptoms) with delta in the household setting to be 34% (bootstrap 95% CI -15 to 60). Sensitivity analyses using a 14 day threshold for time since second vaccination to study recruitment to denote fully vaccinated did not materially affect our estimates of vaccine effectiveness or SAR (data not shown). Although precision is restricted by the small sample size, this estimate is broadly consistent with vaccine effectiveness estimates for delta variant infection based on larger datasets. 9, 16,17 The vaccination status of 138 epidemiologically linked index cases of 204 delta variant-exposed household contacts was available (figure 1B, table 2). The SAR in household contacts exposed to fully vaccinated index cases was 25% (95% CI 15-35; 17 of 69), which is similar to the SAR in household contacts exposed to unvaccinated index cases (23% [15-31]; 23 of 100; table 2). The 53 PCR-positive contacts arose from household exposure to 39 PCR-positive index cases. Of these index cases who gave rise to secondary transmission, the proportion who were fully vaccinated (15 [38%] of 39) was similar to the proportion who were unvaccinated (16 [41%] of 39). The median number of days from the index cases' second vaccination to the day of recruitment for their respective contacts was 73 days (IQR 38-116). Time interval did not differ between index cases who transmitted infection to their contacts and those who did not (94 days [IQR 62-112] and 63 days [35-117], respectively; p=0•43).</p>
<p>18 of the 163 delta variant-infected index cases that led to contact enrolment were themselves recruited to ATACCC2 and serial URT samples were collected from them, allowing for more detailed virology and genome analyses. For 15 of these, their contacts were also recruited (13 household contacts and two non-household contacts). A corresponding PCR-positive household contact was identified for four of these 15 index cases (figure 1B). Genomic analysis showed that index-contact pairs were infected with the same delta variant sub-lineage in these instances, with one exception (figure 2A). In one household (number 4), an unvaccinated index case transmitted the delta variant to an unvaccinated contact, while another partially vaccinated contact was infected with a different delta sub-lineage (which was probably acquired outside the household). In the other three households (numbers 1-3), fully vaccinated index cases transmitted the delta variant to fully vaccinated household contacts, with high viral load in all cases, and temporal relationships between the viral load kinetics that were consistent with transmission from the index cases to their respective contacts (figure 2B).</p>
<p>Inclusion criteria for the modelling analysis selected 133 participant's viral load RNA trajectories from 163 PCR-positive participants (49 with the pre-alpha variant, 39 alpha, and 45 delta; appendix p 14). Of the 45 delta cases, 29 were fully vaccinated and 16 were unvaccinated; partially vaccinated cases were excluded. Of the 133 included cases, 29 (22%) were incident (ie, PCR negative at enrolment converting to PCR positive subsequently) and 104 (78%) were prevalent (ie, already PCR positive at enrolment). 15 of the prevalent cases had a clearly resolvable peak viral load. Figure 3 shows modelled viral RNA (ORF1ab) trajectories together with the viral RNA copy numbers measured for individual participants. The E-gene equivalent is shown in the appendix (p 2). Estimates derived from E-gene cycle threshold value data (appendix pp 5, 7, 9, 11) were similar to those for ORF1ab.</p>
<p>Although viral kinetics appear visually similar for all four groups of cases, we found quantitative differences in estimated viral growth rates and decline rates (tables 3, 4). Population (group-level) estimates of mean viral load decline rates based on ORF1ab cycle threshold value data varied in the range of 0•69-0•95 log 10 units per mL per daxes 4; appendix p 10), indicating that a typical 10-day period was required for viral load to decline from peak to undetectable. A faster decline was seen in the alpha (pp=0•93), unvaccinated delta (pp=0•79), and fully vaccinated delta (pp=0•99) groups than in the pre-alpha group. The mean viral load decline rate of the fully vaccinated delta group was also faster than those of the alpha group (pp=0•84) and the unvaccinated delta group (pp=0•85). The differences in decline rates translate into a difference of about 3 days in the mean duration of the decline phase between the pre-alpha and delta vaccinated groups. Non-household exposed contacts (n=24, all PCR negative) were excluded. One PCR-negative household contact who withdrew from the study without vaccination status information was excluded. One PCR-negative household contact who could not be linked to their index case was also excluded. *The rows below show the number of contacts exposed to each category of index case.</p>
<p>Viral load growth rates were substantially faster than decline rates, varying in the range of 2•69-3•24 log 10 units per mL per day between groups, indicating that a typical 3-day period was required for viral load to grow from undetectable to peak. Our power to infer differences in growth rates between groups was more restricted than for viral decline, but there was moderate evidence (pp=0•79) that growth rates were lower for</p>
<p>(A) Genomic analysis of the four households with lineage-defining mutations for delta 18 and additional mutations within ORFs displayed to give insight into whether strains from individuals within the household are closely related. Lineages AY.4 and AY.9 are sub-lineages of delta. (B) Viral trajectories and vaccination status of the four index cases infected with the delta variant for whom infection was detected in their epidemiologically linked household contacts. All individuals had non-severe disease. Each plot shows an index case and their household contacts. Undetectable viral load measurements are plotted at the limit of detection ( 10 We estimated mean peak viral load for 50-year-old adults to be 8•14 (95% CrI 7•95 to 8•32) log 10 copies per mL, but peak viral load did not differ by variant or vaccination status. However, we estimated that peak viral load increases with age (pp=0•96 that the slope of peak viral load with log[age] was &gt;0), with an estimated slope of 0•24 (95% CrI -0•02 to 0•49) log 10 copies per mL per unit change in log(age). This estimate translates to a difference of 0•39 (-0•03 to 0•79) in mean peak log 10 copies per mL between those aged 10 years and 50 years.</p>
<p>Within-group individual participant estimates of viral load growth rate were positively correlated with peak viral load, with a correlation coefficient estimate of 0•42 (95% CrI 0•13 to 0•65; appendix p 8). Hence, individuals with faster viral load growth tend to have higher peak viral load. The decline rate of viral load was also negatively correlated with viral load growth rate, with a correlation coefficient estimate of -0•44 (95% CrI -0•67 to -0•18), illustrating that individuals with faster viral load growth tend to experience slower viral load decline.</p>
<p>Households are the site of most SARS-CoV-2 trans mission globally. 19 In our cohort of densely sampled house hold contacts exposed to the delta variant, SAR was 38% in unvaccinated contacts and 25% in fully vaccinated contacts. This finding is consistent with the known protective effect of COVID-19 vaccination against infection. 8,9 Notwithstanding, these findings indicate continued risk of infection in household contacts despite vaccination. Our estimate of SAR is higher than that reported in fully vaccinated household contacts exposed before the emergence of the delta variant. 1,20,21 The time interval between vaccination and study recruitment was significantly higher in fully vaccinated PCR-positive contacts than fully vaccinated PCR-negative contacts, suggesting that susceptibility to infection increases with time as soon as 2-3 months after vaccination-consistent with waning protective immunity. This potentially important observation is consistent with recent large-scale data and requires further investigation. 17 Household SAR for delta infection, regardless of vaccination status, was 26% (95% CI 20-32), which is higher than estimates of UK national surveillance data (10•8% [10•7-10•9]). 10 However, we sampled contacts daily, regardless of symptomatology, to actively identify infection with high sensitivity. By contrast, symptom-based, singletimepoint surveillance testing probably underestimates the true SAR, and potentially also overestimates vaccine effectiveness against infection.</p>
<p>We identified similar SAR (25%) in household contacts exposed to fully vaccinated index cases as in those exposed to unvaccinated index cases (23%). This finding indicates that breakthrough infections in fully vaccinated people can efficiently transmit infection in the household setting. We identified 12 household transmission events between fully vaccinated index case-contact pairs; for three of these, genomic sequencing confirmed that the index case and contact were infected by the same delta variant sub-lineage, thus substantiating epide miological data and temporal relations hips of viral load kinetics to provide definitive evidence for secondary transmission. To our knowledge, one other study has reported that transmission of the delta variant between fully vaccinated people was a point-source nosocomial outbreak-a single health-care worker with a particular delta variant sub-lineage in Vietnam. 22 Daily longitudinal sampling of cases from early (median 4 days) after exposure for up to 20 days allowed us to generate high-resolution trajectories of URT viral load over the course of infection. To date, two studies have sequentially sampled community cases of mild SARS-CoV-2 infection, and these were from highly specific population groups identified through asymptomatic screening programmes (eg, for university staff and students 23 and for professional athletes 24 ).</p>
<p>Our most predictive model of viral load kinetics estimated mean peak log 10 viral load per mL of 8•14 (95% CrI 7•95-8•32) for adults aged 50 years, which is very similar to the estimate from a 2021 study using routine surveillance data. 25 We found no evidence of variation in peak viral load by variant or vaccination status, but we report some evidence of modest but significant (pp=0•95) increases in peak viral load with age. Previous studies of viral load in children and adults 4,25,26 have not used such dense sequential sampling of viral load and have, therefore, been restricted in their power to resolve age-related differences; the largest such study 25 reported a similar difference between children and adults to the one we estimated. We found the rate of viral load decline was faster for vaccinated individuals with delta infection than all other groups, and was faster for individuals in the alpha and unvaccinated delta groups than those with pre-alpha infection.</p>
<p>For all variant vaccination groups, the variation between participants seen in viral load kinetic parameter estimates was substantially larger than the variation in mean parameters estimated between groups. The modest scale of differences in viral kinetics between fully vaccinated and unvaccinated individuals with delta infection might explain the relatively high rates of transmission seen from vaccinated delta index cases in our study. We found no evidence of lower SARs from fully vaccinated delta index cases than from unvaccinated ones. However, given that index cases were identified through routine symptomatic surveillance, there might have been a selection bias towards identifying untypically symptomatic vaccine breakthrough index cases.</p>
<p>The differences in viral kinetics we found between the pre-alpha, alpha, and delta variant groups suggest some incremental, but potentially adaptive, changes in viral dynamics associated with the evolution of SARS-CoV-2 towards more rapid viral clearance. Our study provides the first evidence that, within each variant or vaccination group, viral growth rate is positively correlated with peak viral load, but is negatively correlated with viral decline rate. This finding suggests that individual infections during which viral replication is initially fastest generate the highest peak viral load and see the slowest viral clearance, with the latter not just being due to the higher peak. Mechanistically, these data suggest that the host and viral factors determining the initial growth rate of SARS-CoV-2 have a fundamental effect on the trajectory throughout infection, with faster replication being more difficult (in terms of both peak viral load and the subsequent decline of viral load) for the immune response to control. Analysis of sequentially sampled immune markers during infection might give insight into the immune correlates of these early differences in infection kinetics. It is also possible that individuals with the fastest viral load growth and highest peaks contribute disproportionately to community trans mission, a hypothesis that should be tested in future studies.</p>
<p>Several population-level, single-timepoint sampling studies using routinely available data have found no major differences in cycle threshold values between vaccinated and unvaccinated individuals with delta variant infection. 10,27,28 However, as the timepoint of sampling in the viral trajectory is unknown, this restricts the interpretation of such results. Two other studies longitudinally sampled vaccinated and unvaccinated individuals with delta variant infection. 23,29 A retrospective cohort of hospitalised patients in Singapore 29 also described a faster rate of viral decline in vaccinated versus unvaccinated individuals with delta variant, reporting somewhat larger differences in decline rates than we estimated here. However, this disparity might be accounted for by the higher severity of illness in unvaccinated individuals in the Singaporean study (almost two-thirds having pneumonia, one-third requiring COVID-19 treatment, and a fifth needing oxygen) than in our study, given that longer viral shedding has been reported in patients with more severe illness. 30 A longitudinal sampling study in the USA reported that pre-alpha, alpha, and delta variant infections had similar viral trajectories. 24 The study also compared trajectories in vaccinated and unvaccinated individuals, reporting similar proliferation phases and peak cycle threshold values, but more rapid clearance of virus in vaccinated individuals. However, this study in the USA stratified by vaccination status and variant separately, rather than jointly, meaning vaccinated individuals with delta infection were being compared with, predominantly, unvaccinated individuals with pre-alpha and alpha infection. Moreover, sampling was done as part of a professional sports player occupational health screening programme, making the results not necessarily representative of typical community infections.</p>
<p>Our study has limitations. First, we recruited only contacts of symptomatic index cases as our study recruitment is derived from routine contact-tracing notifications. Second, index cases were defined as the first household member to have a PCR-positive swab, but we cannot exclude the possibility that another household member might already have been infected and transmitted to the index case. Third, recording of viral load trajectories is subject to left censoring, where the growth phase in prevalent contacts (already PCR-positive at enrolment) was missed for a proportion of participants. However, we captured 29 incident cases and 15 additional cases on the upslope of the viral trajectory, providing valuable, informative data on viral growth rates and peak viral load in a subset of participants. Fourth, owing to the age-stratified rollout of the UK vaccination programme, the age of the unvaccinated, delta variant-infected participants was lower than that of vaccinated participants. Thus, age might be a confounding factor in our results and, as discussed, peak viral load was associated with age. However, it is unlikely that the higher SAR observed in the unvaccinated contacts would have been driven by younger age rather than the absence of vaccination and, to our knowledge, there is no published evidence showing increased susceptibility to SARS-CoV-2 infection with decreasing age. 31 Finally, although we did not perform viral culture here-which is a better proxy for infectiousness than RT-PCR-two other studies 27,32 have shown cultivable virus from around two-thirds of vaccinated individuals infected with the delta variant, consistent with our conclusions that vaccinated individuals still have the potential to infect others, particularly early after infection when viral loads are high and most transmission is thought to occur. 30 Our findings help to explain how and why the delta variant is being transmitted so effectively in populations with high vaccine coverage. Although current vaccines remain effective at preventing severe disease and deaths from COVID-19, our findings suggest that vaccination alone is not sufficient to prevent all transmission of the delta variant in the household setting, where exposure is close and prolonged. Increasing population immunity via booster programmes and vaccination of teenagers will help to increase the currently limited effect of vaccination on transmission, but our analysis suggests that direct protection of individuals at risk of severe outcomes, via vaccination and non-pharmacological interventions, will remain central to containing the burden of disease caused by the delta variant.</p>
<p>AS, JD, MZ, NMF, WB, and ALal conceptualised the study. AS, SH, JD, KJM, AK, JLB, MGW, ND-F, RV, RK, JF, CT, AVK, JC, VQ, EC, JSN, SH, EM, TP, HH, CL, JS, SB, JP, CA, SA, and NMF were responsible for data curation and investigation. AS, SH, KJM, JLB, AC, NMF, and ALal did the formal data analysis. MAC, AB, DJ, SM, JE, PSF, SD, and ALac did the laboratory work. RV, RK, JF, CT, AVK, JC, VQ, EC, JSN, SH, EM, and SE oversaw the project. AS, SH, JD, KJM, JLB, NMF, and ALal accessed and verified the data. JD, MZ, and ALal acquired funding. NMF sourced and oversaw the software. AS and ALal wrote the initial draft of the manuscript. AS, JD, GPT, MZ, NMF, SH, and ALal reviewed and edited the manuscript. The corresponding author had full access to all the data in the study and had final responsibility for the decision to submit for publication.</p>
<p>Anjna Badhan, Simon Dustan, Chitra Tejpal, Anjeli V Ketkar, Janakan Sam Narean, Sarah Hammett, Eimear McDermott, Timesh Pillay, Hamish Houston, Constanta Luca, Jada Samuel, Samuel Bremang, Samuel Evetts, John Poh, Charlotte Anderson, David Jackson, Shahjahan Miah, Joanna Ellis, and Angie Lackenby.</p>
<p>NMF reports grants from UK Medical Research Council, UK National Institute of Health Research, UK Research and Innovation, Community Jameel, Janssen Pharmaceuticals, the Bill &amp; Melinda Gates Foundation, and Gavi, the Vaccine Alliance; consulting fees from the World Bank; payment or honoraria from the Wellcome Trust; travel expenses from WHO; advisory board participation for Takeda; and is a senior editor of the eLife journal. All other authors declare no competing interests.</p>
<p>An anonymised, de-identified version of the dataset can be made available upon request to allow all results to be reproduced. Modelling code will also be made publicly available on the GitHub repository.</p>
<p>χ²</p>
<p>10</p>
<p>(viral copies per mL) Log</p>
<p>10</p>
<p>(viral copies per mL)</p>
<p>Log</p>
<p>10</p>
<p>(viral copies per mL) Log</p>
<p>10</p>
<p>(viral copies per mL) Log</p>
<p>10</p>
<p>(viral copies per mL) Log</p>
<p>10</p>
<p>(viral copies per mL) Log</p>
<p>10</p>
<p>(viral copies per mL) www.thelancet.com/infection Vol</p>
<p>www.thelancet.com/infection Vol 22 February 2022</p>
<p>www.thelancet.com/infection Vol 22 February 2022</p>
<p>This work is supported by the National Institute for Health Research (NIHR200927), a Department of Health and Social Care COVID-19 Fighting Fund award, and the NIHR Health Protection Research Units (HPRUs) in Respiratory Infections and in Modelling and Health Economics. NMF acknowledges funding from the MRC Centre for Global Infectious Disease Analysis and the Jameel Institute. PSF and MAC are supported by the UK Dementia Research Institute. JD is supported by the NIHR HPRU in Emerging and Zoonotic Infections. MGW is supported by the NIHR HPRU in Healthcare Associated Infections and Antimicrobial Resistance. GPT is supported by the Imperial NIHR Biomedical Research Centre. We thank all the participants who were involved in the study, Public Health England staff for facilitating recruitment into the study, the staff of the Virus Reference Department for performing PCR and sequencing assays, and the Immunisations Department for assisting with analysis of vaccination data. We also thank Kristel Timcang, Mohammed Essoussi, Holly Grey, Guilia Miserocchi, Harriet Catchpole, Charlotte Williams, Niamh Nichols, Jessica Russell, Sean Nevin, Lulu Wang, Berenice Di Biase, Alice Panes, Esther Barrow, and Lauren Edmunds for their involvement in logistics, conducting data entry, or quality control; and the Molecular Diagnostics Unit at Imperial College London, in particular Lucy Mosscrop, Carolina Rosadas de Oliveira, and Patricia Watber, for performing RNA extraction, quantitative RT-PCR, and preparing samples for sequencing.</p>
<p>ORF1ab:T609I ORF1ab:A1306S ORF1ab:P1640L ORF1ab:P2046L ORF1ab:P2287S ORF1ab:A2529V ORF1ab:A2891T ORF1ab:V2930L ORF1ab:A3209V ORF1ab:T3255I ORF1ab:T3646A ORF1ab:V3718A ORF1ab:T3750I ORF1ab:T4129I ORF1ab:P4715L ORF1ab:G5063S ORF1ab:P5401L ORF1ab:T5631I ORF1ab:A6319V S:T95I S:G142D S:E156G S: Δ157-158 S:A222V S:D614G ORF7a:A55S ORF7b:T40I ORF8: Δ119-120 ORF8:n.28271delA N:G215C N:S232G</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f207651418"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:14+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Three-dimensional reconstruction of dynamic scenes is an important prerequisite for applications like mobile robotics or autonomous driving. While much progress has been made in recent years, imaging conditions in natural outdoor environments are still very challenging for current reconstruction and recognition methods. In this paper, we propose a novel unified approach which reasons jointly about 3D scene flow as well as the pose, shape and motion of vehicles in the scene. Towards this goal, we incorporate a deformable CAD model into a slanted-plane conditional random field for scene flow estimation and enforce shape consistency between the rendered 3D models and the parameters of all superpixels in the image. The association of superpixels to objects is established by an index variable which implicitly enables model selection. We evaluate our approach on the challenging KITTI scene flow dataset in terms of object and scene flow estimation. Our results provide a prove of concept and demonstrate the usefulness of our method.</p>
<p>This contribution has been peer-reviewed. The double-blind peer-review was conducted on the basis of the full paper.</p>
<p>3D reconstruction of dynamic scenes is an important building block of many applications in mobile robotics and autonomous driving. In the context of highly dynamic environments, the robust identification and reconstruction of individually moving objects are fundamental tasks as they enable save autonomous navigation of mobile platforms and precise interaction with surrounding objects. In image sequences, motion cues are amongst the most powerful features for separating foreground objects from the background. While approaches for monocular optical flow estimation have matured since the seminal work of (Horn and Schunck, 1980) 35 years ago, they still struggle with real world conditions such as non-lambertian surfaces, variable illumination conditions, untextured surfaces and large displacements. Apart from more sophisticated regularizers, stereo information provides a valuable source of information as it can be used to further constrain the problem. Furthermore, depth information allows for a more meaningful parametrization of the problem in 3D object space. Recent algorithms for scene flow estimation leverage this fact (Vogel et al., 2013, Vogel et al., 2014) and provide promising segmentations of the images into individually moving objects (Menze and Geiger, 2015).</p>
<p>In this paper, we build upon the method of (Menze and Geiger, 2015) but go one step further: Instead of simply decomposing the scene into a set of individually moving regions which share a common rigid motion, we decompose the scene into 3D objects and in addition to the rigid motion also model their pose and shape in 3D. Towards this goal, we incorporate a deformable 3D model of vehicles into the scene flow estimation process. More specifically, we exploit the Eigenspace-based representation of (Zia et al., 2011) which has previously been used in the context of pose estimation from a single image. Given two stereo pairs as input, our model jointly infers the number of vehicles, their shape and pose parameters, as well as a dense 3D scene flow field. The problem is formalized as energy minimization on a conditional random field encouraging projected object hypotheses to agree with the estimated motion and depth. A representative result is shown in Fig. 1 which depicts scene flow estimates projected to disparity and optical flow as well as the result of model-based reconstruction. The remainder of this paper is structured as follows. We first provide a brief summary of related work in Section 2. and a detailed formal description of the proposed method in Section 3. In Section 4. we present results for dynamic scenes on the novel KITTI scene flow dataset proposed by (Menze and Geiger, 2015). We conclude the paper in Section 5.</p>
<p>In this section, we provide a brief overview over the state-of-theart in scene flow estimation as well as related work on integrating 3D models into reconstruction.</p>
<p>Scene flow estimation has first been addressed by (Vedula et al., 1999, Vedula et al., 2005) who define scene flow as a flow field describing the 3D motion at every point in the scene. Like in classical optical flow estimation (Horn and Schunck, 1980), the problem is often formulated in a coarse-to-fine variational setting (Basha et al., 2013, Huguet and Devernay, 2007, Pons et al., 2007, Valgaerts et al., 2010, Wedel et al., 2011, Vogel et al., 2011) and local regularizers are leveraged to encourage smoothness in depth and motion. As in optical flow estimation, this approach eventually fails to recover large displacements of small objects. Following recent developments in optical flow (Yamaguchi et al., 2013, Nir et al., 2008, Wulff and Black, 2014, Sun et al., 2013) and stereo (Yamaguchi et al., 2014, Bleyer et al., 2011, Bleyer et al., 2012), Vogel et al. (Vogel et al., 2013, Vogel et al., 2014) proposed a slanted-plane model which assigns each pixel to an image segment and each segment to one of several rigidly moving 3D plane proposals, thus casting the task as a discrete optimization problem. Fusion moves are leveraged for solving binary subproblems with quadratic pseudo-boolean optimization (QPBO) (Rother et al., 2007). Their approach yields promising results on challenging outdoor scenes as provided by the KITTI stereo and optical flow benchmarks (Geiger et al., 2012). More recently, (Menze and Geiger, 2015) noticed that many structures in the visual world move rigidly and thus decompose the scene into a small number of rigidly moving objects and the background. They jointly estimate the segmentation as well as the motion of the objects and the 3D geometry of the scene. In addition to segmenting the objects according to their motion (which doesn't guarantee instances to be separated), in this paper, we propose to also estimate their shape and pose parameters. Thus, we infer a parametrized reconstruction of all moving vehicles in the 3D scene jointly with the 3D scene flow itself.</p>
<p>3D Models have a long history in supporting 3D reconstruction from images (Szeliski, 2011). Pioneering work, e.g. by (Debevec et al., 1996) made use of shape primitives to support photogrammetric modelling of buildings. While modelling generic objects, like buildings, is a very challenging task, there are tractable approaches to formalizing the geometry of objects with moderate intra-class variability, like faces and cars. A notable example is the active shape model (ASM) proposed by (Cootes et al., 1995) where principal component analysis of a set of annotated training examples yields the most important deformations between similar shapes. (Bao et al., 2013) compute a mean shape of the observed object class along with a set of discrete anchor points. Using HOG features, they adapt the mean shape to a newly observed instance of the object by registering the anchor points. (Güney and Geiger, 2015) leverage semantic information to sample CAD shapes with an application to binocular stereo matching. (Dame et al., 2013) use an object detector to infer the initial pose and shape parameters for an object model which they then optimize in a variational SLAM framework. Recently, (Prisacariu et al., 2013) proposed an efficient way to compress prior information from CAD models with complex shape variations using Gaussian Process Latent Variable Models. (Zia et al., 2013a, Zia et al., 2013b, Zia et al., 2015) revisited the idea of the ASM and applied it to a set of manually annotated CAD models to derive detailed 3D geometric object class representations. While they tackle the problem of object recognition and pose estimation from single images, in this paper, we make use of such models in the context of 3D scene flow estimation.</p>
<p>Our aim is to jointly estimate optimal scene flow parameters for each pixel in a reference image and a parametrized reconstruction of individually moving vehicles as shown in Fig. 2. The proposed algorithm works on the classical scene flow input consisting of two consecutive stereo image pairs of calibrated cameras. We define the first image from the left camera as the reference view. Following the state-of-the-art, we approximate 3D scene geometry with a set of planar segments which are derived from superpixels in the reference view (Yamaguchi et al., 2013). Like Figure 2. Data and Shape Terms. Each superpixel si in the reference view is matched to corresponding image patches in the three remaining views. Its shape and motion are encouraged to agree with the jointly estimated 3D object model. (Menze and Geiger, 2015), we assume a finite number of rigidly moving objects in the scene. It is important to note that using this formulation, the background can be considered as yet another object. The only difference is that we do not estimate a 3D model for the background component.</p>
<p>In this section, we first give a formal definition of our model and the constituting energy terms for data, shape and smoothness. Then, the employed active shape model and the inference algorithm are explained in detail.</p>
<p>Let S and O denote the set of superpixels and objects, respectively. Each superpixel si ∈ S is associated with a region Ri in the image and a random variable (ni, li) T where ni ∈ R 3 describes a plane in 3D (n T i x = 1 for points x ∈ R 3 on the plane) and li ∈ {1, . . . , |O|} is a label assigning the superpixel to an object. Each object o k ∈ O is associated with a random variable (ξ k , γ k , R k , t k ) T comprising its state. ξ k ∈ R 3 determines the pose, i.e. the position (2D coordinates in the ground plane) and the orientation of the object in terms of its heading angle. γ k ∈ R 2 contains the parameters determining the shape of the 3D model. R k ∈ SO(3) and t k ∈ R 3 describe the rigid body motion of object o k in 3D, i.e. the rotation and translation relating the poses of the object at subsequent time steps. Each superpixel si is associated with an object via li. Thus, the superpixel inherits the rigid motion parameters of the respective object (R l i , t l i ) ∈ SE(3). In combination with the plane parameters ni, this fully determines the 3D scene flow at each pixel inside the superpixel.</p>
<p>Given the left and right input images of two consecutive stereo frames at t0 and t1, our goal is to infer the 3D geometry, i.e. the plane parameters ni of each superpixel and its object label li together with the rigid body motion, the pose and the shape parameters of each object. We specify our model as a conditional random field (CRF) in terms of the following energy function</p>
<p>where s = {si|i ∈ S}, o = {o k |k ∈ O}, and i ∼ j denotes the set of adjacent superpixels in S. We use the same data term ϕ(•) and the same smoothness term ψ(•) as proposed in (Menze and Geiger, 2015), and add an additional shape term κ(•) to model the pose and shape of the objects in 3D. To make the paper selfcontained, we will briefly review the data term before we provide the formal description of the novel shape term.</p>
<p>Data fidelity of corresponding image points is enforced with respect to all four input images in a combined data term depending on shape and motion. Since both entities are encoded in different random variables, the data term is defined as a pairwise potential between superpixels and objects</p>
<p>where li assigns superpixel i to a specific object and [•] denotes the Iverson bracket, which returns 1 if the condition in square brackets is satisfied and 0 otherwise. Thus, the actual data term Di(n, o) is only evaluated with respect to the selected object.</p>
<p>It comprises three components: A stereo, an optical flow and a cross term which relate the reference view (left image at t0) to the three remaining images, as depicted in Fig. 2:</p>
<p>Note that this term depends on the plane parameters n of the superpixel and the rigid motion parameters of the object o. Each sub-term sums matching costs C of all pixels p inside the region R of superpixel i. As we assume that the geometry within a superpixel can be approximated by a local plane, we are able to warp pixels from the reference view to the other images using homographies computed from n and o:</p>
<p>The superscript of D indicates which image is compared to the reference view, with x ∈ {stereo, flow, cross}. Without loss of generality, the camera calibration matrix K ∈ R 3×3 is assumed to be the same for both cameras. The matching cost Cx(p, q) is a dissimilarity measure between a pixel at location p ∈ R 2 in the reference image and a pixel at location q ∈ R 2 in the target image.</p>
<p>In this work, we evaluate two types of features and define Cx(p, q) as the weighted sum of matching costs based on dense Census features (Zabih and Woodfill, 1994) and sparse disparity and optical flow observations:</p>
<p>The dense matching cost is computed as the truncated Hamming distance between Census features. Pixels leaving the target image are penalized with a truncation value. As precomputed disparity estimates (Hirschmüller, 2008) and optical flow features (Geiger et al., 2011) are not available for every pixel, we calculate C sparse x only at locations for which observations exist. More specifically, we define C sparse x as the robust l2 distance between the warped pixel πx(p) and the expected pixel q</p>
<p>where ρτ i (x) denotes the robust truncated penalty function ρτ i (x) = min(|x|, τi) with threshold τi and πx(p) denotes the pixel p, warped according to the set of sparse feature correspondences. Πx is the set of pixels in the reference image for which correspondences have been established. For more details, we refer the reader to (Menze and Geiger, 2015).</p>
<p>Our novel shape consistency term enforces consistency between the 3D plane of superpixel si and the pose and shape of the referenced object. Similarly to the data term, we can take advantage of the fact that this term decomposes into computationally tractable pairwise potentials between superpixels and objects:</p>
<p>Here, Si(ni, o k ) enforces consistency between the shape of object o k and the 3D plane described by ni. In analogy with the data term, shape consistency is evaluated with respect to the object associated with the superpixel via li. We define the penalty function Si as</p>
<p>where C bg denotes a constant penalty for superpixels associated with the background, and C obj i (n, o) denotes the sum of the truncated absolute differences between the 3D model of object o k projected to a disparity map (see Section 3.5) and the disparities induced by the 3D plane ni. Differences are computed for all pixels inside Ri which coincide with the projection of o k . Remaining, uncovered pixels are penalized with a multiple of C bg . Note that in contrast to the data term Di this term evaluates the consistency between the deformed shape model and the reconstructed superpixels.</p>
<p>The second part of Eq. 3 is the occlusion penalty O ik . It penalizes a possible overlap between parts of a foreground model and superpixels that are assigned to a different object via the arguments of the leading Iverson bracket. The overlap penalty itself is chosen to be proportional to the overlap of the projected model of object o k with the superpixel si. This term is crucial to avoid object models from exceeding the true object boundaries.</p>
<p>To encourage smooth surface shape and orientation as well as compact objects, the following smoothness potential is defined on the CRF:</p>
<p>The weights θ control the influence of the three constituting terms. First, regularization of depth is achieved by penalizing different disparity values d at shared boundary pixels Bij:</p>
<p>Second, the orientation of neighboring planes is encouraged to be similar by evaluating the difference of plane normals n</p>
<p>Finally, coherence of the assigned object indices is enforced by an orientation-sensitive Potts model: The weight w(•, •) in the coherence term is defined as</p>
<p>and prefers motion boundaries that coincide with folds in 3D.</p>
<p>Here, λ is the shape parameter of the penalty function which is normalized by the number of shared boundary pixels |Bij|.</p>
<p>For encoding prior knowledge about the objects {o k |k ∈ O} and in order to restrict the high-dimensional space of possible shapes, we follow (Zia et al., 2013b) and use their 3D active shape model.</p>
<p>In particular, we apply principal component analysis to a set of characteristic keypoints on manually annotated 3D CAD models. This results in a mean model over vertices as well as the directions of the most dominant deformations between the samples in the training set. In our CRF, the shape parameters γ k of object o k are optimized for consistency with the jointly estimated superpixels. The deformed vertex positions v are specified by a linear sub-space model</p>
<p>where m is the vertex mean and ei denotes the i'th eigenvector weighted by the standard deviation of the corresponding eigenvalue. We define a triangular mesh for the vertices v(γ k ), transform it according to the object pose ξ k and render a virtual disparity map 1 for the reference image in order to calculate the shape consistency term in Section 3.3.</p>
<p>Fig. 3 depicts the mean shape in the center and deformed versions of the model on the left and right, illustrating the range of different layouts covered by the first two principal components. While the first principal component accounts mostly for the size of the object, the second component determines its general shape. We limit our model to the first two principal components as we found this to be an appropriate tradeoff between model complexity and the quality of the approximation.</p>
<p>Due to the inherent combinatorial complexity and the mixed discrete-continuous variables, optimizing the CRF specified in Eq. 1 with respect to all superpixels and objects is an NP-hard problem. To minimize the energy, we iteratively and adaptively discretize the domains of the continuous variables in the outer 1 http://www.cvlibs.net/software/librender/ loop of a max-product particle belief propagation (MP-PBP) framework (Trinh andMcAllester, 2009, Pacheco et al., 2014).</p>
<p>In the inner loop, we employ sequential tree-reweighted message passing (TRW-S) (Kolmogorov, 2006) to infer an approximate solution given the current set of particles.</p>
<p>To keep the computational burden tractable, we perform informed sampling of pose and shape parameters. In each iteration of the outer loop, we draw 50 particles, jointly sampling pose and shape from normal distributions centered at the preceding MAP solution. The respective standard deviations are iteratively reduced.</p>
<p>To prune the proposals, the shape consistency term, Eq. 3, is evaluated for each particle with respect to the superpixels' MAP solution of the previous iteration. Only the best particle is kept and introduced into the optimization of Eq. 1.</p>
<p>In our implementation, we further use 10 shape particles for each superpixel, 5 particles for object motion, and 10 iterations of MP-PBP. All motion particles and half of the superpixel plane particles are drawn from a normal distribution centered at the MAP solution of the last iteration. The remaining plane particles are proposed using the plane parameters from spatially neighboring superpixels.</p>
<p>To demonstrate the value of our approach, we process challenging scenes from the scene flow dataset proposed by (Menze and Geiger, 2015). As we evaluate additional metrics regarding the quality of the estimated objects we use a set of representative training images for which ground truth information is publicly available. The observations evaluated in the data term comprise densely computed differences of Census features and additional sparse features. We use optical flow from feature point correspondences (Geiger et al., 2011) and precomputed disparity maps using semiglobal matching (SGM) (Hirschmüller, 2008). Sparse cross features, connecting the reference view with the right image at t1, are computed by combining the optical flow matches with valid disparities from the SGM maps. We initialize all superpixel boundaries and their shape parameters using the StereoSLIC algorithm (Yamaguchi et al., 2013) with a parameter setting that yields approximately 1000 superpixels for the used input images.</p>
<p>One typical oversegmentation of a car is depicted in Fig. 4. While most of the outline is faithfully recovered, shadows can lead to bleeding artifacts. 1. Scene Flow Error. This table shows the benefits of integrating the proposed object model, evaluated for all results shown in the paper. We specify the percentage of outliers with respect to disparity estimates in the subsequent stereo pairs (D1,D2), optical flow in the reference frame (Fl) and the complete scene flow vectors (SF). See text for details.</p>
<p>Qualitative Results: Fig. 5 and Fig. 6 illustrate resulting disparity, optical flow and wire-frame renderings of the object models superimposed to the respective reference views of eight representative scenes. The top part of each sub-figure depicts the layout after initialization as described above. In most cases, the shapes do not match the observed cars and there are some significant positional offsets. In addition, there are spurious objects initialized due to wrong object hypotheses. The lower part shows our reconstruction results after optimizing Eq. 1. Objects which are not referred to by any of the superpixels are considered absent and thus not drawn. For all examples shown in Fig. 5, the model position is successfully aligned with the observed object and the shape of the model is faithfully adapted to the depicted cars. Spurious hypotheses are removed, demonstrating the intrinsic model selection capabilities of our approach. Sub-figures (b,c) of Fig. 6 contain successfully reconstructed cars in the foreground. Some of the spurious objects are removed while others remain in the final result. This is due to strong erroneous motion cues in the respective image patches contradicting the estimated background motion. Note that for visualization we only render fully visible faces of the CAD models. The last sub-figure (d) of Fig. 6 shows a failure case of the approach: Here, object hypotheses with many inliers occur in the very challenging regions next to the road. The numbers in the sub-captions specify the intersection-over-union (IOU) of the estimated object shape with respect to ground truth at initialization and after optimization as explained in the next paragraph.</p>
<p>Shape Adaption: To quantify the improvement gained by optimizing the model parameters, we evaluate the intersection-overunion criterion which is frequently used for evaluating segmentation and object detection in the literature. In particular, we compare the ground truth mask of the annotated objects to the mask of the projected 3D model as inferred by our method. We discard objects without successful initialization and report the intersection-over-union averaged over all detected cars. 1 which specifies the mean percentage of outliers for all eight examples shown in Fig. 5 and Fig. 6 using the evaluation metrics proposed in (Menze and Geiger, 2015), i.e., a pixel is considered as outlier if the estimated disparity (D1,D2) or optical flow (Fl) exceeds 3 pixels as well as 5% of its true value. As a baseline, we optimize Eq. 1 without the shape consistency term κ and sample only motion particles for the objects instead, corresponding to the method of (Menze and Geiger, 2015). In contrast, our full model ("Ours") also optimizes shape and pose parameters of the 3D model as described in Section 3. Table 1 shows that the performance for background regions (bg) slightly decreases in all categories while there is a significant improvement of 5 percentage points for the foreground objects (fg) and moderately improved results for the combined scene flow metric (bg&amp;fg).</p>
<p>We extended the scene flow algorithm of (Menze and Geiger, 2015) by a deformable 3D object model to jointly recover the 3D scene flow as well as the 3D geometry of all vehicles in the scene. Our results show that the estimation of only 5 model parameters yields accurate parametric reconstructions for a range of different cars. In the future, we plan to incorporate additional observations of a class-specific object detector as well as to estimate motion over multiple frames in order to improve completeness of the retained objects and to further increase robustness against spurious outliers.</p>
<p>This contribution has been peer-reviewed. The double-blind peer-review was conducted on the basis of the full paper.Editors: A. Yilmaz, C. Mallet, M. Ying Yang, and Y. Vizilter doi:10.5194/isprsannals-II-3-W5-427-2015</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f210887427"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:20+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The historical connection between the Transeurasian languages, i.e. the Japonic, Koreanic, Tungusic, Mongolic, and Turkic languages, is among the most disputed issues of historical linguistics. Here, we will combine the power of classical historical-comparative linguistics and computational Bayesian phylogenetic methods to infer a phylogeny of the Transeurasian languages. To this end, we will use lexical etymologies supporting the reconstruction of proto-Transeurasian forms with meanings that belong to the Leipzig-Jakarta 200 basic vocabulary list. Our application of Bayesian phylogenetic inference to the classification of the Transeurasian languages is unprecedented. In addition to the methodological implications for Bayesian inference applied to proposed language phyla at relatively deep time depths and with relatively sparse sets of surviving daughter languages, our research has also factual implications for the existing theories of Transeurasian relationships. Our results move the field forward in that they provide a quantitative basis to test various competing hypotheses with regard to the internal structure of the Transeurasian family.</p>
<p>The term 'Transeurasian' refers to a group of geographically adjacent and structurally homogeneous languages across Eurasia that consists of up to five different families: the Turkic, Mongolic, Tungusic, Koreanic, and Japonic languages. It was coined by Johanson and Robbeets (2010: 1-2) to complement the traditional term 'Altaic', which we reserve for the unity of the Turkic, Mongolic, and Tungusic languages only. Figure 1 shows twenty-three contemporary Turkic languages, ten Mongolic languages, ten Tungusic languages, six Japonic languages in addition to Korean. These numbers approximate the number of languages per family recognized by Glottolog (i.e. twenty-seven Turkic, seventeen Mongolic, thirteen Tungusic, fifteen Japonic, and two Koreanic).</p>
<p>The question of whether these five groups descend from a single common ancestor has been the topic of a long-standing debate. As early as 1692, Nicolaes Witsen first mooted the contours of the Transeurasian language family, but Ramstedt is usually considered the founder of Transeurasian linguistics because he established a modern linguistic framework for Transeurasian comparison, supported by regular sound correspondences (1957) and morphological cognates (1952). While, until the late sixties, the field focused on the comparison of Turkic, Mongolic, and Tungusic on the one side (e.g. Poppe 1960Poppe , 1965Poppe , 1975) ) and of Korean and Japanese on the other (e.g. Martin 1966), in the seventies, Miller's (1971) monograph 'Japanese and the other Altaic languages' increased the scholarly interest in the overall comparison of these languages. Clauson (1956) and Doerfer (1963Doerfer ( -1975) ) raised substantial criticism against the genealogical relatedness of these languages, which was mainly based on the alleged lack of basic vocabulary and the explanation of all correlations by borrowing. Starostin et al. (2003) resurrected scholarly interest in the Transeurasian unity, accumulating a body of evidence that was far more impressive in quantity and rich in empirical material than the number and scope of etymologies proposed previously. However, these new matches were, in their turn, criticized for reason of phonological, morphological, or semantic overpermissiveness, among others by Robbeets (2005), leaving room for a reduced core of reliable etymologies and by Vovin (2005Vovin ( , 2009Vovin ( , 2010) ) and Georg (2007), completely rejecting all evidence advanced so far. For an elaborate discussion of the history and the current state of the debate, see Robbeets (2017). Robbeets (2005Robbeets ( , 2015) ) has shown that even if the majority of support provided in the past is questionable, there is nonetheless a core of reliable evidence for the classification of Transeurasian as a valid genealogical grouping. In line with the requirements of the classical comparative method of historical linguistics, the evidence consists of regular sound correspondences, lexical etymologies including common basic vocabulary and shared verb morphology. As a result, the hypothesis that the Transeurasian languages are related is gradually gaining acceptance in the field (Go ¨zaydin 2006;Rozycki 2006;Bu ¨yu ¨kmavi 2007;De ´csy 2007;Kara 2007;Dybo 2016).</p>
<p>Whereas supporters of Transeurasian affiliation basically agree about the unity of the family, they do not necessarily coincide on its internal structure. Here, we set up four different hypotheses of classification that are representative of the variation in the different classifications proposed in the past. To this end, we will use contemporary and historical lexical data, which yield proto-Transeurasian reconstructions corresponding to an item on the Leipzig-Jakarta 200 basic vocabulary list. By applying Bayesian phylogenetic methods to the phylogeny of the Transeurasian languages, our aim is to infer which model is best supported by the data. In this way, we intend to provide a quantitative basis to determine the internal structure of the Transeurasian family. Abbreviations for languages are explained as follows: Ama.: Amami; Az.: Azerbaijani; Bao.: Bao'an; Bash.: Bashkir; Bur.: Buriat; Chu.: Chuvash; Dag.: Dagur; Dlg.: Dolgan; Dong.: Dongxiang; EYugh.: Eastern Yughur; Even: Even; Evk.: Evenki; Gag.: Gagauz; J: Japanese; Kalm.: Kalmuk; KBalk.: Karachay-Balkar; Krm.: Karaim; Kkp.: Karakalpak; Kaz.: Kazakh; Khak.: Khakas; Khal.: Khalkha; Khalaj: Khalaj; Kir.: Kirgiz; K: Korean; Kum.: Kumyk; Ma.: Manchu; MK: Middle Korean; MMo.: Middle Mongolian; Miy.: Miyako; Mogh.: Moghol; Mgr.: Monguor; Na.: Nanai; Neg.: Negidal; Nog.: Nogai; Oki.: Okinawa; Olcha: Olcha; OJ: Old Japanese; OT: Old Turkic; Ord.: Ordos; Oroch: Oroch; Shor: Shor; Sibe: Sibe; Sol: Solon; Tat.: Tatar; Tofa.: Tofalar; Tk.: Turkish; Tkm.: Turkmen; Tuva: Tuva; Ud.: Udehe; Uigh.: Uighur; Uz.: Uzbek; Yae.: Yaeyama; Yak.: Yakut; Yon.: Yonaguni.</p>
<p>Over the last century, various hypotheses have been suggested on the basis of either the classical historical-comparative method or lexicostatistic methods (Vladimircov 1929: 44-47;Street 1962: 95;Poppe 1965: 147;Miller 1971: 44;Baskakov 1981: 14;Tekin 1994: 82;Starostin et al. 2003: 236;Bla zek and Schwarz 2014;Robbeets 2015: 506).</p>
<p>All classifications proposed so far agree that, first, if a Japonic branch is postulated, Koreanic and Japonic are more closely related to one another than to any of the other branches concerned and, second, that Mongolic forms a binary unity with either Turkic or Tungusic, distinct from the Japano-Koreanic branch. The main difference in the proposals so far has to do with the position of Tungusic vis-a `-vis the other branches: Does Tungusic represent a first-order split, which separated simultaneously with Japano-Koreanic and Mongolo-Turkic? Does Tungusic cluster with Japano-Koreanic or does it rather belong with Mongolic and Turkic? And, if the latter is the case, does Tungusic stand in a binary unity with Mongolic or not?</p>
<p>Given these issues, the first set of proposals concerns a polytopology (Fig. 2; Hypothesis A in Fig. 6) whereby Tungusic separated simultaneously from Japano-Koreanic and Mongolo-Turkic. The second set of representations involves a binary topology in which Tungusic clusters with the Japano-Koreanic branch, separately from the Mongolic and Turkic branches (Fig. 3; Hypothesis B in Fig. 6). The third set of conceptions also reflects a binary topology, but here Tungusic clusters with the Mongolic and Turkic branches to form a separate 'Altaic' unity, bifurcated from the Japano-Koreanic unity (Fig. 4; Hypothesis C in Fig. 6). In this view, Tungusic stands in a binary unity with Mongolic and Turkic is the first to branch off from the Altaic unity. Finally, completing the set of logically possible hypotheses with regard to the position of Tungusic, we hypothesised a fourth possible scenario, whereby Turkic stands in a binary unity with Mongolic and Tungusic is the first to branch off (Fig. 5; Hypothesis D in Fig. 6). To enhance comparability, most figures represent simplified versions of the original classifications suggested by the respective scholars. They are adapted from the original, for instance, by leaving out the sub-branching of the individual proto-families, omitting designations for intermediate stages or turning the trees in the horizontal direction.</p>
<p>The polytypology (Fig. 2; HA) is the classification supported by the so-called 'Moscow School'. It was first proposed by Vladimircov (1929: 44-47) and lived on in the view of Baskakov (1981: 14), both scholars using the classical historical-comparative method. More recently, however, this hypothesis was confirmed on the basis of lexicostatistic methods by Starostin 6) (Baskakov 1981: 14;Starostin et al. 2003: 236). 6) (Miller 1971: 44;Bla zek &amp; Schwarz 2014: 90).</p>
<p>consisting of three principal groups: Turko-Mongolic, Tungusic, and Japano-Koreanic. However, contrary to the classical conception, in Startostin's view, Turko-Mongolic and Japano-Koreanic separated around the same time, in the fourth millennium BCE.</p>
<p>A binary topology whereby Tungusic clusters with the Japano-Koreanic unity is favored by some Transeurasian linguists in the West, especially by specialists in Japanic and Koreanic languages (Fig. 3; HB in Fig. 6). Miller (1971: 44) proposed a unity between Tungusic, Koreanic and Japonic, which recalls the suggestion made by Unger and the Altaic panel (1990: 481) to limit the Transeurasian reconstructions to a 'Macro-Tungusic' perspective, consisting of Tungusic, Koreanic, and Japonic languages only. However, unlike Unger's proposal, Miller conceives of the position occupied by the Ryukyuan languages as independent from Mainland Japanese. The view of a separate unity between Tungusic, Koreanic, and Japonic, which was initially reached by using the classical historical-comparative method, was recently supported by Bla zek and Schwarz (2014: 90) application of lexicostatistic methods. However, they conceive of Mongolo-Turkic as the second unity making up the Transeurasian family.</p>
<p>Most western scholars involved in the classification of the Transeurasian languages using the classical historical-comparative method agree on a binary topology for the Transeurasian family, whereby Tungusic is classified in a unity with Turkic and Mongolic (Fig. 4; HC in Fig. 6). Poppe (1960Poppe ( , 1965: 147) : 147) included Korean as a separate branch of Altaic but later he remarked that 'Korean is a language only partly belonging to the field of Altaic studies' (Poppe 1975: 172), referring to the possibility that Korean could be a non-Transeurasian language imposed on a Transeurasian substratum. This possibility is indicated with a dotted line in Fig. 4. In his review of Poppe (1960), Street (1962: 95) suggested a different configuration for the Japanese and Korean branches, speculating that the Japano-Koreanic branch could eventually cluster with Ainu. The dotted line with the question marks in Fig. 4 represents Street's uncertainty about the inclusion of Japanese and Ainu. Tekin (1994: 82) included Koreanic in the classification, assuming that proto-Koreanic was first to branch off from the Transeurasian unity, but he did not accept the inclusion of Japonic into the family. Robbeets' (2015) tree confirms the basic classification of this 'western' school. Our research starts from the three most recently proposed hypotheses that are representative for each set of proposals, given in Figs 234, and we add Fig. 5 (HD in Fig. 6) to complete the set of logical possibilities with regard to the position of the Tungusic branch: While Tungusic stands alone in HA, it clusters with Japonic and Koreanic in HB and with Altaic in the remaining hypotheses, whereby in HC it stands in a binary unity with Mongolic and in HD it does not.</p>
<p>In addition, there are some extralinguistic factors, related to the genetic and archaeological past, that motivate the inclusion of hypothesis D in the set of alternatives. Recent paleogenetic studies (Wang et al. 2016;Siska et al. 2017;Jeong and Wang in press, 2019) indicate that contemporary speakers of Tungusic languages are genetically continuous with ancient individuals of the Neolithic Boisman culture (4825-2470 BC) in the Southern Primorye. 1 Contemporary Turkic and Mongolic speakers share this ancestral eastern lineage, albeit with an increasing western admixture from the Bronze Age onwards. In addition, archaeologists show that the basic subsistence strategy in the Southern Primorye during the Neolithic and Bronze Age was agriculture supplemented by fishing, hunting, and gathering, while pastoralism was gradually adopted in the homelands of Turkic and Mongolic speakers West of the Liao River and on the Eastern steppes (Taylor 2016;Taylor et al. 2017;Jeong and Wang in press, 2019). Thus, genetics and archaeology converge on a scenario whereby the linguistic ancestors of the Tungusic speakers separated at an early time from the linguistic ancestors of Turkic and Mongolic speakers, who from the Bronze Age onwards started to share not only an increasing degree of genetic admixture with Western steppe herders but also adopted a common pastoralist subsistence strategy.</p>
<p>For the purposes of this article, it is legitimate to group the above nine existing classifications into four distinct hypotheses because some variations involve mere timing or uncertainty about the inclusion of a certain subgroup, but do not affect the essential structure of the family. The variation in Fig. 2 is due to a difference in branch length and thus absolute time depth, the variation in Fig. 3 has to do with whether the separation of Turkic vis-a `-vis Mongolic follows a breakaway or a binary split model, and the variation in Fig. 4 is the result of uncertainty about the inclusion of Japonic or Koreanic as a subgroup of the family. However, none of these differences involves basic family structure. Hence, we aim to test the four overarching hypotheses summarized in Fig. 6. 1 The use of the term 'continuous' in this context implies that the ancient genome continued as a virtually unbroken line into the contemporary genome and that it would be plotted on top of the contemporary genome in a principal component analysis.</p>
<p>Classical Bayesian approaches to language classification usually start from a basic vocabulary list and code 1 for words with identical basic meaning that display a cognate form and 0 for such words lacking a cognate form.</p>
<p>Even if this coding principle, illustrated for the basic item WOOD in Table 1, would yield reliable results for the internal structure of the individual daughter languages, it is expected to leave only a weak historical signal at a deeper Transeurasian level. This is due to the considerable time depth of the Transeurasian family combined with a relatively high extinction rate of the daughter languages. By way of comparison, the Austronesian and Indo-European language families respectively count about 1,200 and 445 living languages, whereas hardly 50 Transeurasian languages have survived to the present. Thus, for language families in general, with the elapse of time, meanings will have diverged in such a way that at best only a few cognate sets with identical basic meanings are left. However, in the Transeurasian case, many languages that may have reflected these identical meanings will have died out. Hence, the effect of cognate attrition for the Transeurasian languages is expected to be much stronger than that for the Austronesian languages because first, the common ancestor of the former is estimated around 4700 BCE, while the latter is only around 3500 BCE, and second, because much fewer Transeurasian languages have survived. 2 Therefore, restricting our coding to cognate sets with identical meaning would fail to produce a meaningful Transeurasian tree.</p>
<p>Given this challenge, we have chosen to apply an alternative coding principle, illustrated in Table 1, which starts from the Transeurasian reconstructions displaying a basic meaning, e.g. pTEA *mOrO 0 tree, wood 0 . Here we code 1 for presence of a cognate in a daughter language and 0 for absence of a cognate, irrespective of whether the meanings are identical or not. In our example, we code 1 for Japanese and Korean in addition to Evenki and Khalkha. This coding principle yields a stronger historical signal because it triggers a higher number of positive values than the classical principle.</p>
<p>Applying this coding principle to our data, we reach the list of codings given in the Supplementary Data (SI 4). In order to illustrate our expectation that the traditional coding would produce less historical signal than the alternative one, we added a further specification to the coding of our basic vocabulary data (Supplementary Data, SI 5). Here, we code 0 for the absence of a cognate, 1 for the attestation of a semantically equivalent cognate and 2 for the attestation of crosssemantic cognate. On a total number of 2,735 cognates, we count 1,621 cognates with equivalent meaning and 1,114 cross-semantic cognates. In the conventional cognate coding, the total number of forms yielding code 1 would be equal to or lower than 1,621. The expectation of a number lower than the number of semantically equivalent cognates is motivated by the convention that if there is competition between two forms with equivalent meaning in the traditional approach, the one with the most frequent use is selected. When using the cross-semantic coding, the number of cognates in the dataset is notably larger (2,735) compared to the number of semantically strictly equivalent cognates ( 1,621). By consequence, the traditional coding is expected to produce less positive values, i.e. less 1 codings and more 0 codings.</p>
<p>In our study, we use lexical data from fifty contemporary and seven historical varieties of the Transeurasian languages, including twenty-three Turkic languages in addition to Old Turkic, ten Mongolic languages in As the latter timedepth does not substantially differ from that of our prior, we cannot draw firm conclusions on the dating or proto-Transeurasian on the basis of Bayesian inference alone, but taken together with the lexicostatistic result, it may serve as an indication. There is a relative consensus as far as the timedepth of Austronesian is concerned; see Blust (2013: 24-29).</p>
<p>addition to Written Mongolian and Middle Mongolian, ten Tungusic languages in addition to Manchu and Jurchen, Korean in addition to Middle Korean and Japanese and five Ryukyuan languages in addition to Old Japanese. We collected these data by consulting dictionaries in combination with written sources against the background of previous etymological proposals evaluated in Robbeets (2005). Historical varieties are only used for the purpose of reconstruction and not integrated as data-points in the tree. This is because historical varieties were reconstructed using the comparative method due to which they possess a certain level of uncertainty which we do not prefer to include in our analyses. By restricting ourselves to a limited number of contemporary languages, we make abstraction from many different local varieties, such as for instance the various dialects spoken in neighboring villages on the Ryukyuan Islands that are in variation with the five local languages of Amami, Okinawa, Miyako, Yaeyama, and Yonaguni.</p>
<p>Judging from the number of languages recognized in Glottolog, our set of languages is amply sampled; for Turkic twenty-three languages out of twenty-seven are represented, for Japonic six out of fifteen, Koreanic one out of two, Mongolic ten out of seventeen, and Tungusic ten out of thirteen, so there is no potential that our sampling strategy causes the problems suggested in the biological literature (Hillis et al. 2003).</p>
<p>The lexical data we collected correspond regularly in form and function to such an extent that they yield proto-Transeurasian reconstructions for items that occur on the Leipzig-Jakarta 200 basic vocabulary list (Tadmor et al. 2010). For the regular vowel and consonant correspondences underlying our reconstructions, we refer to the Supplementary Data (SI 1). We reached 150 etymologies spread over 107 distinct items of the basic vocabulary list.</p>
<p>The cognate coding allows for a certain degree of semantic development in the daughter branches-in other words, inexact meaning correspondence between lexical items coded as cognates-but only to the extent that the proposed semantic development between proto-Transeurasian and the daughter branches answers to cross-linguistically observed polysemies, semantic associations, or grammaticalizations. The penultimate column of Supplementary Table 3 (SI 2) indicates the cross-linguistic availability-and hence, the regularity or acceptability-of a proposed semantic correspondence. To this end, we consulted the database of cross-linguistic colexifications published by List et al. (2014), which brings together instances where two or more meanings are simultaneously covered by the same lexical item in a certain language. The number in the penultimate column corresponds to the number of the relevant semantic community in List et al. (2014), while the number behind the slash is the number of nodes in that community. Whereas the number of the community is an arbitrary number for identification, the number of nodes (n) represents how many meanings can be joined together in the same network. This means that a given set of meanings compared in Supplementary Data (SI 2) represents an acceptable semantic correspondence that ranks among a total of n permissible semantic associations.</p>
<p>The tag 'Gram' means that the development is a cross-linguistically well-attested grammaticalization process. This is for instance the case for the development of the verb (25) 'to do, make' in an iconic pro-verb following sound symbollic expressions (Heine and Kuteva 2002: 112-13), the development (39) 'this' from a demonstrative into a personal pronoun, (Heine and Kuteva 2002: 119-20) and the development of the interrogative pronoun ( 50) 'what?' into an interrogative particle. Finally, the tag 'Poly' marks a semantic development that is supported by a polysemy, which is not reported in List et al. (2014), although it is found across the languages of the world and/or in one or more Transeurasian lexemes of the dataset. For instance, the development ( 12) 'breast' into 'heart' is acceptable, even if it is lacking in List's database. That is because it is attested in a number of languages in Australia, such as Arabana and Wangkanguru, in which the term for 'heart' is a reduplication of the term for 'chest' (Wilkins 1996: 289). Moreover, it is also found on a distinct, unrelated etymon in a Transeurasian language, notably Yonaguni ccimu 'heart, liver', which is derived as Yo. ccimuti 'breast'. Using cross-linguistically observed patterns of colexification, semantic association, and grammaticalization in this way, we can provide an empirical base for the degree of semantic latitude permitted in our Transeurasian comparisons.</p>
<p>We appended an overview of the basic vocabulary shared between the Transeurasian languages (Supplementary Data, SI 2) in addition to a detailed documentation of the underlying etymologies (Supplementary Data, SI 3). This dataset is new in the sense that it expands, revises, and updates the etymologies evaluated and proposed in Robbeets (2005Robbeets ( , 2015)). We expanded the previous dataset with etymologies for basic items that do not have a Japanese cognate, we consistently added cognates from the Ryukyuan languages, we carried out a detailed morphological analysis in order to delimit the roots more precisely and to identify petrified suffixes more accurately and, we answered to criticism in reviews of earlier etymologies.</p>
<p>The response to this criticism is included in the discussion of individual etyma in Supplementary Data (SI 3). Among the ten reviews of the lexical evidence in Robbeets (2005), six were very (Go ¨zaydin 2006;Rozycki 2006;Bu ¨yu ¨kmavi 2007;De ´csy 2007) to mildly positive (Kara 2007; Dybo 2016), while four were negative (Knu ¨ppel 2006;Georg 2007;Miller 2007 andVovin 2009). Of the 359 lexical etymologies proposed as core evidence in Robbeets (2005), seventy-three were criticized in the reviews. Among these, twenty-three etymologies for basic vocabulary present in the Leipzig-Jakarta list in Supplementary Data (SI 2/3) are met with objection, i.e. 1 fire, 3 to go, 5 a/b mouth, 7 blood, 8 bone, 12 breast, 30a tooth, 32c big, 39a this, 46 bite, 54 new, 55 burn, 56 not, 63 soil, 68 skin, 80a wood, 84 ash, 92 shade, 94 salt, 96 wide, 97 star, and 99 hard. In some cases, where we considered the criticism legitimate, we left out the problematic part of the etymology under discussion. In other cases, we answered to the cricitism and motivated our decision to leave the etymology unchanged.</p>
<p>It is highly unlikely that all similarities between the basic items in our dataset are the result of contact instead of genealogical relationship. Traditionally, the strength of basic vocabulary lies in the fact that words with basic meanings tend to resist borrowing more successfully than random lexical items. The very fact that we find 150 Transeurasian etymologies covering 107 distinct basic vocabulary concepts thus is a strong argument against borrowing by itself. In addition, we can advance other arguments against borrowing, such as (1) the misfit with the expected borrowing hierarchy; (2) the misfit with the expected typology of verbal borrowing; (3) the regularity and complexity of sound correspondence; (4) the occurrence of broken contact chains; (5) the multiple setting; and (6) the well-spread distribution of the cognates; see also Robbeets (in press, 2019).</p>
<p>First, among the concepts of the Leipzig-Jakarta list, we find fifty-nine actions, thirty-two property words, twenty-three deictic or grammatical items and eighty-six nominal concepts. Out of ninty-one concepts for actions and property words, we find fifty-nine Transeurasian verbal etymologies, which means that as much as 65% of the basic verbal concepts on the Leipzig-Jakarta list are etymologized. Out of twenty-three concepts for deictic and grammatical items, we find thirteen etymologies, which implies that 57% of the basic deictic and grammatical items on the list are etymologized. Out of eighty-six nominal concepts, we find thirty-seven etymologies, indicating that only 43% of the nominal concepts are covered by a Transeurasian etymology. Empirically, it is observed that languages tend to borrow lexical items more easily than grammatical ones and nouns more easily than verbs (a.o. Wohlgemuth 2009;Matras 2009;Tadmor et al. 2010). In contrast to this tendency, there are more correlations for verbs (65%) and deictic and grammatical items (57%) in the Transeurasian basic vocabulary than for nouns (43%). This observation indicates that it is unlikely that the comparative sets can be explained by borrowing, as borrowing would be expected to yield more correspondences in nouns than in verbs and grammatical markers.</p>
<p>Second, as far as the mechanisms of loan verb accomodation are concerned, most recipient languages can be categorized into two distinct groups: borrowed verbs either arrive as verbs, needing no formal accommodation, or, they arrive as nonverbs and need formal accommodation. Most Transeurasian languages can be assigned to the second group because they display a clear preference for the nonverbal strategy (Wohlgemuth 2009: 159, 161). If the thirty Transeurasian verbal etymologies in our basic vocabulary list would be the result of borrowing, they would represent instances of the verbal strategy. This would run against the observable preference of the Transeurasian languages to apply the nonverbal strategy to loan verbs.</p>
<p>Third, the comparative sets for basic vocabulary display regular correspondences for each consonant of the verb root and for each but the root-final vowel, conform to the requirements in Supplementary Data (SI 1). Even if extensive contact can result in systematic sound correspondences, it is unlikely that this is the case here because some sound correspondences reflect divergence to such an extent that they cannot be attributed to the mere imitation of model sounds in a process of borrowing. This is, for instance, the case for the homoganic and heteroganic cluster correspondences 5, 6, 11, 12, 17, and 18 in Supplementary Table 1 (SI 1).</p>
<p>Fourth, gaps in the attestation of members of an etymology, whereby a cognate is absent in one or more intermediate contact branches are indicative of borrowing. The absence of a Korean member in the etymology (12) 0 breast 0 , for instance, makes a borrowing scenario whereby the word got borrowed directly from Tungusic into Japonic rather unlikely.</p>
<p>Fifth, most examples of borrowing have a binary setting in common: they typically go from a model language into a recipient language. Especially for verbs and grammatical markers, examples of the same item progressing into a third or fourth language are relatively rare. However, the Transeurasian unity consists of five families and it is especially grammatical markers and verbal concepts that is well distributed over all branches. Since repetitive borrowing is particularly rare for verbs and grammatical items, this observation argues against borrowing.</p>
<p>Finally, the distribution of a certain basic item to a single language or to only few languages of a certain subgroup could serve as an indication of borrowing. However, such cases do not occur among our basic vocabulary etymologies. Based on his hypothesis that West Old Japanese or its immediate predecessor absorbed a large number of loanwords from Old Korean, Vovin (2010) proposed to reject all cognates that are missing in the Ryukyuan languages as probable loanwords. However, out of 101 proto-Japonic forms in our basic vocabulary list, 82 are supported by reflexes in the Ryukyuan languages, corresponding to 81% of all proto-Japonic reconstructions. The solid distribution of Japonic cognates in the Ryukyuan languages reduces the probability of borrowing from Old Korean.</p>
<p>Since the amount of data is relatively small, we introduce as much of the prior information that we have into the analysis as we can. By using rooted time trees in our analysis instead of undirected trees, we capture the fact that these languages evolved through time, which helps restrict possible histories. We know that languages evolved through time, so we should use that information in the model. We add two kinds of prior information to the tree: monophyletic constraints restricting possible combinations of language groupings and timing information restricting the age of internal nodes in the tree. Figure 7 shows the set of monophyletic constraints within language family phylogenies from Glottolog (Hammarstro ¨m et al. 2017), which are considered noncontroversial. Note that no constraints are implied above the family level.</p>
<p>As far as timing restrictions is concerned, we added rather generously sized time intervals for the most recent common ancestors of the language families (nodes coinciding with proto-Turkic, proto-Mongolic, proto-Tungusic, and proto-Japonic), but not for Korean because it is the sole living descendant of proto-Koreanic. We supported our estimates of the upper and lower time limit for each node (Table 2) mainly with information from linguistic and historical sources.</p>
<p>Chronologically, Proto-Tungusic is a relatively shallow entity. Applying Starostin's lexicostatistic methods, Korovina (2011) dated Proto-Tungusic to the sixth century BCE, but other computational methods such as Bayesian inference and the AJSP yielded much younger dates, notably 200 CE (Oskolskaya et al. unpublished manuscript) and 681 CE (Holman et al. 2011: 854), respectively. Referring to the name change in Chinese dynastic chronicles of the Tungusic ethnonym 'Yilou' to 'Wuji', Robbeets (2015: 16-18) situated the breakup of Proto-Tungusic at the end of the Han period (206 BCE-220 CE). Pevnov (2012: 32) estimated that Proto-Tungusic could not be younger than two thousand years on the basis of a rough measure of mutual intelligibility. A chronological interval roughly between 500 BCE and 500 CE was supported by Janhunen (2012: 8), who placed the breakup of Proto-Tungusic in the Iron Age, in line with the diversification of other language families in the area. In sum, linguists estimate the time depth of proto-Tungusic between 600 BCE and 500 CE.</p>
<p>Proto-Mongolic is nearly equivalent with the language spoken by the historical Mongols around the time of the Mongol Empire (1206-1368), which is documented in historical sources, written in several different scripts and collectively termed Middle Mongol. Some of the written varieties of Middle Mongol contain features that reflect dialectal forms slightly different from, or even earlier than the stage of Proto-Mongolic. Therefore, the depth of the Mongolic family, as measured on the basis of both written documents and living languages included in our dataset is no more than 700 to 1000 years (Rybatzki 2003), although the AJSP yields a date as early as 267 BCE (Holman et al. 2011: 854). Nevertheless, given the close similarity with Middle Mongolian, it is reasonable to estimate the time depth of proto-Mongolic between 1000 and 1300 CE. However, there were historical languages related to Mongolic spoken also in southwestern Manchuria, and perhaps even further south. The most unambiguous evidence comes from Khitan, the dynastic language of the Liao Empire (907-1125). The Khitan lineage may be traced back to several historical and prehistorical ethnopolitical groups in the region, including the Tabghach of the Northern Wei (386-534), the Xianbei or 'Serbi' (208 BC-235 AD) and the Donghu (the first millennium BC). The written traces of these groups are too fragmentary to be included in our dataset, but they seem to represent an extinct branch parallel to the Proto-Mongolic lineage. Although the information on Khitan and its presumed ancestors is still very scarce, we may date the breakup of the Macro-Mongolic to a time level preceding Proto-Mongolic by at least several centuries, most probably to the very period of the Xianbei.</p>
<p>Based on evidence from contact linguistics, the earliest split between the two principal branches of Turkic, i.e. Bulgharic and Common Turkic, is usually dated to between the middle of the first millennium BCE and the turn of the eras (Janhunen 2009). Turkic phylogenies relying on quantitative methods basically support the lower estimate. The following dates are obtained by lexicostatistic calculations: the third century BCE (Tenishev et al. 2006), around 120 BCE (Mudrak 2009), the beginning of the first century CE (Dybo 2007). A preliminary Bayesian analysis of the Turkic family Savelyev (in press, 2019) dates the split of Proto-Turkic into Common Turkic and Bulgharic branches approximately to 200 BCE, with a highest posterior density interval between 2000 BCE and 400 CE. As this time depth coincides with the beginning of the Xiongnu empire (209 BCE-100 CE), the association of Xiongnu with Proto-Bulgharic does not seem unreasonable. However, given the relatively large credible interval involved in the Bayesian dating, the breakup of proto-Turkic may also be connected with the first disintegration of the Xiongnu confederation under influence of the military successes of the Chinese in 127-119 BCE (Mudrak 2009). In sum, the time depth of the breakup of Proto-Turkic can be estimated between 500 BCE and 100 CE.</p>
<p>Table 2. Upper and lower time limits for the most recent common ancestors of the language families on the Transeurasian tree. From these limits, normal distributions with mean l and variance r (last column) were fitted such that the 95% HPD coincides with end and start times. The normal distributions were used as calibrations in the Bayesian analysis.</p>
<p>Lower</p>
<p>Bayesian phylogenetic inference has never been applied to the Transeurasian family before. Previously, methods used for the classification of the Transeurasian family were restricted to the classical comparative method and the lexicostatistic method. The lexicostatistic method is a distance-based method, which estimates the relationship between two languages by measuring the amount of difference in shared cognate proportion between them. In contrast, the classical comparative method makes use of a character-based method in order to generate trees. More specifically, it relies on the parsimony method, which seeks a tree that explains a dataset by minimizing the number of evolutionary changes required to produce the observed state (Dunn 2015).</p>
<p>Cognate data was ascertained in such a way that some patterns never occur in our data: each site in the alignment contains a one in at least two families. Therefore, sites with one or more ones in only one family never occur, neither do sites with only zeros. The likelihood of the data P data is affected by this sampling strategy; instead of calculating the P data , we actually only calculate the likelihood of the data under condition it does not form a pattern with only ones occurring in a single family. To compensate for this, we use ascertainment correction (Felsenstein 2004), which calculates the ascertained likelihood P ascertained as P data /(1ÀP forbidden ) where P forbidden is the probablity of all patterns we ruled out. We calculate P forbidden by calculating for each family (except Korean) the probability of patterns with question marks for each of the languages in the family and zeros for all other languages. For Korean, we calculate the probability of all languages being zero, but Korean being 1. The sum of these probabilities contains four times the probability that each language is zero, so we subtract three times the probability of each language being zero to obtain the probability of forbidden patterns P forbidden . From this we calculate the ascertained likelihood from the likelihood of the data P data as follows P ascertained ¼ P data /(1ÀP forbidden ).</p>
<p>A birth/death sampling process is most appropriate for tree prior when analyzing languages, and the Yule model (Gernhard 2008) is the simplest such model, which assumes a pure birth process governed by a single parameter: the birth rate. We found that more complex models resulted in a worse fit with our data (details below).</p>
<p>There are various models of evolution of characters along branches of a tree that may be suitable for our data. We compared three frequently used models; the binary GTR (with and without gamma rate heterogeneity over sites), covarion (Tuffley and Steel 1998), and stochastic Dollo (Nicholls and Gray 2008) models. The GTR is a variant of the general reversible model for nucleotides (Rodriguez et al. 1990) adapted for two states. The model allows cognates to become present and absent multiple times along branches, and offers a simple model of evolution. The gamma rate heterogeneity over sites model (Yang 1996) caters for different rates of evolution for different cognates and works well with the GTR model. The covarion model (Tuffley and Steel 1998), like the GTR model, allows cognates to become absent and present multiple times along a branch, but furthermore allows a character to be in a fast or a slow state. When in a fast state, changes between present and absent are very frequent, and when in a slow state changes occur much less often. More parameters are involved but the covarion model has a remarkable property that it is not very sensitive to borrowing. The stochastic Dollo model (Nicholls and Gray 2008) is based on the Dollo principle that a cognate can only appear once, but can be lost multiple times. This closely fits the definition of cognate, but is also sensitive to borrowing events. For a more detailed description of these models see, for example, Bouckaert and Robbeets (2017) or Bouckaert et al. (2012) Supplementary Data for details of these models. Furthermore, we considered the pseudo Dollo and pseudo Dollo covarion models (Bouckaert and Robbeets 2017). When tracking the history from the root of the tree to a leaf, these models allow at most one birth followed by at most one death. However, unlike the stochastic Dollo model, multiple births are allowed, for example at siblings in a tree, thus catering for borrowing events.</p>
<p>We assume a molecular clock implying that over time there is a certain rate of change along branches of the tree that is constant on average. However, in practice rates on branches are not constant, and a model where rates on branches are independent of other branches, but are drawn from a log normal distribution (with its mean and standard deviation estimated) fits much better and is flexible enough to capture most rate variation. This clock model is known as the uncorrelated relaxed clock with log normal distribution (Drummond et al. 2006).</p>
<p>The covarion model with uncorrelated relaxed clock with log normal distribution tends to perform well with cognate data (e.g. Bouckaert et al. 2012;Bowern and Atkinson 2012;Gray et al. 2009). To determine the most suitable model for our data, we use this as our base model and compare other models against it by estimating the marginal likelihood using nested sampling (Maturana et al. 2017) with 100 particles yielding a standard deviation of around 1. From these estimates, we calculated Bayes factors (Kass and Raftery 1995) to decide which model best fits our data. Table 3 shows the results; changing from relaxed to strict clock results in a sixty-eight point drop of the marginal likelihood with respect to our base model. Likewise, changing the substitutio model to binary GTR (with or without gamma rate heterogeneity) or stochastic Dollo model results in large drops in ML estimates. However, changing to a pseudo Dollo model (with or without gamma) increases ML estimates, but the pseudo Dollo covarion gives an even better estimates. In fact, the pseudo Dollo covarion model with relaxed clock has an overwhelmingly better fit than any other model (BF ) 100 with respect to any other model).</p>
<p>We consider four main hypotheses that cover most of the variation in proposed groupings of the Transeurasian language families. Hypothesis A is the polytopology (HA in Fig. 6), hypothesis B represents the binary topology in which Tungusic clusters with the Japano-Koreanic branch (HB in Fig. 6), Hypothesis C the binary topology in which Tungusic clusters with Mongolic and Turkic, with Turkic branching off first (HC in Fig. 6), Hypothesis D the binary topology in which Tungusic clusters with Mongolic and Turkic with Tungusic branching of off first (HD in Fig. 6).</p>
<p>We test which of the four hypotheses is best supported by the data by restricting the tree space to conform to the hypotheses and estimating the marginal likelihood for each of the hypotheses. The Bayes factor is then calculated as the ratio of marginal likelihoods (in practice, we exponentiate the difference between the log marginal likelihoods). We constrained the analysis for HB, HC, and HD by simply adding monophyletic constraints in addition to the ones depicted in Fig. 7. Since we are working with binary trees, HA requires an extra condition on top of the same monophyletic constraints of HB, namely that the branch above the Tungusic clade has length zero, and the branch above Japano-Koreanic has length zero as well.</p>
<p>Table 4 gives the priors and posteriors based on an MCMC run, and Bayes factor comparing the different hypotheses in the rows to those in the columns when using the best fitting model as shown in Table 3. A Bayes factor between 6 and 10 is considered as strong evidence for the competing hypothesis in the row, while a factor over 10 (bold in Table 4) is considered to be very strong evidence. Therefore, Table 4 indicates that the hypothesis with the highest credibility is HD, the binary topology in which Tungusic clusters with Mongolic and Turkic with Tungusic branching off first (Fig. 6). Since HD has a BF &gt; 20 wrt HB we conclude that HA is not plausible since if HA was the correct model we would not be able to distinguish HB from HD. The results presented in Table 4 are based on the Yule prior. Results with the next best fitting model from Table 3 shows even stronger support for HD (BF ¼ 87.56 wrt HB). Likewise, model comparison based on marginal likelihoods with both best and second best fitting models give similar but stronger BFs than in Table 4. Unfortunately, as far as timing is concerned, the root age of the inferred phylogeny has large uncertainty when using a Yule prior (95% HPD Interval [2.55kya, 7.54kya] a priori [4.33kya, 9.45kya] a posteriori), so we cannot draw firm conclusions on the timing aspects of our results. This is not surprising given the small amount of data compared to many other cognate-based analyses: there are just 240 informative sites in our data while it is not unusual to have over ten thousand sites (Gray et al. 2009;Bouckaert et al. 2012;Bowern and Atkinson 2012). However, we can make substantial statements about the topology.</p>
<p>We further captured our results in a DensiTree (Fig. 8). The internal structure of the family is close to the hypotheses proposed by Transeurasian scholarship in the past (HA, HB, or HC in Fig. 6), but does not coincide with any of them. The DensiTree classification seems to favor the classification proposed by the Russian school (Fig. 2) in that it views the Turkic branch as most closely related to Mongolic. However, similar to the view in the West (Fig. 3), it pictures Tungusic, Mongolic, and Turkic as a separate unity. We get a strong historical signal with 98.3% support for Japano-Koreanic, 90.3% for Tungusic-Mongolic-Turkic, and 100% for Mongolic-Turkic. There is 3.4% support for constructing a Tungusic branch outside the rest as proposed in Fig. 2 and6.31% support for establishing a separate Tungusic-Japano-Koreanic unity as in Fig. 4. There is no support (0%) for the Mongolic-Tungusic unity proposed in Fig. 3.</p>
<p>The implications of our research are two-fold. First, there are methodological implications for Bayesian phylogenetic inference applied to proposed language phyla at relatively deep time depths and with relatively sparse sets of surviving daughter languages. Second, there are factual implications for the existing theories of Transeurasian relationships.</p>
<p>From a methodological point of view, we applied an unconventional coding method and improved the modeling by way of a pseudo Dollo covarion model. Our choice of coding strategy allows us for the first time to infer relationships among different language families based on cognate data. The classical method of cognate judgment results in far fewer cognates being found to be shared among language families. Consequently, it does not allow inference of such relationships because it has a much more stringent requirement regarding not allowing small semantic changes in cognates. Our new coding strategy allows us to use analytical approaches that give us insight into the relationships between the various Transeurasian families. Besides, the new strategy allows to integrate classical-comparative linguistic research more effectively into Bayesian approaches as we use etymologies established by expert linguists as our dataset.</p>
<p>Moreover, our recently introduced pseudo Dollo covarion model with relaxed clock served as a new model for capturing evolution in our cognate sets. We showed that for our dataset it had a better fit than the currently existing models.</p>
<p>From a factual perspective, our results can be situated in the broader context of the scholarly debate on Transeurasian, which centers around two issues: the distinction between the effects of inheritance and borrowing and the internal classification of the Transeurasian family. Our research addresses the major objections raised against Transeurasian affiliation by showing that the Transeurasian languages share a substantial proportion of basic vocabulary, refining the evidence, answering the criticisms raised against particular basic etymologies, and arguing that not all correlations in the basic vocabulary can be explained as the result of language contact.</p>
<p>Moreover, our results solve a long-standing question about the exact shape of the Transeurasian tree by providing a quantitative basis to test various competing hypotheses with regard to the internal structure of the Transeurasian family.</p>
<p>Our application of Bayesian phylolinguistics to infer a phylogeny of the Transeurasian languages is unprecedented. Previous classifications were based on either classical historical-comparative linguistics or lexicostatistics. The difference between prior approaches and the current Bayesian approach lies in both the methodology and the dataset. Whereas the lexicostatistic method is a distance-based method, measuring the proportion of cognates between two languages, the classical comparative and the Bayesian methods are character-based methods. The former is a parsimony method, inferring trees on the basis of shared innovations, while the latter generate trees by quantifying how likely it is that the observed data have been produced by a certain model of the evolution of cognates along that tree. In addition, the datasets used in previous approaches differ from ours. Whereas classical historical linguistic approaches started from shared innovations in phonology, lexicon and morphosyntax, previous lexicostatistic approaches, just like our current Bayesian approach, were based on basic vocabulary. However, our collection of Transeurasian basic vocabulary is innovative because it is based on the recently developed Leipzig-Jakarta list, sifts and revises questionable etymological proposals, answers previous criticisms and expands the dataset with material from understudied languages such as the Ryukyuan languages.</p>
<p>Because of our innovative morphological approach and our fine-tuning of the dataset, we were able to obtain new results that allow us to determine the most competitive hypothesis with regard to the internal structure of the Transeurasian family. The hypothesis with the highest credibility is a binary topology in which Tungusic clusters with Mongolic and Turkic, with Tungusic branching off first (HD in Fig. 6). This solves a controversy between the Russian school, proposing a binary Mongolo-Turkic unity (Fig. 2) and the western school, supporting a Tunguso-Mongolic unity (Fig. 3), in strong favor of the Russian school as there is no support (0%) for the proposed Tunguso-Mongolic unity. Moreover, it solves a second dispute about the placement of Tungusic either in a cluster with Japonic and Koreanic, or in a cluster with Turkic and Mongolic, in favor of the second view with a credibility of 90.3%. Overall, our results move the field forward in that they provide a quantitative basis to test various competing hypotheses with regard to the internal structure of the Transeurasian family.</p>
<p>For the first time in the history of linguistics, we integrated classical historical-comparative linguistics and computational Bayesian phylolinguistics to infer a phylogeny of the Transeurasian languages. For this purpose, we introduced a new dataset, a new coding principle and applied a newly introduced evolutionary model for capturing the historical behavior of the cognate sets. Our dataset consisted of 150 comparative sets of Japanic, Koreanic, Tungusic, Mongolic, and Turkic cognates, which yield proto-Transeurasian reconstructions for 107 Leipzig-Jakarta basic vocabulary items. We applied an unconventional coding principle, permitting a certain degree of semantic freedom in the development of the cognates. In comparison with the conservative approach, which is restricted to semantic equivalents only, our new approach enabled us to capture a stronger historical signal at a more remote time depth. We further applied our recently introduced pseudo Dollo covarion model with relaxed clock as a new model for capturing evolution in our cognate sets. We showed that it had a better fit than the currently existing models for our dataset.</p>
<p>Applying the alternative coding and improved modeling to our renewed dataset in a Bayesian setting, we provided a quantitative basis to test various competing hypotheses with regard to the internal structure of the Transeurasian phylum. We found that a hypothesized binary topology for the Transeurasian family, whereby the Tungusic subgroups clusters with the Altaic unity and branches off first, represented the best supported Transeurasian phylogeny.</p>
<p>2 Lexicostatistic dating methods such as Bla zek and Schwarz (2009) reach 4750 BC for the timedepth of Transeurasian, a date, which converges with our own Bayesian estimation of the root age of Transeurasian as 4700 BC.</p>
<p>Downloaded from https://academic.oup.com/jole/article-abstract/3/2/145/5067185 by MPI Science of Human History user on 07 August 2018</p>
<p>The authors would like to thank Wayne Lawrence, Sander Savelyev, and Sonya Oskolskaya for their contributions to the dataset. The research leading to these results has received funding from the European Research Council under the Horizon 2020 Program/ERC Grant Agreement no. 646612 granted to M. R. This research was further funded by Marsden grant (UOA1308), granted to R. B. (http://www.royalsociety.org.nz/ programmes/funds/marsden/awards/2013-awards/).</p>
<p>Supplementary data is available at Journal of Language Evolution online.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f533447945"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:20+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Periodic undulating topographies (such as sandwaves and sandbars) are very common in coastal and estuarine areas. Normally incident water surface waves propagating from open sea to coastal areas may interact strongly with such topographies. The wave reflection by the periodic undulating topography can be significantly amplified when the surface wavelength is approximately twice the wavelength of the bottom undulations, which is often called as Bragg resonant reflection.</p>
<p>Although the investigations on the hydrodynamic characteristics related to Bragg reflection of a region of undulating topography have been widely implemented, the effects of Bragg reflection on harbors have not yet been studied. Bragg resonant reflection can effectively reduce the incident waves. Meanwhile, however, it can also significantly hinder the wave radiation from the harbor entrance to the open sea. Whether Bragg reflection can be utilized as a potential measure to alleviate harbor oscillations is unknown.</p>
<p>Harbor oscillations (also called harbor resonance or seiches) refer to the gathering and magnification of the incident wave energy inside bays or harbors, which can be triggered by atmospheric fluctuations, infragravity waves, tsunami waves, steady-state or transient wave groups, shear flows, or seisms (Bellotti, 2007;De Jong and Battjes, 2004;Fabrikant, 1995;Gao et al., 2017a;Gao et al., 2020;Kumar and Gulshan, 2017;Okihiro and Guza, 1996;Zheng et al., 2021). It may interrupt the operation of docks, create excessive movements of moored ships, cause unacceptable mooring forces, and even lead to the break of mooring lines (Gulshan et al., 2020;Kumar et al., 2016). The research progresses on harbor oscillations during the last three decades have been reviewed and summarized by Rabinovich (2009).</p>
<p>Harbor resonance phenomenon began to attract attention of coastal engineers from 1940s (Knapp and Vanoni, 1945), and the related scientific investigations started from the early 1950s (Vanoni and Carr, 1950). Most of existing studies focus on the stationary harbor resonance triggered by periodic oceanic waves propagating from the open sea, such as steady-state infragravity waves or steady-state short wave groups. Before the energy propagating from the external incident waves is balanced by energy dissipation generated by bottom friction, boundary absorption, and radiation from the entrance, the stationary resonance inside a bay or a harbor grows significantly (e.g., Gao et al. (2017b); Gao et al. (2019b); Kumar and Gulshan (2018); Losada et al. (2008); Wang et al. (2014)). A small number of scholars have also implemented the investigations on the transient harbor oscillations, which are basically triggered by tsunami waves or transient wave groups (Endoh et al., 2018;Gao et al., 2021;Gao et al., 2019a;Gao et al., 2020).</p>
<p>Water surface waves scattered by the periodic undulating seabed have been widely investigated in the past four decades (e.g., Davies and Heathershaw (1984); Hsu et al. (2007); Liu et al. (2019a); Miles and Chamberlain (1998)). When investigating the issue of water surface waves propagating over a region of sinusoidal undulating topography, the most attractive phenomenon is the wellknown Bragg resonant reflection of incident waves. When the wavelength of the periodic bottom undulations is approximately one half of the wavelength of the water surface waves, the overwhelming majority of the incoming waves could be reflected by the periodic undulating seabed, which would cause the significant decrease of the transmitted waves to the shoreline (Davies and Heathershaw, 1984;Liu et al., 2019b). The Bragg reflection phenomenon provide a possibility that periodic undulating seabeds at the offshore may decrease the wave energy propagating towards the coastline and protect the beach from energetic wave attack (Guo et al., 2021;Liu et al., 2015;Peng et al., 2019).</p>
<p>The investigations on the Bragg reflection phenomenon can be divided into two categories, that is, the theoretical study of Bragg reflection and its application research in the real coastal engineering. For the theoretical study, the sinusoidal undulating topography was most frequently considered, and various mathematical analysis methodologies were adopted to deduce the analytical solution for Bragg reflection, and the possible mechanism of the phenomenon were systematically revealed (e.g., Davies and Heathershaw (1984); Kar et al. (2020); Liu et al. (2019a); Miles and Chamberlain (1998)). In the aspect of engineering application, considering that Bragg reflection of periodic undulating seabed has significant wave prevention effect, in recent years, many scholars have carried out extensive studies on the influences of the section form, structural size and layout of the undulating seabed on Bragg reflection characteristics; the section forms of the undulating seabed considered mainly include rectangle, rectified cosine, trapezoid, triangle, semicircle, and so on (e.g., Li et al. (2020); Liu (2017); Liu et al. (2019b); Zeng et al. (2017)). Heretofore, the studies on Bragg reflection so far have been mostly confined to a region of periodic undulations set on flat or sloping seabeds, and both the seaward and leeward sides of the region of the periodic undulation were basically the simple horizontal bottom (Davies and Heathershaw, 1984;Kar et al., 2020;Kirby and Anton, 1990;Liu, 2017;Miles and Chamberlain, 1998;Peng et al., 2019;Zeng et al., 2017;Zhang et al., 2012).</p>
<p>In coastal and estuarine areas, patches of periodic undulating topographies (such as sandwaves and sandbars) are frequently observed, with the wavelength ranging from a few meters to a few hundred meters (Boczar-Karakiewicz and Davidson-Arnott, 1987;Dolan and Dean, 1985;Elgar, 2003;Guazzelli et al., 1992;Zheng et al., 2016). Hence, the hydrodynamic interactions between the incident waves from the open sea, the periodic undulating topography and the harbor are very common in coastal and estuarine zones (e.g., for the Ponta da Madeira Harbor (Brazil) (Araújo et al., 2004), East London Harbor (South Africa) (Russell, 1982)), and Kesennuma Harbor (Japan) (Mogi, 1965)). However, to the best of the authors' knowledge, the coupling effects between the periodic undulation and the harbor subjected to water surface waves have not yet been investigated so far.</p>
<p>Although it has been widely acknowledged that Bragg reflection can significantly reflect the incident wave energy propagating from the offshore to the coastline when the patch of periodic undulation is set on flat or sloping seabeds, it is still unknow whether the periodic undulating topographies could notably weaken the strength of harbor oscillations if they are in front of the harbor entrance. The occurrence of Bragg resonant reflection can indeed significantly decrease the wave energy propagating into the harbor, which is beneficial to alleviate harbor oscillations.</p>
<p>Meanwhile, however, when it occurs, the patch of periodic undulation could also significantly reflect the radiated waves from the harbor entrance back to the harbor, which would aggravate the intensity of harbor resonance. The specific influence of Bragg reflection on harbor resonance depends on the relative strength between the alleviating and the aggravating effects mentioned above.</p>
<p>Hence, the following four questions arise:</p>
<p>(1) Can the patch of periodic undulating topographies mitigate the strength of the harbor resonance induced directly by the incident regular long waves?</p>
<p>(2) If the answer to question (1) is yes, can the periodic undulating seabed further alleviate the harbor resonance triggered by the incident wave groups?</p>
<p>(3) If the answer to question (2) is yes, what a kind of spatial-scale relationship between the periodic undulating seabed and the incident waves should be satisfied? More specifically, there exist two possible spatial scale relationships: (i) the wavelength of undulating seabed is approximately equal to half of the wavelength of the incident short waves, and (ii) the former is approximately equal to half of the wavelength of the incident wave groups. Which relationship should be satisfied? (4) If both answers to questions (1) and ( 2) are yes, how the geometrical parameters of the periodic undulating topography (including the number and the amplitude) affect the mitigation effect for harbor resonance and the optimal wavelength of the undulating topography that can achieve the best mitigation effect?</p>
<p>To answer these questions, in this article, the interactions between a region of periodic undulating seabed, a harbor and incident steady-state surface waves will be systematically investigated for the first time. The incident steady-state waves considered in the present study include regular long waves and bichromatic short wave groups. The periodic undulating seabed is represented by sinusoidal bars which have been frequently adopted in the study of Bragg reflection (e.g., Davies and Heathershaw (1984); Liu et al. (2019a); Liu et al. (2019b); Miles and Chamberlain (1998)). The generation and propagation of the incident steady-state waves and their interactions with both the sinusoidal bars and the harbor are performed by using a Boussinesq-type numerical model. For simplification, the crest/trough lines of the sinusoidal bars are set to be parallel to and outside the harbor entrance. The harbor is assumed to be long and narrow; the free-surface displacement inside them essentially becomes one-dimensional. Except over the region of periodic undulating seabed, the water depth inside and outside the harbor is set to a constant.</p>
<p>The influences of the sinusoidal bars on the harbor resonance induced by the regular long waves are first examined and the capacity of Bragg reflection to mitigate the strength of harbor resonance is revealed for the first time in this study. Further, the effects of the number and the amplitude of the sinusoidal bars are examined on the mitigation effect for harbor resonance and on the optimal wavelength of the sinusoidal bars that can achieve the best mitigation effect. The lowest four resonant modes of the harbor are considered to reveal the sensitivity of the research findings to the resonant mode. Then, both the capability of Bragg reflection to restrain the harbor resonance induced by the bichromatic short wave groups and what a kind of spatial-scale relationship should be satisfied are proved and determined by setting two sets of sinusoidal bars with different wavelength ranges. How the geometric parameters of the sinusoidal bars affect the strength of harbor resonance and the optimal topographic wavelength is also discussed. However, different from regular long waves, the above discussions are only limited to the lowest resonant mode of the harbor when the bichromatic short wave groups are considered.</p>
<p>The remainder of the paper is organized as follows: Section 2 briefly describes the numerical model, and its abilities to reproduce various hydrodynamic phenomena related to Bragg reflection and harbor resonance are verified by three sets of physical experiments. Section 3 introduces the parameters of the incident waves and illustrates the numerical wave tank as well. Section 4 describes the simulation results along with detailed explanations. Conclusions are finally drawn in Section 5.</p>
<p>and</p>
<p>where</p>
<p>In these equations, η, h, t, and g denote the free wave surface, the water depth, the time, and the gravitational acceleration, respectively. uα denotes the vector of the horizontal velocity at a reference elevation zα=αh with α=-0.531. The subscript t denotes the first-order time partial derivative of the corresponding variable. =(∂/∂x, ∂/∂y) denotes the horizontal gradient vector.</p>
<p>The wave-making methodology of Chawla and Kirby (2000) is used to generate regular or irregular waves. At the boundaries of the numerical wave tank, sponge layers are arranged to dissipate outgoing waves with different frequencies and directions effectively. With the great improvement in both nonlinearity and dispersion, the numerical model can model the propagation and transformation of the water waves from intermediate depth to coastline accurately and robustly (Bruno et al., 2009;Gao et al., 2018;Kirby et al., 2003).</p>
<p>To the best of our knowledge, heretofore, the experimental data for the coupling interaction between Bragg reflection and harbor resonance have not yet been reported. Hence, the capability of the present model to reproduce Bragg reflection of water surface waves and to reproduce harbor resonance will be separately validated by using existing laboratory experiments in the following.</p>
<p>The validation for Bragg reflection is shown in subsection 2.2.1. The verifications for harbor resonance are presented in subsections 2.2.2 and 2.2.3 where the linear harbor resonance and the nonlinear harbor resonance are respectively reproduced.</p>
<p>Two physical experiments with different bar numbers and water depths are reproduced here, and their specific parameters are listed in Table 1. In Tests 1 and 2, the numbers of bars are 4 and 10, respectively; the water depths are 0.156 m and 0.313 m, respectively. The amplitude of bars is D=0.05 m in both tests. For each test, a series of cases with various wavelengths of the incident regular waves are simulated, and all cases are run for 80 wave periods. The time series of the free-surface elevations for the last 30 waves recorded by G1 and G2 are selected for analyses.</p>
<p>In this subsection, the classical resonance problem in an elongated harbor is considered. The ratio of the incident wave amplitude and the water depth is quite small so that the harbor response is linear. The purpose of performing the test for the linear harbor resonance is to validate the ability of the model for accurately estimating the resonant frequencies and the resonant wave amplitudes for various modes. and Goda (1963) and Lee (1971). Lw and l denote the width of the wave-making zone and the length of the harbor, respectively. Ippen and Goda (1963) and Lee (1971) always set to be one wavelength of the incident waves. A wave gauge is deployed at the center of the backwall of the harbor (i.e., the point A). Based on the experimental data, the incident wave amplitude, a, is set to 0.003 m, and hence it can be seen that the wave nonlinearity is quite small (a/h=0.01).</p>
<p>It should be noted that for the nonlinear harbor resonance induced by the bichromatic short wave groups (it will be elaborated in Section 3), its generation mechanism is essentially the transfer of wave energy from the short wave components to the 2 nd -order difference-frequency (subharmonic) component. The good performance of the present model in modeling nonlinear wave energy transfer between various harmonic components during harbor resonance guarantees that the nonlinear harbor resonance excited by the bichromatic wave groups can also be accurately simulated by the present model. Rogers and Mei (1978) and simulated results with for (a) Bay 1, (b) Bay 2, and (c) Bay 3. •, fundamental harmonic; ▲, second harmonic; ◆, third harmonic; -, simulated results.</p>
<p>The harbor oscillations triggered by two kinds of incident steady-state waves (i.e., regular long waves and bichromatic short wave groups) are investigated in the present study. Hence, the parameters for these two kinds of incident waves are separately presented in subsections 3.1.1 and 3.1.2.</p>
<p>In this article, an elongated rectangular harbor with the length of l=20 m, the width of b=2 m and a constant water depth of h0=1 m is considered. Based on the linear analytical solution of Mei (1983), the amplification factor curve at the center of the backwall is calculated and presented in Fig. 7. It is seen that the lowest five resonant frequencies for the harbor are 0.035 Hz, 0.108 Hz, 0.180 Hz, 0.249 Hz, and 0.313 Hz. Because the lowest four resonant modes are investigated for the harbor resonance excited directly by regular long waves, the frequencies of the incident regular waves are set equal to the lowest four resonant frequencies. The incident wave height is H=0.02 m for all cases. Specific wave parameters for the harbor resonance triggered directly by the incident regular long waves are listed in Table 2. Ti and Li in the table refer to the period and the wavelength of the incident waves with the frequency fi (i=1, 2, 3 and 4), and Li is determined according to the linear dispersion relation. Table 2. Specific parameters of both the incident waves and the sinusoidal bars for the harbor resonance triggered directly by regular long waves. Ti and Li denotes the period and the wavelength of the incident waves with the frequency fi (i=1, 2, 3 and 4), and the latter (Li) for different resonant modes vary over a wide range (see Table 2), the length of the computational domain outside the harbor is designed according to the incident wavelength for each mode and is equal to 9.5Li. While the width of the wave tank for all the four resonant modes is always set to 20 m. In the xand the y-directions, two uniform grid sizes, Δx=0.25 m and Δy=0.20 m, are utilized in the whole computational domain. For each resonant modes, the total time of 60 wave periods is simulated, and the time step of Δt=0.03 s is adopted. Twenty-one wave gauges (G1-G21) are deployed equidistantly along the central line of the harbor, and the distance between adjacent gauges is 1.0 m.</p>
<p>Gauges G1 and G21 are placed at the backwall and the entrance of the harbor, respectively.</p>
<p>For the harbor oscillations excited by the bichromatic short wave groups, only the first resonant mode of the harbor is considered. To answer the questions (2) and (3) raised in the Introduction, two types (i.e., long-bar type and short-bar type) of sinusoidal bars are taken into considerations here (see Table 3). For the long-bar type topography, all setups about the wave tank are identical to those adopted in simulating the first resonant mode induced by regular long waves, except that the bichromatic short wave groups are simulated here. While for the short-bar type topography, the setups about the wave tank are identical to those for the long-bar type topography, except that the spatial scale of the short bars is designed according to the wavelength of the incident short waves, ζ, rather than to the wavelength of the free long waves, L1.</p>
<p>It should be noted here that N=0 means no sinusoidal bar existing outside the harbor. In other words, only the pure harbor resonance process is simulated. The purposes of considering the cases with N=0 lies in constructing the comparative group for the cases with N&gt;0.</p>
<p>The time series of the wave surfaces and the spatial distribution of the wave amplitudes inside the harbor subjected to both the regular long waves and the bichromatic short wave groups are first analyzed in subsection 4.1 by using various data analysis techniques. Based on the analysis results in subsection 4.1, the effects of Bragg reflection on the harbor oscillations excited by the incident regular long waves are discussed in subsection 4.2. Finally, all the analysis results related to the influences of Bragg reflection on the harbor resonance triggered by the incident bichromatic short wave groups are presented in subsection 4.3. Based on the time series of the free-surface elevations during the steady-state process, the mean zero-up-crossing wave amplitudes at all gauges are calculated, and their spatial distributions inside the harbor for the eight cases in Fig. 9 are further illustrated in Fig. 10. It is noted that the spatial distributions of the wave amplitude are normalized by A * 1 that denotes the response amplitude at gauge G1 for the no-bar topography. For comparison, the analytical amplitude distribution based on Mei (1983)'s solution for each resonant mode is also plotted here. Three phenomena can be easily observed. Firstly, for all the four cases with N=0, because there is no bar outside the harbor, the amplitude distributions simulated by the numerical model coincides well with the analytical ones of Mei (1983), which indicates again the accuracy of the present numerical model in simulating the harbor resonance phenomenon.</p>
<p>Secondly, because of the total reflection at the backwall of the harbor, there always exist a maximum value of the response amplitudes there, no matter whether the patch of bars exists or not.</p>
<p>Hence, considering the significance of the response amplitude at gauge G1, the ratio of the response amplitude at gauge G1 for N&gt;0 (denoted by A1) to that for N=0 (denoted by A * 1) will be used as a measure to quantitatively assess the effect of sinusoidal bars on the harbor resonance.</p>
<p>Thirdly, for the four resonant modes, the response amplitudes inside the harbor for the cases with N=6 are shown to be always lower than the corresponding ones for the cases with N=0 to different degrees. To illustrate this point quantitatively, the amplitude ratios, A1/ A * 1, for all the four x/l resonant modes are listed in Table 4. It is seen that for Modes 1 and 2, the amplitude ratios are 69.99% and 67.77%, which indicates that the intensity of the harbor resonance are reduced by about 30% due to the external sinusoidal bars. For Modes 3 and 4, the amplitude ratios decrease to 31.54% and 32.94%, respectively. This illustrates that more than 70% of the resonant amplitude inside the harbor is suppressed for these two resonant modes. Based on the limited information presented in Fig. 10 and Table 4, it seems that Bragg resonant reflection can effectively alleviate the harbor resonance for various modes induced by the regular long waves. More comprehensive results and discussions on the effects of Bragg reflection on the harbor oscillations excited by the regular long waves will be presented in subsection 4.2.</p>
<p>The technique of Morlet wavelet transform is adopted here to reveal both time-and frequencydomain information from the time series of the free-surface elevation.</p>
<p>Mode 1 energy enters the harbour. However, the radiated waves are mostly cylindrical with respect to the origin at the harbor entrance. They propagate with a variable direction with the bars and are not in the optimal condition for Bragg reflection. Furthermore, the radiated waves reflected by the bars do not go back directly into the harbor, but more likely attack the surrounding coastline.</p>
<p>Secondly, the sinusoidal bars tend to intensify harbor oscillations when 2S/Li is approximately larger than 1.15. Under this condition, the alleviating effect of the periodic bars becomes weaker than its aggravating effect. Thirdly, both the minimum value of A1/A * 1 (denoted by the symbol "(A1/A * 1)m" hereinafter) and its corresponding value of 2S/Li (called as the optimal normalized wavelength of the undulating topography and denoted by the symbol "(2S/Li)m") for each set of N, D and the resonant mode are closely related to the geometrical parameters of the bars and to the resonant mode. More detailed discussions on how the geometrical parameters of the bars and the resonant mode affect them will be shown in subsections 4.2.2-4.2.4.</p>
<p>It is obvious that the value of (A1/A*1)m can quantitatively embody the mitigation effect of Bragg reflection on the harbor resonance induced directly by regular long waves, and that a lower 2019)). Secondly, the value of (2S/Li)m is shown to gradually increase with the increase of N, which is also consistent with the theoretical finding of Liu et al. (2019a) for pure Bragg reflection (see Table 2 in Liu et al. (2019a)). These two phenomena indicate that Bragg resonant reflection plays a dominant role in the coupling interactions between the patch of sinusoidal bars and the harbor. 1, the variation range of (2S/Li)m is from 0.70 to 0.95, and the difference between the upper and the lower limits is 0.25; while for Mode 4, its variation range is from 0.90 to 1.0, and the difference between the upper and the lower limits is only 0.10. It can be qualitatively explained as follows. For both Modes 1 and 2, their intensities of harbor oscillations are significantly stronger than those of Modes 3 and 4 (see Fig. 7). Therefore, the energy of the radiated waves for the former two modes are much higher than that for the latter two modes; the modulatory effects of the radiated waves on Bragg reflection for the former two modes are significantly stronger those for the latter two modes.</p>
<p>Hence, it well explains why (2S/Li)m deviates from 1.0 more notably and is more sensitive to N for Modes 1 and 2. 18). On the contrary, (2S/Li)m is shown to increase with the resonant mode overall, although there also are some fluctuations for D/h0=0.3 and 0.4 (see Fig. 19). It means that the value of (2S/Li)m becomes closer to 1.0 as the resonant mode rises, which is consistent with the related finding in Fig. 15. In view of the effectiveness of the long-bar type topography on mitigating nonlinear harbor 11 oscillations, the discussions will focus only on this type of topography. 12 13 N, for the long-bar type topography. It is seen that for (AL1/A*L1)m (Fig. 21a), its value declines with the increase of the bar number overall, which indicates that the mitigation effect of Bragg reflection on the nonlinear harbor oscillations becomes better and better as N rises. This phenomenon is similar to that shown in Fig. 14 where the harbor resonance triggered by regular long waves is concerned.</p>
<p>For (2S/L1)m (Fig. 21b), its value is shown to increase gradually with the increase of N and its variation range is from 0.80 to 1.0, which is like the phenomenon illustrated in Fig. 15.</p>
<p>The following main conclusions can be drawn from the results of this study:</p>
<p>(1) The patch of periodic bar topographies can remarkably mitigate the harbor oscillations induced directly by the regular long waves when Bragg resonant reflection occurs. Under this condition, the alleviating effect of the periodic bars resulting from the remarkable reflection of the incident (5) Based on the investigations for the pure Bragg reflection, it has been found that not only the sinusoidal bars but also the artificial bars with other section forms (e.g., rectangle, trapezoid, and triangle) can result in the Bragg resonant reflection. Hence, it can be reasonably inferred that, like the sinusoidal bars, these artificial bars are probably capable of alleviating harbor oscillations. Compared to the sinusoidal bars, these artificial bars are more suitable for the actual engineering because they are easier to be manufactured. However, the mitigation effect of these artificial bars needs to be further investigated in the future.</p>
<p>This research is financially supported by the National Natural Science Foundation of China (Grant Nos. 52071060 and 51809039), the Natural Science Foundation of Jiangsu Province (Grant No. BK20201455), the Natural Science Foundation of the Jiangsu Higher Education Institutions (Grant No. 20KJD170005) and the Qing Lan Project of Jiangsu Universities. The work is also partially supported by UK EPSRC (Grant No. EP/T026782/1), the Royal Academy of Engineering (Grant No. UK-CIAPP/73) and the Royal Society (Grant No. IEC\NSFC\181321).</p>
<p>AL1/A * L1 is 77.0% (see Fig. 20h). 1 2 waves are always stronger than its aggravating effect caused by the reflection of the radiated waves back into the harbor, which indicates that Bragg resonant reflection always dominates the coupling process. On the other hand, the radiated waves from the harbor entrance also play a modulation role to a certain extent, especially for the lowest two resonant modes of the harbor.</p>
<p>(2) When Bragg resonant reflection occurs, the alleviating effect of the sinusoidal bars on the harbor resonance excited by regular long waves is linearly enhanced as the number or the amplitude of bars increases. The optimal normalized wavelength of bars denoted by (2S/Li)m (i=1, 2, 3, and 4) is not always exactly equal to 1.0. For most cases, its value is less than 1.0. Moreover, the value of (2S/Li)m is shown to gradually increase with the bar number, regardless of the resonant mode of the harbor. However, the effect of the bar amplitude on (2S/Li)m depends closely on the resonant mode. For Mode 1, the increase of the amplitude tends to cause the increase of (2S/Li)m; while for Modes 2-4, the rise of the amplitude is inclined to decrease the value of (2S/Li)m.</p>
<p>(3) The long-bar type topography has the capacity of alleviating the nonlinear harbor oscillations induced by the bichromatic short wave groups effectively when Bragg resonant reflection occurs. In the variation ranges of the parameters of the long-bar type topography considered, the strength of the nonlinear harbor oscillations can be weakened by up to 76.4%. However, for the short-bar type topography, its capability of mitigating the nonlinear harbor resonance is limited. In the ranges of the parameters of the short-bar type topography, the strength of the nonlinear harbor oscillations can be weakened only by 23.0%.</p>
<p>(4) Like the harbor resonance triggered directly by the regular long waves, the alleviating effect of the long-bar type topography on the nonlinear harbor resonance induced by the bichromatic wave groups becomes better and better as the number or the amplitude of bars increases, and the optimal normalized wavelength of the long-bar type topography denoted by (2S/L1)m also increases gradually with the number of bars. However, (2S/L1)m is always shown to fluctuate with the amplitude of bars around certain values that depend on the number of bars.</p>
<p>(5) For most cases, the optimal normalized wavelength of bars is less than 1.0, rather than exactly equal to 1.0, no matter for the harbor resonance triggered directly by the regular long waves or the nonlinear harbor resonance induced by the bichromatic wave groups. This downward shift of the optimal normalized wavelength of bars is consistent with the related finding in the investigations of the pure Bragg reflection phenomenon.</p>
<p>We reaffirm here that the above-mentioned conclusions are only valid for the given harbor, incident wave parameters and resonant modes, and the variation ranges of the geometrical parameters of the sinusoidal bars considered in this article.</p>
<p>Based on the above conclusions, the following implications can be obtained in the practice:</p>
<p>(1) To mitigate the long-period resonance in a built harbor is very tough and expensive (Lee and Xing, 2009). Alteration of the general layout is one option, but sometimes it seems impossible, especially for a built harbor. The present research proposes a new option: to change the bottom profile to use the Bragg reflection to mitigate the harbor resonance, which is much more feasible as long as the navigating depth is guaranteed.</p>
<p>(2) If there are natural bars at the location of a harbor to be built, the possible countermeasure and its mitigation effect on harbor resonance depend on the wavelength of the natural bars. For the bar wavelength, S, with the order of tens of meters to hundreds of meters, the general layout of the harbor needs to be carefully designed based on the following principle. That is, the wavelength of the incident long waves that correspond to the most destructive resonant mode, Li, should approach the value of (2S/Li)m as closely as possible. In general, to meet the above principle, a trial-and-error designing process is inevitable.</p>
<p>(3) For the natural bars with the wavelength ranging only from meters to more than ten meters, the natural bars should be artificially modified (if needed) so that their wavelength approaches the value of (2S/ζ)m as closely as possible. (2S/ζ)m denotes the optimal normalized wavelength of the short-type bars that can achieve (AL1/A * L1)m (refer to Fig. 20e-h). ζ here corresponds to the short wavelength of the spectral peak period. This countermeasure could also alleviate the harbor resonance to a certain extent, although its mitigation effect is not as good as that of the above-mentioned long-type bars with much longer wavelengths.</p>
<p>(4) For built harbors without natural bars, the artificial bars could be arranged outside the harbor entrance. The designing principles of the artificial bars are similar to those presented in the implications (1) and (2) and are not repeated here. Compared to the natural bars, the artificial bars are more suitable for small-scale harbors (e.g., the marina). This is because, for large-scale harbors, if the relationship of (2S/Li)m was satisfied, the value of S might be too large to make</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f82866372"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:47+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Research has shown that priming one's racial identity can alter a biracial individuals' social behavior, but can such priming also influence their speech? Language is often used as a marker of one's social group membership and studies have shown that social context can affect the style of language that a person chooses to use, but this work has yet to be extended to the biracial population. Audio clips were extracted from a previous study involving biracial Black/White participants who had either their Black or White racial identity primed. Condition-blind coders rated Black-primed biracial participants as sounding significantly more Black and White-primed biracial participants as sounding significantly more White, both when listening to whole (Study 1a) and thin-sliced (Study 1b) clips. Further linguistic analyses (Studies 2a-c) were inconclusive regarding the features that differed between the two groups. Future directions regarding the need to investigate the intersections between social identity priming and language behavior with a biracial lens are discussed.</p>
<p>People have multiple social identities based on group memberships, social roles, and affiliations that can become more or less salient over time and across context (i.e., race, gender, age, occupation). This kind of social identity priming can be understood from the perspective of social identity theory (Tajfel and Turner, 1986) which states that an individual's self-concept is defined based on one's perceived group membership. Moreover, one's social identity has been proven to be an important source of self-esteem, behavior, one's sense of belonging, and purpose in the social world (Tajfel and Turner, 1986;Correll and Park, 2005). Social identity priming reveals that the salience of various identities can easily be swayed by cues in the environment. For example, we may identify more with our occupation when at work, but when at home other aspects of our identities (e.g., as parents or spouses) may become more salient. Similarly, chronic or momentary cues to our racial, ethnic, gender, or occupational identity may also subtly influence our behavior.</p>
<p>Research has explored a variety of contexts that can prime one's social identity. However, there is a particularly understudied population within the social identity theory frameworkbiracial individuals (those with parents from two different racial backgrounds). Recent research has highlighted the fact that that social context can significantly alter how biracial individuals racially identify, forcing them to navigate between their different racial identities subconsciously (e.g., Chiao et al., 2006;Cheng and Lee, 2009; for a review see Gaither, 2015). More specifically, a simple racial identity priming task has been shown to affect how much biracial Black/White individuals identify and socially interact with other Black or White people (Gaither et al., 2013). Therefore it is clear that racial identity is a psychological mechanism that elicits changes on biracial individuals' behavior. We know that a biracial person's identification is influenced by a number of contextual and interpersonal variables including the racial group membership of one's interaction partner. But what remains unknown is whether this shift in identity caused by racial priming can also shape other aspects of the way biracial individuals express their identity such as their verbal behavior independent of the race of their interaction partner.</p>
<p>In fact, language is one of the most prominent means of expressing one's social identity. Previous work has shown that context can influence one's language use, suggesting a degree of malleability similar to other manifestations of identity (e.g., Giles andJohnson, 1981, 1987;Gumperz, 1982;Ochs, 1993;Pennebaker et al., 2003). Unfortunately, while it is clear that language use is influenced by one's social context, the specific mechanisms by which social identity influences language use in the moment are not clear. This is partly a result of the fact that research in the social psychological and sociolinguistic domains has typically proceeded independently of each other. Generally speaking, social psychologists probe the social and cognitive factors involved in the formation and expression of identity while sociolinguists investigate the systematic ways that language use varies between different social groups and contexts. Unfortunately, very little interaction exists between these literatures, despite the fact that identity strongly manifests itself through language use, which can substantially vary based on social affiliation. The goal of the present investigation was to begin to bridge these disciplines and explore the specific cognitive mechanisms that support the connection between social identity and language. To do so, we focused on the speech of a group that regularly moves between different social identities-the biracial Black/White population (e.g., Chiao et al., 2006;Cheng and Lee, 2009;Gaither et al., 2013;Gaither, 2015).</p>
<p>Both styleswitching and codeswitching are defined as a moment when people alter their speech between one or more speaking styles. While the terms are often used interchangeably in the literature, they differ subtly. Styleswitching usually refers to an intentional stylistic switch in speaking to align with one's context or with one's perceived identity in a given situation whereas codeswitching often occurs to resolve basic communicative needs such as when a bilingual individual only knows the name of an object in one of their languages (e.g., Labov, 1972). Therefore, styleswitching most commonly occurs in response to one's audience and the topic at hand and may involve all levels of linguistic structure, with shifts in syntactic, morphological, and phonological patterns as well as word choice and low-level phonetic features (Blom and Gumperz, 1972;Gumperz, 1982). One early theory, proposed by Labov (1996), is that speech style varies in relation to the amount of attention paid by a speaker to his or her speech. According to Labov (1996), speech may be generally seen to span a continuum from 'casual' (the speech used in everyday situations when no attention is being paid to how one is speaking) to 'careful' (e.g., the speech used when one knows he or she is being recorded), with linguistic features associated with formality appearing in the latter but not the former. A more comprehensive theory was proposed by Bell (1984), who argued that styleswitching is primarily a form of audience design, where speakers shape their speech directly in response to the identity of their interlocutors. On this view, styleswitching is often a form of accommodation whose purpose is to create (or in some cases, reduce) 'alignment ' among interlocutors (e.g., Fuller, 1993;Bucholtz, 2009).</p>
<p>In fact, to date, sociolinguistic theorizing has tended to make the external factors their object of focus. The audience design proposal, for example, locates one's addressees as the primary determinants of styleswitching (e.g., Giles and Powesland, 1975;Gumperz, 1982;Bullock and Toribio, 2009). Speakers are always crafting (consciously or unconsciously) their speech in relation to the social identity of one's interlocutor. Styleswitching is also an important means of expression for individuals who are navigating multiple social or cultural identities. Benor (2012), for example, reports that Baalei Teshuva (Jews who are becoming more observant) styleswitch between Jewish dialects of English as part of their "hybrid self-presentation." This highlights how important styleswitching is for the expression and management of identity as well as how easily bicultural individuals can accommodate their speaking styles situationally based on their current sense of self or social identity. In this vein, sociolinguistic research has tended to investigate styleswitching by manipulating the factors external to a speaker such as different interlocutors, environments, topics, and so on.</p>
<p>In the present study, we take this approach in a new direction by manipulating speakers' self-concept and observing the effects on speech. This approach allows us to ask two primary questions. First, the identity priming techniques developed by social psychologists have been shown to influence relatively high-level social processes such as behavioral tendencies and social identification; we ask whether it can also influence relatively low-level cognitive processes like speech style. Second, independently manipulating an individual's selfconcept and external factors allows examination of the relative contributions of identity and environment to speech style. If styleswitching occurs primarily in response to external factors (e.g., accommodation), we would expect an interlocutor (and the goals one may have with regard to that interlocutor) to play a decisive role in determining the occurrence and extent of styleswitching. On the other hand, if some aspects of style are linked in a stable way to aspects of one's identity, we may observe that manipulating an individual's self-concept can influence some aspects of their speech, irrespective of their interlocutors.</p>
<p>To explore these questions, we tested whether priming one of a biracial Black/White individual's racial identities influences ordinary, spontaneous speech. In an earlier study (Gaither et al., 2013) self-identified biracial Black/White individuals living in the greater Boston area were recruited for an in-lab videotaped social interaction study with either a Black or White interaction partner where they discussed affirmative action. Before this interaction, participants were randomly assigned to write for 7 min about the racial identity of one of their parents: either their White parent or their Black parent (see Chiao et al., 2006). Gaither et al. (2013) showed this prime significantly affected participants' levels of racial identification in accordance with the racial prime: biracial Black-primed participants identified more with other Black people while White-primed participants identified more with other White people. Additionally, this racial prime altered social behavior: participants primed with the same racial identity as that of their interaction partner (i.e., White prime and White interaction partner) had significantly more positive interactions (i.e., lower levels of anxiety and increased eye contact) than participants who had the opposite racial identity primed (i.e., White prime and Black interaction partner). Considered together these findings critically demonstrate that racial identity priming influenced the self-concept of the biracial participants, influencing in turn their explicit and implicit social behavior. To determine whether this shift also influences linguistic behavior (i.e., induces styleswitching), the conversations between these participants and their interaction partners were analyzed in the present study.</p>
<p>As mentioned before, dialects or 'varieties' of languages can differ at all levels of linguistic structure, from the principles that govern sentence formation down to the specifics of how various sounds are articulated. While regional variation is perhaps the most generally recognized (and oldest studied) form of linguistic variation, linguistic features are also known to co-vary with racial and ethnic identity (e.g., Boberg, 2004;Slomanson and Newman, 2004;Szakay, 2008;Newman and Wu, 2011;Benor, 2012). These features are not biologically determined (just as regional variants are not biologically determined) rather they represent particular linguistic principles learned (implicitly or explicitly) by particular communities of individuals. Given these correlations, listeners often use linguistic features to make inferences about a speaker's social identity. While some inferences may relate to social stereotypes (that is, cultural values may become associated with particular features, e.g., Johnson and Buttny, 1982;Koch et al., 2001, see Baugh, 2003and Cavanaugh, 2005 for reviews) other inferences may simply relate to the fine-grained statistical co-variation of linguistic features and identity (e.g., Labov et al., 2006;Warren et al., 2007;Smith et al., 2010;Newman and Wu, 2011).</p>
<p>Relatedly, past work has also shown that listeners are extremely accurate in identifying Black versus White speakers (for a review, see Thomas and Reaser, 2004) and research has suggested that there are phonetic characteristics that listeners associate with African American speech (e.g., Walton and Orlikoff, 1994;Purnell et al., 1999). Therefore, we hypothesized that participants primed with their Black identity would sound more 'Black' and those primed with their White identity would sound more 'White' to outside listeners. In Studies 1a,b, naive coders were recruited to assess whether identity priming does in fact shape biracial individuals' speech. Inspired by our findings, we also sought to determine the dimensions along which identity priming can shape biracial Black/White individuals' style. Therefore, in Studies 2a-c we investigated whether identity priming influences the degree to which such individuals utilize common linguistic features of African American English (AAE). Together, the goal of these studies was to shed light not only on the relationship between the cognitive construct of identity and language use but also how this identity can interact with the specifics of linguistic knowledge.</p>
<p>Audio clips were extracted from each of 56 interactions to include only the voice of the biracial participant. This previous study was university IRB approved and informed consent was obtained from all participants. No utterances of the confederate's voice were extracted to ensure that only the voice of the biracial participant would be coded. Some audio could not be extracted either due to poor audio quality (n = 10) or an inability to cut out all occurrences of hearing the confederate's voice (n = 2), resulting in a final sample of 44 3-4 min clips (12 Black-primed females, 12 White-primed females, 13 Black-primed males, seven White-primed males).</p>
<p>As our main dependent variable, four coders (two female; two White, one Asian, and one biracial Asian/White) rated each audio clip. These coders were research assistants who had no linguistic training and therefore represented how the average person would perceive these biracial speakers. While these research assistants were blind to condition and hypotheses, they were still knowledgeable about the various ways that Blacks and Whites are stereotyped-including the nature of their speech. Therefore, in line with how the average listener would hear different types of speech, coders rated each audio clip for how stereotypically Black to White participants sounded using a scale of 1 (very Black) to 7 (very White). In case a speaker's position on affirmative action (the topic of the conversations) influenced perceived race, coders also rated the speaker's perceived position on affirmative action 1 (very opposed) to 7 (very in favor). Lastly, to ensure that there were no differences in how anxious participants sounded (which could be equated with various prejudicial attributions such as being nervous or unprepared), coders also rated participants on how anxious to calm they sounded using a scale of 1 (very anxious) to 7 (very calm).</p>
<p>Across the four coders, one average rating was calculated for each rated item to create on rating per item (sounding Black: intraclass r = 0.63; sounding in favor of affirmative action: intraclass r = 0.81; sounding anxious: intraclass r = 0.75). As expected, Black-primed participants were rated as sounding significantly more Black (M = 3.26, SD = 0.73) than Whiteprimed participants (M = 3.78, SD = 0.73), t(42) = 2.33, p = 0.025, r = 0.34. Black-primed participants were also rated as sounding significantly more in favor of affirmative action (M = 4.44, SD = 0.90) than White-primed participants (M = 3.95, SD = 0.61), t(42) = 2.05, p = 0.046, r = 0.30. Furthermore, ratings of sounding more White were also found to be positively correlated with sounding more opposed to affirmative action, r = 0.54, p &lt; 0.01. To examine whether the biracial individuals' stance on affirmative action may have influenced coders' judgments as to whether the speaker sounded more Black or White, the coder's ratings of sounding more in favor of affirmative action were included a as a covariate in a subsequent analysis. When doing so, the perceived group differences of Black-primed participants sounding more Black and White-primed participants as sounding more White was no longer statistically significant, F(1,41) = 2.04, p = 0.16.</p>
<p>There was no significant difference on sounding more anxious between Black-primed (M = 3.93, SD = 1.04) and White-primed participants (M = 3.97, SD = 0.89), t(42) = 0.15, p = 0.88 [see Figure 1 showing the original Gaither et al. (2013) study racial identification results and these results]. Lastly, perceived phenotypicality ratings (degree of Black facial characteristics; see Maddox, 2004) of the biracial participants that were collected in the original study did not affect these outcomes. Therefore, appearing more physically Black did not affect how Black participants sounded.</p>
<p>Crucially, a 2 (primed identity: Black, White) × 2 (race of partner: Black, White) ANOVA revealed no interaction between identity prime and the race of one's interaction partner on sounding more White to Black, F(1,40) = 0.15, p = 0.70. This suggests that the racial identity prime was strong enough to affect verbal behavior for biracial Black/White individuals irrespective of the race of their interlocutor, suggesting for the first time that styleswitching does not solely occur based on one's interlocutor (or one's goals with respect to the interlocutor). However, participants in this previous study were all racially primed before the interaction, meaning we still do not know if the race of one's interaction partner would affect biracial speech when a biracial person's identity is not explicitly primed. Therefore, future work should further explore the effects of interlocutors on biracial speech.</p>
<p>In sum, this study demonstrates that racial identity priming not only affects social behavior, but it also influences how Black or White a biracial individual speaks. However, despite our efforts at control, it is possible that coders may have relied on perceived positions on affirmative action when making their judgments of how Black/White they sounded. Therefore, in an effort to eliminate this possibility, Study 1b recoded these clips after eliminating all affirmative action related content.</p>
<p>Using a thin slicing approach (see Ambady et al., 2006 for similar methods), the same audio clips from Study 1a were shortened to 10-20 s segments that excluded all specific mention of affirmative action or other minority related material to ensure that the content of the audio clips would not be affecting the ratings in this second study1 . Four new coders (three female; three White, one Black) that again had no linguistic training and were blind to condition and hypotheses rated each participant's thin slice audio clip on the following dimensions: (1) how stereotypically Black to White participants sounded using a scale of 1 (very Black) to 7 (very White); (2) how uninformed to informed (i.e., intelligent) participants sounded on a scale of 1 (very uninformed) to 7 (very informed); and (3) how unsure to confident participants sounded on a scale of 1 (very unsure) to 7 (very confident). These last two ratings were used to explore past findings stating that voices from certain stereotyped groups tend to evoke prejudices associated with those groups. More specifically, past work has shown that both Black and White listeners perceive Black speakers less favorably than White speakers on traits including intelligence, confidence and ambition (e.g., Johnson and Buttny, 1982;Koch et al., 2001). Additionally, to control for affect, coders were also asked to rate how positive the speakers sounded using a 7-point scale 1 (very negative) to 7 (very positive). Lastly, coders were asked to list what they thought the person was talking about in order to ensure that listeners could not infer that the participants were speaking about minority-related issues.</p>
<p>It is possible that a Black individual may perceive Black sounding speech differently than non-Black listeners, and since there were no Black coders in Studies 1a,b provided an opportunity to explore this possibility. However, we found high reliability across all coders regardless of their racial background, suggesting coder race was not a factor at least under the parameters of the present study. Therefore, an average rating was calculated for each rated item (sounding Black: intraclass r = 0.63; sounding informed: intraclass r = 0.72; sounding confident: intraclass r = 0.70; sounding positive intraclass r = 0.55). As in Study 1a, Blackprimed participants were rated as sounding significantly more Black (M = 3.14, SD = 0.90) than White-primed participants (M = 3.73, SD = 0.69), t(38) = 2.29, p = 0.028, r = 0.35. Blackprimed participants were also rated as sounding significantly less informed (M = 3.73, SD = 1.08) than White-primed participants (M = 4.36, SD = 0.80), t(38) = 2.10, p = 0.042, r = 0.32 and significantly less confident (M = 3.88, SD = 1.12) than White-primed participants (M = 4.53, SD = 0.80), t(38) = 2.09, p = 0.043, r = 0.32. There were no differences between Blackprimed (M = 3.92, SD = 0.57) and White-primed participants (M = 4.14, SD = 0.57) on how positive they sounded, ruling out affect as a contributing factor in speech perception, t(38) = 1.22, p = 0.23. Furthermore, coders also did not list that any of the speakers were talking about any issues related to affirmative action. Lastly, as in Study 1a, neither phenotypicality nor the race of participants' interaction partners affected these results [see Figure 2 showing the original Gaither et al. (2013) study racial identification results and these results].</p>
<p>In sum, this study replicates findings from Study 1a in that racially priming biracial Black/White individuals significantly affects how they vocally sound to outside listeners-a fact that is not contingent upon the content of the speech or the racial background of the interlocutor. These results, combined with those from Study 1a, indicate that internal identity primes can manifest in speech, extending biracial identity flexibility research for the first time to verbal behavior. They also demonstrate that external factors such as interlocutors are not the only force that drives styleswitching behavior (e.g., Hartsuiker et al., 2004;Pickering and Garrod, 2004). This is not to say that interlocutors have no effect on one's speech, a fact that has been clearly demonstrated in many previous studies. We will return to this issue in the Section "General Discussion."</p>
<p>Having shown that racial priming influences the speech of biracial individuals, in Studies 2a-c, we conducted a linguistic investigation to determine if there are specific grammatical structures that differed between the White-and Black-primed participants. Dialects differ from each other at all levels of linguistic structure: the syntactic forms of sentences, the particular combinations of affixes used to form words, the particular sound patterns found within words, and the basic phonetic properties of the speech signal itself. The goal of these studies was to examine if certain linguistic properties may be involved in the styleswitching for biracial Black/White individuals. Since our participants were biracial Black/White, we contrasted the use of features commonly found in AAE (typically spoken by Black individuals, though by no means exclusively) and 'General' American English (GAE; a catchall term we use here as a proxy for the varieties of English most commonly spoken by White Americans). Study 2a investigated whether the speech of the Black-and White-primed participants differed in their syntactic and morphological properties, that is, features relating to the order of words in a sentence and the use of prefixes and suffixes to encode grammatical features. For example, the absence of the copula (e.g., 'he crazy') and the use of aspectual markers such as bin (e.g., 'he bin working') are common in AAE but not GAE and could serve as markers of Black identity (e.g., Rickford and McNair-Knox, 1994).</p>
<p>In Study 2b, we investigated whether the two groups exhibited any differences in their use of a set of phoneme-level phonological patterns. Lastly, in Study 2c we examined whether the Black-and White-primed participants differed in their use of a number of handful low-level phonetic properties (e.g., pitch). To anticipate the results, we found no differences in the use of these features.</p>
<p>Transcripts of the thin-sliced audio clips from Study 1b were prepared by four transcribers naive to the purpose of the study. Each audio clip was transcribed word-for-word and false starts, disfluencies, filled pauses, and salient unfilled pauses were also included. As an example, the transcript for Participant 73 was as follows: "and, uhhhh, (pause) I haven't really thought that much about it because it's never really directly affected my life. . .." Standard orthography was used for all words (e.g., running, not running).</p>
<p>The written transcripts afforded us the opportunity to directly investigate whether there were differences in the syntactic or morphological patterns of the groups' speech. By using transcripts, we isolated syntactic and morphological information while excluding phonological and phonetic factors from consideration. Ten coders who were blind to the purpose of the study were recruited to read and rate the transcripts individually using the same scales as Study 1b.</p>
<p>An average rating was calculated for each coded item and no significant differences by racial prime were found for (1) sounding more Black, (2) more informed, or (3) more confident (all ts &lt; 0.54, all ps &gt; 0.59). Therefore, we can infer that the differences perceived by the coders in Studies 1a,b are driven primarily by phonological properties and not the syntactic, morphological, or semantic content of the thin-slices. That is, these results suggest that the phonological and phonetic properties of the biracial participants' speech are the dominant dimensions of styleswitching in these individuals.</p>
<p>The purpose of this study was to determine the extent to which the styleswitching of the Black-and White-primed groups involved categorical phonological patterns. Varieties of the same language frequently differ in which sounds appear in different environments. For example, American English speakers typically pronounce /t/ as a tap-[R], a rapidly articulated voiced consonant that sounds similar to [d]-when it appears between two vowels (compare the /t/ of note [noUt] to that of notable [noUR@b@l] or pity [pIRi]). In contrast, speakers of the Cockney variety of British English frequently pronounce intervocalic /t/ with a glottal stop-[P], the voiceless stop in the middle of uh-oh-such as in the word pity [pIRi]. For the present study, four phonological patterns were identified that are not exclusive to AAE but are less common in GAE, particularly the variety spoken in the Boston area. These patterns were: interdental fricative substitution (e.g., GAE/AAE: these [ðiz]/[diz], brother [br2ðÄ]/[br2v@]), 'g-dropping' (e.g., running [r2nIN]/[r2nIn]), final cluster reduction (e.g., desk [dEsk]/[dEs]); and final /l/-and /r/-deletion (e.g., sore [sOr]/[sO]; all [Ol]/[O])2 . Although cluster reduction may affect all word-final clusters, we excluded: (1) clusters ending in /t/ and /d/ (e.g., fast, bend) since these sounds are frequently deleted in all varieties of American English (e.g., Patrick, 1999) and the size of our sample didn't allow us to quantitatively distinguish between varieties; and (2) clusters ending in /s/ and /z/ since these clusters are rather unlikely to be reduced.</p>
<p>Two trained linguists blind to participant priming condition (Calvin L. Gidney and Ariel M. Cohen-Goldberg) conducted the present analysis. The first step was to identify all words in the thin-sliced transcripts that could possibly undergo the phonological rules listed above. For example, 'g-dropping' can only be observed in words that contain a word-final /N/. The coders then compared their ratings and attempted to resolve any disagreements by repeated review of the tokens. In total, 339 words were identified that could possibly undergo one of the four phonological patterns described above, an average of 8.4 words per participant.</p>
<p>The coders initially disagreed on the coding of 17 of the 339 cases and were able to resolve all but four of the disagreements. We report the data with these remaining cases excluded. Overall, 96% of the tokens were coded as having a GAE pronunciation. AAE pronunciations were observed in 4/28 potential cases of 'gdropping, ' 8/116 potential cases of /l,r/-deletion, 1/38 potential cases of final cluster reduction, and 0/153 potential cases of interdental fricative substitution. In addition, two cases of unstressed syllable deletion and two cases of monophthongization were incidentally observed. These AAE features were observed in only nine of the 40 participants and the use of AAE phonological features did not differ across the two priming groups: five of the participants (nine observed AAE features) were in the Whiteprime condition while four participants (five observed AAE features) were in the Black-primed condition. Lastly, seven of the nine participants who produced AAE pronunciations used only one pattern; the other two used two patterns. On average, participants in the White prime condition produced more slightly more segments with the AAE variant (M = 4.3%, SD = 10%) than participants in the Black prime condition (M = 3.3%, SD = 7%) of the time but this difference was not significant t(38) = 0.36; p = 72; d = 0.12. These results suggest that the speech of Black-and White-primed individuals was not primarily distinguished by the four discrete sound-level properties examined here.</p>
<p>Fundamentally, speech is a physical act involving the coordination of many different components of the vocal tract. Most speech sounds used in the world's languages begin with the controlled exhalation of air from the lungs. During this process, the vocal folds rapidly open and close, adding periodic energy-voicingto the airstream. Voicing plays an important role in many speech sounds and the frequency of vocal fold vibration determines the pitch of one's voice. Speakers then move the tongue, lips, and velum in a highly coordinated fashion to further shape the airstream, producing individual speech sounds. The specific ways that sounds are physically articulated differ across languages and dialects/varieties and thus form part of a speaker's knowledge of his or her language. In this study we examined five phonetic features that have previously been described as differing to some degree between AAE and GAE: jitter, shimmer, harmonicsto-noise ratio (HNR), utterance-wide pitch, and the degree of monophthongization in the vowel /aI/.</p>
<p>Jitter and shimmer quantify the magnitude of the variation in the timing and intensity (frequency and amplitude), respectively, of consecutive vocal fold closures while HNR quantifies the amount of noise in the speech signal. Walton and Orlikoff (1994) reported that speakers of AAE tend to exhibit more jitter and shimmer than speakers of GAE while Purnell et al. (1999) reported that AAE speakers tend to exhibit reduced HNR relative to GAE speakers. Other studies have reported that AAE and GAE speakers may differ in the extent to which their pitch (the highness or lowness of one's voice, defined as the fundamental frequency of vocal fold vibration) may vary across an utterance. Loman (1975) and Jun and Foreman (1996) report that AAE speakers tend to exhibit greater changes in pitch across utterances than GAE speakers.</p>
<p>Finally, AAE is known to exhibit a greater degree of monophthongization than many (but not all) varieties of English spoken by White Americans. Vowels can generally be classified as monophthongs-vowels such as /i/ (feet), /I/ (fit), or /u/ (food) that involve a static placement of the lips and tongue-and diphthongs, which are vowels such as /aI/ (time), /aU/ (pout), and /OI/ (toy) that involve a trajectory of the tongue and possible change in lip rounding. Monophthongization is the tendency in Southern U.S. and African American dialects for diphthongs to be pronounced as monophthongs (e.g., pronouncing the /aI/ in time as [a:]). AAE speakers are more likely to exhibit monophthongized vowels than GAE speakers (Fasold and Wolfram, 1970). Interestingly Hay et al. (1999) analyzed recordings of The Oprah Winfrey Show and found that Winfrey was significantly more likely to monophthongize /aI/ when introducing an upcoming African American guest than a non-African American guest. The fact that monophthongization may occur when the interlocutor is not present suggests that it may be a good candidate for the sort of styleswitching being investigated in the present study 3 .</p>
<p>Jitter, Shimmer, HNR, and Pitch</p>
<p>The degree to which a vowel is articulated as a monophthong or diphthong can be assessed acoustically by examining the first and second formants. Formants are the frequencies of the speech signal that have the highest energy-the lowest such spectral peak is called the first formant ('F1') while the next lowest is called the second formant ('F2'). For this analysis, we examined the vowel /aI/ obtained from tokens of the first person pronoun I. In the diphthong /aI/, F1 generally falls in frequency over the course of the vowel while F2 generally rises, consistent with the tongue moving higher and farther forward, respectively, over the 3 It is important to note that Winfrey's monophthongization is likely the product of unconscious sociolinguistic styleswitching as well as conscious performative effort. It thus may be difficult to generalize these results to speakers in ordinary conversational situations. course of vowel articulation. In contrast, F1 and F2 remain relatively unchanged in frequency the course of the monopthongized counterpart of this vowel, /a/. Since a vowel's formant structure is influenced by its neighboring sounds, we sought to standardize the measurements by measuring the same word in each participant. In the end, all measurements were made from the first person pronoun I since this word was uttered by nearly all of the participants.</p>
<p>Jitter, Shimmer, HNR, and Pitch T-tests of clip-wide values revealed no significant differences across the Black-and White-primed participants: the average jitter (measured as Relative Average Perturbation) for Blackprimed participants (M = 0.016, SD = 0.01) did not differ from White-primed participants (M = 0.017, SD = 0.01), t(36) = 0.24, p = 0.81; d = -0.10; the average shimmer (local, db) for Blackprimed (M = 1.63, SD = 0.11) and White-primed participants (M = 1.62, SD = 0.11) did not differ, t(36) = 0.291, p = 0.77; d = 0.09; and the average HNR for Black-primed (M = 5.57, SD = 1.24) and White-primed participants (M = 5.73, SD = 1.40) also did not differ, t(36) = 0.37, p = 0.72; d = -0.12. Lastly, there were no differences in the degree of pitch variation (average SD) between Black-primed (M = 35.39, SD = 14.13) and Whiteprimed participants (M = 41.30, SD = 27.53), t(36) = 0.87, p = 0.39; d = -0.27, but a marginally significant difference was found in minimum pitch, with Black-primed participants (M = 83.35, SD = 20.39) having a lower minimum pitch than White-primed participants (M = 100.17, SD = 35.69), t(36) = 1.81, p = 0.08; d = -0.58.</p>
<p>The results of the six analyses are presented in Table 1, which reports the beta weight estimate, SE of the estimate, and t-value for each fixed effect. The number of tokens varies across analyses since the different measurements could not be made on all tokens (e.g., failure to estimate a token's fundamental frequency). Generally speaking, predictors with t-values ≥ 2 are significant in models with large datasets such as the ones reported here (in the table predictors with t-values ≥ 2 are highlighted; significant results for vowel identity are not highlighted for clarity). Although all of the nuisance variables were significant in at least one model, Priming Condition was never significant. This provides additional support that that the identity prime manipulation did not significantly influence the speakers' jitter, shimmer, HNR, or pitch.</p>
<p>Our results demonstrate for the first time that the experimental manipulation of a social psychological variable (racial identification) leads to a real-time shift in speaking style. As demonstrated by Gaither et al. (2013), biracials are sensitive to these primes in guiding their behavior. In this paper, we show that this influence extends to their patterns of speech, with implications for how they may be perceived by others. Sounding black is sufficient to activate cultural stereotypes, potentially biasing subsequent evaluations (e.g., Johnson and Buttny, 1982;Koch et al., 2001). These results hold important theoretical and methodological implications for both the social psychological and sociolinguistic literatures. First, the demonstration that momentary shifts in social identity can be expressed through speech broadens our understanding of identity as a psychological phenomenon, indicating that intimate links exist between social and linguistic cognitive processes. Second, these results extend biracial identity flexibility research to language, highlighting another commonality between biracial and bicultural populations through social identification and language use. Lastly, our study suggests that language could potentially be used as an implicit index of social identification in laboratory experiments, complementing more traditional measures such as ratings.</p>
<p>Our results also enrich the sociolinguistic literature. First, they demonstrate that styleswitching can occur in response to the internal state of the individual, not simply in response to the individual's environment. This suggests that at least some components of style are stably linked to aspects of a speaker's identity and may manifest as those aspects become prominent. Second, our results suggest that social psychological techniquesidentity priming in particular-may be a useful addition to the sociolinguist's toolbox, allowing the research to independently manipulate speaker identity and context.</p>
<p>Individuals with multiracial identities face unique challenges in navigating the social landscape by adopting specific cognitive strategies that enable them to associate more with one racial identity as needed (e.g., Chiao et al., 2006;Bonam and Shih, 2009;Gaither et al., 2013). We believe that the racial priming utilized in this study is (at least temporarily) changing the internal or personal racial identification of the participant which in turn directly affects their verbal behavior (Gaither et al., 2013). We show that styleswitching for biracial individuals is more of a holistic phenomenon since it affects participants' speech overall, not just the words they choose to use. Furthermore, this explicit prime causes the focus to be on one's own identification rather than the group membership of the interlocutor. However, other work suggests that additional research is needed to investigate the situational factors that may prime styleswitching abilities (Fu et al., 2007). Future work should examine whether biracial individuals who are not explicitly primed naturally styleswitch based on the racial background of their interaction partner. Furthermore, this study included audio analysis only of biracial Black/White individuals-it is imperative to study other mixed-race populations (especially those who grew up speaking more than just variations of English) and other linguistic markers to investigate whether these findings apply more generally to the mixed-race demographic.</p>
<p>One particularly interesting finding is that although the styleswitching was apparent to listeners, the specific linguistic manifestations of this shift were less clear. This, however, has precedent in the literature. For example, Gaudio (1994) reported that listeners could reliably judge speakers' sexual orientation based on short audio passages even though he was not able to instrumentally find reliable phonetic differences between gay and straight speakers (see also Moonwomon, 1985). And similar difficulties have been noted in identifying which features listeners use to distinguish Asian American (Newman and Wu, 2011) and Black speakers (Thomas and Reaser, 2004).</p>
<p>While it is always difficult to interpret null results, we believe a number of factors may have contributed to our failure to instrumentally find specific linguistic markers of Black/White identity. The first and most straightforward account is that participants utilized linguistic features to indicate identity that were simply not covered in our analysis. While we examined many of the prominent features that distinguish these varieties (and indeed, some that have been shown to specifically manifest in styleswitching), many features were not analyzed and these gaps should be filled in future studies. Second, the Black-primed participants exhibited many grammatical markers of GAE while still "sounding Black" to our coders. This suggests that there are possibly other characteristics of speech that listeners strongly associate with African American speech that have yet to be empirically documented (e.g., Walton and Orlikoff, 1994;Spears, 1998;Thomas and Reaser, 2004;see Munson, 2011 for a general discussion of the difficulties surrounding phonetic 'parameterization'). Third, environmental factors may have played an important role in shaping the linguistic competence of our biracial speakers. While it is common for monoracial individuals to grow up in a household where both parents speak the same dialect, this likely was not the case for our participants. Our biracial participants may thus have been exposed to greater heterogeneity in their linguistic experience, causing their speech to incorporate subtle shifts in speech patterns that are more difficult to detect or label empirically. There may also be heterogeneity in the way speakers shift between Black and White speech-some speakers may adopt particular features and not others (Zwicky, 1997). Our analyses-and statistical tests-considered each specific feature in isolation. Given that the properties measured in the present analyses are rather small (typical Cohen's d-values were ∼0.1), it is possible that our sample size was too small to reliably detect these differences. It is also likely that each feature contributes in a weighted fashion to the listener's percept of the speaker's linguistic identity, making analyses of individual features less likely to reliably distinguish between AAE and GAE speech. For example, while Newman and Wu (2011), identified a number of properties used by listeners to identify Asian American speakers, no feature was used by all speakers. Thus, listeners may utilize a mosaic of "separate pieces of individually weak evidence [. . .] to yield a judgment" that has a high probability of being correct (Liberman, 2010, cited in Newman andWu, 2011). Finally, it may be that a fundamental component of navigating a Black/White biracial identity in the U. S. is the maintenance of a subtle (rather than overt) blend of one's dialects (Zwicky, 1997). We offer these possibilities as avenues for future research.</p>
<p>Overall, these results underscore the importance of examining the intersections between social identity and all forms of behavior-social and verbal-especially for biracial individuals who may exhibit different speaking strategies based on salient racial identities. Most importantly, this work emphasizes the need for social psychological and linguistic research to further define their methods to include biracial populations who do not seem to fit within the currently established methods and frameworksframeworks that were constructed originally based on the study of monoracial populations. This is further support that the biracial population contradicts the traditional social construction of race but extends that contradiction to language for the first time. With the mixed-race population estimated to be over 25% of the total population within the next 40 years (with biracial Black/White individuals being the most commonly reported, U.S. Census, 2010), it is time to change our methods and frameworks to be more in line with our changing demographic.</p>
<p>Frontiers in Psychology | www.frontiersin.org</p>
<p>April 2015 | Volume 6 | Article 457</p>
<p>Four audio clips were excluded from analysis in Study 1b because there was not a 10-20 s clip available that was free of race-related content, resulting in a final sample of 40 thin slice audio clips (11 Black-primed females, 12 White-primed females, 10 Black-primed males, seven White-primed males).Frontiers in Psychology | www.frontiersin.org</p>
<p>Although /r/-deletion is common in the varieties of English spoken in New England, we included it in our analysis since it is less common among younger speakers and speakers with more education(Irwin and Nagy, 2007), demographics that described the majority of our biracial participants. Further, /l/-deletion is uncommon in New England, making it potentially diagnostic of African American English (AAE).</p>
<p>This work was supported by a NSF Graduate Research Fellowship, a Ford Foundation Dissertation Fellowship, a Tufts Graduate Research Award, a SPSSI Clara Mayo Grant, and a University of Chicago Provost's Postdoctoral Scholarship awarded to Sarah Gaither. This project was supported in part by a grant from the Tufts University Faculty Research Awards Committee. We would like to thank our research assistants for assistance on this project and Ben Munson for feedback on earlier drafts of this manuscript.</p>
<p>SG and KM were responsible for the original research question and design. AG and CG were responsible for designing and implementing linguistic analyses. SG and AG completed all data analysis with guidance from KM and CG All authors agreed to be accountable for all aspects of this work and ensured its accuracy and integrity. All authors also significantly contributed to the writing and final approval of this manuscript.</p>
<p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f395357142"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:46+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Pollen exposure weakens the immunity against certain seasonal respiratory viruses by diminishing the antiviral interferon response. Here we investigate whether the same applies to the pandemic severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which is sensitive to antiviral interferons, if infection waves coincide with high airborne pollen concentrations. Our original hypothesis was that more airborne pollen would lead to increases in infection rates. To examine this, we performed a crosssectional and longitudinal data analysis on SARS-CoV-2 infection, airborne pollen, and meteorological factors. Our dataset is the most comprehensive, largest possible worldwide from 130 stations, across 31 countries and five continents. To explicitly investigate the effects of social contact, we additionally considered population density of each study area, as well as lockdown effects, in all possible combinations: without any lockdown, with mixed lockdown-no lockdown regime, and under complete lockdown. We found that airborne pollen, sometimes in synergy with humidity and temperature, explained, on average, 44% of the infection rate variability. Infection rates increased after higher pollen concentrations most frequently during the four previous days. Without lockdown, an increase of pollen abundance by 100 pollen/m 3 resulted in a 4% average increase of infection rates. Lockdown halved infection rates under similar pollen concentrations. As there can be no preventive measures against airborne pollen exposure, we suggest wide dissemination of pollen-virus coexposure dire effect information to encourage high-risk individuals to wear particle filter masks during high springtime pollen concentrations. COVID-19 | pollen | viral infection | aerobiology P rogress of COVID-19 is presumed to be often asymptomatic or associated with only mild to moderate symptoms, mainly fever and dry cough (1). However, in susceptible individuals, such as elderly persons with metabolic, cardiovascular, and/or pulmonary comorbidities (2), COVID-19 can exacerbate to severe pneumonia requiring oxygen supplementation and intensive care treatment. COVID-19-associated deaths are mainly due to severe acute respiratory syndrome (SARS), cytokine storm (3)(4)(5), or disseminated coagulopathy leading to multiorgan failure. According to World Health Organization (WHO) estimates, the overall case fatality rate is 3.4% (6,7).</p>
<p>SARS coronavirus 2 (SARS-CoV-2), the causative of COVID-19, is a novel member of the Betacoronaviridae family with presumed zoonotic origin (8). It is a positive-stranded RNA virus with a genome size of ∼30 kb (9). SARS-CoV, the agent of the SARS epidemic of 2002 and its closest related sibling, is highly susceptible to antiviral interferons (IFNs) and has developed immune suppression mechanisms on the basis of antagonizing host cell IFNs. The accessory proteins encoded by the genes ORF3b, ORF6, M, and N of SARS-CoV-2 are highly homologous to their SARS-CoV and Middle East respiratory syndrome counterparts, which are type I IFN antagonists (10). Another set of accessory proteins, encoded by the genes E, ORF3a, and ORF8b and common to both SARS-CoV and SARS-CoV-2, are activators of the NLRP3 inflammasome (11,12) and have up to 95% interstrain amino acid sequence identity (9). Excessive Significance Coexposure to airborne pollen enhances susceptibility to respiratory viral infections, regardless of the allergy status. We hypothesized this could be also true for SARS-CoV-2 infections. To investigate this, we tested for relationships between SARS-CoV-2 infection rates and pollen concentrations, along with humidity, temperature, population density, and lockdown effects. Our unique dataset derives from 130 sites in 31 countries and across five continents. We found that pollen, sometimes in synergy with humidity and temperature, explained, on average, 44% of the infection rate variability. Lockdown halved infection rates under similar pollen concentrations. As we cannot completely avoid pollen exposure, we suggest wide dissemination of pollen-virus coexposure information to encourage high-risk individuals to wear particle filter masks during high springtime pollen concentrations.</p>
<p>inflammasome activation and subsequent pyroptosis is the underlying mechanism for the IL-1β dominated cytokine storm associated with SARS-CoV mediated multiorgan failure (4,13).</p>
<p>A recent, large cohort study from South Korea reported that asthma exacerbations in school-aged children are associated with coexposure to multiple seasonal environmental factors, that is, ozone, rhinovirus, and tree pollen (14). Another study recently reported that pollen grains of various plant taxa release as yet unidentified compounds that down-modulate the production of antiviral λ-IFNs in respiratory epithelial cells, and provided evidence from human and mouse models that pollen exposure leads to enhanced susceptibility to infection with two different respiratory viruses, human rhinovirus and respiratory syncytial virus (15). Also, some pollen types enhance the release of the IL-1 family cytokines IL-1β, IL-18, and IL-33 from epithelial cells in vitro, indicating a role for pollen in NLRP3 inflammasome activation (16,17). Thus, two mechanisms of the innate immune response, inflammasome activation and antiviral IFN response, appear to be modulated toward the same direction by pollen and SARS-CoV-2.</p>
<p>The first COVID-19 cases were officially reported for European countries at the middle to end of January 2020. On 12 March, the WHO officially announced the onset of a global COVID-19 pandemic, with over 33% of the world´s nations reporting local spreading of the infection. Around the same time, a large-scale warm spell across the bulk of the Northern Hemisphere initiated the first large seasonal peak in tree pollen emissions. The synchronized timing of the spreading of the infection and the higher pollen concentrations, in combination with the recently found potential of pollen to enhance susceptibility for respiratory viruses, prompted us to analyze whether, under certain weather conditions, a positive correlation between SARS-CoV-2 infections and airborne pollen could be observed. We therefore collected airborne pollen data from most pollen monitoring stations operating at that time, from a total of 31 countries and from all inhabited continents, including both the Northern and Southern Hemispheres, and investigated for relationships between daily pollen concentrations and SARS-CoV-2 infection rates, also taking meteorological and sociodemographic factors into account.</p>
<p>Our results reveal that the simultaneous exposure to SARS-CoV-2 (via other infected human carriers) and airborne pollen may, under "favorable" weather conditions, promote viral infection. While it is meaningful to inform the public about this risk, the wording should be extremely well considered to avoid misunderstandings and to not cause panic. On the other hand, wide dissemination of the potential dire effects of virus-pollen coexposure ought to be urgently and clearly communicated: As we cannot avoid airborne pollen exposure, high-risk groups have to be informed to wear particle filter masks during the pollen season, especially in springtime.</p>
<p>To examine the potential effects of pollen-virus coexposure, a large cross-sectional and longitudinal study was set up, based on 248 airborne pollen monitoring sites, from 31 countries in all inhabited continents across the globe (Fig. 1). The initiative started when, during 10 to 14 March 2020, a warm weather episode brought about higher airborne pollen concentrations across the Northern Hemisphere (denoted as larger circles in Fig. 2), which was evident in mainland Europe mainly on 12 March. This coincided with high SARS-CoV-2 infection rates (denoted with darker color circles in Fig. 2) characteristic for the early exponential infection phase.</p>
<p>The median day of onset of COVID-19 exponential phase (for definition, see Materials and Methods) was 13 March 2020 (Fig. 3), which corresponds, on average, to a cumulative pollen concentration of 1,201 grains/m 3 up to 4 d before (daily average: Higher airborne pollen concentrations correlated with increased SARS-CoV-2 infection rates, as evidenced from 31 countries across the globe under study, it was found that the onset date of the exponential phase per region positively and significantly correlated with the cumulative amount of pollen up to 4 d before (P &lt; 0.001, r = 0.25). Those regions mainly with lower pollen concentrations and high human contact because of the carnival events in late February, as well as with humid, colder continental climates (on 20-21 March), were categorized as outliers in Fig. 3.</p>
<p>On a cross-sectional approach, we investigated for differences during the exponential infection phase between the infection rates for all sites of the study, grouped into four categories: low vs. high population density and low vs. high pollen concentrations (Fig. 4). To isolate the genuine pollen effect, we elaborated only intervals for all countries without any lockdown. The mean and median of the infection rates were found to differ between low-and high-pollen sites by ∼0.1 (low population density) and 0.3 (high population density); that is, a more pronounced pollen effect was observed for the high-population density sites. The extreme values revealed an even stronger signal: Regardless of the population density, near-zero infection rates were observed only in regions with low pollen levels. Conversely, the absolute maximum infection rate was reached in the high-population vs. high-pollen case (P &lt; 0.01).</p>
<p>On a longitudinal setup and focusing on the geographically large or climatically diverse countries, which contain the vast majority of regions under study, we investigated for spatial anomalies of the infection rates, which were correlated countrywise with spatial anomalies of pollen concentrations. To eliminate low-level statistical noise, very low pollen concentrations (&lt;50 pollen/m 3 ) and regions sparsely populated (&lt;100 inhabitants/m 2 ) were not included in the analysis. Only the before or no lockdown time intervals were included in the analyses. It was found that the anomaly correlation coefficient was positive for all countries and significantly positive in six out of eight (Fig. 5). The regression slopes show that the infection rate's sensitivity to pollen, on average, is 0.04 per 100 pollen/m 3 (range: 0.03 to 0.25) for the countries with significant correlations. Depending on the region (note the different x axes values in Fig. 5), this corresponds to 6 to 15% of the exceedance of the rate over zero. The R 2 values shown in Fig. 5 (including also nonsignificant relationships) illustrate that 10% of variability in the infection rate is explained by its sensitivity to pollen fluctuations.</p>
<p>The pollen effect was proven strong, sometimes regardless of the population density. Switzerland, as one of the countries with the highest pollen concentrations across the world during the exponential phase of the pandemic, serves as a case study to illustrate the relative importance of the pollen effect, by comparing three cities located close to each other and with comparable climates and population densities, but with different pollen exposure (SI Appendix, Fig. S1).</p>
<p>To test the influence of other cofactors, environmental but also human interaction related, we performed a per-country longitudinal analysis (Fig. 6). Complementing the analysis and results in Fig. 5, ridge regressions were conducted for all 31 countries and 130 regions under investigation. For those countries in which no lockdown had been implemented, or the lockdown had started almost in parallel with the onset of the exponential infection phase (&lt;5 d difference), we could not possibly consider the lockdown variable in the analysis. Despite the significant and negative effect of lockdown in the majority of countries for which we included it as dummy variable (11 out of 14 countries, in the mixed design with no lockdown-lockdown regime), environmental cofactors were still significantly correlated with increases in daily infection rates in 12/14 of cases (P &lt; 0.05) (Fig. 6). Regardless of the exposure conditions, either with or without a lockdown regime (Fig. 6), of the three environmental factors examined here, pollen was significant in 10/21 countries, air temperature in 14/23, and relative humidity in 10/ 23. All significant correlations of infection rates with environmental factors (pollen, temperature, humidity) were, by rule, positive, and those with lockdown and weekend, by rule, negative. The average lag effect of airborne pollen on daily infection rates was 4 d (using backward stepwise removal of independent variables), which is consistent with the cross-sectional analyses described above. Under an early lockdown design (lockdown before or &lt;5 d after the onset of the exponential infection phase), pollen concentrations were still significantly and positively correlated with daily infection rates in 6/14 countries, and, in 5/14 pollen, was the primary factor. Under a mixed lockdown design (full exposure ≥ 5 d, then lockdown), lockdown was significantly and negatively correlated with daily infection rates in 11/14 of cases, in 9/14 as the primary factor. Strikingly, even under an early lockdown, the synergy of environmental factors could explain, on average, 44% of the infection rate variability in 9 out of 14 countries (Fig. 6). It is worth mentioning that, of the remaining countries with no significant relationships with airborne pollen abundances (or with other environmental factors as well), 7 countries exhibited very low pollen concentrations during the examined period, explicitly less than 5% of the averaged total pollen load of all countries. These countries, by rule in the Southern Hemisphere or in colder and humid continental climates (Fig. 6), most frequently did not correlate with any environmental parameter at all.</p>
<p>We further investigated the lockdown effect, longitudinally, among countries, and, cross-sectionally, in association with airborne pollen concentrations. Almost all countries had a lockdown of some type, mostly a partial one. Only nine countries adopted a strict lockdown from the beginning. Lockdown significantly decreased the infection rates as compared to no lockdown (P &lt; 0.001) (Fig. 7A). A significant positive correlation between daily infection rates and daily pollen concentrations was observed under both lockdown and no-lockdown regimes (R 2 = 0.02; P &lt; 0.001). However, the magnitude of the lockdown effect was such that, under comparable amounts of pollen, daily infection rates were reduced to approximately half during lockdown compared to full exposure: The association of infection rates with pollen concentrations was still positive and significant (note the different y axes in Fig. 7B).</p>
<p>Our large-scale retrospective data analysis based on 80 individual time series from 130 regions in 31 countries in all inhabited continents across the globe (8,019 data points) enabled us to reveal a robust and significant positive correlation between SARS-CoV-2 infection rates and airborne pollen concentrations, which was halved under lockdown. We managed to obtain pollen data from the majority of all pollen monitoring stations worldwide that were operative despite considerable spread of COVID-19 infection rates already by that time, resulting in the most comprehensive aerobiological dataset possible to conduct such a study.</p>
<p>In the current pandemic situation, SARS-CoV-2 infection spread is primarily and foremost dependent on person-to-person interaction, which is mirrored by the observed, significant effect of lockdown. The rapid kinetic of infection in the absence of herd immunity is prone to mask any potential effect of environmental cofactors that may exacerbate contact-dependent mechanisms. The example of Switzerland shown in SI Appendix, Fig. S1 highlights the major assumption made in the longitudinal study: The cities should have similar weather conditions and be similar from a sociodemographic standpoint. On the opposite side of this case study, in the United States, these very requirements were not upheld for the five sites tested (distance between them exceeded 2,000 km, some were in maritime and some in strongly continental climate, different states with different strategies regarding lockdown, mean income, and other factors). This lack of homogenous conditions may easily explain the strong scatter in the United States anomaly correlation chart.</p>
<p>The COVID-19 pandemic hit Europe and North America during springtime, when rising air temperatures are associated with increased social and outdoor activities, which, in turn, means increased environmental exposure-to bioaerosols, pollutants, or infected humans. Given the complexity of intertwined environmental, social, and political cofactors, it is anticipated that no clear signal may be observed unless it is tremendously robust. Moreover, environmental exposures, whether climatic factors, air pollutants, or pollen, often exert their effects at the same time, and many of these factors are collinear, which complicates the statistical analysis. Nonetheless, from all the countries that showed a significant correlation of the infection rate with pollen, this correlation was always positive, which suggests that the mechanism reported for pollen exposure on antiviral immunity to rhinovirus (15) could also be influencing innate immunity toward SARS-CoV-2. To verify this statement, we conducted multiple tests to check for bias, including bootstrapping and permutation tests. If, under this statistical noise, we can still see such a signal, we may safely consider the results robust enough, with our concerns being actually about whether we potentially underestimate the magnitude of this effect. Fig. 4. SARS-CoV-2 infection rates are positively correlated with airborne pollen. Mean infection rate in the exponential phase for sites with low (&lt;1,000 inhabitants/km 2 ) and high (≥1,000 inhabitants/km 2 ) population density and for low (&lt;250 pollen/m 3 ) and high (&gt;250 pollen/m 3 ) average pollen concentration during the 2 wk of near-constant infection rate. Only the regions and time intervals with no lockdown were selected.</p>
<p>Infections with endemic coronaviruses (strains OC43, HKU1, 229E, and NL63), as well as other frequent respiratory viruses, such as respiratory syncytial virus and influenza A, peak in winter or early spring; a general negative trend of air temperature on these infections has been evidenced (18). Therefore, it is likely that parameters like air temperature act, in the long term, as confounding factors for the short-term positive effect of pollen on infection rates. Also, while the anomaly correlation between airborne pollen and infection rates was significantly positive, the effect size was small, indicating that pollen is only one of a number of environmental factors influencing SARS-CoV-2 infection. However, if one considers that the study was conducted marginally in the start of the pollen season in most regions, this statement may be under dispute. Extending this study deeper into the 2020 pollen season would not offer clearer information, as we would have an even wider variety of data, with ceased lockdown measures and opening borders and tourist activities taking place almost up to the end of 2020.</p>
<p>When checking for additional environmental cofactors, including human interaction indicators, an average of 4 d of lag effect was found in increases in pollen concentrations associated with increases in infection rates. This was connected with the temperature and/or humidity lag of the same or the previous day. A 4-d lag effect of pollen is in agreement with the proposed physiological mechanism of action, an interference of pollen with the innate antiviral immune system. A study based on infection data from Singapore and the Chinese provinces of Tianjin and Hubei estimated an incubation time for COVID-19 of between 4 and 5 d (19,20), which is much shorter than original estimates (2) but close to our results. It is also in agreement with a hypothesis of environmental exposure factors acting by reducing the incubation period. Unfortunately, this assumption could not be supported by similar pollen data from China, as aerobiological monitoring there is not yet well established.</p>
<p>Respiratory and olfactory epithelium has been shown to express the viral entry receptors for SARS-CoV-2, ACE-2, and TMPRSS2 (21,22), which makes the nasal cavity a potential early virus reservoir and stresses its importance in innate antiviral defense (23,24). Since the upper airways are also the entry site for pollen grains, the previously shown immunosuppressive effect of pollen on respiratory epithelia (15) could influence the susceptibility to SARS-CoV-2 infection as well. Pollen grains act on the very site of virus entry, the nasal epithelium, by inhibiting antiviral λ-IFN responses (15). Early treatment with IFN-λ has recently been discussed as a first-line therapeutic option to prevent COVID-19-associated cytokine storm (25)(26)(27). This highlights the conclusiveness of our primary hypothesis, which is supported by the epidemiological results reported here.</p>
<p>The observed correlation of airborne pollen with infections did not depend on the allergenic nature of the pollen types present in the air during the study period. Although we analyzed the entire biodiversity spectrum of pollen taxa (SI Appendix, Fig. S2), when stratifying pollen by "allergenic" and "total" pollen, both showed similar correlations with COVID-19 cases (SI Appendix, Fig. S3). This agrees with our previous findings on immune modulatory effects of pollen, for example, inhibition of NF-κB (28), MyD88 (29), and antiviral IFNs (15), which do not depend on pollen-derived allergens and are effective in sensitized as well as in nonsensitized individuals (30,31). Thus, although we do not (and could not possibly, to our knowledge) have any information on the allergy status of the COVID-19 cases on which our analysis was based, we assume that the pollen effect is relevant for the entire population. It might, however, be more pronounced in allergics, asthmatics, or chronic rhinosinusitis patients, due to an intrinsically weaker antiviral immune response (32)(33)(34)(35).</p>
<p>Our results</p>
<p>were not yet able to reveal the genuine magnitude of the pollen effect, as the entire springtime pollen peak of the Northern Hemisphere was not fully included, either in terms of abundance or in its whole seasonality. The data acquisition was stopped in early April due to lockdown restraints. An unavoidable major limitation of the longitudinal data analysis is, therefore, the shortness of some of the time series. During that time, only a few studied sites were subjected to the substantially varying pollen load similar to that shown for Switzerland; practically, we had to deal with two subsets of data, one with a mixed design of lockdown-exposure effects and another design of early enough lockdown to almost annihilate the pollen effect in some occasions.</p>
<p>The sites located in the Southern Hemisphere were mostly out of the pollen season during the study period, and most had not reached the exponential infection phase yet. Whether this is in support of our hypothesis cannot be conclusively answered at this stage, but it should become evident by examining the Southern Hemisphere's pollen season in October 2020 and thereafter.</p>
<p>Another limitation is the spatial resolution of the COVID-19 cases, as, for some sites, local COVID-19 data (SI Appendix, Table S1) were not yet available, data had gaps or were registered in a biased way, or the number of cases was too low. In such occasions, we had to access the COVID-19 cases per country, which might not be the best approximation and is reliant on testing strategies within each country. At this early stage of the pandemic, infection rates were based on documentation of numbers of cases presenting to public hospital services and may not have included mild or asymptomatic cases in the community.</p>
<p>To minimize bias of COVID-19 data due to registry lags and errors, we regularly updated our database (last update: 10 May 2020). In most countries, COVID-19 databases were updated within the time frame of a month and then did not change any more. Therefore, we consider our COVID-19 database curated up to 8 April as "reliable." We were, however, unable, at this stage, to correct for every possible confounder, such as underreporting or changes in testing strategy. In our cross-sectional analysis, we controlled for population density, but we are aware that, still, a comparison across all countries is problematic due to the above limitations, and we attempted to overcome this by doing longitudinal analyses per country, and by two different approaches.</p>
<p>We specifically searched the data, per site and per country, for weekly cycles that might arise from gaps in weekend recordings. While recurrent accumulations of COVID-19 cases on some weekdays, mainly on Wednesdays and Thursdays, can be most likely attributed to weather events, we still included "weekend" as a dummy variable in the ridge regression, where it turned out to be less significant than the effects of lockdown and environmental factors, with the exception of three countries.</p>
<p>In the light of the present pandemic situation, our findings should be communicated with caution so as to avoid misunderstandings and panic. It has to be made very clear that 1) the demonstrated correlations suggest that pollen is a modulating factor to the overall progression of the SARS-CoV-2 infection, with the potential to add an extra 10 to 30% to the infection rate (Fig. 5), 2) there is no evidence for airborne pollen grains Humidity, diurnal humidity range (DHR); Three lockdown regimes are examined: no lockdown at all (green color); mixed, firstly with no lockdown and under lockdown later (blue color); and almost exclusively under lockdown (light blue color). All relationships of infection rates were, by rule, positive with pollen, temperature, and relative humidity, and negative with the weekend and lockdown effects); n.a.,: lockdown not included as variable in the ridge regression; #, total pollen during the study period per region &lt; 5% of the averaged total pollen of all examined regions. themselves being carriers of virus particles (36), and 3) without contact, there is no risk of infection.</p>
<p>Of note is that the effect of pollen on reported infection rates was shown to be less pronounced under lockdown regimes. It is also possible that high temperatures in summer would counteract infections to some extent, provided, of course, that social distancing will still be kept. Therefore, the infection-promoting effect of pollen could become evident only during spring, when air temperatures are not high enough yet to limit viral spread, but high concentrations of tree pollen occur. To avoid future waves of high virus transmission under "favorable" combinations of air temperature, humidity, and pollen, we recommend taking stricter protection measures, for example, wearing particle filtering masks during springtime higher pollen concentrations. The installation of reliable, real-time bioaerosol measurement networks and the use of pollen information and forecasting systems should be encouraged.</p>
<p>Looking to the future, it is yet unknown whether other air particles, like fungal spores, or complex interactions with pollen, other meteorological variables, and air pollutants may also play a role. Even though there is published evidence on the effects of various environmental parameters, like nitrogen dioxide (NO 2 ), particulate matter (PM 2.5 ), and ultraviolet radiation (37-41), these usually refer to preliminary results and investigation of only a single factor. If one takes into account the huge effect of ongoing climate change and urbanization on the long-term trends in airborne pollen levels (42,43), as well as emerging viral infections, it is of utmost importance to forecast the associated risk for human health in future pandemics and take appropriate measures to reduce it as much as possible. Coexposure is certainly not the exception but the rule under natural conditions, and, hence, we strongly suggest that modeling and forecasting of ongoing and future pandemics ought to consider the whole "soup" of exposome.</p>
<p>Following the strictest publishing recommendations during the COVID-19 pandemic, we followed the STROBE (Strengthening the Reporting of Observational Studies in Epidemiology) protocol, as follows.</p>
<p>Experimental Design. To test our primary hypothesis that coexposure to airborne pollen enhances the susceptibility to infection with SARS-CoV-2, we performed a large-scale retrospective, cross-sectional and longitudinal data analysis on daily SARS-CoV-2 infection rates and the environmental cofactors of airborne pollen concentrations, air temperature, and relative humidity. Apart from environmental cofactors, estimates of human-to-human interaction were also considered, that is, population density, lockdown dates, Data Sources. Airborne pollen concentrations were obtained via monitoring stations across the globe. So as to have representative sites from different climatic regions, we collected data from a total of 248 aerobiological monitoring stations across the world (Fig. 1), mostly operating Hirst-type volumetric traps, following the standard operating guidelines (44).</p>
<p>The climatic classification of participating countries was performed using the Köppen-Geiger classification (45). Daily COVID-19 cases were retrieved for a total of 80 regions (compiled from 130 sites) in 31 countries and on five continents as reported by the local governmental authorities. Whenever available, we chose the finest possible spatial resolution of COVID-19 data, that is, on the level of state, county, or metropolitan region, to best match the pollen data (SI Appendix, Table S1). Last data access was on 10 May 2020.</p>
<p>Air temperature and relative humidity values were obtained from the open-access European Centre for Medium-Range Weather Forecasts Reanalysis 5 meteorological reanalysis. Data were processed per grid point, with the regional average being extracted by point (pixel) or polygon (shapefile). Data on population density was retrieved from the Demographic Yearbook of the United Nations Statistics Division (UNSD) (https://unstats.un. org/unsd/demographic-social/sconcerns/popsize/). For some metropolitan regions that were not listed by the UNSD, we searched Wikipedia.org. Dates of major national and regional lockdown measures were retrieved by extensive internet searches, starting from Wikipedia.org and following the sources cited therein, such as official announcements made by the local governments.</p>
<p>Data Preprocessing. Of the data initially acquired from the 248 pollen monitoring stations across the globe, we further analyzed data from 130 regions, from different climatic regions, from humid subtropical to arid Mediterranean, temperate, oceanic, and continental climates (SI Appendix, Table S1). The selection of the sites was based on data availability of COVID-19 cases by that time. From the pollen concentrations (pollen grains per cubic meter of air) per plant taxon and station, we calculated daily pollen total concentrations by summing up all pollen on that specific day, but excluding fungal spores. So as to ensure harmonized data across all monitoring stations, when acquiring the pollen data, we clearly and necessarily instructed pollen data providers to provide their data only if they genuinely classify the whole spectrum of the biodiversity in each site. In locations that this was not the case, we did not consider them in the final analysis. So, practically, what we analyzed in this design is truly the whole spectrum of pollen taxa, which, in many sites, accounted for a total number of more than 20 taxa already by 8 April 2020 (depicted in SI Appendix, Fig. S2).</p>
<p>Regarding COVID-19 cases, so as to harmonize the registered cases (especially for the cross-sectional analysis), we used daily exponential infection rates (46), calculated from daily COVID-19 cases as follows:</p>
<p>where DIR is the change in infection rate on day n, ∑ From extracted raw data of temperature and relative humidity, we calculated diurnal temperature ranges (DTR = T max -T min ) and diurnal humidity ranges (DHR = RH max -RH min ). By use of DTR and DHR, we attempted to take into account circadian patterns in pollen production and dispersion and, simultaneously, reduce the number of independent variables and lower multicollinearity.</p>
<p>The date of onset of exponential infection phase was defined per site as per all the following criteria: 1) to avoid nonlocal transmission, adequate number of confirmed coronavirus total cases by this date with a minimum of 100; 2) to avoid registration errors, beyond the above threshold, higher than linear increase for at least three successive days; 3) to avoid artificial "jumps" because of improved registration efficiency and so as to avoid the artificial first high peak of infection rates (as per the kinetics of Eq. 1), selection of the second of the above three successive days with higher than linear increase.</p>
<p>Cross-Sectional Data Analysis. Combining data from all sites, we used general linear models (GLMs) and one-way and factorial ANOVAs and simple linear regressions, to test for overall correlations between SARS-CoV-2 infection rates and airborne pollen, controlling for 1) population density or 2) lockdown effect. To select for appropriate lag effects, especially of pollen, we ran autoregressive models and assessed the cross-correlations of the abovementioned variables, as in ref. 15. To additionally check for the linearity of the relationships, generalized nonlinear models were also tested, in exactly the same context. The selection of the GLMs in the final analysis was based on the residual analysis per region, which determined whether each regional dataset followed the normal distribution assumption. For the visualization of results, box-whisker plots were used for the extremes of pollen concentrations vs. infection rates, grouped by high vs. low population density. Moreover, we applied bag plots using the Tukey median depth (47) (onset date of the exponential phase of the pandemic per region correlated with pollen concentrations of the previous 4 d), paralleled with one-way ANOVA and Pearson correlation to validate the relationship. Last, we used scatterplots with linear regression fits with the respective CIs to express significant slopes and quantify the pollen and lockdown effects.</p>
<p>Methods against Bias. To minimize bias across all levels of the study, we elaborated on the following. Selection bias.</p>
<p>Airborne pollen data. The sites originally selected practically corresponded to all active pollen monitoring stations in the world, as many do not operate at all in winter months. Also, data acquired initially were screened for large data gaps (more than three successive days within the exponential phase of the pandemic spread) and for including the whole spectrum of pollen taxa expected in an average site (harmonization of pollen measurements). The spanning period had to be from as early as possible in 2020 (most frequently, on 1 January 2020) and mostly up to 8 April 2020. Pollen data beyond that date were not acquired, as 1) Hirst-type (or Rotorod-type) measurements are based on manual and laborious methods, and, hence, data are delivered often with a delay of at least 8 d; and 2) because of the lockdown restrictions across the world, often strict, many of the monitoring stations suspended their operation. Obtaining data only from a few would eliminate the harmonization of data and minimize the globality of the study design as well as the possibility to investigate climatic variability. Those sites that did not satisfy any of the above prerequisites were excluded completely. The first screening accounted for a sum of 248 sites. In each one of these sites, we summed up all different pollen types each day to obtain the daily pollen load that could affect the spread of the viral infections. To avoid microclimatic spatial variability and potentially obtain clear signals, when many pollen monitoring sites existed per country, we averaged the data over the region (state, province, canton, or county). This depended also on the data availability of daily COVID-19 cases at this scale. The overview of analyzed datasets is shown in SI Appendix, Table S1.</p>
<p>Data Availability. Daily data of 1) pollen concentrations, 2) SARS-CoV-2 infection rates, 3) air temperature, 4) relative humidity, 5) population density, and 6) lockdown dates have been deposited in Mendeley (DOI: 10.17632/ 6f8y8d9cgw.1) (52).</p>
<p>Downloaded at UNIVERSITAETSBIBLIOTHEK AUGSBURG onNovember 22, 2021</p>
<p>of 10 | PNAS Damialis et al. https://doi.org/10.1073/pnas.2019034118 Higher airborne pollen concentrations correlated with increased SARS-CoV-2 infection rates, as evidenced from 31 countries across the globe Downloaded at UNIVERSITAETSBIBLIOTHEK AUGSBURG on November 22, 2021</p>
<p>of 10 | PNAS Damialis et al. https://doi.org/10.1073/pnas.2019034118 Higher airborne pollen concentrations correlated with increased SARS-CoV-2 infection rates, as evidenced from 31 countries across the globe Downloaded at UNIVERSITAETSBIBLIOTHEK AUGSBURG on November 22, 2021</p>
<p>of 10 | PNAS Damialis et al. https://doi.org/10.1073/pnas.2019034118 Higher airborne pollen concentrations correlated with increased SARS-CoV-2 infection rates, as evidenced from 31 countries across the globe Downloaded at UNIVERSITAETSBIBLIOTHEK AUGSBURG on November 22, 2021</p>
<p>ACKNOWLEDGMENTS. We thank Mr. Luis-Leopold Moelter and Mr. Mehmet Gökkaya for assistance in overall data curation. The study was partly implemented in the frame of the European Cooperation in Science and Technology (EU-COST) program, "New approaches in detection of pathogens and aeroallergens (ADOPT)," Grant CA18226 (EU Framework Program Horizon 2020). D.B. and C.T.-H. were supported by the Helmholtz Climate Initiative (HI-CAM), Mitigation and Adaptation. A.Ch. and D.V. were supported by the Municipality of Thessaloniki, Greece (Directorate for the Management of the Urban Environment, Department of Environment). This research has been partly supported by the European Social Fund (Project 09.3.3-LMT-K-712-01-0066) under grant agreement with the Research Council of Lithuania (LMTLT). The study was also partly conducted within the frame of the project of the European Community European Regional Development Fund (EC ERDF) and PostDoc Latvia (Grant 1.1.1.2/VIAA/2/18/283). M.S. acknowledges the Academy of Finland (Project PS4A, Grant 318194). We thank the Department of Health and Rehabilitation of Vinnytsia Regional Council, Ukraine, for providing the numbers of COVID-19 cases. A.H.A. acknowledges Angel Chaves and the Government of Navarra: Institute of Public and Labor Health of Navarra, within LIFE-IP NAdatpa-CC (LIFE16 IPC/ES/000001). A.P. was supported by a predoctoral grant financed by the Ministry of Education, Culture and Sports of Spain, in the Program for the Promotion of Talent and its Employability (Grant FPU15/01668). B.S. acknowledges the Ministry of Education, Science, and Technological Development of the Republic of Serbia (Grant 451-03-68/2020-14/200358). C.T.H. acknowledges the Christine Kühne-Center for Allergy Research and Education (CK-CARE), and The Initiative and Networking Fund of the Helmholtz Association (Immunology &amp; Inflammation)</p>
<p>. We thank Jan Bumberger, Marcus Karsten, Paul Remmler, Jan C. Simon, and Regina Treudler for data provision and curation from Leipzig, Germany. We thank Claudia Langford Brown and Dana Flanders for statistical advice and scientific discussions. We thank Penelope Jones, Edith Bucher, Reyhan Gumusburun, Haydar Soydaner Karakus, Su Ozgur, and Asli Tetik Vardarli for data curation.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f229944176"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:47+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Online learning has the potential to open doors to education for everyone who has access to the technology required to participate. Or does it? When it comes to social inclusion in online learning, who are the "haves" and who are the "have-nots?" Some online learning practices erect barriers to individuals with disabilities-uncaptioned videos are not accessible to students who are deaf, content presented only within graphic images is not accessible to individuals who are blind, unorganized content cluttered on a page creates barriers to some students with learning disabilities and attention deficits, web pages that require the use of a mouse are inaccessible to those who cannot operate a mouse. This article explores the question, "What online learning practices make social inclusion possible for individuals with disabilities?" The author answers this question with lessons learned from her own teaching experiences as well as those presented in research and practice literature. She also shares overall characteristics of distance learning programs that promote the social inclusion of students with disabilities in their courses. The author points out how making courses welcoming to, accessible to, and usable by individuals with disabilities may promote the social inclusion of other students as well. She recommends further dissemination and future research regarding inclusive practices in online learning.</p>
<p>Online learning opens doors to education for everyone who has access to the technology required to participate. Or does it? When it comes to social inclusion in online learning, who are the "haves" and who are the "have-nots?" In some places, such as many postsecondary campuses worldwide, the availability of information technology (IT) places everyone in the institution on the right side of what has been called the "digital divide." However, even there some faculty and students find themselves on the wrong side of the "second digital divide":</p>
<p>This line separates people who can make full use of today's technological tools, services and resources from those who cannot….People with disabilities who are on the right side of the first digital divide, too often find themselves on the wrong side of the second digital divide. They have technology but do not have full access to all of the benefits it delivers to others. (Burgstahler, 2005, p. 84) Inclusive practices in online learning (otherwise called e-learning or distance learning) that support social inclusion can be informed by five cornerstones for promoting social inclusion: (1) valued recognition, (2) human development, (3) involvement and engagement, (4) proximity, and (5) material well-being (Donnelly &amp; Coakley, 2002). Applying this model to inclusive online learning, valued recognition requires the acknowledgment and respect of individual and group characteristics. Human development requires the encouragement of diverse capabilities, skills, and perspectives and recognition of them as worthwhile. Involvement and engagement requires that students receive the necessary support to be fully engaged in all aspects of a course. Proximity ensures the opportunity for students of all backgrounds and abilities to interact in the shared social space of a course. Material well-being requires that potential students have the resources necessary to fully participate in an online course. Donnelly and Coakley (2002) make a clear distinction between inclusive programming and programming that promotes social inclusion and/or integration. Simply being enrolled in an online learning class does not mean that a student is fully included. Ensuring that all students are fully included requires the instructor to take intentional steps, some summarized in the remainder of this article, that ensure a welcoming and accessible environment for students with a broad range of characteristics, including disabilities. Some online learning practices erect barriers to individuals with disabilities. Uncaptioned videos are not accessible to students who are deaf. Content provided only within a graphic image (without an alternative description in a text-based format) is not accessible to screen readers that are used by individuals who are blind, since this technology can only read aloud content formatted as text. Even text-based content in a document or on a web page can be tedious to access for these students when the headings are not structured because their screen readers can only skim through heading text if it is formatted as a heading. In addition, since a screen reader can skip from link text to link text to determine resources they wish to access, links to online resources that are not descriptive of the resource (e.g., "click here" is routinely used instead of a description of the content they will find if they click on that link) do not help in this process; blind students are required to link to each resource to determine what it is. Unorganized content cluttered on a page creates barriers to some students with attention deficits or learning and other disabilities. Web pages that require the use of a mouse are inaccessible to those who cannot operate a mouse or other product with mouse functionality.</p>
<p>This article explores the question, "What online learning practices make social inclusion possible for individuals with disabilities?" The author shares suggestions presented in the literature as well as lessons learned from her own teaching. The article includes recommendations for practices that promote the social inclusion of students with disabilities in online learning programs as a whole and in an individual course. The author points out how making courses welcoming to, accessible to, and usable by individuals with disabilities benefits oth-ers as well, thus laying the foundation for the social inclusion of all potential students. She also recommends future research and dissemination in the field.</p>
<p>Today, it is possible for assistive technology to allow individuals with almost any types of disabilities to operate computers (Closing the Gap, 2015). These products include screen readers for individuals who are blind or who have reading-related disabilities, alternative keyboards and mice for people who have mobility impairments, and assistive software for students with learning disabilities. Worldwide, many people do not have access to these technologies. However, online courses can erect barriers even to students who have access to computers and the assistive technologies they need (National Council on Disability, 2004). For example, screen reader software with speech synthesis reads aloud text that appears on the screen and, thus, provides access to only the content of online resources that are available in text formats. Therefore, online learning designers and instructors can avoid erecting barriers to students who are blind and have access to text-to-speech technology by providing text alternatives such as &lt;alt&gt; tags to fully describe the content presented in graphic images. Similarly, structured textonly versions of documents in Adobe Portable Document Format (PDF) are accessible to individuals who are blind.</p>
<p>Employing multiple and flexible teaching methods to reach students with a wide range of characteristics fosters the academic and social growth of all students (Gurin, Dey, Hurtado, &amp; Gurin, 2002), including those with disabilities (Silver, Bourke, &amp; Strehorn, 1998). Often mentioned in this regard are teaching practices that include cooperative learning, contextual learning, constructive learning, the provision of organizing tools, multimodal instruction, peer editing, and testing in the same manner as teaching.</p>
<p>"Universal design" (UD)-and similar approaches labeled with other names such as "design for all" or "inclusive design"-has emerged over the last two decades as a framework for describing a proactive, fully inclusive model for all aspects of instruction. UD has a rich history in a wide range of applications. Architects, product designers, engineers, and environmental design specialists at the Center for Universal Design (CUD) established seven principles of UD to provide guidance in designing products and environments to be usable by all people, to the greatest extent possible (CUD, 1997). Researchers and practitioners have applied these principles to specific products, practices, and environments. In all applications of UD to teaching, instructors anticipate the presence of students with diverse abilities and other characteristics, and make design deci-sions that result in learning opportunities available to all of these individuals, rather than focusing only on the average or "typical" student (Burgstahler, 2015a). Thus, universally designed courses are welcoming to, accessible to, and usable by all potential students.</p>
<p>IT is well suited to delivering the multiple presentation options characteristic of UD. In 1995 the author of this article co-taught the first online course offered through the University of Washington (UW) distance learning program. It is described below.</p>
<p>Online instructors and institutions tend to employ an accommodations-only model rather than a proactive model in dealing with accessibility (Barnard-Brak &amp; Sulak, 2010;Kim-Rupnow et al., 2001;Kinash et al., 2004;Seale, 2014a). The accommodation-only approach problematizes individual deficits rather than addressing inequalities that result from the inaccessible design of the course. UD at its best promotes a culture of diversity that celebrates individual differences. Being both proactive (by applying universal design principles) and reactive (by being ready to provide accommodations to individual students when needed) is the ideal when it comes to social inclusion in the online world.</p>
<p>Accessibility has been addressed in general standards for high quality online learning. For example, the International Association for K-12 Online Learning (2011) published standards for quality online courses that include accessible design recommendations for both technology and learning activities. In addition, the Quality Matters Rubric for high quality e-learning courses includes accessibility and usability as the eighth benchmark and recommends that this benchmark be applied to the other seven-course overview and introduction, learning objectives (competencies), assessment and measurement, instructional materials, course activities and learning interaction and engagement, course technology, and learner support (Quality Matters, n.d.). With respect to accessibility, many online learning guidelines point to the work of the World Wide Web Consortium (W3C). W3C is the organization that develops and maintains protocols to ensure interoperability of the web world-wide. It has always been committed to UD. According to Tim Berners-Lee, the inventor of the web, "The power of the Web is in its universality. Access by everyone regardless of disability is an essential aspect" (Berners-Lee, n.d.). Consistent with its vision of a fully inclusive environment, in 1997 W3C introduced a Web Accessibility Initiative (WAI) to develop guidelines for the accessible design of websites. The WAI recognizes that web accessibility also benefits people without disabilities. For example, a key principle of web accessibility is designing websites and software that are flexible to meet different user needs, preferences, and situations. This flexibility also benefits people without disabilities in certain situations, such as people using a slow Internet connection, people with "temporary disabilities" such as a broken arm, and people with changing abilities due to aging. (WAI, n.d.-c, What is Web Accessibility section)</p>
<p>In 1999, the Web Content Accessibility Guidelines 1.0 (WCAG 1.0), with input from a wide variety of stakeholders worldwide, were published as a W3C recommendation (2003). Now WCAG 2.0 is widely regarded as the current international standard for web accessibility. The WAI guidelines make it possible to objectively measure whether web pages are accessible, and many software tools have been developed for checking or validating content for accessibility. WCAG 2.0 includes recommendations for making web content accessible to people with a wide range of disabilities that include blindness and low vision, deafness and hearing loss, learning disabilities, cognitive limitations, limited movement, speech difficulties, photosensitivity, and combinations of these.</p>
<p>There are many ways to justify making social inclusion of students with disabilities an important issue for online learning program administrators to address. They include: (1) many people consider it unethical to bar some eligible participants from program access; (2) applying accessible design principles is a best practice for all students;</p>
<p>(3) costly redesign may be required when a student with a disability enrolls in an inaccessible course; and (4) legislation in some countries mandates that programs be accessible to qualified people with disabilities. Even the Convention on the Rights of Persons with Disabilities of the United Nations ( 2006) states as a purpose to ensure that people with disabilities have access, on an equal basis with others, to information and communications, including information and communications technologies and systems. How UD can be integrated into the practices of online learning programs as a whole is not widely addressed in the literature. However a set of guidelines for distance learning programs was created as a product of a study conducted by the DO-IT Center at the University of Washington in Seattle (Burgstahler, Corrigan, &amp; McCarter, 2005) and disseminated through DO-IT's Center for Universal Design in Education (DO- IT, n.d.-a).</p>
<p>The exploratory study addressed the research question: What are program-level policies and practices re-lated to delivering online courses that are fully accessible to students with disabilities? Building on lessons learned in early work in this area (Burgstahler, 2002;Burgstahler, Corrigan, &amp; McCarter, 2004), a draft of an initial list of Distance Learning Program Accessibility Indicators (DLP Accessibility Indicators) was created. It was designed to be used as a checklist of programmatic characteristics that can ultimately lead to more inclusive courses in any online learning program. The study engaged online learning programs at institutions whose disabled student service directors were part of projects funded by the United States Department of Education (grant #P333A020044 and #P333A990042) and directed by the DO-IT Center. These projects focused on training faculty and staff at postsecondary institutions to more effectively include students with disabilities in their courses and service offerings. Of the twenty-three schools initially considered for the distance learning project, eighteen had online learning programs that offered courses at a distance and in multiple academic areas. Online learning administrators of two of these eighteen schools declined to participate in the study, resulting in an 89% participation rate.</p>
<p>A wide range of institutional characteristics was represented in the sixteen participating schools-large and small schools; two-year (5) and four-year institutions ( 11 The DLP Accessibility Indicators were refined through formative feedback from participants in an iterative process that resulted in the list shared in the paragraphs that follow. (Burgstahler, 2006(Burgstahler, , p. 86, 2012, p. 3), p. 3). It is organized by relevant stakeholder group.</p>
<p>Distance learning programs committed to accessibility assure that students and potential students know of the programs' commitment to accessible design, how to report inaccessible design features they discover, how to request accommodations, and how to obtain alternate formats of printed materials; the distance learning home page and all online and other course materials of distance learning courses are accessible to individuals with disabilities.</p>
<p> Accessibility Indicator 10: A system is in place to monitor the accessibility of courses, and, on the basis of this evaluation, the program takes actions to improve the accessibility of specific courses and to update information and training given to potential students, students, course designers, and instructors.</p>
<p>An average of only 3.3 (33%) of the ten Indicators were already implemented to some degree at participating schools as the project began. These findings are consistent with literature that concludes that students with disabilities are rarely considered in the design of distance learning courses (Kinash et al., 2004). At the beginning of this study the sixteen participating schools had implemented a total of forty-eight Indicators, at least partially, representing an average of 3 per school; by the end of the study, they had implemented or partially implemented a total of sixty-six Indicators, an average of 4.1 per school. In addition, some participants took steps that did not represent enough improvements to change an Indicator from "no" to "some" or "yes." It should be noted that changes made at three schools accounted for 14 (78%) of the changes overall.</p>
<p>The idea of accessibility, once understood, was enthusiastically received by most of the distance learning staff engaged in the study, but change was slow. These findings are consistent with literature that has for many years concluded that systemic change is often a slow process (Bruce &amp; Wyman, 1998;Guy, Reiff, &amp; Oliver, 1998). Reports from participants suggest increases in awareness, interest, and skills that may lead to ongoing, systemic changes in the distance learning programs they represented. In many cases, project engagement opened or increased communications between staff from disability services, distance learning programs, and computing services. Lack of time to address accessibility issues and the need to work with other staff were the most commonly reported reasons for not implementing changes. More research is needed to study how online learning programs can employ practices that ensure the social inclusion of students and instructors with disabilities in all course offerings.</p>
<p>Many e-learning courses unintentionally erect access barriers that can have a negative effect on the social inclusion of students with disabilities (Burgstahler, 2002(Burgstahler, , 2006(Burgstahler, , 2007(Burgstahler, , 2015b;;Coombs, 2010;Fichten et al., 2009;Keeler &amp; Horney, 2007;Kim-Rupnow, Dowrick, &amp; Burke, 2001;National Council on Disability, 2004;Thomson, Fichten, Havel, Budd, &amp; Asuncion, 2015). Inaccessible features of these courses that students with disabilities report include uncaptioned videos, disorganized content and presentations, and PDF files and other course documents that cannot be read by screen readers (Gladhart, 2010). In one study, close to 70% of students with disabilities had not disclosed their disabilities to their online instructors (Roberts, Crittenden, &amp; Crittenden, 2011). Almost half of the respondents said that they perceived their disabilities to have a negative impact on their ability to succeed in an online course. In another study female students with learning disabilities who enrolled in online courses reported that the learning environments of these courses were less supportive and less satisfactory than females who did not have learning disabilities (Heiman, 2008). Some designers are unaware of accessibility issues; some are aware but place a very low priority on employing accessible practices; others consider the market for accessible courses to be too small to address. One study concluded that People with disabilities want to use the same products that everyone else uses. Implementation of universal design satisfies this desire of people with disabilities, while also providing more cost-effective products for all users. While it is impossible to satisfy the needs of all users, products and services that come closer to accommodating a variety of physical and cognitive differences will benefit both users and companies. (National Council on Disability, 2004, p. 20) Many strategies for making online learning accessible to students with disabilities are reported in the literature (e.g., Burgstahler, 2015b;Coombs, 2010;Fichten et al., 2009;Keeler &amp; Horney, 2007;Pearson &amp; Koppi, 2006;Rangin, 2011;Savidis &amp; Stephanidis, 2005;Seale, 2014a). For example, to get started in designing an accessible online course, DO-IT (n.d.-b, p. 1) has suggested that first steps include:</p>
<p>Online learning researchers and practitioners offer these questions to be addressed by online instructors (Thomson, Fichten, Havel, Budd, &amp; Asuncion, 2015, pp. 282-283):</p>
<p>Applying UD reduces the need for accommodations for students with disabilities. For example, captioning videos to be used in an online course means that students who are deaf will not require an accommodation to access the content. Captions may benefit other students as well. Through captions, students can see the spelling of words spoken in the presentation and search through the caption text for specific topics. Second language learners report that captions increase their attention, improve processing of vocabulary, and reinforce previous knowledge (Winke, Gass, &amp; Sydorenko, 2010). Several studies suggest the positive effects of captioning on recall and retention (Danan, 2004). Some evidence suggests that simultaneous text presentation along with audio can aid native and advanced nonnative speakers of English with word learning under certain conditions, as assessed by both explicit and implicit memory tests (Bird &amp; Williams, 2002). Such findings align with UD principles that recommend multimodal instruction. Although empirical research and anecdotal reports suggest the beneficial effect of captions, more data needs to be systematically collected to determine specific long-term benefits for students with various characteristics.</p>
<p>Many researchers consider involvement of the student critical in designing online courses, but they differ in their views regarding how best to involve them and the level to which people with disabilities are routinely involved in the testing. Design methods that measure aspects of the social inclusion of students with a wide variety of characteristics hold promise for exploring the efficacy of UD with respect to online learning practices (Emiliani, 2009;Friedman, Kahn, Borning, &amp; Huldtgren, 2013). As summarized by Jane Seale in the United Kingdom:</p>
<p>We need new methodological approaches to "liberate" disabled students' voices; methods that offer us opportunities for critical self-reflection but also enable a dialogical relationship to be established with disabled students in which they are genuinely heard. (Seale, 2014b, p. 192) Seale has explored complex interactions between students and technologies in online learning using a participatory design approach, where students are engaged in all steps of the research (e.g., Bjerknes &amp; Bratteteig, 1995;Seale, 2014b) and tests are made in real-life contexts and in iterative steps as the online learning design is improved.</p>
<p>Other design approaches that maximize the en-gagement of users include learner-centered design (Nesset &amp; Large, 2004). In addition, value-sensitive design, a relatively new design approach which is grounded in the design of technology that accounts for human values within a cultural context (Friedman et al., 2013), addresses human values that include human welfare, privacy, freedom from bias, trust, autonomy, informed consent, identity, and courtesy. Steps in applying value-sensitive design may include identifying values, technology, and context; determining direct and indirect stakeholders; identifying potential benefits and harms for each stakeholder group; mapping benefits and harms onto corresponding values; identifying value conflicts; and integrating value considerations into the structure of the organization (Friedman et al., 2013).</p>
<p>The term usability is used to refer to the iterative testing and feedback process wherein users are observed as they interact with the product features. Usability issues addressed include ease of use, simplicity of learning, efficiency in performing tasks and addressing errors, memorability, and user satisfaction for all users (Nielson, 2012). The usability process is often employed multiple times during phases of product development in order to make the developing product more efficient and practical for customers. Usability testing practices hold promise for studying design practices that employ UD and thus maximize social inclusion in online courses when researchers engage participants with a broad range of abilities and disabilities in the usability tests (e.g., Horton, 2005;Schneiderman, 1999).</p>
<p>An example of a world wide effort that promotes the universal design of technology is the Global Public Inclusive Infrastructure (GPII), a project of Raising the Floor (2011). The purpose of the GPII is not to create new assistive technologies or services, but rather to create an infrastructure that makes their development and use easier, less expensive, and more effective. GPII leaders provide the following analogy:</p>
<p>Like building a road system does not provide transportation but greatly enhances the ability of car companies and others to do so-and provides an infrastructure that car companies themselves cannot do. The Internet is the infrastructure for general information and commerce. The GPII enhancements to the Internet would provide the infrastructure to enable the Internet to be truly inclusive for the first time. (Raising the Floor,n.d.,p. 1) The goal of GPII is to eliminate barriers to access and use of the Internet that are related to disability, literacy, technical expertise, aging, or financial resources. As countries build their broadband infrastructures to reach everyone, GPII leaders work to ensure that "everyone" includes people with a wide range of characteristics that include disability.</p>
<p>In spite of efforts by researchers and practitioners to promote universal/accessible design of online learning and the availability of guidelines and standards for the accessible design of technology and teaching strategies, evidence of widespread practice of the inclusive design of online courses does not exist. Besides general issues related to difficulties in making people aware of changes needed and integrating changes into existing practices, reasons for this situation may include that many content specialists who are charged with developing online courses have little guidance in creating effective online learning and little if any background in pedagogy and effective instructional design, including inclusive design practices. Even those charged with supporting the design of online courses may not have knowledge of strategies for reaching a broad audience and of IT accessibility issues. Therefore, few exemplar courses are available to faculty members and to those in course design and IT support roles. Based on interactions with individuals in these roles, the author of this article believes that few of them have learned of accessible/universal design practices in their own training process. In order for widespread adoption, there is a need to increase resources for online learning designers, faculty, IT support staff, and IT developers regarding legal requirements to offer accessible online courses, guidelines and standards available, and examples of successful practices. Further research is also needed to document the efficacy of specific universal design strategies overall and specifically for students with various types of disabilities.</p>
<p>The application of UD to online instruction holds promise for addressing the needs of a worldwide student body that is increasingly diverse with respect to race, ethnicity, culture, native language, age, learning style, background knowledge, gender, disability, and other characteristics. UD and similar terminology have emerged to describe approaches to inclusive design that has the potential to support social inclusion. In these approaches, instructors and course designers consider the needs of students with a broad range of characteristics as they develop flexible strategies that make instruction welcoming to, accessible to, usable by all students. Employing a UD process goes beyond ensuring accessibility for individuals with disabilities to address usability issues such as ease of use, efficiency, memorability, and user satisfaction for all users. Improving access and usability for people with disabilities also improves usability for others, thus creating a platform for the social inclusion of all students. It can be argued that it is simply good business practice for online course providers to avoid excluding large populations of consumers from effectively engaging in their courses.</p>
<p> Perceivable-Information and user interface components must be presentable to users in ways they can perceive.  Operable-User interface components and navigation must be operable.  Understandable-Information and the operation of user interface components must be understandable.  Robust-Content must be robust enough that it can be interpreted reliably by a wide variety of user agents, including assistive technologies. 4.1 Compatible. Maximize compatibility with current and future user agents, including assistive technologies. WAI guidelines are updated regularly. They are general enough that they stand the test of time, applying to new technologies as they are developed. In addition to WCAG, individual countries have developed standards for web accessibility (e.g., the British Standard BS 8878; British Standards Institute, 2010).</p>
<p> DLP Accessibility Indicator 4: A statement about how people can obtain alternate formats of printed materials is included in publications.  DLP Accessibility Indicator 5: The online and other course materials of distance learning courses are accessible to individuals with disabilities.</p>
<p>This article is based on work supported by the National Science Foundation (grant number CNS-1042260 and number 1550477). Any opinions, findings, and conclusions or recommendations are those of the author and do not necessarily reflect the policy or views of the U.S. government, and you should not assume its endorsement.</p>
<p>The author declares no conflict of interests.</p>
</text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f343446413"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T12:50+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>With the advent of the European Commission's Copernicus two-satellite Sentinel-1 constellation, operated by the European Space Agency (ESA), a massive volume of high-quality Cband Synthetic Aperture Radar (SAR) observations with moderate spatial (2-14m) and temporal resolution (6-12 days) has become freely available [1]. With a 250-km-wide cross-track coverage in the default Interferometric Wide Swath (IWS) mode, Sentinel-1 provides a unique and powerful dataset that has the potential to be used for monitoring surface deformation at spatial scales ranging from a few meters to tens of kilometers. Interferometric Synthetic Aperture Radar (InSAR) is a particularly suitable technique for measuring deformation induced by various geophysical phenomena, including the coseismic [2][3][4], postseismic [5][6][7][8] and interseismic phases of the earthquake deformation cycle [9][10][11][12], volcanic movements [13][14][15], terrain deformation due to geothermal activities [16][17][18] and slow-moving landslides [19,20]. Since the launch of Sentinel-1B in 2016, data are acquired globally with a typical revisit period of 12 days, and every 6 days in Europe [21]. The relatively short revisit time (compared to 35-days of previous ESA SAR satellites) is a significant advance because interferograms spanning a short interval usually maintain better coherence and allow a more accurate estimate of rapid deformation. The short revisit time also leads to a greater number of acquisitions, which is useful for statistical reduction of the noise contribution (e.g. due to atmospheric phase delay) in InSAR time series analyses [22]. The data is particularly important for global monitoring of tectonic and volcanic activities [23]. Over the last five years, numerous earthquakes and volcanic eruptions have already been imaged by Sentinel-1 interferograms, aiding rapid response and resulting in a greater scientific understanding of the events and their geophysical properties [8,[24][25][26].</p>
<p>With slightly different aims, NASA JPL has developed an Advanced Rapid Imaging and Analysis (ARIA) system, which automatically generates SAR-derived data products, primarily from the Sentinel-1 mission. It incorporates an automatic processing chain to generate co-seismic interferograms in response to major earthquakes and recently it has begun to provide standard InSAR displacement products, allowing users to circumvent the use of specialized radar processing software altogether and make InSAR products more accessible for science applications [44]. However, ARIA also does not currently plan to mass produce products over large regions for long time series analysis.</p>
<p>To achieve the high precision coregistration required for TOPS mode interferometry, we use the spectral diversity (SD) technique [49] that estimates a mis-registration offset in azimuth direction, based on inversion of azimuth ramps in interferograms formed from overlaps between bursts of primary and secondary SLC images. To keep a reasonable coherence in the burst overlap interferograms and thus increase reliability of the SD estimate, an existing RSLC is used instead of the primary SLC if its epoch is closer to the epoch being coregistered -this temporally nearest RSLC is recognised as RSLC3. The primary SLC can also serve as RSLC3.</p>
<p>Frame definitions are stored in the table polygs. The table includes the generated frame identifier (the naming convention is explained in Section 3) and geographic coordinates of frame corners, among other metadata. The geographic coordinates are generated either from the set of bursts comprising the frame in the case of IWS products or they are set to cover a particular area of interest in case of SM frames. The bursts are linked to the related frames through a lookup table polygs2bursts. Geodatabase functions are enabled through tables bursts2geom and polygs2geom, for both bursts and frames.</p>
<p>The rapid availability of Sentinel-1 data following acquisition (a few hours), together with the short revisit period for many areas of 6 days, provides a unique opportunity to develop an automatic earthquake response system using the LiCSAR infrastructure. The main objective of this responder is to form co-seismic interferometric pairs in a rapid manner, as well as pre-and postseismic interferograms, and to make these data widely and freely available to the community. We anticipate that these products have applications for the scientific understanding of events as well as for operational crisis management and disaster mitigation 51,52].</p>
<p>The frames remain in their active status for a pre-defined period to allow for rapid production of post-seismic interferograms (a post-seismic InSAR response). We scale this time period depending on the magnitude of the event and the number of expected Sentinel-1 images in that location, see Table 1. We also plan to extend the system to volcanic activity rapid response.</p>
<p>The LiCSAR system is also producing Sentinel-1 frame interferograms globally over 80% of the 1331 on-land volcanoes considered active during the Holocene [57]. Frames covering areas with volcanic activity are being updated three times per week and the list of these frames is updated based on new and ongoing volcanic activities reported by the Smithsonian Institution [57]. Figure 7 shows the global distribution of the active volcanoes and the number of interferograms for each of them. We develop routines to augment these frames into a 'live' status, i.e. to have interferograms generated as soon as a new acquisition appears at some of our source data stores.</p>
<p>Interferograms related to recent seismic events are generated by the LiCSAR Earthquake Responder processes. Figure 7 includes locations of earthquakes where LiCSAR generated coseismic frame interferograms. We are currently testing an updated version of the Earthquake Responder that runs through earthquake-related update routines every 30 minutes. The frequent updates of the processing status of the frames ensure their temporary 'live' status until a specified time after the earthquake (in order to also generate several post-seismic interferograms). Global Active Faults data are from [58].</p>
<p>Figure 8 shows the LiCSAR system file structure hierarchy and naming convention. The blue parts represent the current state and the gray areas show the capabilities which will be available in the future. Starting from the top level, the LiCSAR products are categorised into 175 folders that correspond to the 175 orbital tracks per orbital cycle (relative orbits) of the Sentinel-1 satellites.</p>
<p>Currently, a special folder EQ contains geocoded outputs of the LiCSAR Earthquake Responder categorised according to the USGS ComCat code for each earthquake.</p>
<p>The naming convention of frame identifiers (used also as folder names for frame related data) has a structure: OOOP_AAAAA_BBBBBB, where OOO denotes the number of the relative orbit, P identifies orbital pass -either descending (D) or ascending (A), AAAAA is a colatitude identifier, i.e. a complementary angle of the latitude of the frame centre (multiplied by 100), and BBBBBB identifies the number of included bursts (three pairs of digits corresponding to number of bursts in each of three Sentinel-1 IWS swaths).</p>
<p>Inside the frame directory, the generated InSAR products are located in the interferograms subfolder. The name of each interferometric pair shows the date of acquisition epochs used for that pair. The basic interferometric products reside in each interferometric pair folder as:</p>
<p>-yyyymmdd_yyyymmdd.geo.cc.tif: coherence image (GeoTiFF) of the interferometric pair. The values vary between 1-255 where 1 refers to the lowest coherence values and 255 indicates the highest values of coherence. It is in uint8 format with 0 as the 'no data' value, -yyyymmdd_yyyymmdd.geo.diff_pha.tif: wrapped-phase spatially filtered differential interferogram image (GeoTiFF). The values vary within the range of -π to π radians. The phase values pertain to the the satellite LOS, thus the signal can be interpreted as motion away from the satellite if the observed phase difference is positive. The phase values are saved in the file in a float32 precision with 0 as 'no data' value, -yyyymmdd_yyyymmdd.geo.diff_unfiltered_pha.tif: wrapped-phase interferogram image (GeoTiFF). The only difference between this and the previous image is that the phases are not spatially filtered.</p>
<p>-yyyymmdd_yyyymmdd.geo.unw.tif: unwrapped phase image in radians (GeoTiFF). Keeping the same rule as the wrapped phase images, the values are in the satellite LOS direction, i.e. positive values mean a range increase (i.e. motion away from from the satellite), while negative values mean a range decrease (i.e. motion towards the satellite) perhaps caused by uplift. The format of the file is float32 with zero values as 'no data' often related to pixels which are masked due to low coherence.</p>
<p>In addition to the interferograms, georeferenced MLI images for each processed epoch are stored in the epochs folder in directories corresponding to the acquisition date in the format yyyymmdd. The intensity images are produced by space-domain averaging of the SLC images with 4 and 20 as the number of azimuth and range looks respectively. MLI images are generated without a radiometric calibration and only for a co-polarised channel (VV).</p>
<p>Additional files are stored in the metadata folder: -OOOP_AAAAA_BBBBBB.geo.{E,N,U}.tif: these files (GeoTiFFs)contain the east (E), north (N) and upward (U) components of the LOS unit vector for each pixel. They are calculated from the SAR look-vector elevation and orientation angle of each pixel, based on the SAR imaging and DEM geometries with the local topography taken into account. The unit vector information can be used, for example, to project E-N-U modeling results or 3-D geodetic observations like GNSS data onto the LOS vector in order to be able to compare them to the LiCSAR results [43],</p>
<p>-OOOP_AAAAA_BBBBBB.geo.hgt.tif: this image (GeoTiFF) contains the height values extracted from the DEM used in processing, baselines: a text file containing the temporal and spatial baselines of each acquisition with respect to the master image, metadata.txt: a text file containing various other information related to the frame (e.g. primary epoch and acquisition time for its center location, etc.) In the near future the time-series and velocity folders will contain outputs stemming from multitemporal InSAR processoring based on the LiCSBAS approach [61]. The main objective of this module (currently still under development) is to generate average displacement velocity maps and time series of displacements for all processed LiCSAR frames. The velocity and time</p>
<p>Since the initial development of the LiCSAR system, numerous research projects have been carried out to study deformation of the Earth's crust using LiCSAR products. Typical deformation sources include magma chambers, dike intrusions, and faults that slip during different phases of the earthquake cycle. Below, we highlight some case studies where LiCSAR has contributed to the monitoring of tectonic activity and volcanic events.</p>
<p>Provision of Sentinel-1 InSAR products produced by the LiCSAR processor with a wide spatial coverage increases the potential for large-scale InSAR studies of tectonic processes. Over the past few years, the LiCSAR system has proved to be a powerful tool in various tectonic applications, leading to improved understanding of crustal deformation processes.</p>
<p>The LiCSAR system is currently producing Sentinel-1 interferograms for all the frames covering seisimcally active portions of the Alpine-Himalayan belt (9,000 x 2,000 km), where many of the planet's most deadly earthquakes occur. The LiCSAR Earthquake Responder is actively generating interferometric products for almost every major shallow earthquake affecting continental regions on Earth.</p>
<p>The global coverage of LiCSAR also makes it possible to derive high-resolution, precise and global estimates of tectonic strain rates based on a time series inversion. For example, the LOS velocity for the frame shown in Fig. 11a has been used to derive strain rates for Anatolia [64].</p>
<p>The total number of interferograms calculated for volcanoes is greater than 240,000 (as of December 2019). The objectives of volcano processing are to provide a global InSAR dataset to the scientific community and to support the monitoring of ground unrest on any active volcanoes. Because of the large number of products, it becomes impossible to visually check all of them. Therefore, the COMET team has developed several machine learning approaches for automatically detecting ground deformation signals based on blind signal separation methods [25,65] and deep learning techniques [66][67][68]. The latter algorithms can detect large ground deformation signals in wrapped interferograms, whereas the former approach can detect the onset of slow ground deformation or subtle changes in rate of any background deformation in InSAR time series.</p>
<p>Interferograms of a short temporal baseline in the LiCSAR database can be used to detect strong volcanic deformation related to shallow magma intrusions, such as the March 2017 intrusion at Cerro Azul (Galapagos) and the January 2017 dyke intrusion at Erta Ale (Ethiopia) (Fig 12). The interferogram at Cerro Azul shows two lobes of displacements: ~11 cm of subsidence in the North and ~14 cm of uplift in the South (Fig 12a).</p>
<p>In addition, coherence products can be used to map the emplacement of new volcanic products during an eruption (Fig. 13). The loss of coherence (black) in the central area is an indication of the fresh lava flow emplaced during the 2017 Erta Ale eruption. The production of time series of coherence is useful for tracking flow propagation (e.g. lava initially flows to the NE before flowing to the SW on June 2017) and to derive cumulative flow area [69].</p>
<p>LiCSAR unwrapped interferograms can be used to produce time series of ground deformation to track the long-term dynamics of magmatic systems. For example, InSAR time series from the Campi Flegrei caldera (Italy) reveal a persistent uplift signal of about 5.7 cm/yr for the period 2015-2019, consistent with GPS results [61] (Fig. 14). We also observe variations in the associated rates of displacement with period of deceleration (late 2016) and period of acceleration (early 2018).</p>
<p>InSAR time series derived from LiCSAR products have already been successfully used to better understanding the dynamics of magmatic systems during the 2017 eruptions at Mt. Agung (Indonesia) [26] and Erta Ale (Ethiopia) [69].</p>
<p>Whilst the focus of this paper is on tectonic and volcanic applications, other uses of LiCSAR data could include hydrosphere, cryosphere, and mass movement studies. For example, temporal decorrelation of glacier surfaces leads to a loss of coherence that can prominently reveal the extent and movement of glaciers [70], which is particularly useful for glaciers covered in debris that are difficult to classify using optical data. LiCSAR coverage across the Alpine-Himalayan belt and in parts of Alaska will facilitate the investigation of glaciers using coherence data. Another potential application of LiCSAR data is to map earthquake-induced landslides. SAR data can be collected through cloud cover, which means data availability is often much quicker than optical acquisitions. Loss of coherence following ground disruption is therefore a potentially useful tool to produce timely regional landslide distribution maps [71].</p>
<p>Here we have introduced the LiCSAR system for observing tectonic and volcanic terrain deformations using Sentinel-1 interferometric processing. The purpose of LiCSAR is to generate and disseminate open interferometric products in formats that are ready for direct use by the research community, particularly in the field of geohazards.</p>
<p>The system aims to continuously monitor actively deforming regions and to provide a response to events such as earthquakes or volcanic eruptions. As of May 2020, the system has processed about 88,000 Sentinel-1 acquisitions and generated more than 288,000 interferograms (around 18 TB). Among the 1,507 LiCSAR frames, 470 frames are related to 1,024 volcanoes. Frames over priority tectonic zones are currently being updated to a 'rolling' status. This is now operational for about 150 frames. Frames covering active volcanoes are processed on a short-term basis (three updates per week), with specific processing structures being developed that should allow generation of interferograms over all active volcanoes as soon as Sentinel-1 SLC data are available (a 'live' status). The 'live' status will also be applied temporarily to frames covering recent earthquakes.</p>
<p>The products are provided for download and visualization in the LiCSAR portal (Fig. 15 or https://comet.nerc.ac.uk/COMET-LiCS-portal ). Author Contributions: Writing -Original Draft Preparation, M.L. and Y.M.; Software, M.L., P.G., K.S., R.W., E.H., N.G., D.J. and J.R.W.; Investigation, F.A., YuM., J.R.W. and J.E.; Writing -Review &amp; Editing, J.E., E.H., F.A., YuM., P.G., J.R.W., and C.S.W.; Supervision, T.J.W. and A.H.; Funding Acquisition, T.J.W. and A.H.</p>
<p>This work is supported by The Natural Environment Research Council large grant, "Looking inside the continents from Space" (NE/K010867/1). YuM. is supported by Japan Society for the Promotion of Science Overseas Research Fellowship. J.E. is supported by a Royal Society University Research Fellowship (UF150282). The APC was funded by the University of Leeds. D.J. has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 731070 (EUROVOLC). COMET is the NERC Centre for the Observation and Modelling of Earthquakes, Volcanoes and Tectonics, a partnership between UK Universities and the British Geological Survey.</p>
<p>The authors declare no conflicts of interest.</p>
</text>
</tei>
  <tei>
    <teiHeader>
        <fileDesc id="f83585266"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:11+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text lang="en">
        <p>The Mediterranean diet has been linked to a number of health benefits, including reduced mortality risk and lower incidence of cardiovascular disease. Definitions of the Mediterranean diet vary across some settings, and scores are increasingly being employed to define Mediterranean diet adherence in epidemiological studies. Some components of the Mediterranean diet overlap with other healthy dietary patterns, whereas other aspects are unique to the Mediterranean diet. In this forum article, we asked clinicians and researchers with an interest in the effect of diet on health to describe what constitutes a Mediterranean diet in different geographical settings, and how we can study the health benefits of this dietary pattern.</p>
        <p>Antonia Trichopoulou, (Figure 1)</p>
        <p>In purely descriptive terms, the traditional Mediterranean diet is the dietary pattern prevailing among the people of the olive tree-growing areas of the Mediterranean basin before the mid-1960s, that is, before globalization made its influence on lifestyle, including diet. Key determinants of the traditional Mediterranean diet have been climate, flora and hardship, the latter discouraging import or consumption of expensive, at that time, red meat [1].</p>
        <p>The traditional Mediterranean diet is characterized [2] by high consumption of vegetables, fruits and nuts, legumes, and unprocessed cereals; low consumption of meat and meat products; and low consumption of dairy products (with the exception of the long-preservable cheeses). Alcohol consumption was common in the traditional Mediterranean diet, but generally in moderation and in the form of wine and, as a rule, during meals-in the spirit of the ancient Greek word 'symposium'. Total intake of lipids could be high (around or in excess of 40% of total energy intake, as in Greece), or moderate (around 30% of total energy intake, as in Italy) but, in all instances, the ratio of the beneficial monounsaturated to the non-beneficial saturated lipids is high, because of the high monounsaturated content of the liberally used olive oil. Finally, fish consumption has in the past been a function of the distance from the sea but has been, overall, at a moderate level.</p>
        <p>In a somewhat reductionist approach, the traditional Mediterranean diet can be considered as a mainly, but not dogmatically, exclusive plant-based dietary pattern. Of note, olive oil is a plant product (in fact a fruit juice) and so is wine.</p>
        <p>The traditional Mediterranean diet has entered the medical literature following publications by the legendary Ancel Keys and his colleagues of results from their 'Seven Countries Study', initiated in the late 1950s [3]. An important conclusion of this study, based largely on ecological evidence, was that low content of saturated lipids in the Mediterranean diet could explain the low incidence of coronary heart disease in Mediterranean countries, through the reduction of blood cholesterol, a recognized major risk factor for this disease (the distinction between high (HDL) and low (LDL) density lipoprotein cholesterol was not known at that time). Later work, however, has shown that the traditional Mediterranean diet is not simply, or mainly, a cholesterol-lowering diet, but has a range of beneficial health effects.</p>
        <p>Two developments in the early 1990s have led to an explosion of interest in, and studies of the health effects of, the Mediterranean diet: (1) The recognition that high intake of carbohydrates, particularly simple carbohydrates, may not be beneficial to health because they constrain the levels of the 'good' HDL cholesterol and increase the metabolically undesirable glycemic load. This has shifted interest to innocuous, indeed beneficial, lipids, like those from olive oil [4]. Of note, carbohydrates and lipids are the principal sources of energy intake; at about 10% of total energy intake, proteins contribute less and with limited variability across individuals and populations in economically developed countries.</p>
        <p>(2) The operationalization of adherence (or conformity) to the traditional Mediterranean diet through a simple score, or variations of which, that have been used in a multitude of analytical (individual-based), rather than ecological observational, studies to evaluate the health effects of adherence to this diet [5]. It should be made clear that, in contrast to scores and diet pyramids developed in order to point to 'optimal' diets, the Mediterranean diet score is purely descriptive of the traditional Mediterranean diet. The fact that this diet has considerable beneficial health effects constitutes a 'natural experiment' that investigators try to understand and people benefit from.</p>
        <p>Collectively, these studies have indicated convincing inverse associations with overall mortality [6] and with the incidence of coronary heart disease [7] and thrombotic stroke [8], compelling inverse associations with incidence of cancer overall [9,10] (including, possibly, incidence of breast [11] and colorectal [12] cancer), likely inverse association with the incidence of adult-onset diabetes mellitus [13] and possibly with the incidence of hip fractures [14]. There have also been randomized trials supporting a beneficial role of the Mediterranean diet on the incidence of cardiovascular events [15] and of survival from coronary heart disease [16].</p>
        <p>The traditional Mediterranean diet can be defined, however loosely, and has clearly beneficial health effects. Why it is health promoting, however, is not easy to answer. From the randomized trials, de Lorgeril infers that alpha-linolenic acid is a key factor [16], whereas the PREDIMED (Prevención con Dieta Mediterránea) primary prevention trial emphasizes extra virgin olive oil and nuts [15]. In an anatomy of the overall health effects of conformity to the Mediterranean diet in the Greek EPIC cohort (as reflected in the apparent reduction of total mortality), high consumption of plant foods accounted for 37.2% of the reduction (vegetables 16.2%, fruits and nuts 11.3%, legumes 9.7%), moderate alcohol intake, as contrasted to high or none for 23.5% of the reduction, whereas low meat intake accounted for 16.6% and olive oil (as reflected in the monounsaturated-to-saturated ratio) for 10.6%. The other components of the traditional Mediterranean diet score did not have a statistically significant impact, nor was there significant evidence for an over-additive synergism between any two components. The important role of olive oil in favoring high consumption of vegetables and legumes, however, could not be captured in the analysis [17].</p>
        <p>As for mechanistic processes, the effect of alcohol on HDL, the high anti-oxidant content of this plant-based diet, the high content of fiber, and the low glycemic load of this high-lipid diet and other mechanisms have been considered but not adequately substantiated. Future studies may follow, or improve and enrich, our approach to disentangle the health effects of the components of the Mediterranean diet and of their mutual interactions [17]. They could also focus on the identification of the key compounds in this diet or biochemical or molecular mediators of its beneficial health effects. Meanwhile, people could try to adjust their diets to the principles of the traditional Mediterranean diet, as outlined above. After all, this diet is not only health promoting, as the overwhelming evidence indicates, but also delicious, as many of those who have tried variations of it readily acknowledged.</p>
        <p>AT declares that she has no competing interests.</p>
        <p>Miguel A Martínez-González (Figure 2)</p>
        <p>The concept 'Mediterranean diet' was developed to reflect the typical dietary habits followed during the early 1960s by inhabitants of the Mediterranean basin, mainly in Crete, much of the rest of Greece and Southern Italy [18]. It is essentially a frugal diet that was followed by poor rural societies [19].</p>
        <p>More recently, the Mediterranean diet has been operationally defined in order to assess its role in analytical epidemiologic studies [20,21]. The operational definition of Mediterranean diet most commonly used is the Mediterranean Dietary Score (MDS) proposed by Trichopoulou et al. in 1995 [5,20] and updated thereafter [2]. The MDS is built by assigning a value of 0 or 1 to each of nine components with the use of the sexspecific median as the cut-off. For five beneficial components (vegetables, legumes, fruits + nuts, cereal and fish), persons whose consumption is below the sex-specific median of the sample are assigned a value of 0, and persons whose consumption is at or above the median are assigned a value of 1. A sixth beneficial component is the ratio of monounsaturated lipids to saturated lipids, in order to reflect the principal role of olive oil consumption in the traditional Mediterranean diet. A value of 1 is assigned to persons whose consumption is at or above the sample-specific median and a value of 0 is assigned to persons who are below the median. For components presumed to be detrimental (all meats, and all dairy products, which are rarely non-fat or lowfat in Mediterranean countries), persons whose consumption is below the median are assigned a value of 1, and persons whose consumption is at or above the median are assigned a value of 0. For alcohol, a value of 1 is assigned to men who consume between 10 and 50 g per day and to women who consume between 5 and 25 g per day. Thus, the total Mediterranean-diet score ranges from 0 (minimal adherence to the traditional Mediterranean diet) to 9 (maximal adherence) [2].</p>
        <p>The MDS is based on sample medians and, therefore, its score is highly dependent on the specific characteristics of the sample. This fact may represent a limitation for the transferability of results to other samples. An alternative is to build scores according to absolute/normative cutoff points for the consumption of specific food groups (pre-defined servings/day or servings/week) [22][23][24]. This is the approach followed by the screener which was instrumental in performing the dietary intervention with the Mediterranean diet in the successful PREDIMED trial [15,24,25].</p>
        <p>When compared with other 'healthy' diets, two elements of the Mediterranean diet are unique: 1) abundant fat intake is allowed provided that it comes from virgin olive oil, tree nuts and fatty fish, and 2) moderate intake of red wine during meals [17,26]. Other components (fish instead of red meats, abundance of plant-based foods) are common with other 'healthy' diets. Alcohol should be included in the definition of the Mediterranean diet. The Mediterranean alcohol drinking pattern [26] seems a key element for reducing total mortality [17,26].</p>
        <p>The disparity of definitions for the Mediterranean diet may seem surprising. The reasons for the disparate definitions are diverse, complicated and not completely understood. Some historical reflections may shed light on the reasons explaining the different definitions. The Lyon Diet Heart Study was a landmark trial because it was the first randomized trial to show a strong cardiovascular protection for a dietary intervention using an overall dietary pattern. This trial included 605 patients who had had a previous myocardial infarction (that is, this was a 'secondary' prevention trial). These patients were randomly allocated to a so-called Mediterraneantype diet or a control diet following the guidelines of the American Heart Association Step I diet. The Mediterranean-type diet group received advice to increase the consumption of vegetables, fruits and fish, but to reduce the consumption of red meats. They were asked to replace butter and cream with a special linolenic acid-rich margarine. The results were impressive with a 73 percent relative reduction in the rate of coronary events after 27 months of follow-up [16]. The use of another type of fat different from olive oil might have opened the road to other modifications of the original definition of Mediterranean diet [27].</p>
        <p>The most widely researched health benefits of the Mediterranean diet are the reduction in cardiovascular disease, including peripheral artery disease [15,16,[27][28][29]. The available evidence to support a causal vascular protection is sufficiently strong with successful randomized trials [15,16,29]. Other benefits extensively researched include the prevention of type 2 diabetes [30,31] and metabolic syndrome [32], cognitive impairment [33][34][35], and unipolar depression [36,37]. The EPIC study has also provided some benefits against the occurrence of cancer [10]. The evidence of potential protection seems stronger for gastric, colorectal, and breast cancers, especially when alcohol is excluded from the definition [10,38].</p>
        <p>MAM declares that he has no competing interests.</p>
        <p>Tammy YN Tong, Nita G Forouhi (Figures 3 and4)</p>
        <p>Mediterranean countries are historically among the healthiest countries in the world, recording relatively low rates of cardiovascular diseases and cancer as well as greater longevity. This ecological observation led to the idea of a healthy Mediterranean diet, based on traditional diets of regions such as Crete, other parts of Greece and Southern Italy [18,19]. Offering a potential solution to improve health and well-being through reduction in chronic disease incidence and mortality, the 'Mediterranean diet' has been studied for its effects on a range of conditions in countries not limited to the original Mediterranean region.</p>
        <p>Consistent with the findings of the landmark Lyon Diet Heart Study [16,39] and the five-year PREDIMED trial [15,31], a number of long-term observational studies supported protective roles of the Mediterranean diet against noncommunicable diseases [5,34,[40][41][42][43]. The diet is also received favorably by the general population and government agencies alike, being rated joint third best diet overall by the US News &amp; World Report [44], as well as being recommended by the UK National Health Service as a healthy meal choice [45]. A further 'feather in the cap' of the Mediterranean diet is its recognition by UNESCO as an intangible cultural heritage of several Mediterranean countries [46].</p>
        <p>The Mediterranean diet pyramid (Figure 5), as recommended by the Fundación Dieta Mediterránea, promotes a high consumption of cereals, fruits and vegetables; low consumption of red meats and sweets and moderate consumption of dairy, poultry and fish [18,19]. Additionally, the diet also includes moderate consumption of wine and use of olive oil (replacing other forms of fats) as essential components of the diet. Both these factors can be considered reasonable recommendations, given past evidence of health benefits for cardiovascular health associated with olive oil [47,48] and moderate alcohol consumption [49].</p>
        <p>To improve the evidence for the health benefits of the Mediterranean diet, more systematic and quantitative approaches are needed in research practice. To date, applicability of the Mediterranean diet to non-Mediterranean countries has not been established. The premier study in Greece by Trichopoulou et al. [5] evaluated eight dietary factors as components of the Mediterranean diet: vegetables, legumes, fruits and nuts, grains, meats, dairy, alcohol, as well as dietary fats, with fish added later on as a ninth component [43]. However, while consumption of these factors provides a good approximation to a Mediterranean type diet under certain circumstances, it has several shortcomings. One problem is that the selection and use of the dietary information is too specific to the local populations studied. Therefore, when examining benefits of the Mediterranean diet in different populations, the patterns of consumption of key dietary components should be examined first in order to make appropriate adjustments.</p>
        <p>Considering many advances in dietary research in the past decade, modifications to existing methods of assessing adherence to the Mediterranean diet are also warranted. This is particularly so since most studies have not evaluated the health benefits of adherence to the Mediterranean diet that was originally characterized in the Mediterranean region [18,19]. For example, when assessing the Mediterranean diet, it still remains unclear as to whether, for alcohol intake, any distinction should be made between red wine and other types of alcohol, even though wine is the form of alcohol traditionally consumed in Mediterranean countries [18,19,50]. While some epidemiological studies have reported potential health benefits of moderate wine consumption, the extent of these health benefits seems to be less apparent for other alcoholic beverages [51,52]. However, only a few studies on the Mediterranean diet recognized wine as a standalone component instead of total alcohol [53,54]. Future observational studies should take into account this differentiation, and ideally incorporate wine only as an element of the Mediterranean diet when assessing adherence to this dietary pattern. It will be of particular interest to examine differences in association with disease risk when wine alone versus total alcohol intake is included.</p>
        <p>Moreover, high intake of dairy products is considered as adverse in the landmark publications on the Mediterranean diet and health [5,43]. However, recent epidemiological evidence suggests lower cardiometabolic risk associated with consumption of dairy products, in particular fermented dairy products [55][56][57][58]. Importantly, moderate amounts of fermented dairy products are also traditionally consumed in Mediterranean countries [18,19]. Similarly, grains and meat products are of interest, in regards to whether whole grains and refined grains, or unprocessed red meats, processed meats, and poultry should be distinguished.</p>
        <p>Existing studies of the Mediterranean diet have used varying definitions of the diet and found associations of adherence to the diet with different health outcomes. However, none of them has fully examined the traditional Mediterranean diet, reflecting the difficulty of attempting to use a simple definition to describe dietary behavior which is inherently complex. Future research should, therefore, aim to amalgamate existing definitions of the Mediterranean diet with up-to-date scientific evidence of health outcomes associated with individual components. Furthermore, the Mediterranean diet is essentially part of a lifestyle, requiring the simultaneous consideration of other non-dietary behavioral factors when assessing its effects. What the Mediterranean diet, therefore, means in the context of some countries with distinct cultural diets and lifestyles, such as for instance in China, India, and parts of Africa, needs further research and thought, despite the fair amount of evidence among the Western and, particularly, Mediterranean countries.</p>
        <p>The authors acknowledge core MRC Epidemiology Unit support (MC_UU_12015/5), and declare they have no competing interests.</p>
        <p>Shweta Khandelwal, Dorairaj Prabhakaran (Figures 6 and7)</p>
        <p>The term 'Mediterranean Diet' is usually employed to indicate the typical diet of almost 16 countries located on the Mediterranean seacoast [28,59]. Several publications report the cardio-protective benefits conferred by this dietary pattern [15,[59][60][61][62][63]. However, the applicability and suitability of the Mediterranean diet in the Indian context have not been studied previously.</p>
        <p>India is in the midst of a 'nutrition transition', where changes in diet parallel an expanding industrial economy and a rapidly progressing epidemic of obesity and noncommunicable diseases, particularly in urban locations [64,65]. Furthermore, it is well known that Indians have a higher risk of developing diabetes and cardiovascular disease (CVD) than other populations [66,67]. Although the reasons for this are unclear, diet could play a major role. In this regard it is attractive to speculate that the Mediterranean diet may exert a protective role. Here, we discuss the constituents of the Indian diet that are similar to the Mediterranean diet, and evaluate the potential of adapting the Mediterranean diet to an Indian context.</p>
        <p>By and large, a typical Indian diet is rich in carbohydrates (largely refined cereals), low quality proteins (largely from legumes), rich gravies (high in saturated fats and salt) and has low levels of fresh fruits and vegetables. The overall meat consumption is not very high, even among those who report non-vegetarian food consumption [68][69][70].</p>
        <p>Some of the Mediterranean diet constituents and their suitability in the current Indian context are outlined in Table 1 and discussed below. In India, cooking oils vary considerably depending upon the region. However, some mono unsaturated fatty acid-rich oils in India similar to olive oil include ground nut oil, rice bran oil and mustard oil. There is not much evidence on the cardio-protective effects of oils used in Indian cooking. However, some studies suggest that mustard oil conferred about 50% lower risk reduction for ischemic heart disease among the Indian population. Even rice bran oil has been shown to have hypolipidemic effects [71,78,89]. Further evidence on long term usage of these oils on cardiovascular health from good quality longitudinal studies is warranted. Olive oil has not gained huge popularity in India until now as a result of its cost, as well as its unsuitability for Indian frying conditions. However, recent subsidies provided by the Agricultural Ministry for olive cultivation confirm the increasing interest and the rising demand among Indians for olive oil [90,91].</p>
        <p>High consumption of fresh fruit and vegetables is a principal characteristic of the Mediterranean diet. Although India is the second largest producer of fruits and vegetables in the world (annual production of 94 million tons), the consumption per capita is quite low and has steadily declined in the last 50 years (120 to 140 g/day) [92]. A number of studies have reported a declining fruit and vegetable consumption pattern in different Indian populations [68,84,87,88]. The most documented reasons for sub-optimal consumption involve affordability, awareness and access issues [93]. India can learn from some of the successful strategies to increase consumption in other countries [92,94]. Most of the evidence supports starting early and using multi-component interventions for increasing fruit and vegetable intake [95,96]. Inexpensive, culturally-acceptable and feasible interventions for boosting the fruit and vegetable consumption must be piloted and scaled up if successful. Policy interventions, such as subsidies on growing and storing fruits and vegetables, can offer sustainable solutions for enhancing consumption among developing countries such as India [97].</p>
        <p>Key to the Mediterranean diet, consumption of legumes may be associated with a reduced risk of coronary heart disease (CHD) [98,99]. Legumes are high in bean protein and water-soluble fiber, and are a good source of proteins, vitamins, minerals, omega-3 fatty acids and non-starch polysaccharides [77]. Per capita availability of legumes in India has decreased from 60 g in 1950 to 38 g in 1990, a reduction of nearly 40 per cent [100]. On the other hand, the per capita availability of cereal and millets has increased from 330 g to 470 g in spite of a four-fold increase in population. The cereal-to-pulse ratio, which should be ideally 8:1, has risen from 6:1 to 12:1 [99]. Even though pulses production increased by 3.35% per year during the last decade, the cost of production and consequent prices are too high to be affordable to many people; to increase production at lower cost is a bigger challenge. Experts suggest that technological efforts need to be supported by the right policy environment to leverage research and development in agriculture [101].</p>
        <p>Another important item in the Mediterranean diet is fish, which owes its heart-healthy attribute largely to the long chain omega 3 fatty acids (n-3) [102]. While fish is widely consumed in the Mediterranean diet, consumption</p>
        <p>Evidence from some studies shows a positive association between refined carbohydrates and insulin resistance.</p>
        <p>Experiments with complex whole grains and fiber have yielded a better glycemic profile [80][81][82]. However, dietary data collection methods which are largely self-reported in these studies need to be standardized further for better quality data.</p>
        <p>Observational data suggests that dairy consumption in India was inversely associated with obesity. After controlling for potential confounders, the risk of being obese was lower among women (OR = 0.57; 95% CI: 0.43 to 0.76) and men (OR = 0.67; 95% CI: 0.51 to 0.87) who consume ≥1 portion of plain milk daily than those who do not consume any milk [83]. However, interventional studies are warranted to confirm this association.</p>
        <p>Fresh raw fruits and vegetables</p>
        <p>The protective role of fruits and vegetables especially for better cardiovascular health (better lipid profiles, immunity, blood glucose levels and so on) has been ascertained in multiple studies globally but high costs, perishability and lack of awareness in some societies are challenging, especially in India [84][85][86][87][88]. Educational campaigns from school level coupled with policy interventions are needed to enhance consumption and improve heart-health.</p>
        <p>CHD, coronary heart disease; CI, confidence interval; CVD, cardiovascular disease; IHD, ischemic heart disease; RR; relative risk.</p>
        <p>in India varies considerably depending on the region. Studies indicate that irrespective of the fish eating behavior, the plasma and erythrocyte levels of n-3 are usually very low across the Indian population [103,104]. This may be because the consumption of n-3 rich foods is not frequent and when subjected to intense cooking methods, even the small available amounts get nearly eliminated. Several studies from other parts of the world have also looked at supplementation with n-3 as an isolated nutrient versus whole fish consumption [105]. The latter seemed to offer better cardiovascular health benefits. This may be because of additional protective constituents (such as fiber, protein, minerals and so on) or their synergistic effect in fatty fish as a whole. Indian diets also have some alternative sources of n-3, such as mustard oil, some nuts and flaxseeds [106,107]. However, these sources usually contain the shorter chain n-3, which need to get converted in vivo to their longer chain counterparts to offer a similar cardio-protective role. This conversion (dependent on the elongase and desaturase enzymes) is usually limited due to an excess of omega-6 fats (which compete for the same enzymes) in Indian diets [108]. However, a few studies in India have shown a modest beneficial impact especially on lipid profiles of adults when their diets were supplemented with flaxseeds and mustard oil [109,110].</p>
        <p>In terms of whole grains, Indian diets are rapidly transitioning. The traditional home cooked meals consisting largely of coarse grains and whole cereals are now replaced by cheaper refined versions. The latter are devoid of the fiber and other healthier components of complex carbohydrates. Recent studies in India have established strong positive associations between refined grain intake and type 2 diabetes, and confirm the protective effect of fiber, which is contained in whole grains [80][81][82]. Carbohydrates are integral to Asian Indian dietary traditions and re-introduction of culturally acceptable, traditional, carbohydrate-rich grains with high nutrient density may be a prudent step in reducing disease burden in this population.</p>
        <p>While moderate wine consumption is typical in those consuming a Mediterranean diet, Indians are usually characterized as binge drinkers, largely consuming whisky or beer, in contrast to everyday wine consumers from western and European countries. The pattern of consumption also varies; in India people usually consume alcohol before meals while in other countries, it is consumed along with meals. The impact of alcohol consumption on CVD risk in India has been described in two studies (Table 1). The differential preference in the type of alcohol and pattern of drinking seem to reverse the cardio-protective effect conferred by smallmoderate quantities of everyday wine consumption in other populations. Longitudinal data evaluating the role of alcohol in CVD risk among Indians are currently unavailable but urgently warranted.</p>
        <p>Processed red meat is associated with a higher CVD risk profile [111,112]. While red meat consumption is generally low in those adopting a Mediterranean dietary pattern, the UN Food and Agriculture Organization (FAO, 2007) reported Indians' per capita annual consumption of meat is rising [113]. Although the consumption statistics are still lower than the global average (Indian per capita annual consumption is about 5 to 5.5 kilograms or 11 to 12 pounds; and for the rest of the world, it is about 38 kilograms or 83.7 pounds), the steady rise in meat consumption among Indians reflects changing dietary preferences. Religion, and to some extent income, dominates the meat consumption pattern in India. While Hindus avoid beef, Muslims shun pork among the non-vegetarian populations in India. Longitudinal data from studies assessing the association between red meat consumption in India and CVD outcomes are needed.</p>
        <p>The emphasized need for a higher quantity and quality of nutrition studies becomes even more relevant because nutrition research in India is still very nascent. Poor emphasis on and lack of academic/professional training in nutrition epidemiology in developing countries constraints the public health researchers and often yields sub-optimal data quality [114,115]. Further, the commonly employed dietary data collection methods in Indian studies are not well standardized and contain self-reported information. These limitations further prevent high quality evidence building in the field of nutrition research.</p>
        <p>Indians are already known to have higher cardiovascular disease risk than other populations [66,116,117]. Since unhealthy diet exacerbates the already high cardiovascular risk profile, well-designed nutritional epidemiological studies are warranted in the Indian population. Successful dietary interventions need to be adapted, particularly for dietary patterns rather than isolated nutrients, and tested in Indian settings for comparison with available global evidence. The role of individual constituents of the Mediterranean diet, their interactions with each other and with other items consumed concomitantly, along with various types of processing in traditional Indian mixed dishes, may alter some of their preventive properties and may also contribute substantially to increased CVD risk [118]. High quality intervention studies, such as the PREDIMED trial [15], assessing the acceptability of the Mediterranean diet or comparable constituents and their effect on the risk of major cardiovascular events in India are warranted. Until such data are available, Indians should be encouraged to consume a scientifically proven and contextually acceptable healthy dietary pattern comprising whole grains, fresh fruits and vegetables, good quality proteins (from pulses, chicken or fish) and some dairy products. Additionally, resources need to be urgently invested in strengthening nutrition research infrastructure and training to conduct and analyze high quality intervention and longitudinal studies in India. Strategies promoting collaborative studies and opportunities to build capacity in public health research should be deeply encouraged.</p>
        <p>The authors declare that they have no conflict of interest.</p>
        <p>Dariush Mozaffarian (Figure 8)</p>
        <p>An impressive and ever-expanding body of evidence has taught us that overall dietary quality strongly influences health, in particular risk of cardiometabolic diseases such as coronary heart disease, diabetes, and obesity [119]. Indeed, suboptimal diet quality is now the leading modifiable cause of death and disability in the world [120]. In contrast to the erroneous notions that diet quantityhow much a person eatsor isolated single nutrients are most important, the most relevant characteristics of healthful diets are the overall patterns of foods consumed.</p>
        <p>Among various dietary patterns, consistent and compelling evidence indicates that traditional Mediterranean-style diets produce substantial health benefits. Diverse cultures and agricultural patterns exist in the Mediterranean region: there is no one, pure 'Mediterranean diet'. Still, as discussed in the previous sections, traditional Mediterranean diets share fundamental characteristics, which either individually or together have been proven to improve cardiometabolic health. Because of this abundance of beneficial foods, such diets are also naturally lower in harmful foods such as highly processed snacks, cereals, and similar ready-made products; red and processed meats; and other refined grains, starches, and sugars [121].</p>
        <p>Ecologic comparisons, prospective cohort studies, and randomized trials consistently demonstrate significant beneficial effects of Mediterranean-type diets and their components on cardiometabolic risk factors and disease endpoints [15,119,[121][122][123]. The Spanish PREDIMED trial demonstrated a reduction in the risk of cardiovascular events by approximately 30% when participants were advised to follow a Mediterranean diet, supplemented with either nuts or extra-virgin olive oil [15]. Notably, extra-virgin olive oil largely replaced regular (non-virgin) olive oil, suggesting that the benefits of olive oil may be more closely related to bioactive compounds in extra-virgin oils [124] rather than to monounsaturated fats per se. Mediterranean diets also improve glycemic control [125] and reduce the incidence of type 2 diabetes [31]. The key components of Mediterranean diets are also beneficial for weight loss in obese patients [126] and for preventing long-term weight gain in non-obese populations [127]. Thus, rather than focusing on reductions in total calories or portion sizes, or on increasing or decreasing isolated nutrients, an emphasis on overall diet quality according to types of foods consumed has the strongest evidence-base for reducing adiposity and preventing diabetes and cardiovascular diseases. The main exceptions to this food-focused approach may be dietary additives such as sodium and trans fat, because very similar foods can be consumed that are either higher or lower in these additives, indicating a separate need to target these nutrients.</p>
        <p>How does the Mediterranean diet compare to other healthful diet patterns? One close relative is the Dietary Approaches to Stop Hypertension (DASH) diet, which shares many of the same characteristics. Notably, while the original DASH diet was lower in fat and higher in carbohydrate, controlled clinical trials demonstrate that a higher-fat DASH diet, rich in healthful vegetable oils and nuts, produces even larger cardiometabolic benefits than the original low-fat DASH diet [128,129]. People are also increasingly asking about vegetarian or vegan diets to improve their health. Unfortunately, because such diets are defined only by what is not consumed, the concept provides little accurate guidance for health. For instance, French fries, soda, and ketchup are vegetarian, as are refined grains, sugars, starches, sodium, and industrial trans fat. It is true that people who choose to be vegetarians or vegans are often health-conscious, so that they more often select healthier, minimally processed foods consistent with a Mediterranean diet [130]. a vegetarian or vegan diet per sethat is, the sole absence of animal products -has little influence on health, as true healthful diets are best defined by what is consumed, while also being characterized by lower consumption of unhealthful foods, many of which are actually 'vegetarian'.</p>
        <p>Unfortunately, diets in the Mediterranean region have worsened over time. In Crete, a Mediterranean island with historically low rates of chronic disease, the diets now contain less fruit and olive oil and more meats than diets of earlier generations, with associated population increases in serum cholesterol and adiposity [131]. A global dietary Renaissance is required, returning the traditional Mediterranean diet to its primacy in the region and, crucially, incorporating our knowledge of its numerous health benefits to practical, regionally tailored dietary guidance and policies worldwide.</p>
        <p>Dr. Mozaffarian reports ad hoc honoraria from Bunge, Pollock Institute, and Quaker Oats; ad hoc consulting for Foodminds, Nutrition Impact, Amarin, Astra Zeneca, and Life Sciences Research Organization; membership, Unilever North America Scientific Advisory Board; and royalties for a chapter on fish oil from UpToDate.</p>
        <p>Mediterranean diet: from tradition and empiric description to modern science Michel de Lorgeril (Figure 9)</p>
        <p>The term 'Mediterranean diet' usually describes the dietary habits of populations living near the Mediterranean Sea [27]. The definition of the Mediterranean diet varies with geography, historical time and the nationality of the authors. In reality, the traditional dietary habits of the Greeks in 1950 were neither those of the Italians at that time, nor those of the Spaniards or Lebanese in 2014, although all of them do live on the shores of the Mediterranean Sea. These differences mainly explain the controversy about the definition of the Mediterranean diet.</p>
        <p>After years of biological and medical research [27], it is definitely possible to look at the Mediterranean diet as a robust and complex scientific concept. It can be used by any practitioner, provided it is adapted to each specific geographic area and population, and called the modernized Mediterranean diet [27]. The next paragraphs will try to explain the shift from the empiric description of the traditional dietary habits of various Mediterranean populations to modern scientific medicine.</p>
        <p>One good example is the dietary fat issue. It cannot be summarized with a single statement about olive oil. Briefly, Mediterranean people use several types of fats, from both plant and animal (including marine) sources. Many different fatty acids make up these fats. As shown in Table 2, comparing the modernized Mediterranean diet with a Western-type dietgrossly defined as the dietary habits of the US and North European (Finland, the Netherlands) populations investigated in the Seven Countries Study [3] -, it is important to differentiate oleic acid (the main monounsaturated fatty acid) provided by olive oil and the same chemical provided by animal fat. Oleic acid is indeed one of the main fatty acids of beef and pork fat. When the relations between the intake of oleic acid and any health item are analyzed within a Western cohort, investigators mainly analyze the relations with beef and pork consumption. When they do the same within a Mediterranean cohort, they analyze the relations with olive oil and the results are totally different. This may explain why certain (Western) experts refuse to acknowledge any health benefit from consuming olive oil, as if olive oil and oleic acid are the same things.</p>
        <p>On the other hand, while the modernized Mediterranean diet is not a vegetarian diet, it is definitely a plant-based diet. It is, therefore, crucial to identify the main sources of the essential omega-3 and omega-6 polyunsaturated fatty acids. Since olive oil is poor in both omega-6 and omega-3 fatty acids, what are the true sources of omega-3 and omega-6 fatty acids in either the traditional or the modernized Mediterranean diet? Along the same line, it is crucial to differentiate the main sources of the specific omega-3 fatty acidsthose provided by plants and those provided by marine or terrestrial animalsand also the main sources of omega-6 fatty acids from either plants or animals (Table 2).</p>
        <p>Finally, in the contemporary world where industrial foods are consumed by more and more people, it would be a mistake to still think that most saturated fats come from foods. Actually, saturated fatty acids also come from plants, such as the palm oil and cocoa butter incorporated in industrial foods. In the same way, it is essential to differentiate the (toxic) trans fatty acids produced by the industrial hydrogenation process and the (healthy) trans fatty acids naturally produced by ruminants and found in the dairy products typical of the Mediterranean diet.</p>
        <p>All of these fat items, as well as other dietary items, illustrate how the empirical description of the traditional Mediterranean diet has become a modern scientific concept [27]. This is important to understand in order to design the optimal nutrition strategy to prevent disease. For instance, when testing the effects of the Mediterranean diet against cardiovascular complications in a controlled trial among French patients whose dietary habits were very different from the traditional Mediterranean diet, we were able to reproduce the main dietary aspects of the Mediterranean diet as regards fat (Table 2), without exclusively using olive oil [16,39]. By advising our patients to use canola oil and canola oil-based margarine, plus some other Mediterranean foodsincluding olive oil, fatty fish, and nutswe did reproduce the blood fatty acid profile characteristic of Mediterranean populations, with the appropriate omega-3/omega-6 ratio [132]. This may, at least in part, explain the impressive protection observed in the Lyon Diet Heart Study [16,39], which was recently confirmed in the PREDIMED trial [15]. Thus, future trials testing the effects of a modern version of the Mediterranean diet in various clinical contexts (prevention of cancer or Alzheimer-type dementia) or future epidemiological studies should include that new knowledge in their protocols and designs. As an example, it will be important to differentiate the different essential (both omega-3 and omega-6) polyunsaturated fatty acids and also their food sources, animal versus plant (Table 2).</p>
        <p>Finally, it is noteworthy that wheat, both whole and refined, is a major ingredient of the Mediterranean diet, mainly under the form of bread, but also of other typical Mediterranean diet foods, such as pasta and couscous [27,133]. The physicians and nutritionists who are aware of the basic principles of the modernized Mediterranean diet recommend eating complex carbohydrates and whole grains, in particular bread and other wheat-based foods. However, the last decades have seen great changes in the prevalence and clinical presentation of two diseases linked to wheat: the celiac gluten-induced enteropathy and non-celiac gluten sensitivity [134,135]. These changes have taken place as new wheat hybrids were introduced into human foods [134]. This is definitely a critical medical and environmental issue, which needs to be appropriately managed by physicians when their patients report new gastrointestinal or non-gastrointestinal symptoms after adhering to the modernized Mediterranean diet. The worst thing to do would be to deny the reality of these</p>
        <p>Total fat slightly higher or not different [16,39] Plant and animal saturated fats much lower [16,39] Plant monounsaturated fats much higher [16,39] Animal monounsaturated fats lower [27] and cited references</p>
        <p>Animal n-6 polyunsaturated lower [27] Plant n-6 polyunsaturated much lower [16,39] Plant n-3 polyunsaturated much higher [16,39] Animal (including marine) n-3 polyunsaturated moderately higher [16,39] Industrial trans fatty acids much lower [27] and cited references Natural (ruminant) trans fatty acids slightly higher or not different [27] and cited references symptoms. There are alternatives to gluten-rich grains, and physicians and nutritionists should be careful to select such alternatives so as to respect the basic principles of the modernized Mediterranean diet. Thus, the gluten/wheat issue illustrates how a dietary pattern is not a static thing, but rather an ongoing change In summary, even if wheat bread and olive oil are the very symbols of the traditional Mediterranean diet, a modernized Mediterranean diet concept makes it possible to obtain all the health benefits of typically Mediterranean dietary habits without olive oil or wheat bread. In other words, the modernized Mediterranean diet concept opens the way to a scientifically-founded protective dietary pattern which could be independent from the Mediterranean geography, climate and cultures. Future researchfor instance when constructing a modern Mediterranean diet score in observational epidemiologic studywill have to integrate that new knowledge [134,135].</p>
        <p>2014, 12:112 http://www.biomedcentral.com/1741-7015/12/112</p>
        <p>2014, 12:112 http://www.biomedcentral.com/1741-7015/12/112</p>
        <p>Jul 2014 2014, 12:112</p>
        <p>The author declares that he has no competing interests.</p>
    </text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f326509939"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:37+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>UK Biobank is a population-based cohort of half a million participants aged 40-69 years recruited between 2006 and 2010. In 2014, UK Biobank started the world's largest multimodal imaging study, with the aim of re-inviting 100,000 participants to undergo brain, cardiac and abdominal magnetic resonance imaging, dual-energy X-ray absorptiometry and carotid ultrasound. The combination of large-scale multi-modal imaging with extensive phenotypic and genetic data offers an unprecedented resource for scientists to conduct health-related research. This article provides an in-depth overview of the imaging enhancement, including the data collected, how it is managed and processed, and future directions.</p>
<p>maging provides structural and functional information on internal anatomy and physiological processes. Its use in clinical practice has transformed the diagnosis, management and treatment of disease. Imaging can detect asymptomatic pathology before disease development and thus can be used to screen highrisk populations to support precision and preventative medicine. In some cases, imaging can provide insights into the biological mechanisms underlying exposure-disease associations.</p>
<p>Large-scale population-based prospective studies can facilitate the identification of imaging measures as targets for prevention or provide an insight into disease mechanisms. Although some epidemiological studies have incorporated imaging measures, these have usually been limited to a specific imaging modality or body region (such as the brain or heart), have often been restricted to selective population subgroups at high risk for certain diseases and have included no more than a few thousand participants. For example, the first cohort studies to use magnetic resonance imaging (MRI), such as the Rotterdam study and the Multi-Ethnic Study of Atherosclerosis (MESA), included &lt;5000 participants 1,2 .</p>
<p>However, to assess the moderate associations that may exist between genetic and lifestyle factors and imaging-derived phenotypes (IDPs), or between IDPs and subsequent risk of a wide range of diseases, it is necessary to perform imaging in very large numbers of healthy individuals as only a relatively small proportion of them will develop any particular condition during follow-up. Furthermore, in the era of 'Big Data', large, diversely phenotyped cohorts are essential to maximise recent developments in artificial intelligence (AI). To address this challenge, more ambitious multi-modal imaging protocols have been initiated in longitudinal cohorts, including brain and body MRI in the German National Cohort on 30,000 participants 3 , and MRI of the brain, blood vessels, heart and liver in the Canadian Partnership for Tomorrow Project (CPTP) for 10,000 participants (see www. partnershipfortomorrow.ca).</p>
<p>Here, we provide an overview of the programme currently underway in UK Biobank (UKB), the largest and most detailed imaging study to date. The UKB imaging enhancement aims to perform brain, cardiac and abdominal MRI, full body dual-energy X-ray absorptiometry (DXA) and a carotid ultrasound scan on 100,000 of the existing 500,000 UKB participants before the end of 2023 4 . As of early 2020, over 45,000 participants have undergone an assessment, already making the UKB imaging enhancement by far the largest multi-modal imaging study in the world. This article outlines the scientific rationale and processes involved in collecting, curating and disseminating the imaging data for research purposes, and describes recent developments, such as the initiative to repeat the imaging of at least 10,000 participants.</p>
<p>Between 2006 and 2010, 9.2 million women and men aged 40-69 who were registered with the UK's National Health Service (NHS) were sent postal invitations to attend one of 22 UKB assessment centres in England, Scotland and Wales 5 . Of these, ~500,000 (5.5%) individuals joined the study. Although UKB is not representative of the UK population, the large sample size and heterogeneity of measures nonetheless enable a valid assessment of many exposure-outcome relationships to be made. During the baseline assessment, extensive sociodemographic, lifestyle and health-related information was collected through a touchscreen questionnaire and verbal interview, and a wide range of physical measures were performed 4,6 . Participants also provided biological samples that have been used to perform genotyping 7 and haematological and biochemistry assays for the full cohort 8 . Once recruitment was fully underway, additional measures were incorporated into the baseline assessment, including tests of hearing and arterial stiffness (n = ~200,000), a cardiorespiratory fitness test (n = ~100,000) and various eye measures (n = 100,000-150,000). Since the baseline visit, subsets of participants have supported additional data collection through various enhancements to the study. These have included: a full repeat of the baseline assessment (n = ~20,000, 2012-2013), collection of physical activity data over 7-days by wearing accelerometers (n = ~100,000, 2013-2015 and n = ~2500 on four occasions, 2018-2019) and regular online questionnaires covering a variety of topics such as diet, cognitive function, occupational history, mental wellbeing, gastrointestinal health and pain (sent to ~330,000 participants with email addresses; ~35-50% response rate for each questionnaire).</p>
<p>All participants provided consent for their health to be followed-up through linkage to health-related records, which currently includes death, cancer and hospital inpatient records for the full cohort. Primary care data are also available for ~45% of the cohort (with data for the remaining participants pending). Together, these electronic medical record data capture information on type and date of diagnosis and symptoms, procedures and operations, prescriptions, test results and referrals by general practitioners.</p>
<p>UKB received approval from the National Information Governance Board for Health and Social Care and the National Health Service North West Centre for Research Ethics Committee (Ref: 11/NW/0382). UKB is compliant with both the previous Data Protection Act and the more recent General Data Protection Regulation (GDPR) implemented in 2018. For the GDPR, participants were contacted by email or post to explain how UKB meets the requirements of the new regulations (https://www. ukbiobank.ac.uk/gdpr/).</p>
<p>Rationale for multi-modal imaging on 100,000 participants in UK Biobank. When the original UKB protocol was reviewed in 2006, the UK Biobank International Peer Review Panel recommended exploring the feasibility of conducting enhancements in large subsets of the cohort. The inclusion of imaging measures was deemed of value and further consultation with the wider scientific community was recommended. Consequently, UKB established an expert Imaging Working Group in 2011 who, after consultation with over 100 imaging specialists worldwide, developed an imaging protocol that aimed to maximise the scientific value of the imaging data collected while also being achievable at scale (i.e., non-invasive with short acquisition times).</p>
<p>A key requirement was the inclusion of several imaging modalities that could provide precise and reliable information on multiple organ systems as opposed to single body sites. The protocol thus includes collection of imaging data on the brain, heart, large blood vessels, body composition, bone and joints. This provides researchers with the opportunity to use measures from different organ systems to explore the multifactorial biological mechanisms of complex diseases. For example, the diversity of data could contribute to a better understanding of the relationships between systemic health and dementia through capture of data regarding the structure and function of the brain (brain MRI) in conjunction with adiposity (body MRI and DXA) and vascular risk factors (cardiac MRI and carotid ultrasound) 9 . The integration of multiple 'gold-standard' imaging measures can also be used to calibrate and expand upon the data collected at the baseline assessment. For example, the whole-body DXA scan complements measures of bone density obtained from the heel ultrasound performed at baseline. Further, body MRI and DXA could provide more detailed data on body composition and fat distribution than that provided by the bioimpedance measures. This will support more refined analyses of body composition, such as whether disease risk varies in those with a normal body mass index (BMI) but who have a high visceral fat content 10 .</p>
<p>Another consideration for the Imaging Working Group was how many participants to image. This was done by ultimately balancing estimates of the power of potential future nested casecontrol studies with pragmatic considerations based on costs and feasibility. Approximately 5000 and 10,000 cases are required to detect an odds ratio of 1.5 and 1.33 with 80% power, respectively, when the exposure prevalence is 10% 11 . Although imaging 100,000 participants is unprecedented, it is clear this is the sample size needed to capture sufficient cases to reliably explore a wide range of associations.</p>
<p>Protocols of the UK Biobank imaging enhancement. Following ethical approval, a pilot study of ~5,000 participants was performed between 2014 and 2015 to demonstrate the feasibility of high-throughput imaging and to finalise the imaging protocols required for the main phase. Funding was then released to extend the imaging enhancement to an additional 95,000 participants, with data collection estimated to finish by 2023. The imaging assessment takes place in dedicated, purpose-built centres based in Stockport (termed Central), Newcastle-upon-Tyne (North), Reading (South-East) and Bristol (South-West). The locations were selected to minimise travel times for the majority of participants, based on driving times and availability of public transport links, as travelling time was recognised as one of the main determinants as to whether a participant was likely to attend or not.</p>
<p>Invitation process. Invitations for the Central region of the UK began in April 2014, followed by the Northern region in April 2017, the South-East region in June 2018 and the South-West centre in February 2020. Initially, invitations were sent by email as this is the most cost-effective means of communicating with participants. However, as not all participants provided an email address, postal invitations began in early 2020 to provide all participants the opportunity to attend, should they wish to do so. Therefore, all surviving UKB participants will be invited, except for those who have informed UKB they no longer wish to be contacted or now live outside the UK (&lt;0.5% of participants to date). Participants are provided with comprehensive information about the project, including an invitation letter briefly describing what the assessment visit involves and an information leaflet describing the individual scans, eligibility criteria and benefits and risks of participation as well as links to a dedicated UKB imaging website (https://imaging.ukbiobank.ac.uk/). If interested, participants are asked to telephone the Participant Resource Centre who makes an initial assessment as to whether the potential participants are eligible for inclusion in the enhancement (e.g., the MRI scans are not safe for individuals who have metal implants or who have had certain surgeries) and for tolerability (e.g., claustrophobia). Completion of the full protocol is not possible for those unable to lie still, hold their breath voluntarily or hear instructions. Participants who have MR-compatible metal implants in their body (not limbs) are also excluded as these can affect the quality of the scan in regions close to the metal and reduce their value for research purposes.</p>
<p>Reminder emails are sent to non-responders 2 weeks, 4 weeks, 6 months, 12 months and 24 months after the initial invitation. All email invitations and reminders contain a decline link, where participants can opt out of receiving subsequent invitations. To obtain imaging data on 100,000 participants, an attendance rate of at least 20% of the 500,000 UKB participants is required. To date, this has been achieved, with 31% of invited participants expressing an interest, of which 71% are eligible and have booked an appointment; of these, 97% have attended an imaging assessment centre (Fig. 1). Approximately 12% of participants book an appointment in response to an initial invitation, with response rates of 7% after the 2 week reminder and a further 4% after the 4-week reminder.</p>
<p>General imaging process. The target throughput for each imaging centre is 18 participants per 12-hour working day, and the centres are open every day (except for the Christmas and Easter holidays). When fully operational, a monthly average of 17 participants per day is achieved (with 95% attendance rate). Each centre is staffed by six radiographers, three healthcare assistants, a laboratory specialist, a healthcare assistant team leader and a centre manager, with a lead radiographer and MR physicist providing support across all centres. Four sub-specialist third party consultant radiologists, each with experience in brain, cardiac, abdominal or musculoskeletal imaging, review scans that are flagged by radiographers as having a potentially serious incidental finding. Fig. 1 Flow chart of participation in the UK Biobank multi-modal imaging study. Note that as the invitation process is ongoing, this flow chart is only accurate as of early 2020. For example, some participants classified as 'no response' might attend the imaging enhancement in future.</p>
<p>On arrival at the assessment centre, the participant's eligibility is again checked with a radiographer, and electronic consent is obtained to confirm that the participant understands the nature of the study and potential implications, such as the detection and feedback of incidental findings. There are four imaging stations: one consisting of the brain MRI, another one covering both the cardiac and abdominal MRI, one for DXA and a final station for carotid ultrasound. To fully maximise the use of the facilities, three participants go to a separate station simultaneously and serially rotate through different stations. Once participants have finished the imaging assessments, they repeat all the measures collected at the baseline assessment, except for the eye examinations, 4-lead electrocardiogram (ECG) during exercise and saliva sampling.</p>
<p>General imaging quality control. A centralised training and monitoring team is responsible for quality assurance across all imaging centres. All staff members undergo a six-week training programme before centres open, with monthly training provided by the MR physicist. To ensure fully harmonised imaging data are acquired across centres, identical scanner models, software, adjustment and tuning methods, types of coils and protocols are used. Quality assurance and control measures are also in place including a standardised training programme for all radiographers in each centre, system acceptance testing, standard operating procedures, as well as routine phantom measurements, regular servicing and performance checks that are conducted by a dedicated UKB physicist. The radiographer visually inspects the MRI images for quality control purposes while participants are undergoing scanning and immediately after acquisition. Quality control assessments consisting of qualitative and quantitative comparisons conducted by external imaging experts for each modality confirmed that images acquired during the pilot study were of excellent quality for research purposes (Table 1). Incidental findings. UKB developed an approach to managing the clinical review of images acquired in consultation with stakeholders, funders and the UKB Ethics and Governance Council (now the Ethics Advisory Committee). Consistent with the practices established for other data collected by UKB, participants are informed that the data collected is intended for research use only, that the scans will not be routinely assessed for evidence of disease and that individual results will not be made available to them (detailed information on incidental findings can be found at https://imaging.ukbiobank.ac.uk). However, and consistent with the approach adopted for incidental findings during the original assessment visit, if while scanning a participant, a radiographer observes an incidental finding that might be clinically serious or life-threatening then the relevant scans undergo further review by a specialist radiologist, who determines independently whether UKB should notify the participant and their general practitioner. All participants explicitly consent to participate in the imaging enhancement on this basis. This approach was evaluated through comparison with systematic radiology review of all images from the first 1000 imaged participants. Compared to the systematic radiologist review, radiographer flagging resulted in substantially fewer participants with potentially serious incidental findings (179/1000 [17.9%] versus 18/1000 [1.8%]) but a higher proportion with serious final diagnoses (21/179 [11.7%] versus 5/18 [27.8%]). Radiographer flagging missed 16/21 serious final diagnoses (false negatives) while systematic radiologist review generated large numbers of non-serious final diagnoses (158/179, false positives). All participants who were notified of a potentially serious incidental finding consulted their GP, and 90% had some further clinical assessment (most commonly additional imaging (79%), or referral to a specialist (64%)). Some participants reported that feedback of their incidental findings had a negative impact on their emotional wellbeing, insurance status or finances, or work and leisure activities (17%, 9% and 6%, respectively).</p>
<p>In light of these findings from the pilot and with additional advice from UKB's independent Ethics and Governance Council, we concluded that the proposed UKB imaging incidental findings protocol to use radiographer flagging (and not systematic radiologist review) provides an acceptable balance of benefit versus harm to the participants, as detailed elsewhere 12 .</p>
<p>Rationale, protocol and data processing for each imaging modality Brain MRI. There are several neuroimaging methods that can measure different aspects of the brain. However, MRI is unique as it can capture high-resolution structural and functional information in a single examination in a non-invasive manner (i.e., with no use of non-ionising radiation). Both structural and functional brain measures show promise as markers to guide strategies for disease prevention, monitoring of disease progression or as predictive markers for disease risk (e.g., by identifying neuroanatomical markers related to the risk of developing dementia) 13 . However, although brain MRI has been used commonly for smaller clinical and non-clinical neuroscientific research 14 , its use in largescale population-based epidemiological studies like UKB is limited.</p>
<p>Cardiac MRI. Cardiac MRI captures information related to both the structure and function of the heart and can provide a range of measures which have been implicated in cardiovascular disease such as left ventricular mass, left ventricular ejection fraction, left atrial volume and aortic stiffness [20][21][22][23] . Prior to UKB, the largest studies of cardiac MRI were the Multi-Ethnic Study of Atherosclerosis (5000 participants) 2 , the Dallas Heart Study (3000 participants) 24 and the Jackson Heart Study (2000 participants) 25 .</p>
    <p>Abdominal MRI. Anthropometric measures, such as weight, height, BMI and waist-to-hip ratio, are commonly collected in epidemiological studies and have informed our knowledge about the role of adiposity with disease risk. However, these measures are fairly crude indicators of body composition and provide little information on the type and distribution of body fat, which have been shown to be important predictors of disease risk 33 . For example, visceral obesity (abdominal fat surrounding the internal organs) has been linked to an increased risks of type II diabetes, cardiovascular disease, cancer and mortality [34][35][36] . Accumulation of ectopic fat in the liver can cause hepatic steatosis (fatty liver), which is associated with insulin resistance and hepatocellular carcinoma 37,38 . MRI is considered the gold standard for body composition measurement and offers an unprecedented opportunity to measure internal and ectopic fat content, as well as whole-body and site-specific fat and muscle volume. However, abdominal MRI has not been conducted in any large-scale studies previously. Consequently, UKB is an unprecedented resource to further our understanding of how body fat composition and distribution influences disease risk.</p>
<p>The abdominal MRI protocol follows the cardiac examination on the 1.5 T scanner, employing relevant elements of spine and body matrix coils. The scan includes sequences that last 10 min. Table 4 reports the selected parameters of the abdominal MRI protocols.</p>
<p>For quality control, images are visually inspected immediately after reconstruction at the scanner. Fully automated tools are not currently available for extracting quantitative parameters from the images. However, research groups are developing semiautomated tools to extract fat, muscle and organ measures, including visceral and ectopic fat content 40 and liver measures 41 . In-depth information on the abdominal MRI protocol have been published elsewhere 40,42,43 .</p>
<p>Dual-energy X-ray absorptiometry. DXA captures precise sitespecific (e.g. proximal femur, lumbar spine) measures of bone mineral density and whole-body composition (e.g. bone, fat and lean mass), with no extensive additional processing and analysis 44 . DXA is regarded as the 'gold-standard' tool for the diagnosis of osteoporosis 45 , and can also provide information concerning the joint and its articular surfaces that is relevant to osteoarthritis 46 . Although several population-based cohorts have performed DXA scanning on several thousand participants [47][48][49] , UKB will be about 10-times bigger and uniquely offers the opportunity to compare body composition measures across DXA and MRI modalities. It also enables the investigation of how bone and joint integrity measures are related to a broad range of health outcomes and their genetic and environmental determinants. An iDXA instrument (GE-Lunar, Madison, WI, USA) is used in the imaging enhancement to measure several body sites using a protocol that lasts 20 min. The instrument captures highresolution images of the whole-body, proximal femur, spine (from L4 to T4) and knees, which can be used to identify joint pathology, vertebral fractures and other phenotypes using advanced techniques 50 . Measures of bone mineral density and body composition are automatically derived from the scanner and are transferred to UKB requiring little post-processing. Other measures are also being derived, including indices of bone strength, such as trabecular bone score (a measure of bone texture) and hip structural analysis, as well as hip and knee osteoarthritis phenotypes. High-resolution images of hips, knees, whole body, anteroposterior lumbar spine and lateral thoracolumbar spine are exported as DICOM files for further analysis by researchers.</p>
<p>All radiographers are trained according to a protocol harmonised across the scanning sites to allow consistent, accurate participant positioning and image acquisition. The DXA instrument undergoes manufacturer's daily quality control and local calibration using a phantom (GE-Lunar, Madison, WI). Periodic calibration across sites and over time is undertaken using a European spine phantom to ensure consistent measures are obtained 51 . An automated quality control protocol, where specific DXA analysis results (femoral neck bone mineral density, dual femur total bone mineral content, trunk fat mass, age, DXA weight) are checked for consistency, is being developed and a random sample of 50 scans per site are checked each quarter, with further radiographer training recommended as appropriate.</p>
<p>Carotid ultrasound. Carotid ultrasound imaging provides information about the health of the carotid arteries including measures of vessel thickness (expressed as carotid intima-media thickness (CIMT)) and vessel wall and plaque volume 52 . These measures are useful indicators of vascular pathology, such as atherosclerotic burden, and are predictive of various cardiovascular diseases, such as stroke, myocardial infarction and coronary heart disease 53 .</p>
<p>Participants are imaged using a CardioHealth Station (Panasonic Healthcare Corporation of America, Newark, NJ, USA), which has a 9 MHz linear array transducer. The protocol lasts 10 min. Both right and left carotid arteries are imaged using a 2D sweep along the transverse plane from below the carotid bifurcation to below the jaw and is repeated along the longitudinal plane. The CIMT is measured at predefined angles: 150°and 120°on the right carotid artery, and 210°and 240°on the left. A marker is placed on the screen to guide the operator in aligning the flow divider and a 10 mm region of interest box is overlaid and automatically tracks the far wall of the common carotid. After three consecutive cardiac cycles, the image autofreezes in end-diastole and records the mean, maximum, and minimum CIMT for each angle of acquisition.</p>
<p>All the CIMT measures are automatically generated by the device and do not require further post-processing. However, the quality of data acquisition depends highly on the operator and hence quality control is a high priority. Trained radiographers complete a manual assessment of image quality for all scans against agreed criteria, based on expected key features of the image and automated CIMT measurement 54 . Although vessel wall volume and plaque volume are not available as automated measures within the CardioHealth station, bespoke analysis tools to extract these measures are in development. In-depth information on the carotid ultrasound protocol and quality control process have been published elsewhere 54 .</p>
<p>Data generation, storage and access. Around 2.7 GB of imaging data are generated per participant, with 500TB of storage estimated to be required for 100,000 participants. Imaging data are transferred from the scanners to the data repository via a custombuilt Picture Archiving and Communication System (PACS), at the Nuffield Department of Population Health, University of Oxford. The imaging system was initially set up around a commercial PACS system, but due to the quantity and nature of the imaging workflow, a fully customised solution was essential. Images on the PACS are automatically checked for completeness and then replicated in a core archive. Incomplete datasets are flagged for manual checking and fault resolution. The PACS also has a workflow to manage and track potentially serious incidental findings, enables secure access for radiologists and specialists to view image data, write and review reports, and prepare the correspondence and imaging data for the NHS. All personal identifiers are removed before providing participant data to researchers.
</p>
<p>The UKB resource is available to all bona fide researchers who are associated with academic and commercial institutions anywhere in the world 58 . Researchers must first register with UKB and can then apply to access the data for specified research projects via an online Access Management System (
www. ukbiobank.ac.uk/register-apply), which consists of a brief application form and the selection of data-fields. Applications can be broad in scope as long as the aims of the project are well-defined and consist of health-related research in the public interest.
</p>
<p>UKB became available for researchers to access in 2012, with imaging data for the first 5,000 participants available in mid-2015 and for ~40,000 participants by early 2020. Researchers can request IDPs or the scans if they wish to extract novel features. Example images for each modality are provided on the UKB Data Showcase (http://biobank.ndph.ox.ac.uk/showcase/). Imaging data are uploaded to the resource every 6-12 months in batches of 5,000-10,000 participants, so researchers can update their analyses. Researchers are expected to publish and return their results (i.e., code/syntax, derived variables) so that any imaging-derived phenotypes generated as part of a research project are incorporated back into the UKB resource and are available to others.</p>
<p>Repeat multi-modal imaging on 10,000 participants. Although imaging 100,000 participants is a unique and powerful enhancement to the UKB resource, these data are currently only collected at a single time point and many valuable insights could be gained from observing change in imaging phenotypes over time. Serial measures are necessary to explore trajectories and progression of pathological processes and several measures collected over time typically provides a more accurate insight than a single, cross-sectional measure. For example, measures of change in structural brain MRI are a much better predictor of conversion from mild cognitive impairment to Alzheimer's disease compared to a single measure 59 . Using cardiac imaging, left ventricular mass has been shown to decrease with age in men when examined cross-sectionally, but to increase with age when examined longitudinally in the same study, demonstrating the importance of multiple measures 60 . Repeated measures also enable researchers to account for random measurement error and within-person variability, known as regression dilution bias, that can bias observed associations towards the null 61 .</p>
<p>Recognising this, at least 10,000 of the imaged participants will be re-invited to undergo a complete repeat of the imaging enhancement. Invitations to participants who had attended the first imaging assessment at least 2 years previously were initiated in May 2019 for Central region and July 2019 for the Northern region. Although still in the early stages, the response rate has been high (more than 65%), with ~3200 participants having booked appointments to attend repeat imaging within the first seven months.</p>
<p>Discussion and future directions. By early 2020, almost 50,000 participants had undertaken the imaging assessment, with 100,000 participants expected to have completed the protocol by the end of 2023. Of these, 10,000 participants are expected to have undergone a repeat of the imaging assessment by 2023. Imaging at such a large scale is unprecedented 1,2 . However, as only a small proportion of individuals will go on to develop certain diseases and the influences of risk factors may be small, a large sample size (i.e., in the order of 100,000) is necessary to adequately detect reliable associations with all but the most common conditions and strongest risk factors. The wealth of phenotypic and genetic data available on the UKB cohort will enable researchers to study how imaging phenotypes are related to a wide range of lifestyle, environmental and genetic factors, and to study how these antecedent factors influence disease risk through changes in tissue structure and/or function.</p>
<p>An advantage of the imaging enhancement is that it is embedded in an existing cohort study that has thousands of researchers worldwide actively working with the data. As of early 2020, over 1750 UKB projects were underway, two-thirds of which had received IDPs, and a quarter had received the scans. Hence, while still in the early stages of data acquisition, the imaging data that has been collected (and which is being made available to researchers in regular tranches) has received widespread interest worldwide and is already being used to address a range of novel research questions.</p>
<p>Published output to date has primarily focused on exploring cross-sectional associations between lifestyle factors with IDPs. For example, higher BMI and waist-to-hip ratio have both been associated with smaller volumes in different regions of the brain 62,63 , while hypertension and other vascular risk factors have been linked with abnormal white matter microstructure and other adverse brain measures 64,65 . These early findings could help us understand the mechanism through which vascular risk factors are related to neurodegenerative diseases, such as Alzheimer's disease 9 . A range of cardiovascular risk factors have also been associated with cardiac structure and function [66][67][68] , and other, less obvious, associations have been identified, such as with air pollution 69 , menopausal hormonal therapy 70 and lung function 71 . Novel findings are already emerging, for example diabetes has been shown to be associated with abnormal morphologies and function in all four heart chambers, whereas previously only the left ventricle was typically thought to be affected by diabetes 72 .</p>
<p>In addition to lifestyle factors, there is great interest in exploring how genetic variation is associated with imaging phenotypes to better assess the genetic determinants of early disease and to help understand the biological mechanisms underlying disease associations. For example, genome-wide association studies on over 3000 functional and structural brain imaging phenotypes on 12,000 participants identified novel associations between genes linked to iron transport and IDPs related to lower cognitive function 73 . Other studies have explored the genetic determinants of regional brain volumes and measures of white matter integrity [74][75][76][77][78][79] . One study provided evidence that genes associated with lefthandedness are linked to cortical regions involved in language 80 . These studies are both novel and powerful as previous genetic studies have tended to focus on a narrow selection of imagingrelated outcomes and incorporate data from multiple studies (with heterogeneous data collection and analytic techniques), to achieve a sufficiently large sample size.</p>
<p>The brain IDPs are extracted through a fully automated pipeline (established by WIN/FMRIB) and are therefore relatively easy to integrate into the resource and provide for research use. At present, IDPs from the other imaging modalities are extracted using semi-automated or manual pipelines, which are more time consuming and less readily available. However, the sheer scale of the imaging data available in UKB is facilitating the development of new methods to extract novel IDPs structural measures from the cardiac scans 28,81,82 , body compositional measures from the abdominal MRI 40,43,83 , and measures of fat and iron from the liver MRI 39,42,84 . In accordance with UKB access policies, all results, including individual-level IDPs and the methods used to generate them by research users of the resource, are returned to be integrated into the resource so that they can be made available to everyone approved to use the data.</p>
<p>The imaging enhancement has coincided with recent major advances in applications of machine learning and AI, in particular the development of computational algorithms that can learn how to extract meaningful information from raw images 85,86 . This includes the automated segmentation and classification of anatomical structures as well as the detection of abnormalities. Recently, machine learning techniques such as deep learning have demonstrated enormous potential as diagnostic tools by identifying conditions on a par with experts, for example skin cancer and diabetic retinopathy 29,87 . Development of these algorithms requires training on thousands of images to produce robust results, making UKB an ideal dataset. Machine learning techniques were applied to UKB cardiac MRI scans to identify aortic valve malformations and subsequent major cardiac events 88 . Although this analysis was performed on only the first 10,000 imaged participants, it clearly demonstrates the use of UKB as a valuable resource for AI research using the imaging data.</p>
<p>A key aspect of UKB is its prospective study design, which will enable research concerning the associations between IDPs and a range of incident health outcomes. This is important, as crosssectional analyses cannot determine temporality of an observed association and are particularly affected by reverse causation, i.e., when the outcome influences the exposure. Data from national death and cancer registries and hospital inpatient data are available for the full cohort, with data from primary care made available for about half the cohort in late 2019. Primary care will be immensely valuable for capturing conditions often diagnosed outside of a hospital inpatient setting. For example, compared to using only death registry and hospital admissions records, incorporating primary care data could increase the number of incident cases identified in the UKB cohort by 2021 by ~150% for dementia (5400 to 13,000 cases), by ~50% for stroke (8300 to 12,900 cases), by over 100% for chronic obstructive pulmonary disorder (13,300 to 30,600 cases) and by ~100% for Parkinson's disease (2000-4000 cases). Additional case ascertainment is being aided by online questionnaires which are being developed to collect information on outcomes poorly captured through medical records, such as those related to cognitive function, digestive health, pain, sleep and mental health.</p>
<p>External academic and commercial groups are also enhancing the resource by performing cohort-wide assays on the biological samples, including whole genome sequencing (funded by government, charity and industry), exome sequencing (led by Regeneron and a consortium of industry partners), leukocyte telomere length (University of Leicester, UK) and NMRmetabolomics (Nightingale Health). In line with UKB return of results policy, these data will be returned to UKB and integrated into the resource to be accessible to all researchers registered with an approved application.</p>
<p>UKB is currently on course to collect high quality multimodal imaging data on the brain, the heart, abdominal composition, bones, joints and blood vessels on 100,000 participants. UKB has also begun the process of performing repeat imaging on at least 10,000 participants. The amount of imaging data collected on such a large number of participants is truly unique. Yet it is the combination of these data with the wealth of other phenotypic, genetic and medical record information available in UKB that provides a powerful resource to address previously unanswerable research questions. Traditionally, imaging data might be perceived to be of value mainly to specialists in a narrow range of fields. However, researchers from many disciplines, including, but not limited to, epidemiologists, neuroscientists, statisticians, geneticists and psychologists, can and are using the IDPs already available from the imaging scans to conduct health-related research to provide new insights into the prevention, diagnosis and treatment of disease.</p>
<p>a</p>
<p>DXA dual-energy X-ray absorptiometry, fMRI functional magnetic resonance imaging, IDP imaging-derived phenotype, LV left ventricle, MRI magnetic resonance imaging, UKB UK Biobank. a 96% ≥2 sets of measures obtained from both left and right carotids; 99% ≥1 set of measures obtained from left or right carotid.</p>
<p>FLAIR</p>
<p>NATURE COMMUNICATIONS | (2020) 11:2624 | https://doi.org/10.1038/s41467-020-15948-9 | www.nature.com/naturecommunications</p>
<p>We would first like to acknowledge all UK Biobank participants for not only generously dedicating their free time to participate, but for also maintaining contact over many years that has made an imaging study of this scale possible. L.M.G. was funded by a Wellcome Trust Clinical Research Training Fellowship (107190/Z/15/Z). A.F.F. acknowledges past and ongoing contributions of Le Zhang, Rahman Attar, Dr Marco Pereañez, Mohsen Farzi, Dr Jose Maria Pozo, Milton Hoz and Prof. J Mark Wilkinson on setting up the CMR and DXA quality assessment and quantitative analysis pipelines within the UKB. He also acknowledges partial support from EPSRC (EP/N026993/1), the Royal Academy of Engineering Chair in Emerging Technology (CiET1819/19) and the European Commission (FP7-ICT-2011-9-601055,H2020-SC1-PM-16-2017-777119, H2020-SC1-PM-17-2017-777090). P.L. acknowledges support from the NIHR Oxford Biomedical Research Centre, Oxford BHF Centre for Research Excellence and EPSRC. P.M.M. acknowledges generous personal and research support from the Edmond J Safra Foundation and Lily Safra, an NIHR Senior Investigator Award, the UK Dementia Research Institute and the NIHR Biomedical Research Centre at Imperial College London". S.E.P. acknowledges support from the National Institute for Health Research Barts Biomedical Research Centre. S.M.S. and K.L.M. are supported by Wellcome Trust. The brain image processing is carried out on compute clusters at the Oxford Biomedical Research Computing (BMRC) facility and FMRIB (part of the Wellcome Centre for Integrative Neuroimaging). BMRC is a joint development between the Wellcome Centre for Human Genetics and the Big Data Institute, supported by Health Data Research UK and the NIHR Oxford Biomedical Research Centre. We are grateful to Dr Eleni Kariki and the late Professor Judith Adams for their adjudication of DXA-related incidental findings, to Dr Neil Rane and formerly Dr Alan Jackson for adjudication of brain-related incidental findings, Dr Stephen Lee for adjudication of body-related incidental findings, and Dr Francesca Pugliese and formerly Dr Alexia Rossi and Dr Ermanno Capuano for adjudication of cardiac-related incidental findings. Christie's Medical Physics provide MR safety support/advice as well as radiation protection advice. We would like to thank Mr Jonathan Price for his helpful comments on the custom-built PACS and Dr Mihir Sanghvi for his contributions to the cardiac MRI section. The following are current members of the UK Biobank Imaging Working Group; Paul Matthews, Tony Goldstone, Andrew Blamire, Steffen Petersen, Cathie Sudlow, Lorna Gibson, Alan Jackson, Naomi Allen, Rory Collins, Paul Leeson, Karla Miller, Stefan Neubauer, Stephen Smith, Nicholas Harvey, Jimmy Bell and E. Louise Thomas. The UK Biobank imaging project is funded by the Medical Research Council and the Wellcome Trust. The repeat imaging of 10,000 participants is funded by Dementias Platform UK.</p>
<p>T.J.L. developed the concept for the review and drafted the manuscript with input and guidance from NEA. The 'invitation process' section was drafted by J.H. and the 'incidental findings' section by L.M.G., J.</p>
</text>
</tei>
  <tei>
    <teiHeader>
        <fileDesc id="f300328147"/>
        <encodingDesc>
            <appInfo>
                <application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:56+0000">
                    <ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
                </application>
            </appInfo>
        </encodingDesc>
    </teiHeader>
    <text lang="en">
        <p>With mounting data on its accuracy and prognostic value, cardiovascular magnetic resonance (CMR) is becoming an increasingly important diagnostic tool with growing utility in clinical routine. Given its versatility and wide range of quantitative parameters, however, agreement on specific standards for the interpretation and post-processing of CMR studies is required to ensure consistent quality and reproducibility of CMR reports. This document addresses this need by providing consensus recommendations developed by the Task Force for Post-Processing of the Society for Cardiovascular Magnetic Resonance (SCMR). The aim of the Task Force is to recommend requirements and standards for image interpretation and post-processing enabling qualitative and quantitative evaluation of CMR images. Furthermore, pitfalls of CMR image analysis are discussed where appropriate. It is an update of the original recommendations published 2013.</p>
        <p>The recommendations listed in this section apply to the acquisition and post-processing of all CMR data. CMR studies should be performed for recommended indications. Data acquisition and reporting should conform to the recommendations of SCMR [3,4]. Consistent methods of acquisition and measurements are essential for serial evaluation of changes over time. Standardized structured reports with tables of measurements are helpful for reporting follow-up examinations. Any analysis should be performed using uncompressed or lossless compressed Digital Imaging and Communications in Medicine (DICOM) source images. Factors like type of sequence, spatial resolution, contrast agent and kinetics may influence visual and quantitative analysis and should be considered. Quantitative values should only be provided based on adequate image quality. Since there are no objective criteria for inadequate images, this determination needs to rely on the experience of the reporting physician. Readers should have adequate training and clinical experience that includes normal datasets to avoid over-interpretation of normal variants. The identity and responsibility of the reader should be appropriately documented in the report. Furthermore, the reader of clinical data is also responsible for the use of adequate post-processing hardware and software. The general requirements include:</p>
        <p>1. Workstation and screen of adequate specification and resolution (as per the specifications of the postprocessing software)</p>
        <p>Visual analysis a) Before analyzing the details, review all cines in cine mode, validate observations from one plane with the others, and check for artifacts, especially in patients with irregular heart rates. b) Dynamic evaluation of global LV function:</p>
        <p>Interpretation of both ventricular chambers, in concert with extracardiac structures including assessment for hemodynamic interaction between the two chambers (e.g., shunts, evidence of constrictive physiology). c) Assessment of LV function from a global and segmental perspective. Segmental wall motion is based on segmental wall thickening during systole. Wall motion is categorized as: hyperkinetic, normokinetic, hypokinetic, akinetic, dyskinetic. d) In presence of segmental wall motion abnormalities, use of standard LV segmentation nomenclature corresponding to the supplying coronary artery territories is recommended [3,5,7].</p>
        <p>Quantitative analysis a) General recommendations i) In patients with severe arrhythmias, the endsystolic volumes tend to be overestimated and ejection fraction underestimated. In case of significant artifacts this should be denoted in the report. ii) Calculated parameters: LV end-diastolic volume, LV end-systolic volume, LV stroke volume, LV ejection fraction, cardiac output, LV mass, and body-surface area indexed values of all except ejection fraction. The parameters quantified may vary depending on the clinical need. iii) Evaluation of the stack of short axis images with computer-aided analysis packages. iv) Contours of endocardial and epicardial borders at end-diastole and end-systole (Fig. 1). v) Epicardial borders should be drawn on the middle of the chemical shift artifact line (when present). vi) The LV end-diastolic image should be chosen as the image with the largest LV blood volume. For its identification, the full image stack should be be evaluated and one phase has to be identified as end-diastole for all the short axis locations. In addition, closure of the mitral valve or the phase immediately before opening of the aortic valve may be used for orientation. vii) The LV end-systolic image should be chosen as the image with the smallest LV blood volume.</p>
        <p>For its identification, the full image stack has to be evaluated and one phase has to be identified as end-systole for all the short axis locations. viii)Deviations may occur and extra care should be taken in the setting of LV dyssynchrony. ix) Automatic contour delineation algorithms must be checked for appropriateness by the reader. b) LV volumes i) Papillary muscles and trabecular tissue are myocardial tissue and thus ideally should be included with the myocardium as part of LV mass. As there is still discussion on the exact delineation of papillary muscles (e.g. versus trabeculation) and not all evaluation tools allow for their inclusion without manual drawing of contours, they are often included in the blood pool volume in clinical practice, which is acceptable. Reference ranges that use the same approach both on the acquisition and postprocessing side must be used. (Fig. 1) [8][9][10]. ii) Outflow tract: The LV outflow tract is included as part of the LV blood volume. When aortic valve cusps are identified on the basal slice(s) the contour is drawn to include the outflow tract to the level of the aortic valve cusps. iii) Basal descent: As a result of systolic motion of the mitral valve toward the apex (basal descent), care must be taken with the one or two most basal slices by using a standardized consistent approach. A slice that contains LV blood volume at end-diastole may include only left atrium (LA) without LV blood volume at end-systole. The LA can be identified by tracking wall thickening (if there is thickening -then it is in the LV cavity) and cavity (shrinking in systole, when in the cavity). Alternatively, the basal slice may be defined by at least 50% of the blood volume surrounded by myocardium. Currently however, there is no expert consensus on which method to use. Some software packages automatically adjust for systolic atrioventricular ring descent using crossreferencing from long axis locations. c) LV mass i) Calculation: difference between the total epicardial volume (sum of epicardial crosssectional areas multiplied by the sum of the slice thickness and interslice gap) minus the total endocardial volume (sum of endocardial crosssectional areas multiplied by the sum of the slice thickness and interslice gap), which is then multiplied by the specific density of myocardium (1.05 g/ml). ii) Papillary muscles: Papillary muscles and trabecular tissue are myocardial tissue and thus ideally should be included with the myocardium as part of LV mass, and this is particularly relevant in diseases with LV hypertrophy [6]. However, readers may decide to exclude trabecular tissue and papillary muscles from the myocardial mass. Reference ranges that use the same approach must be used (Fig. 1) [8][9][10]. iii) Basal descent and apex: When the most basal slice contains only a small crescent of basal lateral myocardium and no discernable ventricular blood pool, an epicardial contour for the visible myocardium is included for LV mass only. Similarly, when the most apical slice contains only a circle of myocardium without cavitary blood pool, an epicardial contour without an endocardial contour should be drawn for LV mass calculations. d) Rapid quantitative analysis i) A rapid quantitative analysis, known as the arealength method, can be performed using biplanar (e.g. 2-and 4-chamber views) or rotational multiple long axis views. In cases without expected significant regional variation of wall motion, this technique allows for faster evaluation and is not limited by problems related to basal descent. However, the 4-chamber view is strongly influenced by breath-hold position. The accuracy is not similar to short axis coverage, but allows a fast analysis often more similar to transthoracic echocardiography results. When the area-length method is used, with either a single long-axis view or a biplane approach, specific mention of the analysis technique should be made in the report. ii) Calculation [11][12][13]:</p>
        <p>-Single long-axis equation: LV volume = 0.85 × (LV-area) 2 / LV-length. This is typically performed using a 4-chamber view with calculations of LV volume obtained on both end-diastolic and end-systolic phases. LV area is the planimetered area of the LV cavity from an endocardial contour with the base drawn as a straight line through the medial and lateral aspects of the mitral annulus. LV length is the linear dimension from the midpoint of the mitral annular line to the apical tip of the endocardial contour.</p>
        <p>- Similar to the LV, the parameters quantified may vary depending on the clinical need [16]. ii) The contiguous stack of short-axis images or axial cine images is evaluated with computeraided analysis packages (Fig. 2) [17,18]. Automatically generated contours have to be carefully reviewed. iii) An axial stack of cines covering the RV provides the best identification of the tricuspid valve plane. A short-axis stack of cines is best for delineating the inferior wall. iv) Endocardial borders are contoured at enddiastole and end-systole (Fig. 2). v) The RV end-diastolic image should be chosen as the image with the largest RV blood volume.</p>
        <p>For its identification, the full image stack has to be evaluated and one phase has to be identified as end-diastole for all locations. vi) RV end-systolic image should be chosen as the image with the smallest RV blood volume. For its identification, the full image stack has to be evaluated and one phase has to be identified as end-systole for all slices. vii) As for the LV, it may be necessary to review all image slices in the stack to define end-systole. viii)The pulmonary valve may be visualized, and contours are included just up to, but not superior to this level. b) RV volumes i) Total volumes are taken as the sum of volumes from individual 2D slices, accounting for any interslice gap and slice thickness. RV trabeculae and papillary muscles are typically included in RV volumes. c) RV mass is usually not quantified in routine assessment.</p>
        <p>In selected patients, quantification of RV mass may be considered (e.g., in pulmonary hypertension). d) Confirmation of results i) If no shunts or valvular regurgitation is present, the RV and LV stroke volumes should be nearly equal (small differences are seen as a result of bronchial artery supply and papillary muscle inclusions in the measurements). Since the LV stroke volume is more reliably determined than the RV stroke volume, the LV data can be used to validate RV data.</p>
        <p>Visual analysis a) Workflow: i) Display perfusion and corresponding LGE images side-by-side. ii) Adjust window, contrast and brightness level for an optimized contrast within the LV myocardium (not the entire image). The aim of image adjustment is to set a maximal window width without "spilling" of the LV cavity signal into the myocardium. Ensure that myocardium before contrast arrival is nearly black and that the window settings maximize the contrast within the myocardium. Note that that the correct level and window settings requires review of both pre-and peak contrast images. iii) Apply the same contrast, brightness and window settings to all images of the dynamic series. iv) Review series as cines and/or by scrolling through individual images. v) Check that there was an adequate haemodynamic response to stress by reviewing the heart rate and blood pressure change between stress and symptomatic response to stress. Images may also be checked for 'splenic switch off' during stress [19]. vi) The key diagnostic feature for identifying a perfusion defect is the arrival and first passage of the contrast bolus through the LV myocardium. vii) Visual analysis is based on a comparison between regions to identify relative hypoperfusion. Comparison should be made between endocardial and epicardial regions, between segments of the same slice and between slices. b) Stress images alone may permit the diagnosis of inducible perfusion defects. When the diagnosis is unclear based on stress images alone and rest images are available, these two image series can be compared. In general, an inducible perfusion defect will be present on the stress, but not the rest images. If perfusion defects are seen on both stress and rest images, they may be artifacts or have other causes such as myocardial scar. Note that artifacts may be less pronounced or absent on rest compared with stress images due to differences in haemodynamics and contrast kinetics between stress and rest. c) Scar tissue may not necessarily cause a perfusion defect, especially if rest perfusion is acquired after stress. Scar should therefore always be identified from LGE and not from perfusion images. d) Criteria for an inducible perfusion defect (Fig. 3a): i) Occurs first when contrast arrives in LV myocardium. ii) Persists beyond peak myocardial enhancement and for several RR intervals. iii) Is more than two pixels wide. iv) Is usually most prominent in the subendocardial portion of the myocardium. v) Often manifests as a transmural gradient across the wall thickness of the segment involved: most dense in the endocardium and gradually becoming less dense towards the epicardium. vi) Over time, defect regresses from the subepicardium towards the subendocardium. vii) Is present at stress but not at rest. viii)Conforms to the distribution territory of one or more coronary arteries. e) Interpret location and extent of inducible perfusion defect(s) using AHA segment model [5]. i) Comment on transmurality of perfusion defect [20]. ii) Indicate extent of perfusion defect relative to scar on LGE. f) Criteria for dark banding artifacts (Fig. 3b): A common source of false-positive reports are subendocardial dark banding artifacts [21]. These artifacts have the following characteristics:</p>
        <p>-Are most prominent when contrast arrives in the LV blood pool. -Lead to a reduction in signal compared with baseline myocardial signal whereas a true perfusion defect does not show a decrease in signal compared with baseline. These subtle differences can be hard to appreciate visually. It can therefore be helpful to draw a region of interest (ROI) around the suspected artifact and display its SI-time profile. -Persist only transiently before the peak myocardial contrast enhancement. -Appear predominantly in the phase-encoding direction. Dark banding present at stress and at rest with no corresponding scar on LGE images is also indicative of an artifact [22]. Note however that differences in heart rate and baseline contrast can change the appearance and presence of dark banding between stress and rest perfusion images. Thus, absence of dark banding at rest with typical dark banding at stress should not on its own be considered diagnostic for an inducible perfusion defect.</p>
        <p>g) Pitfalls of visual analysis i) Multi-vessel disease: Visual analysis is based on relative signal differences within an imaged section of the heart. Theoretically, the presence of balanced multivessel disease can result in most or all of the imaged section appearing hypoperfused, which can lead to false-negative readings and needs to be considered in relevant clinical circumstances. In practice, however, truly balanced ischaemia is rare and a perfusion defect in one or more territories will be more prominent. Even if all coronary territories are affected, the severity of the observed defects typically is more pronounced around the geographic center(s) of the coronary territories. In addition, a clear endocardial to epicardial signal gradient is usually seen in multi-vessel disease [23]. Quantitative analysis of the dynamic perfusion data may be of further help to detect globally reduced myocardial perfusion reserve in multi-vessel disease. ii) Microvascular disease: Diseases that affect the myocardial microvasculature (e.g., diabetes mellitus, systemic hypertension) may lead to a global subendocardial reduction in perfusion [24][25][26][27]. This can lead to false-positive readings relative to angiographic methods and needs to be considered in relevant clinical circumstances.</p>
        <p>Features suggesting microvascular disease are the presence of concentric LV hypertrophy and a concentric, often subendocardial perfusion defect crossing coronary territories. Differentiation from multi-vessel disease can be challenging. iii) If vasodilation during stress data acquisition was inadequate, visual analysis may lead to false negative interpretation of the perfusion study [28]. iv) The distance of the myocardium to the surface coil affects signal intensity and may lead to misinterpretation if not considered in the analysis. These problems are less likely if acquisition is corrected for coil sensitivity.</p>
        <p>a) A quantitative analysis of the SI change in myocardial perfusion CMR studies can be performed. Several methods have been described for this purpose. In clinical practice, these are rarely required, but they may supplement visual analysis for example in suspected multi-vessel disease or suspected inadequate response to vasodilator stress. Fully automated methods for quantitative perfusion analysis are becoming available and may soon become more widely used. Quantitative analysis is also frequently used in research studies. b) Requirements: i) Validation and definition of a normal range with the specific pulse sequence and contrast regime used for data acquisition. If only a comparison between regions of the same study is made, establishing a normal range is less relevant. ii) A temporal resolution of one RR interval is recommended. iii) Consideration of potential saturation effects (higher contrast agent doses are more likely to lead to saturation effects). c) Semi-quantitative analysis: i) Analysis methods that describe characteristics of the SI profile of myocardial perfusion CMR studies without estimating myocardial blood flow are typically referred to as "semiquantitative analysis methods". ii) Workflow:</p>
        <p>-Select an image from the dynamic series with good contrast between all cardiac compartments (some post-processing tools generate an average image of the series). -Outline LV endocardial and epicardial contours on this image (manual or automated) (Fig. 3c). -Propagate contours to all other dynamic images. -Correct contour position for in-plane motion (some analysis packages register images prior to contours being outlined). -Depending on the type of analysis to be performed, place a separate ROI in the LV blood pool. Preferably, the basal slice is used. Exclude papillary muscles and flow artifacts from the ROI. -Select a reference point in the LV myocardium for segmentation (usually one of the RV insertion points) [5].</p>
        <p>-Segment LV myocardium according to AHA classification [5] -Generate SI / time profiles for myocardial segments +/-LV blood pool. -Consider generating division into endocardial and epicardial layers and repeat analysis [20]. iii) Frequently used semi-quantitative analysis methods (see [29] for detailed review):</p>
        <p>-Maximal upslope of the myocardial SI profile, may be normalized to LV upslope [30]. -Time to peak SI of the myocardial SI profile [31,32]. -Ratio of stress/rest values for the above (often referred to as "myocardial perfusion reserve index") [33,34]. -The upslope integral (area under the signal intensity-time curve) [35]. iv) Limitations of semi-quantitative analysis methods:</p>
        <p>-SI may vary according to distance from coil. This can be partially corrected by using a pre-contrast proton density image or other coil sensitivity correction tools. -No absolute measurement of myocardial blood flow given. d) Quantitative analysis i) Analysis methods that process the SI profile of myocardial perfusion CMR studies to derive estimates of myocardial blood flow are typically referred to as "quantitative analysis methods" [29,36,37]. ii) Requirements:</p>
        <p>-It is a prerequisite for reliable quantification that data acquisition used an appropriate pulse sequence and contrast regime. -The requirements for the acquisition method depend on the analysis method. Currently, this typically requires at least a proton density image, the generation of an input function which is not saturated by using dual bolus [38] or dual contrast [39]. -Motion correction to correct for respiratory motion is preferable. iii) Workflow:</p>
        <p>-Manual analysis methods require contour placement as described above for semiquantitative analysis. Dynamic SI data are then typically exported to off-line workstations for further processing. -Fully automated methods are becoming available, which generate pixel-wise maps of myocardial perfusion without user input. iv) Several analysis methods have been described, including:</p>
        <p>-Model-based methods [40,41].</p>
        <p>-Model-independent methods [42,43].</p>
        <p>Post should not be a single image intensity). ii) Note, on magnitude (not phase-sensitive inversion recovery [PSIR]) images, if normal myocardium has a faint "etched" appearance (darkest at the border with slightly higher image intensity centrally), this signifies an inversion time that was set too short and will lead to underestimation of the true extent of LGE (Fig. 4). In general, an inversion time that is slightly too long is preferred to one that is slightly too short [44]. c) Criteria for presence of LGE.</p>
        <p>i) High SI area that is visibly brighter than "nulled" myocardium. ii) Verify regions with LGE in at least one other orthogonal plane and/or in the same plane obtain a second image after changing the direction of readout. d) Assess pattern of LGE i) Coronary artery disease (CAD) type: Should involve the subendocardium and be consistent with a coronary artery perfusion territory. ii) Non-CAD-type: Usually spares the subendocardium and is limited to the mid-wall or epicardium, although non-CAD-type should be considered if subendocardial involvement is global [45]. e) Interpret location and extent using AHA 17-segment model [5] [20]. i) Comparison of LGE images should be made with cine and perfusion images (if the latter are obtained) to correctly categorize ischemia and viability [46]. ii) Estimate average transmural extent of LGE within each segment (0%, 1-25%, 26-50%, 51-75%, 76-100%) [44]. iii) In patients with acute myocardial infarction, include subendocardial and mid-myocardial hypoenhanced no-reflow zones as part of infarct size. (regions below the zero-crossing) may appear enhanced [44,48]. iii) Occasionally, it can be difficult to distinguish no reflow zones or mural thrombus from viable myocardium. Imaging using a long-inversion time [49], using PSIR, or performing post-contrast cine imaging may be helpful in this regard. iv) In case of reduced contrast, the interpretation of additional sequences may be necessary (see below section "Dark-blood/grey blood LGE"). v) In PSIR images manual windowing and quantification algorithms may behave differently when compared with magnitude images.</p>
        <p>a) Quantitative analysis is primarily performed to measure LGE extent and/or grey-zone extent for research purposes. Subjective visual assessment is still a prerequisite to identify poor nulling, artifacts, noreflow zones, etc., and to draw endocardial and epicardial borders. b) Multiple different methods of delineating LGE extent are described in the literature including the following: manual planimetry, the n-SD technique, and the full width half maximum (FWHM) technique. As the research applications are evolving and consensus evidence is being accumulated, the Task Force chooses to refrain from making a dedicated statement at this time regarding the optimal method for quantitative assessment [50][51][52][53][54][55].</p>
        <p>Research tools / quantitative analysis a) Quantification of LGE extent: i) Manual planimetry:</p>
        <p>-Outline endocardial and epicardial borders.</p>
        <p>-Manual planimetry of LGE regions in each slice.</p>
        <p>-Summation of LGE areas.</p>
        <p>- LGE image, normal myocardium has a faint "etched" appearance (darkest at the border with higher signal intensity centrally) signifying an inversion time that was set too short and which will lead to underestimation of LGE. On the right panel, the image was repeated with a longer inversion time and demonstrates a larger LGE zone in the inferior wall. For non-PSIR magnitude imaging, always use the longest inversion time possible that still nulls normal myocardium vary dependent on contrast agent type, dose and time after injection, field strength, type of sequence and other variables including the underlying injury itself. As such, there is no cutoff value which works for all situations and usually manual tracing is performed as the standard of truth. But (semi-) automated thresholding may improve reproducibility after adequate standardization. As a starting point for semiautomatic thresholding we recommend 5-SD for infarction. There is currently not enough evidence to provide a cut-off for non-ischemic LGE. -The presence of LGE within the myocardium is then determined automatically. -Requires manual corrections to include noreflow zones and to exclude artifacts and LV blood pool (errors in the endocardial contour). iii) FWHM technique:</p>
        <p>-Manual outlining of endocardial and epicardial borders for the myocardial ROI. -Uses the full width of the myocardial ROI SI histogram at half the maximal signal within the scar as the threshold between normal myocardium and LGE. -Visual determination whether LGE is present or not, and, if LGE is present, manual selection of a ROI that includes the region of "maximum" signal. This subjective selection can affect measurements. -Is also susceptible to spatial variations in surface coil sensitivity, albeit perhaps less so than the n-SD technique [51]. -Considered more reproducible than the n-SD technique [53]. -Since the technique assumes a bright LGE core, it may be less accurate than the n-SD technique if LGE is patchy or grey [56]. -Requires manual corrections to include noreflow zones and to exclude artifacts and LV blood pool (errors in the endocardial contour). b) Peri-infarct zone:</p>
        <p>-Multiple methods for quantifying the extent of the peri-infarct or grey zones are reported [57,58]. -The Task Force does not endorse any specific evaluation technique due to the strong impact of partial volume effects. c) Dark-blood/grey blood LGE -Multiple techniques are described in the literature but one that is "flow-independent", (i.e., does not rely on blood flow to suppress blood-pool signal) is preferable [59][60][61].</p>
        <p>-As the research application(s) are evolving and consensus evidence is being accumulated, the writing group chooses to refrain from making a dedicated statement at this time regarding the optimal method for quantitative assessment of dark-blood/grey blood LGE images.</p>
        <p>There is increasing evidence about LGE imaging of the RV, which is usually captured with standard LGE protocols imaging the LV. Imaging the thin LA wall is difficult and requires specialized sequences. As the applications are evolving and consensus evidence is being accumulated, the writing group chooses to refrain from making a dedicated statement at this time regarding the post-processing assessment of LGE in chambers other than the LV.</p>
        <p>In 2013, the "T1 Mapping Development Group" published a consensus statement that proposed suitable terminology and specific recommendations for site preparation, scan types, scan planning and acquisition, quality control, visualization and analysis, and technical directions [62]. Building on this initiative, the Consensus Group on Cardiac MR Mapping has formed itself and published in 2017 "Clinical recommendations for CMR mapping of T1, T2, T2* and extracellular volume: A consensus statement by the Society for Cardiovascular Magnetic Resonance (SCMR) endorsed by the European Association for Cardiovascular Imaging (EACVI)" [63]. The following recommendations refer to these consensus statements. For more details regarding when and how to use T1 mapping, refer to this original consensus statement as well as to the SCMR protocol recommendations (Fig. 5).</p>
        <p>a) The visual analysis of the series of differently T1weighted source images should aim to detect and verify diagnostic image quality. b) The visual analysis of the final T1 map should aim to detect artifacts and verify diagnostic image quality. Automatically generated quality control maps (e.g., T1*) may be used to exclude misregistration or significant artifacts. c) Maps may be displayed in color if the pertinent look-up tables are set according to site-specific ranges of normal, or in gray scale in combination with appropriate image processing, to highlight areas of abnormality. ROIs should be validated. e) Drawing ROIs on greyscale images rather than color maps may reduce bias. f) For assessing diffuse disease, focal fibrosis as assessed by LGE imaging should be excluded from the ROI. g) There is currently no specific recommended / preferred analysis software package. The image reader should be trained with the local standards and with the analysis software package of choice and be familiar with the appearance of artifacts. h) The sensitivity of mapping techniques to confounders such as heart rate and magnetic field inhomogeneities should be considered during interpretation.</p>
        <p>i) Extracellular volume (ECV) estimation requires T1 mapping acquisitions before contrast agent administration (native T1) and after contrast agent administration (typically &gt; 10 min post-contrast to approach steady-state conditions). The proposed post-processing steps should be applied equally to both maps. j) For calculating ECV, a ROI in the center of the blood pool in the native and in the post-contrast T1 map should be drawn excluding papillary muscles and trabeculae. k) For calculating ECV, hematocrit of the same day should be available. If this is not available, hematocrit may be estimated from native values of blood pool T1 ("synthetic ECV") [65]. l) ECV is given in %. The formula for calculating ECV:</p>
        <p>m) Inline ECV maps can be a useful alternative to manual ECV calculations. The raw images should be checked to verify a diagnostic image quality and processing. n) For clinical reports, the type of pulse sequence, reference range, and type/dose of gadolinium contrast agent (if applied) should be quoted. o) Mapping results should include the numerical absolute value, the Z-score (number of standard deviations by which the result differs from the local normal mean; if available), and the normal range of the CMR system. p) Local results should be benchmarked against published reported ranges, but a local reference range should be primarily used. q) Reference ranges should be generated from data sets that were acquired, processed, and analyzed in the same way as the intended application, with the upper and lower range of normal defined by the mean ± 2 SD of the normal data, respectively. r) Parameter values should only be compared to other parameter values if they are obtained under similar conditions. In other words, the acquisition scheme, field strength, contrast agent and processing approach should be the same, and the results should be reported along with corresponding reference ranges for the given methodology. Post-processing of T2-weighted imaging</p>
        <p>a) The visual analysis T2-weighted images aims for detecting or excluding regions with significant SI increase, as a marker for an increased free water content (edema). b) Qualitative, visual analysis of myocardial SI may be sufficient for diseases with significant regional injury to the myocardium, such as acute ischemic injury/infarction, acute myocarditis (Fig. 6), stressinduced (Takotsubo) cardiomyopathy, and sarcoidosis. c) Workflow: i) Identify and display appropriate image(s).</p>
        <p>ii) Modify image contrast and brightness in the myocardial tissue to minimize SI in the most normal appearing myocardium (noise should still be detectable there) and to maximize the maximal SI displayed in the myocardium area without allowing for "over-shining", i.e., displaying non-white pixels as white. iii) Check for artifacts (typically SI changes crossing anatomical structures). d) Criteria for edema: i) Clearly detectable high SI area respecting anatomical borders. ii) Follows an expected regional distribution pattern (transmural, subendocardial, subepicardial, focal). iii) Verifiable in two perpendicular views. e) High SI areas suggestive of myocardial edema should be compared to i) regional function.</p>
        <p>ii) other tissue pathology such as scar/fibrosis and infiltration. f) Pitfalls of visual analysis: i) Surface coil reception field inhomogeneity: The uneven distribution of the sensitivity of the receiving surface coil may lead to falsely low SI in segments distant to the coil or falsely high SI in segments close to the coil surface, especially in dark-blood triple-inversion recovery spin echo (STIR, TIRM) images. If no efficient SI correction algorithm for balancing the signal intensity across the reception field is available, the body coil, albeit with a lower signal-to-noise ratio, provides a more homogeneous signal reception. ii) Low SI artifacts: Arrhythmia or through-plane motion of myocardium may cause artifacts, making areas appear with falsely low SI, especially in darkblood triple-inversion recovery spin echo images. iii) High SI artifacts: In dark-blood triple-inversion recovery spin echo images, slow flowing blood may lead to insufficient flow suppression and results in high SI of blood, typically along the subendocardial border. This can be confused with myocardial edema.</p>
        <p>Semi-quantitative analysis a) Because low SI artifacts can lead to SI distribution patterns that may mimic extensive myocardial edema, a mere visual analysis may lead to incorrect results. SI quantification with reference regions is much less sensitive to these errors and therefore is recommended. b) Requirements: i) Tested normal values for SI values or ratios. c) Workflow i) Global SI analysis:</p>
        <p>-Outline LV endocardial and epicardial contours. -For the T2 SI ratio, draw the contour for a ROI in a large area of the skeletal muscle closest to the heart and to the center of the reception field of the coil (for short axis views preferably in the M. serratus anterior [66]. ii) Regional SI analysis:</p>
        <p>-Draw the contour for a ROI in the affected area and divide the SI by that of the skeletal muscle. iii) While a cut-off of 1.9 can be used for dark blood triple-inversion recovery spin echo [67], a locally established value is recommended, because SI and ratio values may vary between settings (especially echo time (TE)) and CMR scanner models. For these images, a color-coded map, based on the parametric calculation and display of myocardial pixels with a SI ratio of 2 or higher, can also be used.</p>
        <p>The Consensus Group on Cardiac MR Mapping published in 2017 "Clinical recommendations for CMR mapping of T1, T2, T2* and extracellular volume: A consensus statement by the Society for Cardiovascular Magnetic Resonance (SCMR) endorsed by the European Association for Cardiovascular Imaging (EACVI)" [63]. The following recommendations refer to this consensus statement. For more details regarding when and how to use T2 mapping, refer to this original consensus statement as well as to the SCMR protocol recommendations.</p>
        <p>a) The visual analysis of the series of differently T2weighted source images should aim for detecting and excluding artifacts and significant motion. b) The visual analysis of the final T2 map should aim for detecting and excluding artifacts. c) Maps may be displayed in color if the color look up tables are set according to site-specific ranges of normal, or in gray scale in combination with appropriate image processing, to highlight areas of abnormality.</p>
        <p>Quantitative analysis a) For global assessment and diffuse disease, a single ROI should be drawn conservatively in the septum on mid-cavity short-axis maps to reduce the impact of susceptibility artifacts from adjacent tissues. b) In case of artifacts or non-conclusive results on midcavity ROIs, basal ROIs can be used for validation. c) For focal disease, additional ROIs might be drawn in areas of abnormal appearance on visual inspection. Very small ROIs (&lt; 20 pixels) should be avoided. d) ROIs should be checked if generated automatically. e) Drawing ROIs on greyscale instead of color maps may avoid bias. f) Depending on the goal of the analysis, focal fibrosis as assessed by LGE imaging may be excluded from the ROI. g) There is currently no specific preferred analysis software package. The image reader should be trained with the local standards and with the analysis software package of choice and be aware of and familiar with the appearance of artifacts. h) Sensitivity of mapping techniques to confounders such as heart rate and magnetic field inhomogeneities should be considered during interpretation. i) Mapping results should include the numerical absolute value, the Z-score (number of standard deviations by which the result differs from the local normal mean), and the normal reference range. j) Parameter values should only be compared to other parameter values if they are obtained under similar conditions. In other words, the acquisition scheme, field strength and processing approach should be the same, and the results should be reported along with corresponding reference ranges for the given methodology.</p>
        <p>Visual analysis T2* imaging always requires a quantitative analysis. Visual analysis is used to ensure adequate image quality, which is the most important factor for the accuracy of data analysis.</p>
        <p>a) Evaluation of T2* always requires a quantitative analysis using software with regulatory approval for T2* evaluation in patients. b) Full thickness ROI located in the ventricular septum i) Septal ROI is drawn on mid-LV short-axis image. ii) Take care to avoid blood pool and proximal blood vessels. iii) A septal ROI avoids susceptibility artifact from tissue interfaces. c) Mean myocardial SI from the ROI is plotted against TE (Fig. 7) i) SI falls with increasing TE. ii) Curve fitting should apply a validated algorithm.</p>
        <p>iii) The time for the decay of SI falls (shorter T2*) with increasing iron burden. iv) In heavily iron overloaded patients, SI for higher TEs may fall below background noise causing the curve to plateau and underestimating T2*. v) This can be compensated for by:</p>
        <p>-Truncating the curve by removing later echo times (Fig. 7e) [68,69]. -This issue is not significant when using the double inversion recovery (black blood) sequence [70]. d) Cut-off values at 1.5 Tesla: i) Normal cardiac T2* is 40 ms [71] ii) T2* &lt; 20 ms indicates iron overload [72] iii) T2* &lt; 10 ms indicates increased risk of development of heart failure [73] e) CMR assessment of T2* at 3 T for assessment of iron overload cardiomyopathy cannot be recommended at this time. T2* shortens with increasing field strength making assessment of severe iron overload more problematic, and there is a lack of clinical verification.</p>
        <p>Background CMR flow imaging provides information about blood flow velocities and volumes, and enables the visualization of blood flow. Flow assessment in a 2D slice is in widespread use. Recently, temporally resolved flow evaluation in a 3D volume (4D flow) has evolved enormously. It is currently predominantly used for evaluating congenital heart disease. For further details regarding application, acquisition and postprocessing of 4D flow also refer to the corresponding consensus document [74].</p>
        <p>Visual analysis a) Appropriately aligned acquisitions of cines and stacks of cines can give valuable information on flow in relation to adjacent structures, notably on the directions, time courses and approximate dimensions of jets resulting from valve regurgitation, stenoses or shunts. Such information can be important in assessing the credibility of measurements of flow, which may be subject to several possible sources of error. Gradient echo cines differ somewhat from balanced steady state free precession (bSSFP) in terms of degrees of signal augmentation or reduction attributable to flow effects. Of note, bSSFP can provide clear delineation between the relatively bright signal from voxels aligned within the coherent core of a jet, and low signal from the shear layer that bounds such a jet core. In-or through-plane phase contrast flow velocity acquisitions can also provide visual information on the directions, dimensions and time courses of flow; it can also image morphology, which can yield a clue to the etiology of an abnormal jet [75,76]. It is also often used in congenital heart disease.</p>
        <p>Color flow mapping in post-processing software may be useful in determining directionality of the jet or morphology. b) Pitfalls: i) Flow appearances on both cine and phase encoded acquisitions are highly dependent on image location and orientation, especially in the case of jet flow. ii) Check for the appropriate velocity encoding. If the range of velocity encoding (VENC) is set too high, visualization of the jet may not be obtained and may be inaccurate as well as having poorer SNR. If it is set too low, a mosaic pattern on the images will be visualized [77]. iii) If slice thickness is too large on in-or throughplane velocity mapping, the higher velocities will be "averaged out" with the lower velocities and stationary tissue; jets and flow may not be visualized correctly. iv) If the annulus of valves is very dynamic or the imaging plane is not set correctly, the valve morphology may not be visualized. v) If imaging in the presence of metal containing devices, signal loss may be present as artifact and interpretation must proceed with caution. vi) Check for appropriate spatial and temporal resolution. For spatial resolution, 8 to 16 pixels should fill the vessel to obtain accurate results on through-plane velocity mapping. For temporal resolution, there should be at least 11-16 frames per cardiac cycle [78].</p>
        <p>Quantitative analysis a) Workflow: i) Through-plane measurements may be supplemented by in-plane measures if needed. ii) Review phase and magnitude images side by side. Window the magnitude and phase images to the appropriate brightness and contrast so that the borders of the ROI are sharp. iii) Examine the images to ensure the quality is sufficient and that the VENC was not exceeded, or there is little contrast (i.e., the VENC was too high). iv) Trace the borders of the vessel of interest on each phase and magnitude image so that only the cavity of the vessel is included (Fig. 8); make sure the noise outside the vessel is not included. Check that this is performed correctly on the magnitude images always keeping in mind that it is the phase images that contain the encoded information. v) Baseline-correction may be considered. As the utility and exact methods are not yet established, the writing group chooses to refrain from making a dedicated statement at this time regarding its use. vi) Directly calculated parameters include antegrade and retrograde volume, flow rate, peak and mean velocity. i) On the phase images, the area of flow may be slightly larger than the area of the magnitude images. Care has to be taken when evaluating the magnitude imagesthe size of the ROI has to be adapted. ii) If the VENC is exceeded, some software packages allow for adjusting the "dynamic range" of the velocity scale so that the VENC is not exceeded. For example, if the peak velocity in the aorta is 175 cm/s and the VENC was set at 150 cm/s, the dynamic range is between -150 cm/s and + 150 cm/s (i.e., 300 cm/s). This may be moved to -100 cm/s and + 200 cm/s to account for this accelerated velocity. This will be demonstrated on the graph of the velocity where the phase in which the VENC is exceeded does not "alias" (appears to go the wrong way) after correction. iii) In general, the area that exceeds the VENC in the ROI is in the center of the vessel and not at the edges; if it is at the edges, it is usually (but not always) outside the vessel. iv) If imaging in the presence of devices, signal loss may be present as artifact and interpretation must proceed with caution [80]. v) When measuring peak velocity, some software packages will determine the peak velocity in one pixel in the ROI whereas others may take the peak velocity of the average of a few adjacent pixels in the ROI. By reporting the peak velocity in a single pixel, noise may make this measurement inaccurate. By reporting this as an average of a few adjacent pixels, noise is less of an issue, however, the true peak velocity may be higher than the reported value. These factors must kept in mind and interpretation may need to be adapted to the measurement technique used. vi) When attempting to measure peak velocity using through-plane velocity mapping along a vessel, interpretation should be tempered by the notion that this parameter may be an underestimate as the true peak velocity lies somewhere along the vena contracta; the through-plane velocity map may not have been obtained at the level of the true peak velocity. If the vena contracta is itself narrow or ill defined, jet velocity mapping is unlikely to be possible. vii) Peak velocity is only minimally affected by small background phase offsets, while volume measurements can be dramatically affected by even a small background phase offset due to the cumulative aspect of integration overspace (within the ROI) and time (over the cardiac cycle). Dilatation of a vessel tends to increase error of this type [81]. viii)Orientation of the image plane perpendicular to flow direction can have a significant impact on peak velocity measurement, while not significantly affecting volume flow [78]. ix) Internal consistency may be used to partially assess the accuracy of measurement (e.g., the sum of the flows in the branch pulmonary arteries should sum to the flow in the main pulmonary artery, and comparing the stroke volume obtained by flow measurement with the stroke volume obtained by volumetry of cine images).</p>
        <p>a) Real time velocity mapping: The utility and postprocessing algorithm best applied to this approach is the subject of ongoing research.</p>
        <p>Post-processing of angiography of thoracic aorta, pulmonary arteries and veins Visual analysis a) MIP for first review of 3D data and for demonstration purposes (Fig. 9). Volume rendered (VR) techniques may be used for demonstration purposes, but not for quantitative analysis. b) Aorta [82,83]: i) Wall thickness: Review bSSFP or turbo spin echo images. Avoid measurement in areas with artifacts that may distort anatomy, such as chemical shift artifacts. ii) Wall irregularities: Review 3D-MRA source images and bSSFP or turbo spin echo. c) Pulmonary arteries [84]: i) Multiplanar double oblique and targeted MIP reconstructions for assessment of wall adherent thrombi, emboli, wall irregularities and abrupt diameter changes. d) Pulmonary veins [85]: i) Assess for atypical insertion, small accessory veins and ostial stenoses. e) Coronary arteries: i) Coronary MRA (either contrast-enhanced or non-contrast MRA using 3D whole heart bSSFP) can play a role in assessment of congenital anomalies [86], but not usually in the context of ischemic heart disease. The origins, branching patterns, and course of coronary Quantitative analysis a) Aorta: i) Diameters of the aorta are measured on double oblique MPR of source images perpendicular to the vessel centerline at standardized levels (Fig. 10) [87]. In oval shaped vessels the longest diameter and its perpendicular diameter shall be reported. Both, inner (lumen) or outer (external vessel wall) diameter may be measured. This should be included in the report, as well as the type of angiography (with or without contrastenhancement). Measurement of outer contour is recommended in dilation such as in aneurysms, while the inner contour is recommended in the setting of stenosis, such as in coarctation. ii) In the presence of wall thickening (e.g. thrombus or intramural hematoma) inner and outer diameter including vessel wall thickness should be reported. iii) Aortic root measurements require ECG-gated images. Diameter of the sinus portion should be recorded as the maximum sinus to sinus measurement perpendicular to the vessel centerline.</p>
        <p>For more details and normal values refer to [82]. iv) Standardized structured reports with tables of diameters are helpful for reporting follow-up examinations. b) Pulmonary artery: i) Diameters are measured on double oblique images perpendicular to the centerlines of the pulmonary trunk as well as right and left pulmonary arteries. It should be reported whether the inner or outer contour was measured. In oval shaped vessels the longest diameter and its perpendicular diameter shall be reported, with measurement during systole recommended. Alternatively, cross-sectional area may be measured. For normal values refer to [84]. c) Pulmonary veins: i) Double oblique MPR of pulmonary veins perpendicular to centerline for diameter measurements. For a more comprehensive assessment including flow measurements refer to [85].</p>
        <p>Scott D. Flamm: Dr. Flamm acknowledges institutional grant/research support from Siemens Healthineers and Philips Healthcare. Mark A. Fogel: Two NIH RO1 grants, grant from Siemens develop functional fetal cardiac MR, grant from Edwards Life Sciences -CMR Core lab for COMPASSION trial and Kereos -Medical Monitor for P19 imaging agent. Matthias G. Friedrich: Dr. Friedrich is partially funded by the Canadian Foundation for Innovation and the Fonds de Recherche Santé Québec Christopher M. Kramer: Dr. Kramer acknowledges consultancy for Bayer Dudley J. Pennell: This work was supported by the NIHR Cardiovascular Biomedical Research Unit of Royal Brompton &amp; Harefield NHS Foundation Trust and Imperial College. Sven Plein: Dr. Plein acknowledges research support from Philips Healthcare Eike Nagel: Dr. Nagel acknowledges financial support from the German Ministry of Education and Research and the Hesse Ministry of Arts and Science via the German Centre for Cardiovascular Research (DZHK). Grant support from Bayer Healthcare.</p>
        <p>The authors declare that they have no competing interests.</p>
        <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </text>
</tei>
  <tei>
<teiHeader>
<fileDesc id="f365584111"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:09+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The copyright of individual parts of the supplement might differ from the CC BY 4.0 License.</p>
<p>The coverage of FAO's Global Administrative Unit Layers (GAUL) is generally sufficient, despite some inconsistencies and incorrect assignments of administrative levels:</p>
<p> The Bangladesh district Pirojpur is classified as belonging both to the Barisal division (which is correct) and the Khulna division (which is incorrect). The correct name of the district in the Khulna division is Bagerhat. Adjustments to the name for Bagerhat were made within the main code-link table, rather than the GAUL shapefile.</p>
<p> In India the larger portion of Arunachal Pradesh is classified as 'disputed' area and considered as a 'country', which leaves Arunachal Pradesh with too few ADM2 units.</p>
<p> Algeria has 1,541 ADM2 units (districts) in GAUL, which in Algeria's official publications were classified as ADM3 units (municipalities). SPAM2010 only has data for Algeria at ADM0 and ADM1 levels.</p>
<p>GAUL identified ADM2 units for China by numbers rather than explicit names. Thus, we opted to use the Database of Global Administrative Areas (GADM) Version 1 shapefiles for China, and attributed any overlaps between China (as designated by GADM) and neighboring countries (as designated by GUAL) to the neighbors (i.e., took some area away from China). For example, Disputed areas like Kashmir were not included in SPAM2010.</p>
<p>The country-specific administrative level used for the model is defined as the statistical reporting unit (SRU).</p>
<p>For most countries SPAM is run at an ADM0 level, because of the SRUs are not universally available at the ADM1 level. Table S1 lists the countries which were modelled at an ADM1 level (SRU=k1). All countries not listed in this table were modelled at an ADM0 level (SRU=k0).</p>
<p>Table S1 Countries modeled at an ADM1 level statistical reporting unit (SRU)</p>
<p>Data sources for crop statistics include FAOSTAT, EUROSTAT, CountrySTAT, ReSAKSS, national statistical offices, ministries of agriculture or planning bureaus of individual countries, household surveys and a variety of ad hoc reports related to a particular crop within a particular country. The data sources are slightly different between SPAM2005 (Wood-Sichra et al., 2016) and SPAM2010 (see details in Table S2).</p>
<p>When individual countries reported on a crop of which the FAOSTAT category was not immediately apparent, efforts were made to identify the English name of the crop and assign it to the appropriate category. Table S3 lists the SPAM2010 crops and their respective FAO code. The list is comprised of 33 individual crops (millet and coffee are each split into two sub-categories) and crop aggregates. For millet and coffee we used countrylevel data to determine the shares in the respective sub-categories, and partitioned FAO's country totals accordingly. 515,521,523,526,530,531,534,536,541,542,544,547,549,550,552,554,558,560,592 358,366,367,372,373,388,393,394,397,399,401,402,406,407,414,417,420,423,426,430,446,449,459,461 216,217,220,221,222,223,224,225,226,234,671,677,687,689,692,693,698,702,711,720,723,748,754,836,839 Non-Food Source: Developed using information from FAOSTAT (FAO 2015).</p>
<p>Note: ++ indicates that all crops identified by the FAO code in the adjacent column are also assigned to the respective SPAM2010 crop. For example, "Yautia ++" would read "Yautia, Taro, Roots and Tubers, nes". a Also known as finger millet which includes foxtail, proso, japanese and Kodo varieties.</p>
<p>SPAM2010 calculations were based on the 2009-2011 average of the crop production statistics. All efforts were made to collect statistics from these three years, but if data was missing from this time period the average was calculated from the available data spanning the years 2005 to 2015: [2009,2011] where 𝑘 0 , 𝑘 1 , 𝑘 2 ∈ 𝑘, 𝑚 1 , … , 𝑚 𝑛 are the set of years with data available on crop 𝑗 and administrative unit 𝑘 closest to the 2009-2011 time period (but not earlier than 2005 or later than 2015), 𝑛 was the total number of years used to calculate the average for crop 𝑗 and administrative unit 𝑘.</p>
<p>Note: Average statistics on yield were always taken as a harvested area weighted average</p>
<p>To improve the comparability of the crop production statistics and better align the sub-national data with data derived from the cropland and irrigation maps, we adjusted all national and sub-national statistics using the national 2009-2011 average from FAO (AvgFAOCropHPYjk0) by crop j and country k0:</p>
<p>i. National (ADM0) harvested area (H), production (P) and yield (Y) statistics</p>
<p>ii. Sub-national (ADM1 or ADM2) harvested area (H), production (P) and yield (Y) statistics</p>
<p>In situations where a country only reported one of the three variables for a crop (i.e., harvested area, production or yield), we used FAO national statistics (AvgFAOCropHPYjk0) to infer the missing variables.</p>
<p>Issues of measurement might arise because FAO occasionally updates historical data without documenting which years or crops were changed. This can lead to inconsistencies when users compare SPAM2010 results with published FAO numbers which have been retroactively adjusted since the version used in SPAM2010.</p>
<p>The four farming systems are referred to as irrigated</p>
<p>To run, the model requires knowledge of the share of area cropped by each farming system l, crop j and administrative unit k (Percentjlk); where l = (I, H, L, S). Farming system shares were constructed either at the k = k0 (ADM0 level) or k = k1 (ADM1 level) depending on country's SRU.</p>
<p>The share of crop area and production belonging to each of these farming systems when total area and production are given is often times hard to come by. We rely extensively on expert judgment, but some documented assessments were assembled from household surveys, FAO publications and publications from national statistical offices. It was often necessary to use farming system shares from one crop as proxies for similar crops (e.g., farming system shares for beans were used for all pulses) or shares from one country and apply them to similar countries (e.g., Kuwait, Oman and Qatar were assigned the same farming system shares).</p>
<p>For a small number of large countries, listed in Table S4, we were able to source data on farming system shares at the ADM1 level. For the remaining countries we first assigned the national farming system shares to each ADM1 level, and then adjusted individual ADM1 farming system shares in light of the supporting evidence.</p>
<p>For example, if the national share for irrigation of wheat was 30 percent, we assigned that to all ADM1 units.</p>
<p>Then we looked at individual units, and if supporting evidence (e.g., the Global Map of Irrigation Areas (GMIA) data) indicated that there was no irrigated area present in a particular AMD1 unit, we set the irrigation share of wheat to zero in that administrative unit. Finally the farming system shares at national level were recalculated as the weighted average of the adjusted ADM1 estimates. Source: Developed by authors using data from AQUASTAT and MIRCA (Portmann et al., 2010), the FAO's World Agriculture: Towards 2015/30 report and expert judgment.</p>
<p>Note: Farming systems -irrigated (I); rainfed (R). Farming system shares for rainfed production are an area weighted average of rainfed high input, rainfed low input and rainfed subsistence production. Shares of rain fed production are the sum of production under rain fed -high inputs, low inputs and subsistence and have been aggregated for this table only.</p>
<p>To run the model requires disaggregate harvested area (AdjCropHjk) and yield (AdjCropYjk) for each of the four farming systems. Harvested area by farming system l (AdjCropHjlk) was calculated as follows:</p>
<p>i. National (ADM0) harvested area (H) statistics</p>
<p>ii. Sub-national (ADM1 or ADM2) harvested area (H) statistics</p>
<p>Yields by farming system l were more complicated to calculate. These computations used the farming system shares (Percentjlk) and the yield conversion factors (αIRRjk0, αHLRjk0) to calculate an AdjCropYjlk variable for both national and subnational yield AdjCropYjk statistics. The relevant yield conversion factors included yield ratios for irrigated versus rainfed systems (αIRRjk0) and rainfed -high versus rainfed -low systems (αHLRjk0).</p>
<p>In many instances we used expert judgement to define these factors. Occasionally data was available from reported statistics or field trials (e.g., rainfed -high input/low input ratios were calculated from trials that compared yields with fertilizer applications to those without). Additionally, some yield conversion factors were applied from similar crops (e.g., lentil factors used for 'other pulses') or from similar agro-ecological zones and similar countries (e.g., the same factor was used for all humid tropics areas in SSA). 1.9 1.9 --Nigeria R 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0</p>
<p>Source: Developed by authors using data from the FAO's ( 2002) World Agriculture: Towards 2015/30 report and expert judgment.</p>
<p>Note: Farming systems -irrigated (I) lists factor for irrigated vs. rainfed; rainfed (R) lists factor for rainfed high vs. rainfed low.</p>
<p>In order to disaggregating crop yield by farming systems, the following were assumed to hold:</p>
<p>• The observed yield (𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝑘 ), by definition, was the average of input-specific yields weighted by area:</p>
<p>• Weighted rainfed yield, by definition, was equal to the sum of weighted rainfed -high, weighted rainfed -low yield and weighted subsistence yield (subsistence has cancelled out below):</p>
<p>• By definition of 𝛼𝐼𝑅𝑅 𝑗𝑘 0 :</p>
<p>• By definition of 𝛼𝐻𝐿𝑅 𝑗𝑘 0 :</p>
<p>Given the four equations listed above, we can define the following term:</p>
<p>= 𝑘 0 , 𝑘 1 .</p>
<p>(A-5)</p>
<p>Equations A-1 -A-5 were then used to calculate statistical yields by crop 𝑗 and input 𝑙. Depending on the values of 𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐼𝑘 0 , 𝛼𝐻𝐿𝑅 𝑗𝑘 0 and 𝛽 𝑗𝑘 0 , there were three cases for calculating these yields:</p>
<p>Case 1: 𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐼𝑘 0 &lt;&gt; 100 or (𝛼𝐻𝐿𝑅 𝑗𝑘 0 &lt;&gt; 0 𝑎𝑛𝑑 𝛽 𝑗𝑘 0 &lt;&gt; 0):</p>
<p>• The national (ADM0) yield (𝑌) statistics were equal to</p>
<p>𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐼𝑘 0 ×𝛽 𝑗𝑘 0 +𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐻𝑘 0 ×𝛼𝐻𝐿𝑅 𝑗𝑘 0 +1-𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐼𝑘 0 -𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐻𝑘 0</p>
<p>;</p>
<p>𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐼𝑘 0 = 𝛽 𝑗𝑘 0 × 𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐿𝑘 0 ;</p>
<p>𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝑆𝑘 0 = 𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐿𝑘 0 .</p>
<p>• The sub-national (ADM1 or ADM2) yield (𝑌) statistics were equal to</p>
<p>𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐻𝑘 = 𝛼𝐻𝐿𝑅 𝑗𝑘 0 × 𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐿𝑘 , ∀𝑘 = 𝑘 1 , 𝑘 2 ;</p>
<p>𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐼𝑘 = 𝛽 𝑗𝑘 1 × 𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐿𝑘 , ∀𝑘 = 𝑘 1 , 𝑘 2 ;</p>
<p>𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝑆𝑘 = 𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐿𝑘 , ∀𝑘 = 𝑘 1 , 𝑘 2 .</p>
<p>Case 2: 𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐼𝑘 0 = 100 (i.e., no rainfed agriculture)</p>
<p>• National (ADM0) yield (𝑌) statistic</p>
<p>𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐻𝑘 0 = 𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝐿𝑘 0 = 𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝑌 𝑗𝑆𝑘 0 = 0.</p>
<p>• Sub-national (ADM1 or ADM2) yield (𝑌) statistics</p>
<p>Case 3: 𝛼𝐻𝐿𝑅 𝑗𝑘 0 = 0 𝑎𝑛𝑑 𝛽 𝑗𝑘 0 = 0</p>
<p>• National (ADM0) yield (𝑌) statistic</p>
<p>(1-𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐼𝑘 0 + 𝛼𝐼𝑅𝑅 𝑗𝑘 0 × 𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐼𝑘 0 )× 𝑃𝑒𝑟𝑐𝑒𝑛𝑡 𝑗𝐻𝑘 0</p>
<p>;</p>
<p>.</p>
<p>• Sub-national (ADM1 or ADM2) yield (𝑌) statistics</p>
<p>, ∀𝑘 = 𝑘 1 , 𝑘 2 .</p>
<p>The farming system-specific yields were further modified if they fell outside the lower and upper bounds of acceptable yields for each crop and farming system. These minimum ( 𝑀𝑖𝑛𝑌𝑖𝑒𝑙𝑑 𝑗𝑙𝑘 ) and maximum (𝑀𝑎𝑥𝑌𝑖𝑒𝑙𝑑 𝑗𝑙𝑘 ) yields were calculated by crop 𝑗, farming system 𝑙 and administrative unit 𝑘. The minimum yield (for any farming system) was equal to one-tenth of the average adjusted yield:</p>
<p>The maximum yield were either equal to the average adjusted yield or two or three times its value, depending on the farming system:</p>
<p>The resulting minima and maxima used in SPAM2010 were 𝑀𝑖𝑛𝑌𝑖𝑒𝑙𝑑 𝑗𝑙𝑘 and 𝑀𝑎𝑥𝑌𝑖𝑒𝑙𝑑 𝑗𝑙𝑘 and they were reported at ADM0 and AMD1 levels only.</p>
<p>For each crop in a country we needed to establish how often it was harvested per year on the same area, or if it was grown simultaneously with other crops. If data existed on the area harvested per season 𝑠 (𝑆𝑒𝑎𝑠𝐻𝑎𝑟𝑣𝐴𝑟𝑒𝑎 𝑗𝑙𝑘𝑠 ), then it was used to calculate the relevant cropping intensity for that particular crop 𝑗, Physical area (𝐴) by crop 𝑗, farming system 𝑙 and administrative unit 𝑘 was then calculated using the relevant harvested area (𝐴𝑑𝑗𝐶𝑟𝑜𝑝𝐻 𝑗𝑘 ) and cropping intensity (𝐶𝑟𝑜𝑝𝐼𝑛𝑡𝑒𝑛𝑠𝑖𝑡𝑦 𝑗𝑙𝑘 ):</p>
<p>Cropping intensity values were generally one in temperate and cool climates, and for crops which had long growing periods, like sugar cane or oil palm. Cropping intensities were larger than one for irrigated crops like cereals, especially in Asia, and areas with bimodal rain regimes. Vegetables typically also have higher cropping intensities. The terms of irrigation/rainfed in the current study indicates to farming systems rather than to seasons.</p>
<p>It means that the value of cropping intensity for a I farming system indicates for a year around situation, regardless of the dry/wet seasons. The calculation of cropping intensity is based on the statistics in a few selected sampling areas: cropping intensity = harvested area / cropland area, and the values are further adjusted by expert judgements. Table S11</p>
<p>Source: Developed by authors using data from national statistics and expert judgment.</p>
<p>Note: Farming systems -irrigated (I); rainfed (R). Cropping intensities for rainfed production are an area weighted average of rainfed high input, rainfed low input and rainfed subsistence cropping intensities.</p>
<p>Cropping intensities are one of the instruments used to "force" the optimization to solve. If all of the cropland has been used within a grid, but there is still physical area unused within the allocation process, we can assume that the relevant harvested area did not properly account for intercropping or sequential cropping, and thus increase the cropping intensity. See Section 4.3 in the main text for further discussion on the interventions used to facilitate an allocation process solution if one has not been reached.</p>
<p>For allocation purposes we apply three of GAEZ's water regime/input level combinations: irrigated water/high input levels, rainfed water/high input levels and rainfed water/low input levels. The latter water regime/input level combination was used to represent both rainfed -low and subsistence farming systems. GAEZ's suitability index (SuitIndexijl) was used to estimate the suitable area for grid i, crop j and input l via the following formula:</p>
<p>Where Areai is the physical area in grid i and λ is a discount factor.</p>
<p>The suitability index categorized as "very suitable land" represents land estimated to be able to achieve 80% -100% of maximum attainable yield. In order to remain conservative on our estimation of very suitable land, and lesser suitability ratings, we choose a discount factor (λ) of 0.8. The major crops surveyed by GAEZ include most of the SPAM2010 crops -those not included were assigned values from similar GAEZ crops. Table S8 details these relationships. Suitable areas for maize irrigated, rainfed -high and rainfed low farming systems are mapped in Figure S2. Source: Developed using data from GAEZv3.0 (Fischer et al., 2012). Source: Developed using data from GAEZv3.0 (Fischer et al., 2012).</p>
<p>Note: Suitable area equals the GAEZ's suitability index multiplied by grid size and a discount factor (set to 0.8).</p>
<p>Coupled with the cropland information described above, geo-referenced data on the share of irrigated area within a grid is used to estimate the extent of irrigated cropland per grid. The Land and Water Division of FAO and the University of Frankfurt jointly developed the Global Map of Irrigation Areas (GMIA) version 5.0, which estimates the amount of area equipped for irrigation (IrrAreai) at a 5 arc-minute resolution around the year 2005 (Siebert et al., 2013). IrrAreai is mapped in Figure S3.</p>
<p>
MIRCA (Portmann et al., 2010) can provide crop-specific irrigated area, whereas GMIA cannot. We use GMIA to derive information on irrigation equipped area mainly because MIRCA is for 2000. In fact the SPAM team has collaborating and discussing with
MIRCA team for a long time. SPAM modelling technique is very different from
MIRCA's and we don't want to bring their modelling errors into SPAM. Instead, we used GMIA (
MIRCA also used it) and derived some of irrigation input parameters from
MIRCA. Anderson et al. (2015) compared
MIRCA and SPAM and had a good discussion on that.
</p>
<p>Figure S3 Area equipped for irrigation (5 arc-minute resolution)</p>
<p>Source: GIMAv5.0 (Siebert et al., 2013).</p>
<p>Protected areas are designated by the World Database on Protected Areas 2003 from the International Union for Conservation of Nature, and include both international and national definitions: (a) international designation of protected areas are areas designated or proposed through international or regional conventions, and (b) national designations are proposed at the national or sub-national level.</p>
<p>The population count from the Gridded Population of the World database (GPWv4.0) (CIESIN, 2016) a 30 arcsecond resolution is applied to calculate the population density at 5 arc-minute resolution for SPAM2010 (Figure S5). When it overlays with cropland data, rural population (AggRurPopi) will be selected where population grids intersect with cropland grids. A measure of market accessibility (Accessi) was created from the grid-level estimates of rural population using the following equation:</p>
<p>where rural population densities were constrained by the maximum (MaxPopk0) and minimum (MinPopk0) rural population densities within a country. Table S9 shows the maximum and minimum rural population densities for select countries. These max-min cutoffs were determined by expert judgment. Source: Developed by authors.</p>
<p>According to the assumption of risk aversing and profit maximizing, crop revenure (Rev) would substantially influence farmers' decisions on selecting crops. In SPAM2010, we assume Rev is a function of crop prices (Price), crop potential yield (PotYield) and market accessibility (Access):</p>
<p>We adopt the crop-specific prices (Pricej) from FAO's Gross Production Value. Prices for crop aggregates (e.g., tropical fruit) are calculated as a weighted average from FAO world totals (Table S10). Source: Developed by authors using price data from FAO's (2012) gross value of production.</p>
<p>Note: Prices of pearl and small millet were set equal. Prices of Arabica and Robusta coffee were set equal.</p>
<p>We estimate the crop-specific potential yield (PotYieldijl) as a composite measure of yield based on GAEZ. In addition to estimates of suitability indices by grid, GAEZ also published data on potential dry weight yields by grid i, crop j and farming system l (PotDryYieldijl). To run SPAM2010 requires that this variable be measured in terms of harvested weight, which was derived by dividing the respective dry matter yield by crop-specific conversion factors provided by GAEZ in their Model Documentation (Fischer et al., 2012). If a crop-specific conversion factor was not available for a particular crop or crop aggregate, it was assigned from a similar "standin" crop as follows:</p>
<p>where GAEZactj is the dry-to-harvested weight yield conversion factor and FAOCropYj is the 2009 -2011 average FAO statistic on world yield by crop j. Table S11 lists the GAEZ factors to convert dry matter yields to harvested yields. Potential harvested yield (PotHarvYieldijl) for grid i, crop j and farming system l was then calculated as follows:</p>
<p>Then, the potential yield (PotYieldijl) is calculated as follows:</p>
<p>and Source: Developed by authors using data from GAEZv3.0 (Fischer et al., 2012) and own-calculations.</p>
<p>Note: Column "GAEZ Factor" lists the factors from GAEZv3.0 to convert from dry matter to harvested crop; Column "Other Factor" was a second factor introduced by the authors to convert a "borrowed" yield (e.g., from maize, to be used with temperate fruit); Column "Total Factor" was the final factor by which GAEZ yields were divided to arrive at SPAM2010 yields: GAEZ Factor/Other Factor.</p>
<p>We first adjust the grid-level data on cropland, irrigated area and suitable area before calculating the priors of physical area, in order to satisfy the constraints at the administrative unit level. These constraints are:</p>
<p>(i) that the total land in crops must be greater than or equal to the sum of area equipped for irrigation;</p>
<p>(ii) that statistical physical area summed over all crops and farming systems must be less than or equal to the sum of cropland;</p>
<p>(iii) that irrigated statistical physical area summed over all crops must be less than or equal to the sum of area equipped for irrigation; and</p>
<p>(iv) that statistical physical area must be less than or equal to the suitable area per crop and farming system.</p>
<p>In many cases these conditions are not met.</p>
<p>In many cases these conditions are not met due to the different sources of the data, inaccuracies, different times of measurement, different scales, inconsistencies in classification, and various other reasons. Therefore, we make adjustments following a hierarchy of "credibility" that we defined in decreasing order of importance:</p>
<p>(i) statistical data;</p>
<p>(ii) cropland;</p>
<p>(iii) area equipped for irrigation; and</p>
<p>(iv) suitable area. This is because statistical data was not changed, except in the unusual case when a model run failed to yield a solution, and only after all other modification options were exhausted. The general approach to the grid-level area adjustments was to upscale each variable so that they matched the statistical totals reported for the smallest available administrative unit, checking back that the corresponding totals at higher administrative units also continued to align. If scaling was not enough, we would calculate the missing amounts, and depending on the control parameters condAgi and condSuiti, distributed those amounts equally to grids which could still be expanded (up to total grid area). In a further step we could unconditionally increase areas of cropland, equipped for irrigation or suitable area by a given percentage to try and satisfy the conditions. If constraints were not met after these new adjustments, the specific problem was noted and manual adjustments of other parameters were made to resolve any area discrepancies, guided by expert judgment. Cropland area is worthy of special mention, since not all cropland in an administrative unit was necessarily used within the allocation model. To choose how much cropland would be used in each administrative unit, the grids of cropland for that unit were sorted by the reliability factor (ProbCropLandi) in descending order. Then the cropland was added up until it reached the physical area statistical value. Any excess grids (those with the lowest probabilities) were discarded from the SPAM2010 cropland surface.</p>
<p>In the processing phase, we first introduce the γ parameter which represents a relaxation factor for land constraints from sources less reliable than the statistical offices. Initially, the γ parameter is set to 5% for all of the three measures of gridded area. ii. Sum grids (in order of sort) until sum of cropland is equal to (or slightly greater than) the total physical area. Mark remaining cells for deletion.</p>
<p>iii. Begin with ADM0, then ADM1, then ADM2 statistics. Note: Cells marked for deletion at an administrative level but not marked for deletion at a lower administrative level are retained. For example, if a cell is marked for deletion at an ADM0 level, but not at an ADM1 level, then the cell is kept for the remainder of the analysis.</p>
<p>If the model does not solve after these area adjustments, we would relax constraints within the entropy optimization process on the availability of cropland (constraint ii), irrigated area (constraint iii) or suitable area (constraint iv), by increasing the percentage values (γ) in each cell of cropland, irrigated area or suitable area.</p>
<p>These percentages can vary between area types, but cropland can only be increased if the cell is not classified as a protected area. Areas in each grid can only be increased up to the point that their sum does not exceed the grid size.</p>
<p>If the first entropy condition adjustment does not yield an optimal solution, and it is obvious from the control output that suitable areas were not satisfying the constraints, it is possible to selectively eliminate suitability constraints for individual crops -including all crops if necessary. This means that the allocation would be guided only by cropland, irrigated areas (and crop distribution if data was available), but not by crop suitability considerations. Source: Developed by authors. a Number of crops for which suitability constraints were deactivated. If entry equals "all" then suitability constraints for all crops were deactivated.</p>
<p>We build up a system through which we are able to send the crop maps to collaborators and users alike for comments or assessment. These collaborators mainly include IRRI, CIMMYT, IIASA and CAAS. We carried out field trips and workshops onsite or online where local experts were asked to confirm or validate the crop production maps by providing hand-written comments or posting comments online at the MapSPAM website.</p>
<p>The SPAM maps were evaluated crop by crop, and country by country. As an example, some of rice map validation documents are presented below. Similar documentations can be found from the MapSPAM website.</p>
<p>China:</p>
<p>Generally, the cover for China appears to match the studies which we have found online (The light purple means lower value while the pink and red colors mean higher value in the upper figure), although the following map highlights some difference in the north eastern parts of the country between the DNDC study and our data:</p>
<p>There are although several differences in the province indicated by Arrow C on 6, and the USDA maps are suggesting that our data should be showing significantly more production in this province, but data from a more accurate or detailed study would need to be found to confirm this either way. The following map for example shows the province in question (marked with Arrow E) to be one the highest producing province in India, which reinforces the USDA maps: E On 6 Arrow D indicates two Indian Provinces which are shown to have no data. Although the comparative studies we have found on these provinces is limited, 7 and 8 both suggest that there is rice production on the North side of the Bangladeshi border. Unfortunately, 9 also has no data on the areas in question.</p>
<p>Pakistan:</p>
<p>The SPAM data shows an interesting pattern in the growing areas of Pakistan. This is compared below with a very basic study in 11 by the FAO. It can be seen that the Rice production tracks the river and there are some strong similarities in the patterns, which both follow the river with similar clusters of production in the South.</p>
<p>The striped blue lines which appear in the river tributaries in the North Eastern part of Part of Pakistan are an area which the FAO data suggests to be under intense Rice production. There is no real explanation for the horizontal lines in the SPAM data at that point which suggests an error. Again a more in depth study would likely need to be found to verify this.</p>
<p>Thailand, Cambodia and Vietnam:</p>
<p>One study which serves as a reference, was carried out on the Bac Kan Province of Vietnam, indicated by Arrow F on 13. It can be seen that the SPAM data even at this level is fairly accurate.</p>
<p>The Philippines:</p>
<p>The following study charts the changes of distribution of rice production in the main provinces of the Philippines over the last three decades.</p>
<p>When looking at the SPAM data below, it can clearly be seen that there is some unusual patterning especially in the south. The data from 15 clearly demonstrates that there should be a significant amount of Rice production in the South, but the SPAM data in 16 Below shows some unusual patterning which does not really hold any particular reference to the landscape:</p>
<p>Rice areas corelate with the topography of the region. The SPAM data on the other hand appears to have no real correlation with the topography of the land or the patchy prime rice growing areas in this southerly part.</p>
<p>Brazil:</p>
<p>The following page shows the SPAM data compared with a broad provincial level study of rice production Brazil, comparative to other areas of the world, rice production is much lower here, but the provinces reported to have the highest production, from the FAO study, appear to correlate with the SPAM data. There is only one major exception, which is that the provinces marked with Arrows I and J appear to be completely contradictory.</p>
<p>Otherwise, the only other observation is that areas abruptly change from higher to lower production along provincial boundaries as if the data was entered only as an average for each province, with the result that it looks Note: The confidence rating is raging from 1 to 5 categories (1 represents the highest accuracy or confidence, 5 the lowest).</p>
<p>All Same as national, adjust for some crops Ethiopia Some Irrigation from Agricultural Sample Surveys from 2009 -2011, rest expert judgment countries (</p>
<p>Source: Developed by authors</p>
<p>b FAO's millet crop was split between pearl and small at a ratio specific to the country in question.c Teff was part of 'other cereals' in SPAM and FAOSTAT, despite the explanation in FAOSTAT that it was part of the 'millets' commodity. d FAO's coffee crop was split between Arabica and Robusta at a ratio specific to the country in question.</p>
<p>Average statistics on yield were always taken as a harvested area weighted average.</p>
<p>Other Oilcrops 639.0</p>
<p>All/Some Crops Source of data Shares on irrigated production by crop j and administrative unit k (PercentjIk) were derived by dividing the harvested area cultivated under full control irrigation IrrAreajk obtained from AQUASTAT, MIRCA, and country-level statistics by the overall harvested area AvgCropHjk. Rainfed shares (PercentjHk, PercentjLk, PercentjSk) were primarily estimated based on generalized assumptions for individual countries and crops. For example, all cereals in Western Europe were either grown under irrigated or rainfed -high farming systems, whereas 20 percent of each of the cereals in SSA were grown under a subsistence farming system. We also assumed that fertilization was a proxy for high-input use, so if irrigated crop areas and overall fertilized and non-fertilized areas of a crop were known, it was possible to deduce rainfed high input shares by subtracting the irrigated areas from fertilized areas. The remainder of fertilized area was then classified as rainfed -high area and the non-fertilized areas (1 -PercentjIk -PercentjHk) were split, using expert judgment, between rainfed -low (PercentjLk) and subsistence (PercentjSk) shares. Assignment of rainfed -subsistence shares occurred frequently when there was not enough suitable area for rainfed -low conditions to satisfy the completeness of disaggregated crop statistics in terms of area extent and/or production quantity. In such cases a portion of the rainfed-low statistics were assumed to stem from rainfed -subsistence agriculture, for which area was allocated solely on the condition of rural population and not any crop suitability criteria.</p>
<p>Table S5 shows the shares of production under irrigated and rainfed systems for selected crop groups and countries. We choose Brazil, China, Ethiopia, France, India, Indonesia, Nigeria, Turkey and the United States, because they vary in agro-ecology, region, income level and geographical size. For cereal crops, the three Asian countries (China, India and Indonesia) have the highest shares of irrigated area, whereas the two Sub-Saharan</p>
<p>The CAAS-IFPRI cropland dataset fuses national and subnational statistics with multiple existing global-level land cover maps including GlobeLand30, CCI-LC, GlobCover 2009, MODIS C5 and Unified Cropland (Lu et al., 2020). It reports three major parameters by 500500m grid cells around year 2010: the median and maximum cropland percentage (MedCropLandi and MaxCropLandi) and an estimate of the probability of cropland existence (i.e., greater than zero cropland) within a grid (ProbCropLandi) for those measures. We aggregate these three parameters from 500 m grid cells to 5 arc-minute grid cells: AggMedCropLandi, AggMaxCropLandi and AggProbCropLandi (Figure S1).</p>
<p>Differences between median and maximum cropland estimates reveal the extent to which the various sources used in generating the cropland surface differ in their measure of cropland. The maps of median (Figure S1a) and maximum (Figure S1b) cropland show the respective statistics on the estimated share of cropland per grid across all data sources. The probability of cropland (Figure S1c) gives a grid by grid indication of the degree of agreement between the various sources used in the hybrid map regarding the existence of cropland.</p>
<p>If the previous interventions failed to achieve a solution, the primary data used to create the constraints and priors may be problematic. To address this problem, countries were run at an ADM1 rather than an ADM0 level.</p>
<p>This is only possible if the area and yield statistics are also available for all ADM1 units and all crops in the country in question. In the case of large countries, which are already run at an ADM1 level (e.g., the United States, Canada, China, Russia or India), the details for all ADM1 units were available with few exceptions (e.g. crops which were only grown in small quantities, or "rest of crops" which often were an aggregation of all other crops not reported individually). For other countries we relied on secondary information or own-estimates to complete the statistics. For example, the FAO reported that China grew oil palm, but the Chinese sources did not break down oil palm by ADM1 units. Further literature review revealed that oil palm was grown only in the Hainan province. Thus national totals for oil palm were all assigned to Hainan, while all other provinces were assigned zero oil palm production.</p>
<p>If additional information was not forthcoming, we applied some rules-of-thumb to assign crop production data to ADM1 units when only national data was available. For example, where required we often assigned crop aggregates to ADM1 units in the same shares as the sum of similar crops. Hence, the national value of "rest of crops" for some countries was allocated to ADM1 units using the same share as the sum of all other crops within each sub-national administrative unit. Or "other cereals" was assigned in the same proportion as the sum of all cereals for which there were data. However, the exact method of assigning national statistical totals to the relevant sub-national units was dependent on the crop, country and expert judgment. If a country is run at an ADM1 level, it is necessary to also have data on the farming system shares and cropping intensities at the same administrative level. Absent of existing ADM1 statistics on farming system shares and cropping intensities, we used the national level values. The comparison is fair accept for the area in the north Eastern part of the country indicated by the Arrows A and B on 1 and 2. This may be explained by the following two maps, which although crude, demonstrate that there is a significant difference between the double crop and single crop rice harvest in the North Eastern Part of the country:</p>
<p>India:</p>
<p>We were unable to find any detailed studies of rice in India at Provincial or district level, but generally the data appears to correlate fairly well with the basic country level information that we found except for a few anomalies:</p>
<p>Generally the areas of the SPAM data showing higher levels of production correspond with Prime Rice Land areas shown in 17, but this data also reinforces the fact that the patterning on the Spam Data, should be more clustered, and the horizontal patterning does not correspond with any other available studies. The void in the northern part of the Philippines indicated by Arrow G corresponds to an area of highlands, and it can be seen also that the prime rice land run vertically along the sides of the mountainous region, which is correctly indicated by the red areas on the SPAM data, although the patterning again appears to be unusual.</p>
<p>The area indicated by arrow H for example is shown to be highlands, and 17 shows that the patterns of Prime Argentina:</p>
<p>In Argentina for example the following USDA study (21) shows that rice production is highly concentrated in one very small part of the country.</p>
<p>The SPAM data for this region is particularly interesting for rice production, and specific circular patterning can be seen in the provinces surrounding the river mouth which is unlike any other patterning observed in the data set:</p>
<p>A brief comparison of the data will reveal numerous anomalies between the two. The highest producing areas in the USDA study are the two marked in red which appear to correlate with the patterning which is shown in these provinces on the SPAM data. A brief examination of some topographical maps for the region have provided no reasonable explanation for the circular patterning.</p>
<p>The North Eastern Province in the Iguazu falls areas is shown by the SPAM data to have no registered production, but USDA believe this province to be producing up to 3% of the country's output, now it may be that this is simply too low a level of production to register on the SPAM study, which seem to tie in with the fact that the other provinces marked in grey on the FAO study, except for the fact that the area marked with Arrow L shows production in the only area which the FAO study believes to have no production at all. Particularly noticeable because they have gone to the trouble of dividing the Santa Fe province into three different grades, with the specific purpose of showing that there is no significant production in the southerly part but 3-20 % of the country's total output in the north.</p>
<p>Kenya:</p>
<p>There appears to be little correlation between the SPAM data for Kenya and the Province level study we discovered. Some of the areas appear to correlate with the highest producing areas, but there is little evidence of the vertical band of production which can be seen in 24 but this may just be due to the fact that the production is too low for the SPAM model to recognize.</p>
<p>The confidence rating by users, local experts and collaborators is presented in Table S14. The rating is collected from the feedback and comments from users, local experts and collaborators. We combine all the information together to give a subjective rating on how confidence we, SPAM team, think of our final crop maps (both area and yield).</p>
</text>
</tei>
</teiCorpus>
