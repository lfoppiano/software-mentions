<teiCorpus xmlns="http://www.tei-c.org/ns/1.0" version="4.0.0">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title>Softcite annotated corpus</title>
        <respStmt>
          <resp>Principal Investigator</resp>
          <name>James Howison</name>
        </respStmt>
        <respStmt xml:id="curator">
          <resp>curator</resp>
          <name>James Howison, Cai Fan Du, Patrice Lopez</name>
        </respStmt>
        <respStmt xml:id="annotator0">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator1">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator2">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator3">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator4">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator5">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator6">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator7">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator8">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator9">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator10">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator11">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator12">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator13">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator14">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator15">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator16">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator17">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator18">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator19">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator20">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator21">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator22">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator23">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator24">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator25">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator26">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator27">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator28">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator29">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator30">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator31">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator32">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator33">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator34">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator35">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
        <respStmt xml:id="annotator36">
          <resp>annotator</resp>
          <name>ANONYMIZED</name>
        </respStmt>
      </titleStmt>
      <notesStmt>
        <note>The Softcite dataset is a gold standard corpus of manually annotated software mentions from academic PDFs.</note>
        <note>This corpus file contains one TEI entry for every scholar publication, including or not manual annotations. For scholar publications containing annotations, each paragraph containing at least one manually annotated software mention is encoded under the TEI body element. All the manual annotations under p elements (paragraph) have been further validated or corrected by a curator to reach a final decision.</note>
      </notesStmt>
      <publicationStmt>
        <publisher>Howison Lab, University of Texas at Austin, School of Information</publisher>
        <date when="2022"/>
        <availability status="free">
          <licence target="https://creativecommons.org/licenses/by/4.0/">
            <p>Attribution 4.0 International (CC BY 4.0)</p>
          </licence>
        </availability>
      </publicationStmt>
      <sourceDesc>
        <bibl>Softcite corpus, version 1.0.0, 2022</bibl>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <appInfo>
        <application ident="GROBID" version="0.5.6-SNAPSHOT" when="2019-07-14T13:21+0000">
          <desc>A machine learning software for extracting information from scholarly documents</desc>
          <ref target="https://github.com/kermitt2/grobid"/>
        </application>
        <application ident="GROBID-SOFTWARE-MENTIONS" version="0.6.0-SNAPSHOT" when="2019-11-21T14:59+0000">
          <desc>A GROBID module to recognize in textual documents and PDF any mentions of software</desc>
          <ref target="https://github.com/ourresearch/software-mentions"/>
        </application>
      </appInfo>
      <classDecl>
        <taxonomy>
          <category xml:id="unique_annotator">
            <catDesc>Document originally analyzed by one annotator</catDesc>
          </category>
          <category xml:id="multiple_annotators">
            <catDesc>Document originally analyzed by more than one annotator</catDesc>
          </category>
          <category xml:id="with_reconciliation">
            <catDesc>Document analyzed by one or more annotators with review by the curator team</catDesc>
          </category>
          <category xml:id="with_reconciliation_and_scripts">
            <catDesc>Document analyzed by one or more annotators with review by the curator team, combined with additional corrections driven by automated consistency checks</catDesc>
          </category>
        </taxonomy>
      </classDecl>
    </encodingDesc>
  </teiHeader>
<tei>
<teiHeader>
<fileDesc id="f82833909"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The design of modern scientific experiments requires the control and monitoring of many different data streams. However, the serial execution of programming instructions in a computer makes it a challenge to develop software that can deal with the asynchronous, parallel nature of scientific data. Here we present <rs id="a12896145" type="software">Bonsai</rs>, a modular, high-performance, open-source visual programming framework for the acquisition and online processing of data streams. We describe <rs id="a12896146" type="software">Bonsai</rs>'s core principles and architecture and demonstrate how it allows for the rapid and flexible prototyping of integrated experimental designs in neuroscience. We specifically highlight some applications that require the combination of many different hardware and software components, including video tracking of behavior, electrophysiology and closed-loop control of stimulation.</p>
<p>Here we describe <rs id="a12896147" type="software">Bonsai</rs>, an open-source visual programming framework for processing data streams (Box 1). The main goal of <rs id="a12896148" type="software">Bonsai</rs> is to simplify and accelerate the development of software for acquiring and processing the many heterogeneous data sources commonly used in (neuro) scientific research. We aim to facilitate the fast implementation of state-of-the-art experimental designs and to encourage the exploration of new paradigms. The framework has already been successfully used for many applications. In the following we will specifically highlight <rs id="a12896149" type="software">Bonsai</rs>'s utility in neuroscience for monitoring and controlling a diverse range of behavior and physiology experiments.</p>
<p>In recent years, a number of advances in programming languages and software frameworks have tried to make it easier to create complex software applications by composition of asynchronous computing elements (Bainomugisha et al., 2013). <rs id="a12896150" type="software">Bonsai</rs> builds upon these new efforts and aims to extend these developments to the rapid-prototyping domain by introducing a visual programming language for composing and processing asynchronous data streams. <rs id="a12896151" type="software">Bonsai</rs> was developed on top of the <rs id="a12896152" type="software" subtype="component" corresp="#a12896153">Reactive Extensions</rs> for the <rs id="a12896153" type="software" subtype="environment">.NET</rs> framework (<rs id="a12896154" type="software" subtype="component" corresp="#a12896153">Rx</rs>)  (<rs id="a12896155" type="publisher" corresp="#a12896153">Microsoft Open Technologies</rs>, 2014). <rs id="a12896156" type="software">Rx</rs> provides many built-in operators that transparently deal with the concurrency challenges that inevitably surface when multiple data streams need to be processed and integrated together in a single program. It has become an increasingly popular framework to develop reactive interfaces for next generation mobile and desktop computing platforms, where it is used to handle the growing number of sensors and network communications required by business logic and consumer applications.</p>
<p><rs id="a12896157" type="software">Bonsai</rs> (via <rs id="a12896158" type="software">Rx</rs>) represents asynchronous data streams using the notion of an observable sequence. An observable sequence represents a data stream where elements follow one after the other. An example would be a sequence of frames being captured by a camera, or a sequence of key presses logged by the keyboard. The name observable simply specifies that the way we access elements in the data stream is by listening to (i.e., observing) the data as it arrives, in contrast with the static database model, in which the desired data is enumerated.</p>
<p>In <rs id="a12896159" type="software">Bonsai</rs>, observable sequences are created and manipulated graphically using a dataflow (Mosconi and Porta, 2000;Johnston et al., 2004) representation (Figures 1,2A, Supplementary Video 1). Each node in the dataflow represents an observable sequence. Nodes can be classified as either observable sources of data or combinators (Table 1). Sources deliver access to raw data streams, such as images from a video camera or signal waveforms from a microphone or electrophysiology amplifier. Combinators represent any observable operator that handles one or more of these sequences. This category can be further specialized into transforms, sinks and other operator types depending on how they manipulate their inputs (Table 1). Transforms modify the incoming data elements of a single input sequence. An example would be taking a sequence of numbers and generating another sequence of numbers containing the original elements multiplied by two. Sinks, on the other hand, simply introduce processing side-effects without modifying the original sequence at all. One example would be printing each number in the sequence to a text file. The act of printing in itself changes nothing about the sequence, which continues to output every number, but the sideeffect will generate some useful action. Combinators that change, filter or merge the flow of data streams are neither transforms nor sinks, and they are simply referred to by the more general term combinator. The Sample combinator illustrated in Figure 2A takes two data sequences and produces a new sequence where elements are sampled from the first sequence whenever the second sequence produces a new value. In this example, we use Sample to extract and save single images from a video stream whenever a key is pressed.</p>
<p>The <rs id="a12896160" type="software">Bonsai</rs> framework can be downloaded at <rs id="a12896161" type="url" corresp="#a12896160">https://bitbucket.org/horizongir/bonsai</rs> and installed on Windows operating systems starting with Windows 7 and above. The website is organized into different sections: Downloads (where the latest installer is located), Wiki (with a "Getting Started" guide, tutorials and (FAQ) frequently asked questions), and Issues (where bugs can be reported). We have also created a user forum (address is listed in the FAQ section) where the community of <rs id="a12896162" type="software">Bonsai</rs> users have been sharing their feedback, questions and experiences.</p>
<p>A video tutorial introduction to <rs id="a12896163" type="software">Bonsai</rs> is included with this publication (Supplementary Video 1).</p>
<p><rs id="a12896164" type="software">Bonsai</rs> was designed from the outset to support many different layers of extensibility:</p>
<p>(a) Dataflows: The first layer is through the creation of <rs id="a12896165" type="software">Bonsai</rs> dataflow files themselves. Existing dataflows can be directly reused inside other dataflows as nested nodes. This allows for the sharing of reusable dataflow design patterns between applications. (b) <rs id="a12896166" type="language">Python</rs> Scripting: <rs id="a12896167" type="software">Bonsai</rs> supports embedded scripting using <rs id="a12896168" type="software">IronPython</rs> <rs id="a12896169" type="version" corresp="#a12896168">2.7</rs>. Specifically, <rs id="a12896170" type="software">Bonsai</rs> includes three types of <rs id="a12896171" type="software" subtype="environment">Python</rs> nodes: <rs id="a12896172" type="software" subtype="component" corresp="#a12896171">PythonTransform</rs>, <rs id="a12896174" type="software" subtype="component" corresp="#a12896171">PythonCondition</rs>, and <rs id="a12896175" type="software" subtype="component" corresp="#a12896171">PythonSink</rs>, which all operate by calling a user-defined <rs id="a12896176" type="software" subtype="environment">Python</rs> <rs id="a12896177" type="software" subtype="implicit" corresp="#a12896176">function</rs> described by a <rs id="a12896178" type="software" subtype="implicit" corresp="#a12896177">script</rs>. Below we include a simple example of a <rs id="a12896179" type="software">PythonTransform</rs> for rescaling data: processing filter, or setting the name of the output file in the case of data recording sinks. We have also included the possibility of externalizing node properties into the dataflow (Figure 2B). Externalizing a property means extracting one of the parameters into its own node in the dataflow, making it possible to connect the output of another node to the exposed property. This allows for the dynamic control of node parameters. Finally, we have built into <rs id="a12896180" type="software">Bonsai</rs> the ability to group nodes hierarchically. In its simplest form, this feature can be used to encapsulate a set of operations into a single node which can be reused elsewhere (Figure 2C). This is similar to defining a function in a programming language and is one of the ways to create new reactive operators in <rs id="a12896181" type="software">Bonsai</rs>. Any named externalized properties placed inside an encapsulated dataflow will also show up as properties of the group node itself. This allows for the parameterization of nested dataflows and increases their reuse possibilities. In addition, encapsulated dataflows are used to specify more complicated, yet powerful, operators such as iteration constructs that allow for the compact description of complex data processing scenarios that can be cumbersome to specify in pure dataflow visual languages (Mosconi and Porta, 2000) (see below).</p>
<p><rs id="a12896182" type="software">Bonsai</rs> was designed to be a modular framework, which means it is possible to extend its functionality by installing additional packages containing sources and combinators developed for specific purposes. New packages can be written using <rs id="a12896183" type="language">C#</rs> or any of the <rs id="a12896184" type="software">.NET</rs> programming languages. <rs id="a12896185" type="language" corresp="#a12896186">Python</rs> <rs id="a12896186" type="software" subtype="implicit">scripts</rs> [via <rs id="a12896187" type="software" subtype="environment">Iron-Python</rs> (<rs id="a12896188" type="publisher" corresp="#a12896187">IronPython Community</rs>, 2014)] can be embedded in the dataflow as transforms and sinks, allowing for rapid integration of custom code. All functionality included in <rs id="a12896189" type="software">Bonsai</rs> was designed using these modular principles, and we hope to encourage other researchers to contribute their own packages and thereby extend the framework to other application domains. At present, the available packages include computer vision and signal processing modules based on the <rs id="a12896190" type="software">OpenCV</rs> library (<rs id="a12896191" type="publisher" corresp="#a12896190">Itseez</rs>, 2014). Drivers for several cameras and interfaces to other imaging and signal acquisition hardware were integrated as <rs id="a12896192" type="software">Bonsai</rs> sources and sinks, including support for Arduino microcontrollers (Banzi et al., 2014), serial port devices and basic networking using the OSC protocol (Wright et al., 2003). Given the specific applications in the domain of neuroscience, we also integrated a number of neuroscience technology packages. The <rs id="a12896193" type="software">Ephys</rs> package, for example, builds on the <rs id="a12896194" type="software">Open Ephys</rs> initiative for the sharing of electrophysiology acquisition hardware (Voigts et al., 2013) by providing support for the <rs id="a12896195" type="software">Rhythm</rs> open-source USB/FPGA interface  (<rs id="a12896196" type="publisher" corresp="#a12896195">Intan Technologies</rs>, US). Therefore, the next generation tools for electrophysiology can already be used inside <rs id="a12896197" type="software">Bonsai</rs>, the acquired physiology data implicitly integrated with other available data streams and thus easily assembled into a powerful and flexible experimental neuroscience platform.</p>
<p>The most common application of <rs id="a12896198" type="software">Bonsai</rs> is the acquisition and processing of simple, independent data streams. However, for many modern experiments, basic acquisition and storage of data is often not sufficient. For example, it can be convenient to only record the data aligned on events of interest, such as the onset of specific stimuli. Furthermore, neuroscience experiments often progress through several stages, especially for behavioral assays, where controlled conditions vary systematically across different sessions or trials. In order to enforce these conditions, experiments need to keep track of which stage is active and use that information to update the state of control variables and sensory processing. These requirements often cannot be described by a simple linear pipeline of data, and require custom code to handle the complicated logic and bookkeeping of experimental states. Below we describe a set of advanced <rs id="a12896199" type="software">Bonsai</rs> operators that can be used to flexibly reconfigure data processing logic to cover a larger number of scenarios. These operators and their applications are all built on the single idea of slicing a data stream into sub-sequences, called windows, which are then processed independently and, potentially, in parallel (Figure 3).</p>
<p><rs id="a12896200" type="software">Bonsai</rs> provides different combinators that allow the creation of these sub-sequences from any observable data stream, using element count information, timing, or external triggers (Figures 3A-C). The specific set of operations to apply on each window is described by encapsulating a dataflow inside a Select-Many group, as detailed in the signal processing example of Figure 3D. The input source in this group represents each of the window sub-sequences, i.e., it is as if each of the windows is a new data source, containing only the elements that are a part of that window. These elements will be processed as soon as they are available by the encapsulated dataflow. Windows can have overlapping common elements, in which case their processing will happen concurrently. The processing outputs from each window are merged together to produce the final result. In the case of Figure 3D, past and future samples are grouped in windows to compute a running average of the signal through time, necessarily time-shifted by the number of future samples that are considered in the average.</p>
<p>In the <rs id="a12896201" type="software">Bonsai</rs> dataflow model, dataflows encapsulated in a SelectMany group can be used to represent states in a FSM (Figure 3F, bottom). Specifically, a state is activated whenever it receives an input event, i.e., the dataflow nested inside the state will be turned on. The dynamics of the nested dataflow determine the dynamics of the state. In the Go state presented in Figure 3F, the activation event is used to trigger stimulus onset. In parallel, we start listening for the key press which will terminate the state. Conversely, for the Ready state we would trigger stimulus offset and arm the timer for presenting the next stimulus. An important difference between Bonsai dataflows and pure state machine models is that a dataflow is specified as a directed acyclic graph, i.e., the data stream cannot loop back on itself. However, by taking advantage of the Repeat combinator, we can restart a dataflow once it is completed, allowing us to reset the state machine for the next trial.</p>
<p>As the level of flexibility of a graphical user interface increases, we start to approach the space occupied by general purpose visual programming languages (GPVPL). These are languages that are designed from the outset to be capable of solving problems across a wide variety of domains using a general set of operations. Ideally, the core building blocks of the language will themselves be domain-independent, so that the user can easily apply the same set of operations to the widest possible class of inputs. In order to better illustrate the feel and expressive power of GPVPLs, and to clarify where <rs id="a12896202" type="software">Bonsai</rs> itself is positioned, we will give two examples of popular languages that have succeeded in this niche: <rs id="a12896203" type="software">LabVIEW</rs>  (<rs id="a12896204" type="publisher" corresp="#a12896203">National Instruments</rs>, 2014) and <rs id="a12896205" type="software">Simulink</rs>  (<rs id="a12896206" type="publisher" corresp="#a12896205">MathWorks</rs>, 2014).</p>
<p> <rs id="a12896207" type="software">LabVIEW</rs> is one of the best examples of a GPVPL applied to the design and control of experiments (Elliott et al., 2007). In <rs id="a12896208" type="software">LabVIEW</rs>, users create virtual instruments (VIs) which are composed of a graphical front-panel containing an assortment of buttons, dials, charts and other objects; as well as a back-panel where a flowchart-like block diagram can be used to specify the behavior of the VI. In this back-panel, nodes and terminal elements can represent hardware components, numerical operations or frontpanel objects, which are connected together using virtual wires that specify the flow of data between them. The popularity of <rs id="a12896209" type="software">LabVIEW</rs> grew initially from its support for state-of-the-art data acquisition cards and hardware as well as its data visualization capabilities. The modularity of its architecture also allowed users to quickly develop and implement new nodes within the language itself by using VIs themselves as nodes.</p>
<p>Although the <rs id="a12896210" type="software">LabVIEW</rs> back-panel is a dataflow visual programming language, its execution model tends to follow a polling, rather than event-driven, strategy for dealing with multiple data streams. In order to properly scale this model to the increasing number of available processor cores, <rs id="a12896211" type="software" subtype="environment">LabVIEW</rs> has implemented sophisticated <rs id="a12896212" type="software" subtype="implicit" corresp="#a12896211">code analysis tools</rs> that attempt to identify parallelizable portions of block diagrams automatically (Elliott et al., 2007). Once these sections are identified, <rs id="a12896213" type="software">LabVIEW</rs> will automatically generate parallel processes depending on the number of available cores and will manage the bottlenecks in the code accordingly. Although this mitigates the limitations of the sequential polling programming model, it is important to realize that the goal of such automatic parallelization is still to provide the user with a logically synchronized programming model.</p>
<p> <rs id="a12896214" type="software">Simulink</rs> is a popular dataflow visual programming language for modeling, simulating and analyzing multi-domain dynamic systems. It has become extremely popular for modeling response characteristics of control systems, allowing not only for the rapid prototyping of algorithms, but also the automatic generation of microcontroller code for embedded systems. Again, the success of the language stemmed primarily from the flexibility and ease of use of the block diagrams, as well as the number of prebuilt operations and data visualization tools which quickly took care of many crucial but tedious aspects of control systems modeling.</p>
<p>Like <rs id="a12896215" type="software">LabVIEW</rs>, the execution model for <rs id="a12896216" type="software">Simulink</rs> generated code is still based on polling strategies, where ready to execute dataflow nodes are updated in turn as inputs become available. Again, strategies to scale the output of <rs id="a12896217" type="software">Simulink</rs> to multiple cores have been proposed based on analyzing and segmenting the model into parallelizable sections which can be converted into equivalent parallel execution code for microcontrollers (Kumura et al., 2012).</p>
<p>Similar to <rs id="a12896218" type="software">LabVIEW</rs> and <rs id="a12896219" type="software">Simulink</rs>, <rs id="a12896220" type="software">Bonsai</rs> was designed as a general purpose modular language. The core architecture of <rs id="a12896221" type="software">Bonsai</rs> is domain-independent and provides a general framework to compose asynchronous data streams. A general set of composition operators, or combinators, provides support for Implementing state-machines using window operators. Top: state-machine schematic of a task designed to measure response times.</p>
<p>In the Ready state, the stimulus is off. When entering the Go state, the stimulus is turned on. At the end of each trial, the system goes back to the initial state. Bottom: graphical representation of the equivalent <rs id="a12896222" type="software">Bonsai</rs> dataflow. The SelectMany combinator is used to specify the behavior and transitions of each state. The Take combinator truncates a sequence to include only a specified number of initial elements. In this case, only the first element is included. The Repeat combinator restarts a sequence when no more elements are produced (see text).</p>
<p>iteration, segmentation and merging of parallel data streams, as well as other common manipulations on observable sequences. Both the sources of data and available processing operations can be extended within the language itself using nesting of dataflows. Data visualizers and a growing library of data stream acquisition, processing and logging modules are provided to allow rapid prototyping of a large number of different applications. However, in contrast to <rs id="a12896223" type="software">LabVIEW</rs> or <rs id="a12896224" type="software">Simulink</rs>, <rs id="a12896225" type="software">Bonsai</rs> adopts a very different strategy to implement dataflow execution. Rather than trying to derive a global sequential execution order of dataflow nodes based on the number of active inputs, <rs id="a12896226" type="software">Bonsai</rs> nodes simply react to incoming inputs immediately, without the need to wait for all of them to be active. When multiple observable sequences are present, this allows for a choice of different concurrency composition strategies. Nevertheless, as the result of the composition is an observable sequence itself, such concurrency management can remain functionally isolated from the combinator that is handling the composition. From the point of view of downstream operators, they are simply receiving an observable sequence. There is a tradeoff, of course, that more responsibility for managing the flow of data is passed to the end user, but it also allows for a finer grained control of concurrency that is critical to the specification of parallel applications.</p>
<p>Another important caveat is that <rs id="a12896227" type="software">Bonsai</rs> currently runs exclusively in Windows operating systems. However, <rs id="a12896228" type="publisher" corresp="#a12896229">Microsoft</rs> has recently open-sourced the execution engine of the <rs id="a12896229" type="software">.NET</rs> framework and will pursue implementations for all the major operating systems ( Linux/Mac). This raises the interesting possibility of eventually extending the <rs id="a12896230" type="software">Bonsai</rs> user base into these important platforms.</p>
<p>The validation of <rs id="a12896231" type="software">Bonsai</rs> was performed by using the framework to implement a number of applications in the domain of neuroscience (Figure 4). The breadth of technologies at use in this field demands that modern experiments be able to handle many heterogeneous sources of data. Experimenters need to routinely record video and sensor data monitoring the behavior of an animal simultaneously with electrophysiology, optical reporters of neural activity or other physiological measures. Online manipulation and visualization of data is a fundamental part of the experiment protocol for many of the reported techniques. In the following, we highlight some of these practical applications of <rs id="a12896232" type="software">Bonsai</rs> in more detail in order to illustrate both "best practices" and implementation strategies.</p>
<p>One of the first use cases driving the development of <rs id="a12896233" type="software">Bonsai</rs> was the automated online tracking of animal behavior using video. The most common tracking application involves chaining together operators for image segmentation and binary region analysis to allow the extraction of the spatial location of an animal over time (Figures 4A,B). The same technique can easily be extended to track different kinds of objects, such as eyes or experimental manipulanda in human psychophysics experiments (Figure 4C), provided adequate illumination contrast and the appropriate choice of a method for segmentation. These image processing tools can also be used to acquire and process physiological data in neural imaging setups, where it is now possible to record bioluminescent or fluorescent reporters of neural activity during behavior. For example, Figure 4B demonstrates simultaneous measurement of animal behavior and neural activity using bulk fluorescence calcium imaging in the mouse brain recorded with a CCD sensor and a fiberoptic system (Tecuapetla et al., 2014).</p>
<p>Raw video data from modern high-resolution, high-speed cameras can be expensive and cumbersome to store. Online video compression and storage sinks were implemented taking advantage of parallelism to avoid frame loss. Video compression is processing intensive and can compromise data acquisition if reading the next frame has to wait for the previous frame to be fully encoded. One solution is to buffer incoming frames and compress them in parallel with the rest of the processing stream. By encapsulating this behavior into a <rs id="a12896234" type="software">Bonsai</rs> sink, it became easy to incorporate video recording and compression functionality into any image processing pipeline (Figures G,H).</p>
<p>While simple image processing techniques can easily extract continuous two-dimensional measures of animal location over time, it often becomes the case that the experimenter is concerned with tracking the detailed behavior of specific features in the animal's body, such as head pose. This is an essential component in neurophysiology or stimulation experiments in freely moving animals, where ongoing behavior is the central constraint in interpreting neural responses and manipulations. However, identifying such features and reconstructing their position and orientation in 3D space is a challenging computer vision problem. A common solution is to use planar fiducial markers of known geometry (Kato and Billinghurst, 1999;Garrido-Jurado et al., 2014) (Figure 4D). The computer vision research community has developed some open-source software solutions to this problem (Garrido-Jurado et al., 2014), which have been integrated into <rs id="a12896235" type="software">Bonsai</rs> to allow the possibility of easily and flexibly incorporating online 3D fiducial tracking in video streams. This approach has been used successfully to record 3D head movements of a mouse under optogenetic stimulation in a decisionmaking task (Figure 4D). One final, but important application of video stream processing is in the development of closed-loop interfaces, where the actions of an animal directly modulate manipulations under the experimenter's control. This kind of experiment requires fast online analysis of behavior and physiological variables of interest that are subsequently coupled to hardware control interfaces. In Figure 4E, real-time stimulation conditioned to a region in space was implemented by analyzing the position of an animal in a square arena. Whenever the animal found itself inside a specified region of interest, a signal was sent to an Arduino controller which was then used to drive optogenetic stimulation of specific neural circuits.</p>
<p>Another key data type that is commonly processed by <rs id="a12896236" type="software">Bonsai</rs> dataflows is buffered time-series data. This type of data usually arises from audio, electrophysiology or other digital acquisition systems where multiple data samples, from one or more channels, are synchronously acquired, buffered and streamed to the computer. These buffers are often represented as data matrices, where rows are channels and columns represent individual data samples through time, or vice-versa. Support for simple band-pass filters, thresholding and triggering allowed us to build flexible spike detection and waveform extraction systems (Figure 4F). Using Intan's Rhythm API, we integrated into <rs id="a12896237" type="software">Bonsai</rs> support for a variety of next-generation electrophysiology devices using Intan's digital amplifier technology, such as the <rs id="a12896238" type="software">Open Ephys</rs> acquisition system (Voigts et al., 2013) or Intan's evaluation board (RHD2000, Intan Technologies, US). This system was successfully used to acquire and visualize simultaneous recordings from dense silicon probes where spikes from a loose-patch juxtacellular pipette were used as triggers to align and extract waveform data appearing on the multi-channel extracellular probe. Responses from every silicon probe site could then be superimposed on an accurate rendition of the probe geometry, in real-time.</p>
<p>The ability to rapidly integrate new modules allowed us to support the development and cross-validation of new tools for behavioral neuroscience. A paradigmatic example was the flyPAD, a new method for quantifying feeding behavior in Drosophila melanogaster by measuring changes in electrode capacitance induced by the proboscis extension of a fly (Itskov et al., 2014). The integration of the <rs id="a12896239" type="software" subtype="component" corresp="#a12896240">flyPAD</rs> in <rs id="a12896240" type="software" subtype="language">Bonsai</rs> allowed researchers to quickly get started using this approach to design new experiments. Furthermore, it also allowed the validation of the tool by enabling simultaneous acquisition of highspeed video recordings of fly behavior which were later used for annotation and classification of the sensor feeding traces (Figure 4G).</p>
<p>In a different set of experiments, <rs id="a12896241" type="software">Bonsai</rs> was used to implement a variation on a popular two-alternative forced choice (2AFC) decision-making task for rodents (Figure 4H). In this type of task, animals are placed in an environment with three "ports." They are presented with a stimulus in the center port and afterwards report their perception of the stimulus by going either to the left or right choice ports. In the variation we present in this work, the two choice ports were replaced by regions of interest where the activity of the animal is analyzed using computer vision. This example offered unique challenges as it combined sophisticated sequential control of a task environment with continuous data stream processing of video and sensor data.</p>
<p>After about a year of using <rs id="a12896242" type="software">Bonsai</rs> in an active neuroscience research institute, dozens of different experimental protocols and data analysis pipelines have been successfully implemented using the provided building blocks (Gouvêa et al., 2014;Itskov et al., 2014;Tecuapetla et al., 2014). We were surprised by the diversity of applications and by the pace at which new modules and devices were developed and integrated.</p>
<p>The performance achieved by <rs id="a12896243" type="software">Bonsai</rs> dataflow processing was an important consideration throughout (Box 2). Video processing can be particularly challenging to handle given the bandwidth required to quickly acquire and process large data matrices. In order to correlate continuous measures of behavior with neural activity, it is useful for those measurements to have both high spatial and high temporal resolution. Using <rs id="a12896244" type="software">Bonsai</rs>, we were able to simultaneously process and compress grayscale image sequences from high resolution (1280 × 960) and high frame rate (120 Hz) cameras using standard off-the-shelf desktop computers (Intel Core i7, 8 GB RAM). In fact, many of the reported assays use multiple (&gt;2) such video streams with success and actually process the behavior video online either to control states of the behavior protocol or to pre-process video data for offline analysis.</p>
<p>One of the areas where we see the application of <rs id="a12896245" type="software">Bonsai</rs> becoming most significant is in the development of dynamic behavior assays (environments) using reactive control strategies. Brains evolved to generate and control behaviors that can deal with the complexity of the natural world. However, when neuroscientists try to investigate these behaviors in the lab, it is often difficult to design equivalent environmental complexity in a controlled manner. As an example, consider a simple foraging scenario in which a land animal must collect, in a timely manner, food items that become available at random intervals in many sites. If the item is not collected in time, it rots or gets eaten by competitors. In the case of a single foraging site, a FSM description intuitively represents the workings of the environment (Figure 5A). However, let us now consider a situation where the environment has two of these food sites operating independently, thus introducing the possibility of different events occurring simultaneously at each of the sites. If our environment is modeled as a finite-state machine, then we must represent every possible combination of states and transitions, as in Figure 5B. In the classical state machine formalism the machine can only be in one state at a time, which means we now need to model each state as the combination of the individual independent states at each reward location. Furthermore, because transitions between these states are asynchronous and independent, we thus have edges between nearly every pair of nodes, as each reward site can change its state at any point in time relative to the other.</p>
<p><rs id="a12896246" type="software">Bonsai</rs> takes full advantage of the flexibility of <rs id="a12896247" type="language">C#</rs> and its Just-In-Time (JIT) compiler to bring the computational overhead of running the framework to zero. This is possible due to the fact that the graphical dataflows in <rs id="a12896248" type="software">Bonsai</rs> are actually specifying syntactically correct <rs id="a12896249" type="language" corresp="#a12896250">C#</rs> <rs id="a12896250" type="software" subtype="implicit">code</rs> by means of an expression tree. When the dataflow is executed, <rs id="a12896251" type="language" corresp="#a12896252">C#</rs> <rs id="a12896252" type="software" subtype="implicit">code</rs> is generated for assembling and running the pipeline. This <rs id="a12896253" type="software" subtype="implicit">code</rs> is ultimately compiled into native machine language before execution, which has the consequence that running a <rs id="a12896254" type="software">Bonsai</rs> dataflow is as fast as if one wrote the equivalent Rx code manually. In fact, this also means every <rs id="a12896255" type="software" subtype="language">Bonsai</rs> <rs id="a12896256" type="software" subtype="implicit" corresp="#a12896255">module</rs> is just a standard <rs id="a12896257" type="language">C#</rs> class exposing methods working on <rs id="a12896258" type="software">Rx</rs>'s observable interface, which makes it possible to reference every single <rs id="a12896259" type="software" subtype="language">Bonsai</rs> <rs id="a12896260" type="software" subtype="implicit" corresp="#a12896259">package</rs> from a standard <rs id="a12896261" type="software">.NET</rs> application and just use the module functionality directly.</p>
<p>The level of concurrency and parallelism in <rs id="a12896262" type="software">Bonsai</rs> entirely depends on the structure of each individual dataflow and the specific computer hardware involved. Typically, each hardware device source (e.g., a camera) runs independently in its own logical thread. Some sources can occasionally share threads when the underlying device architecture allows for it. For example microcontroller sources coming from the same USB port effectively require sharing a single communications channel, but this is logically abstracted from the developer so there is no need to worry about handling multiplexed messages.</p>
<p>The specialized handling of concurrency introduced by merging different processing streams is done using dedicated <rs id="a12896263" type="software">Rx</rs> concurrency operators that are exposed graphically through the language. Operators located downstream from the merge point can treat the merged sequence as if it was a single sequential data source. This means most <rs id="a12896264" type="software">Bonsai</rs> operators are actually concurrency-agnostic, meaning they don't have to worry about concurrency at all: they simply assume their inputs are processed sequentially. This functional approach allows <rs id="a12896265" type="software">Bonsai</rs> operators to be simple to program, reliable and extremely performant.</p>
<p>Finally, some <rs id="a12896266" type="software">Bonsai</rs> operators introduce local concurrency implicitly to maximize performance. For example, many of the data logging sinks actually write to disk in parallel with the arrival of data. This prevents processor-heavy routines, such as video compression, to stall the pipeline and allow for online execution to proceed as fast as possible. From the point of view of the developer, however, such optimizations happen transparently.</p>
<p>Being a fully asynchronous framework, <rs id="a12896267" type="software">Bonsai</rs> has to deal with code executing logically in many different processors. There is no particular assumption about time in the framework other than the sequential flow of data through the pipeline, but facilities are in place to help the synchronization and timing of data. For example, the Timestamp operator provides access to hardware performance timers included in modern processors to timestamp event notifications, across the pipeline, using a shared high resolution clock. However, it should be noted that this only applies to processes occurring centrally: for precise sub-millisecond synchronization of physical events happening outside the computer (e.g., stimulation pulse train and electrophysiology data) we still recommend the classical sharing of voltage or optical sync pulses logged simultaneously in each device. of these events can occur independently of each other, but when a sampling event coincides with reward availability (C), then reward (R) is delivered. Because this description is intrinsically asynchronous and parallel, it makes it extremely easy to scale the task to a larger set of locations: just replicate the dataflow for each of the other locations (Figure 5D). In this example, the design space was made more intuitive by introducing the parallel and asynchronous nature of a real-world situation into our modeling formalism.</p>
<p>Another difficulty of the classical state machine formalism is dealing with continuous variables. The natural environment provides constant real-time feedback that tightly correlates with the actions of an animal. Reproducing such closed-loop interaction and manipulating its dynamics is a necessary tool for fully investigating brain function. Such models are virtually impossible to represent in a machine of finite states, given the potential infinitude of feedback responses. However, the dataflow formalism of asynchronous event sources can easily accommodate such models. In fact, this is their natural battleground; nodes represent reactive operators that promptly respond to input values broadcasted by event sources. These models of asynchronous computation are thus ideal for recreating the complex discrete and continuous aspects of natural environments that brains evolved to master. We thus propose <rs id="a12896268" type="software">Bonsai</rs> as a new tool for neuroscientists trying to understand how the brain deals with real world complexity.</p>
<p><rs id="a12896269" type="software">Bonsai</rs> was used to acquire timestamped images from three cameras (eye, person's view, and arm) simultaneously. The videos are synced with presented sound stimulus by using the arm camera to also capture two IR LEDs which are turned on at sound on-set and off-set, respectively. The arm is tracked by using an IR LED mounted on a joystick and processing the video online at 120 Hz to minimize noise from compression. All the videos are compressed to a MP4 encoded file for offline analysis of the eye movements, pupil dilation, and syncing of all events with the sounds. The eye videos are captured at 30 Hz using the IR illuminated pupil headset (https://code.google.com/p/pupil/).</p>
<p>Adult mice performing a two alternative forced choice task were filmed with a high-speed monochrome video camera (Flea3, Point Gray, CA). A fiber optic cable was attached to the mouse's head. The 3D position and orientation of the head was tracked in real-time using square fiducial markers from the <rs id="a12896270" type="software">ArUco</rs> tracking library (Garrido-Jurado et al., 2014). The video (0.24 Megapixel) was simultaneously compressed to a high-quality H.264 encoded file that was used for subsequent offline analysis of the behavior.</p>
<p>Black mice were recorded with a high speed video camera (Flea3, Point Gray, CA), while exploring an open field arena (50×40 cm, L × W), under white illumination (∼250 lux). The x and y position, body centroid and orientation of the animal in the arena was continuously tracked in real-time. Mice were implanted with an optical fiber connected to a laser, in order to receive photostimulation with blue light. A region of interest (ROI, 13 × 10.5 cm, L × W) was defined and a <rs id="a12896271" type="language" corresp="#a12896272">python</rs> <rs id="a12896272" type="software" subtype="implicit">script</rs> was written to outline the conditioning protocol. A digital output signal was sent to a microcontroller board (Uno, Arduino, IT), each time the body centroid of the animal entered in the ROI, producing photostimulation. All data for the animal tracking and digital output was saved in a.csv file, as well as the video, for subsequent offline analysis of the behavior.</p>
<p>Recordings of spontaneous neural activity in motor cortex were performed in anesthetized rodents by means of silicon probes comprising a dense electrode array (A1x32-Poly3-5 mm-25s-177-CM32, Neuronexus, US). An open-source electrophysiology acquisition board (<rs id="a12896273" type="software">Open Ephys</rs>) was used along with a RHD2000 series digital electrophysiology interface chip that filters, amplifies, and digitally multiplexes 32 electrode channels (Intan Technologies, US). Extracellular signals sampled at 30 kHz with 16-bit resolution in a frequency band from 0.1 to 7500 Hz were saved into a raw binary format for subsequent offline analysis. Online analysis of neural spike waveforms across all probe channels was performed by aligning the multi-channel raw data on spike events from a selected channel of interest. A custom <rs id="a12896274" type="software" subtype="language">Bonsai</rs> <rs id="a12896275" type="software" subtype="component" corresp="#a12896274">visualizer</rs> was written using <rs id="a12896276" type="software">OpenGL</rs> to display all channel traces superimposed on the geometric arrangement of probe sites. It was possible to examine the details of extracellular activity in the spatial distribution.</p>
<p>Adult PWD female mice were tested in behavioral experiments using restricted social interaction with adult C57BL6 and PWK males as reward. The behavioral paradigm consists of a custom built arena made of modular acrylic pieces assembled in an aluminum frame. The contact zone between the female and the male (composed of four holes with r = 0.5 cm) was either available for a fixed period of time, or physically restricted by a vertically sliding door controlled by a servomotor. Subjects initiated the interaction by nose-poking in an infrared beam port that would trigger the opening of the door and subsequent availability of the contact zone. Videos were recorded using high-speed monochrome video cameras (Flea3, Point Gray, CA). Performance, monitoring and control of the behavior box was done using a Motoruino board (Motoruino, Artica, PT) and custom <rs id="a12896277" type="software" subtype="language">Bonsai</rs> <rs id="a12896278" type="software" subtype="implicit" corresp="#a12896277">scripts</rs>.</p>
<p>Three to 5 months old Long-Evans female rats were trained sequentially to forage and hunt virtual elements of a projected display in exchange for water rewards. The behavioral paradigm consists of a custom built arena made of structural framing components (Bosch Rexroth, DE). The floor of the arena is a rear-projection screen made out of a frosted acrylic panel. In order to compensate for the short-throw distance, the projected image is reflected off a mirror positioned below the arena floor. Video was recorded using a high-speed monochrome video camera (Flea3, Point Gray, CA) equipped with a visible light cutoff filter (R72, Hoya, JP) and analyzed in real-time using <rs id="a12896279" type="software">Bonsai</rs>. Infrared LED strips were positioned at the bottom of the arena in order to illuminate the floor through the diffuser, allowing for the tracking of the animal without contamination from the visual stimulus. Animals were first conditioned to a tone as a secondary reinforcer and then subsequently trained to either touch the light presented at random locations (foraging) or pursue a moving spot (hunting). Performance, monitoring and control of the behavior box was done using an Arduino board (Micro, Arduino, IT) and a <rs id="a12896280" type="software">Bonsai</rs> reactive state machine.</p>
<p>(c) <rs id="a12896281" type="software">NuGet</rs>: <rs id="a12896282" type="software">Bonsai</rs> <rs id="a12896283" type="software" subtype="implicit" corresp="#a12896282">modules</rs> are natively written in <rs id="a12896284" type="language" corresp="#a12896283">C#</rs> or other <rs id="a12896285" type="software">.NET</rs> languages.</p>
<p>We thank João Bártolo Gomes for suggesting the name <rs id="a12896286" type="software">Bonsai</rs>; Danbee Kim for early discussions on creating virtual environments for rodents; Joana Nogueira, George Dimitriadis and all the members of the Intelligent Systems Laboratory for helpful discussions and comments on the manuscript. We also thank all the members of the Champalimaud Neuroscience Programme who used <rs id="a12896287" type="software">Bonsai</rs> to setup their data analysis and acquisition experiments and in so doing provided valuable feedback to improve the framework. The research leading to these results has received funding from the European Union's Seventh Framework Programme (FP7/2007-2013) under grant agreement n • 600925 and the Bial Foundation (Grant 190/12). GL is supported by the PhD Studentship SFRH/BD/51714/2011 from the Foundation for Science and Technology. The Champalimaud Neuroscience Programme is supported by the Champalimaud Foundation.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f81755791"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T05:59+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>In order to determine which sets of questions were gathering similar information, factor analyses were conducted separately on the groups of items within each of the categories listed above. The goal of the factor analyses was to gauge the appropriateness of analyzing each group of items as one construct. The five constructs we were attempting to measure when the items were written were (1) influence from friends, family, and loved ones; (2) influence from teachers, mentors, and other educators; (3) influences from pop culture and media sources; (4) religiosity; and (5) evolution understanding. All factor analyses were run in <rs id="a12900066" type="software">R</rs> <rs id="a12900067" type="version" corresp="#a12900066">3.0.2</rs>  (<rs id="a12900068" type="publisher" corresp="#a12900066">R Development Core Team</rs> 2013) with the factanal function using maximum likelihood and a varimax rotation.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f564337581"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:37+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Based on what was explained about soft grippers, FEM is used in the current study to investigate the pre-strain effect of the bilayer structure with various thickness ratios on the performance of the 4D-printed bi-stable soft robotic gripper. A design process of and analysis procedure in this study could be seen in Fig. 2 flowchart. As can be seen from the flowchart in Fig. 2, the study begins by investigating the effective parameters according to the literature review. The design of experiments (DoE) is then conducted, followed by the geometric design of a soft gripper by the <rs id="a12972325" type="software">CATIA</rs> <rs id="a12972346" type="version" corresp="#a12972325">V 5</rs> software. Next, the simulation of a soft gripper by <rs id="a12972327" type="software">ABAQUS</rs> <rs id="a12972328" type="version" corresp="#a12972327">2017</rs> software is carried out, followed by extracting simulation results and determining output values. Finally, RSM modelling and optimization results are done in the <rs id="a12972329" type="software">MAT-LAB</rs>-<rs id="a12972330" type="version" corresp="#a12972329">R 2021a</rs> software.</p>
<p>By using <rs id="a12972331" type="software" subtype="component" corresp="#a12972332">Model-Based Calibration (MBC) Model Fitting Toolbox</rs> in <rs id="a12972332" type="software" subtype="environment">MATLAB</rs> <rs id="a12972333" type="version" corresp="#a12972332">R2021a</rs> software, the design of experiments was done based on RSM methodology, which includes three-level input parameters and two output parameters. It also should be mentioned that two modes were considered for the soft robotic gripper designation. In the first mode, the soft gripper consists of a silicone-ethanol composite material with a high coefficient of thermal expansion in the outer layer and a silicone elastomer with a low coefficient of thermal expansion in the inner layer. In the second mode, the order of locating the layers is reversed. Concerning the values of the thermal expansion coefficient, in the first mode, the gripper will be closed, while in the second mode, the gripper will be opened.</p>
<p>In this study, commercial <rs id="a12972334" type="software">ABAQUS</rs> <rs id="a12972335" type="version" corresp="#a12972334">2017</rs> software was utilized to FEM simulate the soft silicone gripper under different applied thermal loading conditions. For this reason, samples of soft grippers with different thickness ratios and pre-strain values were made with <rs id="a12972336" type="software">CATIA</rs> <rs id="a12972347" type="version" corresp="#a12972336">V 5</rs> software (Fig. 3).</p>
<p>In order to check the accuracy of the simulation and the effect of the thermal stimulus on the bilayer soft robotic grippers, the present simulation results were compared to those in [14]. A two-layer structure with a bottom layer (ethanol-silicon composite) thickness of 2 mm, top layer (PDMS) thickness of 1 mm, width of 2 cm, a length of 7 cm and a pre-strain of 0.2, at a temperature of 100 °C, having the properties listed in Table 1, is simulated by <rs id="a12972338" type="software">ABAQUS</rs> software. Figure 4 shows the comparison between the von Mises stress contour in the present work and that in [14]. Fig. 4 The meshing scenario for the bi-stable soft robotic gripper analysis Figure 5 demonstrates the morphing of a bilayer structure with a pre-strain of 0.2, which becomes flat after applying a thermal stimulus, and the highest amount of stress will occur in the middle of the upper surface. Figure 6 represents the curve variations in terms of temperature changes during the deformation process of the 4D-printed bilayer structure. Figure 5 shows the accuracy and precision of the present simulation results compared to that of the research done by Zhou et al. [14]. Also, according to Fig. 5, the longitudinal curvature (κ 1 ) of the bilayer structure decreases by increasing the temperature. In fact, the value of the initial pre-strain is reduced due to the method of layering under the thermal stimulus. Consequently, thermal strains cause the initial pre-strain to be neutralized. Hence, the structure becomes completely flat. However, it is noteworthy that if the materials of the layers are moved, the bilayer structure will shrink instead of flattening. Figure 7 shows the variation of the 4D-printed bilayer structure at different time snaps of morphing. It is evident that by increasing the applied thermal load, the longitudinal curvature of the bilayer structure gradually decreases. Even though the transverse curvature (κ 2 ) has gotten bigger over time, the changes in the transverse curvature are not as big as the changes in the longitudinal curvature.</p>
<p>Having validated the simulation results, 54 experiment cases, according to RSM section, are simulated by <rs id="a12972339" type="software">ABAQUS</rs> software, and the output results are listed in Table 3. Figure 8 reports the stress contour of the bi-stable soft gripper with a bilayer structure, with a pre-strain of 0.1, a thickness ratio of 1 and at a temperature of 100 °C in the shrinking state ( in = 0), while Fig. 9 shows the stress contour with the same parameters as the opening mode ( out = 0). It could be observed that in the shrinking state, or closing mode, ( in = 0), the stress distribution occurs only in the inner layer of the gripper, and its value is less than 100 kPa, while in the opening mode ( out = 0), the stress distribution occurs only in the outer layer of the gripper and its value is less than 50 kPa. It is worth mentioning that in the opening analysis of the bi-stable soft gripper with a bilayer structure, the simulation stops in the middle of the analysis, and the Fig. 10 Strain energy of the pre-strained bi-stable soft robotic gripper Fig. 11 The interplay of the pre-strain and the a temperature, b thickness ratio values on the maximum strain energy in the opening mode; the pre-strain and the c temperature, d thickness ratio values on the average distance of the gripper clamps in the opening mode time of the process does not exceed 40 s. The reason for this is the presence of a ring around the gripper and the bi-stable mode of the soft gripper. This ring plays the role of controlling the deformation of the gripper and preventing excessive deformations.</p>
<p>The need for a quick and efficient design and optimization approach in the recent development of thermally responsive 4D-printed bi-stable structures in soft robotic applications motivated this study. Hence, a RSM optimization with the aid of numerical solutions to investigate effective parameters in the design of a 4D-printed bi-stable bilayer soft robotic gripper was presented. The (FEM) simulation of the soft silicone gripper under the application of thermal stimulus in different conditions was carried out using <rs id="a12972340" type="software">ABAQUS</rs> software. The soft gripper samples with different material thickness ratios and pre-strain were designed in the <rs id="a12972341" type="software">CATIA</rs> <rs id="a12972348" type="version" corresp="#a12972341">V 5</rs> software. Also, experiments were designed based on the RSM procedure by <rs id="a12972343" type="software" subtype="environment">MATLAB</rs>- <rs id="a12972344" type="version" corresp="#a12972343">R 2021a</rs> software using the <rs id="a12972345" type="software" subtype="component" corresp="#a12972343">MBS Model Fitting Toolbox</rs>, which includes three-level variables and two output parameters. After conducting the modelling and optimisation, the most optimal parameters were obtained using the response surface method. The corresponding equations for the maximum strain energy and the average distance of the clamps were obtained for closing and opening modes, concerning pre-strain, thickness ratio and temperature values. According to Table 3 and RSM relationships, the most optimal condition for the opening mode corresponds to model 25 in which the maximum strain energy equals 1.573 mJ and the average distance of the clamps equals 3.281 mm. Likewise, the most optimal condition for the opening mode corresponds to model 46 in which the maximum strain energy of 2.199 and the average distance of the clamps of 2.165 are obtained. This proposed approach was successfully implemented to accelerate the actuation of a thermally responsive model that can be quantitatively controlled by the applied strain and heat stimuli for developing multiscale shape-morphing structures, such as fast buckling and bending, required for soft robotic applications.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f159507344"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:58+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>We have presented a new adaptive QST protocol using an adaptive LRE algorithm and reported a two-qubit experimental realization of the adaptive tomography protocol. In our RAQST protocol, no prior assumption is made on the state to be reconstructed. The infidelity of the adaptive tomography is greatly reduced and can even beat the Gill-Massar bound by adaptively optimizing the POVMs that are performed at each step. We demonstrated that the fidelity obtained by using our RAQST with only the simplest product measurements can even surpass those obtained by using MUB and the two-stage MUB adaptive strategy, for states with a high level of purity. Considering the trade-off between accuracy and difficulty of implementation, it seems that RAQST using the product measurements is the best choice for reconstructing pure and nearly pure entangled states, which are Fig. 3 Experimental setup. The experimental setup can be divided into two modules: state preparation (gray) and adaptive measurement (light blue). In state preparation module, arbitrary Werner states ρ W (p) in can be generated. In adaptive measurement module, the two-photon product measurements are realized and can be adaptively changed by a <rs id="a12972354" type="software">Labview</rs> program. Key to components: HWP, half-wave plate; QWP, quarter-wave plate; BS, beam splitter; IF, interference filter; SPD, single photon detector; PBS, polarizing beam splitter the most important resources for quantum information processing.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f573846896"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:30+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Methods: Building on the emergent stream of studies examining COVID-19-related tweets in English, we performed a temporal assessment covering the time period from January 1 to May 9, 2020, and examined variations in tweet topics and sentiment scores to uncover key trends. Combining data from two publicly available COVID-19 tweet data sets with those obtained in our own search, we compiled a data set of 13.9 million English-language COVID-19-related tweets posted by individuals. We use guided latent Dirichlet allocation (LDA) to infer themes and topics underlying the tweets, and we used <rs id="a12965914" type="software">VADER (Valence Aware Dictionary and sEntiment Reasoner)</rs> sentiment analysis to compute sentiment scores and examine weekly trends for 17 weeks.</p>
<p>The COVID-19 outbreak has propelled an emergent set of studies that have examined public perceptions, thoughts, and concerns about this pandemic using social media data (Table 1). Most of these studies relied on data from the Twitter or <rs id="a12965917" type="software">Weibo</rs> platforms and analyzed data from early periods of the pandemic. The amount of data used in these studies varies from a few hundred tweets to a few million. These studies have collectively provided a rich body of knowledge on how Twitter users have reacted to the pandemic and their concerns in the early stages of the outbreak. Many of these studies did not differentiate between sources of tweets, such as whether the tweet originated from an individual or an organization such as a news channel or health agency. From an infoveillance perspective, it is important to understand the social media discourses pertaining to COVID-19 among the common public rather than by news agencies or other organizations. Further, there is limited understanding of the changes in public sentiments and discourse about COVID-19 over time. To address these gaps, we examined COVID-19-related tweets using a much larger data set covering a time period from January 1 to May 9, 2020. We performed a temporal assessment and examined variations in the topics and sentiment scores over a period of time from before to after the disease was declared a pandemic to uncover key trends.</p>
<p>We collected all COVID-19-related tweets from January 1 to May 9, 2020. The <rs id="a12965935" type="language">Python</rs> programming language was used for our data collection and analyses, and <rs id="a12965936" type="software">Tableau</rs> was used as a supplementary tool for visualization purposes. We used three sources to assemble the tweets required for our analysis. First, we relied on the COVID-19 Twitter data set at IEEE Dataport [21], which contained COVID-19-related tweets from March 20, 2020. Second, we used a Twitter data set posted in GitHub [22] that contained COVID-19-related tweets posted since January 21, 2020. Both these data sets are publicly available and provide a list of tweet IDs for all tweets related to COVID-19. Third, we collected COVID-19-related tweets for the remaining period, including texts and metadata, from Twitter using <rs id="a12965944" type="software" subtype="component" corresp="#a12965945">GetOldTweets3</rs>, a <rs id="a12965945" type="software" subtype="environment">Python</rs> <rs id="a12965946" type="version" corresp="#a12965945">3</rs> library that enables scraping of historical Twitter data <rs id="a12965948" type="bibr">[23]</rs>. Because we were combining tweets from multiple sources, we used a common set of keywords and phrases that other sources had used: corona, coronavirus, covid-19, covid19, and their variants, including their hashtag equivalents. The language-tag setting "EN" and the retweet tag "RT" were used to filter English-language tweets and retweets. We also used the retweets feature in <rs id="a12965949" type="software">GetOldTweets3</rs> to filter out retweets. Due to restrictions of the Twitter platform, the public data sets contained only the tweet IDs. The process of extracting complete details of a tweet, including metadata, from Twitter using the tweet ID is referred to as hydration, and a number of tools have been developed for this purpose [11]. We used the <rs id="a12965952" type="software">Hydrator</rs> software <rs id="a12965953" type="bibr">[24]</rs> listed in IEEE Dataport to gather the complete text and metadata of the tweets.</p>
<p>Our next step was to classify all the tweets posted by individuals versus those that originated from organizations. We first gathered the unique Twitter user IDs of all the Twitter users in our data set. Following the approach outlined in [25], we used a naïve Bayes machine learning model to classify the tweeters into individuals versus organizations. We used a published data set that contained 8945 Twitter users and their profile descriptions, which human coders used to annotate users as individual or institutional [26]. To these data, we added 2000 Twitter user IDs pulled from our data set along with their associated profiles, and we manually annotated them (interrater reliability κ=0.84). Using the combined data set of 10,945 users, we divided our data set into training versus validation sets using an 80:20 split, and we used these sets to train and test our classifier model, respectively. The naïve Bayes classifier yielded an accuracy of 83.2% with a precision of 0.82, a recall of 0.83, and an F1 score of 0.81; these values were considered satisfactory and are comparable to those in other studies [27][28][29]. Multimedia Appendix 1 presents the confusion matrix. Our classifier performance was also robust across multiple split strategies for dividing the data set for training and validation. This classifier was then used to identify all the individual users in our full data set, and only tweets posted by individuals were retained for further assessment. We also eliminated duplicate tweets and retweets (filtered using the "RT" tag), resulting in a data set that contained only original tweets posted by individual users. We preprocessed and cleaned the tweets using the <rs id="a12965959" type="software">Natural Language Toolkit (NLTK)</rs>, regular expression (RegEx), and the <rs id="a12965961" type="software" subtype="component" corresp="#a12965962">gensim</rs> <rs id="a12965962" type="software" subtype="environment">Python</rs> library <rs id="a12965963" type="bibr">[30]</rs>. We removed stop words, user mentions, and links, and we also lemmatized the text of the tweets.</p>
<p>We used two broad approaches to prepare the initial set of topics and the seed words for guided LDA. First, we used the extant literature on COVID-19 infoveillance using Twitter to identify a broad set of topics and potential keywords. Second, we performed traditional LDA with multiple numbers of topics as inputs (n=10, 20, 30, and 40) iteratively and examined the word lists that were generated. We used both steps to generate a list of topics and anchor words for the guided LDA (see Multimedia Appendix 2). The <rs id="a12965965" type="software" subtype="component" corresp="#a12965966">GuidedLDA</rs> package in <rs id="a12965966" type="software" subtype="environment">Python</rs> was used for the topic modeling. Through discussions, the authors then grouped the topics and identified dominant themes. Further, we computed a sentiment score for each tweet using the <rs id="a12965967" type="software" subtype="component" corresp="#a12965968">VADER (Valence Aware Dictionary and sEntiment Reasoner)</rs> tool in <rs id="a12965968" type="software" subtype="environment">Python</rs>. <rs id="a12965969" type="software">VADER</rs> is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments in social media texts such as tweets <rs id="a12965970" type="bibr">[33]</rs>.</p>
<p>To assess the sentiments of tweets, <rs id="a12965971" type="software">VADER</rs> provides a compound score metric that calculates the sum of all Lexicon ratings that have been normalized between -1 (most extreme negative) and +1 (most extreme positive); this method takes into account both the polarity (positive/negative) and the intensity of the emotion expressed. For each tweet, we classified the sentiment as positive, negative, or neutral based on the compound score. A tweet with a compound score greater than 0.05 was classified as positive, a tweet with a score between -0.05 and 0.05 was classified as neutral, and a tweet with a score less than -0.05 was classified as negative. To further understand the changes in the sentiment scores over time, we qualitatively analyzed the content of tweets to explore the rationale behind the changes in the compound sentiment scores. The authors manually examined the tweets pertaining to specific topics in weeks in which variations were observed to infer possible reasons for the variations in sentiment.</p>
<p>We further examined the trends in the sentiment scores for topics underlying the broader themes. Compound scores from <rs id="a12965974" type="software">VADER</rs> were averaged over each topic for every week (Figure S3, Multimedia Appendix 3). This assessment helped us to understand the progression of sentiments for specific topics over the period we examined. To understand the variations in the sentiments, we also qualitatively examined the tweets for weeks in which changes were observed. Sample tweets for each of the themes and topics are shown in Multimedia Appendix 4.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f81719149"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The assembly of reads was executed using <rs type="software" id="s1">SOAP denovo</rs> (Version <rs type="version" corresp="s1">2.04</rs>, parameters: -d 1 -M 3 -R -u -F) <ref type="bibr">[57]</ref>. For each sample, we used a series of k-mer values (from 49 to 87) and chose the optimal one with the longest N50 value for the remaining scaffolds [4]. We mapped the clean data against scaffolds using <rs type="software" id="s2">SOAP2</rs> (Version <rs type="version" corresp="s2">2.21</rs>, parameters: -m 200 -x 400 -s 119). Unused reads from each sample were assembled using the same parameters. Genes (minimum length of 100 nucleotides) were predicted on scaftigs (i.e., continuous sequences within scaffolds) longer than 500 bp using <rs type="software">MetaGeneMark</rs> (<rs type="software" id="s3">prokaryotic GeneMark .hmm</rs> version <rs type="version" corresp="s3">2.10</rs>). Then, a non-redundant gene catalogue was constructed with CD-HIT (version 4.5.8, parameters: -G 0 -aS 0.9 -g 1 -d 0 -c 0.95) [58] using a sequence identity cut-off of 0.95, with a minimum coverage cut-off of 0.9 for the shorter sequences.</p>
<p>Rarefaction analysis was performed to assess the gene richness in the controls, pHTN, and HTN. For a given number of samples, we performed random sampling 100 times in the cohort with replacement and estimated the total number of genes that could be identified from these samples by <rs type="software" id="s4" subtype="environment">R</rs> (Version <rs type="version" corresp="s4">2.15.3</rs>, <rs type="software" subtype="component" corresp="s4">vegan</rs> package).</p>
<p>The optimal number of clusters was estimated using the CH index, as previously described [60]. Only genera with an average relative abundance ≥10 -4 and existed in at least six samples were considered in the analysis. According to Spearman's correlation between genera abundances, the genera in enterotype 1 were clustered, and the co-occurrence network of them was visualized by <rs type="software" id="s5">Cytoscape</rs> (Version <rs type="version" corresp="s5">3.2.1</rs>).</p>
<p>To assess the taxonomic assignment, genes were aligned to the integrated NR database using <rs type="software" id="s6">DIAMOND</rs> (Version <rs type="version" corresp="s6">0.7.9.58</rs>, default parameter except that -k 50 -sensitive -e 0.00001) <ref type="bibr">[61]</ref>. As previously described [59], for each gene, the significant matches, which were defined by e-values ≤10 × e-value of the top hit, and these retained matches were used to distinguish taxonomic groups. The taxonomical level of each gene was determined by the lowest common ancestor-based algorithm and implemented in <rs type="software" id="sA">MEGAN</rs> <ref type="bibr">[62]</ref>. The abundance of a taxonomic group was calculated by summing the abundance of genes annotated to a feature.</p>
<p>The enriched CAGs were identified according to Greenblum S et al.. These CAGs were clustered according to Spearman's correlation. The co-occurrence network was visualized using <rs type="software" id="s7">Cytoscape</rs> (Version <rs type="version" corresp="s7">3.2.1</rs>). The enriched CAGs/genes were identified according to Greenblum S et al. <ref type="bibr">[34]</ref>. Briefly, for each CAG, an OR score was calculated according to the abundance in the set of compared samples. Then, for the comparative analysis between control and HTN samples, the HTNassociated CAGs were classified as HTN-enriched (OR &gt;2) or HTN-depleted (OR &lt;0.5). When calculating HTNassociated ORs, samples of pHTN were excluded from the analysis, and when calculating pHTN-associated ORs, samples labeled as HTN were excluded.</p>
<p>All genes in our catalogue were aligned to the KEGG database (Release 73.1, with animal and plant genes removed) and CAZy database (http://www.cazy.org/) using <rs type="software" id="s8">DIAMOND</rs> (Version <rs type="version" corresp="s8">0.7.9.58</rs>, default parameter except that -k 50 -sensitive -e 0.00001). Each protein was assigned to the KEGG orthology and CAZy families by the highest scoring annotated hits containing at least one HSP scoring over 60 bits [63]. The abundance of KEGG orthology/module was calculated by summing the abundance of genes annotated to the same feature.</p>
<p>16S ribosomal RNA sequencing 16S rRNA community profiles were characterized using Illumina HiSeq sequencing of the V4 region (insert size 300 bp, read length 250 bp). Sequences were de novo clustered at 97% sequence identity and chimeras were removed using <rs type="software">UPARSE</rs> [64]. For each representative sequence, the GreenGene Database was used to annotate taxonomic information [65].</p>
<p>The Shannon index at the genera level was calculated with <rs type="software" id="s9">QIIME</rs> (Version <rs type="version" corresp="s9">1.7.0</rs>). PCA was analyzed using the <rs type="software" id="s10">FactoMineR</rs> package in <rs type="software" corresp="s10" subtype="environment">R</rs> software (Version <rs type="version" corresp="s10">2.15.3</rs>). PCoA was performed and displayed by <rs type="software">ade4</rs> package, cluster packages, <rs type="software">fpc</rs> packages, and <rs type="software">clusterSim</rs> package in <rs type="software" id="s11" subtype="environment">R</rs> software (Version <rs type="version" corresp="s11">2.15.3</rs>). PLS-DA was performed using <rs type="software">SIMCA-P</rs> software to cluster the sample plots across groups.</p>
<p>Differential abundance of genes, genera, and KO modules was tested by Wilcoxon rank sum test, and P values were corrected for multiple testing with the Benjamin &amp; Hochberg method. Only genera with an average relative abundance ≥10 -4 and existed in at least six subjects were considered in the analyses. Correlations between enriched CAGs and clinical indices were tested with Spearman's correlation and visualized by <rs type="software" id="s12">Cytoscape</rs> (Version <rs type="version" corresp="s12">3.2.1</rs>).</p>
<p>Using the profiles of species, CAGs, and metabolites, the samples were randomly divided into training set and test set. A random forest classifier was trained on 80% of the data and tested on the remaining 20% of our data using the <rs type="software" subtype="component" corresp="s13">random forest</rs> package in <rs type="software" id="s13" subtype="environment">R</rs>. In order to evaluate the performance of the predictive model and get more precise curves, we used a 10-fold cross-validation within the training set. The cross-validational error curves (average of 10 test sets each) from five trials of the 10-fold cross-validation were averaged. Variable importance by mean decrease in accuracy was calculated for the random forest models using the full set of features. The number of variables was 1000 at the lowest cross-validational error. Thus, the predictive model was constructed using the 1000 most important variables, which were further applied for ROC analysis. The performance of the smaller models were measured as AUC when applied to the test set, and the confidence intervals for ROC curves were calculated using the <rs type="software">pROC R</rs> package.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f347566724"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:22+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>To confirm the dimensional structure of the scales, this study used confirmatory factor analysis and employed the statistical software <rs id="a12966118" type="software">EQS</rs>. <rs id="a12966119" type="version" corresp="#a12966118">6.1</rs>. First, the factor loadings of the confirmatory model were verified and we eliminated those items that were not statistically significant (at 0.01) or higher than 0.5 (Steenkamp and Van Trijp 1991;Jöreskog and Sörbom 1993). Acceptable levels of convergence, R-square values, and model fit were finally obtained (χ 2 = 368.922, 120 df, p &lt; 0.000; Satorra-Bentler scaled chi-square = 290.076, 120 df, p = 0.057; NFI = 0.969; NNFI = 0.977; CFI = 0.982; IFI = 0.982; RMSEA = 0.052; 90% confidence interval [0.045, 0.060]). To assess construct reliability, this study also checked that values of the composite reliability (CR) indicator (Jöreskog 1971) were above the suggested minimum of 0.65 (Steenkamp and Geyskens 2006), as can be seen in Table 1. To further ensure convergent validity, it was verified that average variance extracted (AVE) values were greater than 0.5 (see Table 1) and converged on only one construct (Fornell and Larcker 1981). Finally, regarding discriminant validity, Table 1 shows that each construct shared more variance with its own measures than with the other constructs in the model (Fornell and Larcker 1981); that is, for each construct, the square root of the AVE is greater than correlations among constructs.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f480604593"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:58+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Detector.-The layout and description of the AMS detector are presented in Ref. [24]. The key elements used in this measurement are the permanent magnet [25], the silicon tracker [26], and the four planes of time of flight scintillation counters [27]. The AMS also contains a transition radiation detector, a ring imaging Čerenkov detector, an electromagnetic calorimeter, and an array of 16 anticoincidence counters. Proton and helium nuclei traversing the AMS were triggered as described in Refs. [22,23,28] with measured efficiencies of &gt; 94% up to 60 GV. Monte Carlo simulated events were produced using a dedicated <rs id="a12972349" type="software" subtype="implicit">program</rs> developed by the collaboration based on the <rs id="a12972350" type="software">GEANT</rs>- <rs id="a12972351" type="version" corresp="#a12972350">4.10.1</rs> package <rs id="a12972352" type="bibr">[29]</rs>. The <rs id="a12972353" type="software" subtype="implicit">program</rs> simulates electromagnetic and hadronic interactions of particles in the material of the AMS and generates detector responses. The Monte Carlo event samples have sufficient statistics such that they do not contribute to the errors.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f237711831"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>At each location, 10 images are recorded (640 • 480 pixels (px), sampled at *20 fps). These images are then filtered and thresholded in <rs id="a12967904" type="software">OpenCV</rs>  (<rs id="a12967905" type="url" corresp="#a12967904">www.opencv.org</rs>), and the pin center coordinates are detected using a contour detection algorithm. Each pin is identified based on its proximity to a default set of pin positions recorded when the sensor is not in contact with the cylinder; if no pin is detected within a radius of 20 px from its default, the position from the previous frame is used instead. A time series of x-and y-deflections of the sensor's pins are then extracted and treated as individual taxel inputs. Several frames are collected to reduce noise arising from the pin detection algorithm and minor displacements of the sensor.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f78066426"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>TNPs cause mitotic arrest and localized DNA damage. In addition to PK analysis, high-resolution intravital imaging allowed for simultaneous monitoring of the cellular response to TNPs at the molecular level. Fluorescently tagged 53BP1 is a key member of the non-homologous end-joining pathway that forms visible puncta at sites of DNA double-strand breaks 29,36 . Based on the hypothesis that treatment with a cisplatin pro-drug would lead to increased DNA damage in tumour cells, we imaged 53BP1 puncta in response to TNP and quantitated the DNA damage response across populations of individual tumour cells at various time points (Fig. 3a). The results show a dose-and time-dependent increase in the fraction of tumour cells exhibiting high levels of DNA damage (Fig. 3b). We next tested whether there was an observable relationship between local payload accumulation and resulting single-cell DNA damage response. We used <rs id="a12895297" type="software" subtype="implicit">automated three-dimensional (3D) segmentation software</rs> to quantify TNP vehicle and payload accumulation within individual tumour nuclei, and correlated this information with DNA damage response in those cells. The results showed that cells exhibiting high levels of DNA damage also had a roughly 300% higher local payload concentration (Fig. 3c). Compared to TNP payload, local concentration of TNP vehicle also correlated with DNA damage, but to a lesser degree (Fig. 3c). DNA damage elicited by Pt treatment generally induces mitotic arrest in vitro 25 , but it has been difficult to directly observe this response in vivo, where anti-mitotics often behave much differently 26 . To determine TNP effects on cell growth, we used time-lapse intravital imaging to track individual tumour cells and mitotic events over the first 3 h following TNP injection in the HT1080 model (Supplementary Fig. 5) and found that TNP indeed caused a substantial reduction in tumour cell division (Fig. 3d). To test generalizability in another tumour model, we next examined local drug accumulation and DNA damage in an orthotopic model of disseminated ovarian cancer (OVCA) 37 . Human A2780CP OVCA cells were intraperitoneally injected in nu/nu mice, and 6 weeks later (once palpable tumours and/or ascites had developed), animals received TNP treatment. The following day, tumours were excised and imaged for TNP accumulation and DNA damage. Imaging shows similar TNP localization patterns as observed with the HT1080 model (Fig. 4a). We also found similar statistically significant correlation between local TNP payload levels and tumour cell DNA damage (Fig. 4b). Taken together, these results demonstrate that TNPs elicit substantial DNA damage response activity and corresponding growth arrest in vivo. In both the subcutaneous and orthotopic OVCA tumour models, the correlation between local drug accumulation and DNA damage response implies that NPmediated drug delivery plays a significant role in governing such PD.</p>
<p>) and lymphocyte-like cells (CD45 þ Lin þ CD11b À Ly6G À ). The anti-human CD29 antibody (clone MAR4) was from BD, and the following anti-mouse antibodies used were from BioLegend: CD45 (clone 30-F11), F4/80 (clone BM8), CD11c (clone N418), Ly6C (clone HK1.4). CD11b (clone M1/70) was from BD Biosciences, along with all antibodies used in the lineage (Lin) mixture: anti-CD90.2 (clone 53-2.1), anti-B220 (clone RA3-6B2), anti-NK1.1 (clone PK136), anti-CD49b (clone DX5), anti-Ter119 (cloneTER-119) and anti-Ly6G (clone 1A8). To exclude dead cells, 7-aminoactinomycin D (Sigma-Aldrich) was used. Data were analysed using <rs id="a12895298" type="software">FlowJo</rs> v. <rs id="a12895299" type="version" corresp="#a12895298">8.8.7</rs>  (<rs id="a12895300" type="publisher" corresp="#a12895298">Tree Star, Inc.</rs>) and <rs id="a12895301" type="software">MATLAB</rs>. BODIPY-630 and amino-BODIPY fluorescence was assessed by using an LSRII flow cytometer and the mean fluorescence intensity (MFI) of the different cell populations was determined. Background autofluorescence for each immunologically defined cell population was measured from control-treated animals that were injected with non-fluorescent PLGA-PEG vehicle; this value was subtracted from the data for the fluorescent TNP-treated animals.</p>
<p>Computational image analysis. Intravital microscopy images were analysed using either <rs id="a12895302" type="software">Matlab</rs>  (<rs id="a12895303" type="publisher" corresp="#a12895302">Mathworks</rs>) or <rs id="a12895304" type="software">ImageJ</rs> and were pre-processed using background subtraction based on data acquired immediately before TNP injection. For vascular half-life calculations, fluorescence time-lapse values from multiple vessels across multiple animals were recorded, averaged and fit to an exponential decay model using nonlinear regression in <rs id="a12895305" type="software">MATLAB</rs>. Single-cell 3D segmentation for image cytometry analysis was performed using a custom <rs id="a12895306" type="software" subtype="environment">MATLAB</rs> <rs id="a12895307" type="software" subtype="implicit" corresp="#a12895306">pipeline</rs>. Briefly, a previously described 3D nuclear-segmentation algorithm was modified to measure the MFI of TNP vehicle and its payload within a given radius of each nucleus. These measurements were then correlated with observed 53BP1-puncta in each individual nucleus, validated by eye (Fig. 3c). Throughout the manuscript, data falling 42 standard deviations from the mean were excluded as outliers from the statistical calculations. For calculation of spatial heterogeneity, measured by the CV (Supplementary Fig. 4), cell-sized regions of interest within images were quantified for MFI. CV for TNP and unencapsulated Pt (CP-11 (ref. 29)) were measured 420 half-lives post injection as an approximation of steady-state tissue distribution (5 and 24 h, respectively).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f129069432"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:33+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Consistency of protein detection. The qualitative similarity of SWATH-MS data acquired at different sites was investigated by comparing the set of inferred proteins detected from the HEK293 proteome across all 229 SWATH-MS data files. Targeted analysis was performed using the <rs id="a12882977" type="software">OpenSWATH</rs> software <rs id="a12882978" type="bibr">35</rs> A-E, six peptides in each) were diluted into a HEK293 cell lysate to span a large dynamic range. Starting at a different upper concentration for each group, they were threefold diluted into the matrix to cover a concentration range from 12 amol to 10 pmol in 1 µg of cell lysate. This created a set of five samples to be run by SWATH-MS on the TripleTOF 5600/5600+ system at each site. Each sample was run once per day on day 1, 3, and 5, with the exception of sample 4 which was run 3× on each day. b After data acquisition, the 229 SWATH-MS files were assembled centrally and processed using two strategies. The SIS peptide concentration curves were assessed using <rs id="a12882979" type="software">MultiQuant</rs> Software, allowing for the determination of linear dynamic range (LDR), and LLOQs for each peptide. In addition, the intraand inter-day CVs were determined before and after normalization. The HEK293 proteome matrix data was analyzed using the <rs id="a12882980" type="software">OpenSWATH</rs> pipeline and the Combined Human Assay Library consisting of ~10,000 proteins. The false discovery rate was controlled at the peptide query and protein level using <rs id="a12882981" type="software">PyProphet</rs>. Protein abundances were inferred by summing the top five most abundant fragment ions from the three most abundant peak groups using the <rs id="a12882982" type="software">aLFQ</rs> software. We then used protein abundances to cluster, and compute Pearson correlation coefficients, for all samples from all sites containing peptide query parameters mapping to 10,000+ human proteins 49 (Fig. 1b). The false discovery rate (FDR) was controlled at 1% at the peptide query and protein levels using the q-value approach [50][51][52][53][54] in the global context, and at 1% peptide query FDR on a sample-by-sample basis. We did not employ any alignment or transfer of peptide identification confidence between runs. A description of FDR calculation, and issues surrounding this, is provided in Supplementary Note 2 and in a related paper explaining FDR considerations in detail 55 .</p>
<p>Having established a high degree of reproducibility of protein detection within and across sites, we went on to investigate the quantitative characteristics of our inter-lab SWATH-MS data set. To determine quantitative reproducibility we computed the coefficient of variation (CV) at different levels. Firstly, we extracted ion chromatograms (XIC) for the SIS peptides and summed the XICs to obtain peptide peak areas using the <rs id="a12882983" type="software">MultiQuant</rs> software (Supplementary Data 4). Next, we computed the CV for each site within 1 day (intra-day) and over the week (inter-day) for the S4 sample, which was acquired every day in triplicate. The median for site intra-day and inter-day CVs (expressed as median ± standard deviation) were 5.5 ± 2.9% and 8.9 ± 11.1%, respectively (Fig. 3a, Supplementary Data 4 and 5). For the majority of sites the intra-day and interday CVs were below 20% (one lab-Site 8-experienced some larger LC-MS variance over the course of the week with decreasing signals that was later explained by a contaminated collision cell). As the signal response varies between instruments, attempting to directly compare raw peak area or intensities across 3 Reproducibility of SWATH-MS measurements. a The CVs of peak areas for each of the 30 SIS peptides for S4 sample, depicted on the y-axis using logarithmic scaling, were determined at the intra-day level within the site (light blue-without normalization, dark blue with normalization), inter-day level within site (light green-without normalization, dark green with normalization), and inter-site level (i.e., over all S4 samples in the study; light gray-without normalization, dark gray-with normalization). The orange line indicates 20% CV for visual reference. b Similarly, the CV of protein abundances for the 4077 proteins that were detected in &gt;80% all samples were computed at the intra-day level within the site, inter-day with site, and inter-site (i.e., all 229 samples in the study). c The inter-site CVs were binned based on log2 protein abundance to visualize the dependence of CV on protein abundance sites is not feasible. To determine if could normalize the instrument response differences by applying a simple normalization, we used the quantitative information from the HEK293 proteome that is expected to be invariant. Specifically, the peptide peak areas from the automated <rs id="a12882984" type="software">OpenSWATH</rs> analysis for each of the 229 files were re-scaled such that the median values from each file were equalized. The resulting protein abundance boxplots in Supplementary Fig. 13 clearly shows the effect of this simple normalization. The normalization coefficients (Supplementary Fig. 14) were used to adjust the peptide peak areas for the SIS peptides derived from the <rs id="a12882985" type="software">MultiQuant</rs> analysis and the intra-day and inter-day CV analysis was repeated (Fig 3a). We then calculated the inter-site CVs for the SIS peptides using all measurements of the S4 sample from all sites. The median of the inter-site CVs using peptide peak areas without normalization was 47.3 ± 13.9%. After normalization, this was reduced to 21.3 ± 10.3%. Normalization also reduced the median within site inter-day CV from 8.9 ± 11.0 to 5.8 ± 5.4% whereas the intra-day CV was less strongly affected (5.5 ± 2.9 to 4.7 ± 2.3% intra-day CV) (Supplementary Data 4 and 5). The CVs obtained are in a range comparable with previous direct comparisons of SWATH-MS and SRM 47 .</p>
<p>We next elected to examine the CV at protein level in the HEK293 proteome across 21 SWATH-MS acquisitions at each site. Protein level abundances were inferred from the <rs id="a12882986" type="software">Open-SWATH</rs> results by summing the top five most intense fragment ion areas from the top three most intense peak groups per protein 42,44,57 (Supplementary Data 6 and 7). For proteins where &lt;3 peak groups were detected, all the available fragments were summed. The CVs, computed from the 4077 proteins that were detected in &gt;80% of all samples, at the intra-day, inter-day, and inter-site levels were 8.3 ± 16.2, 11.9 ± 17.2, and 22.0 ± 17.4% respectively, after peptide level median normalization (Fig. 3b). The inter-site protein CV as a function of protein abundance is shown in Fig 3c . Linearity and dynamic range. To determine the linearity and dynamic range characteristics of SWATH-MS data within and across the sites we first examined the dilution series of SIS peptides in response curves generated from the <rs id="a12882987" type="software">MultiQuant</rs> Software XIC analysis. A representative example for a single site is shown in Fig 4a (remaining sites in Supplementary Fig. 15; equivalent plots separated by peptide are shown in Supplementary Fig. 16; source data in Supplementary Data 8). Peak integration for the lowest concentration peptides was manually inspected to confirm correct peptide detection and that lower limits of quantitation conformed with good bioanalytical standards (&lt;20% CV, 80-120% accuracy, and S/N &gt; 20 at the lower limit of quantitation (LLOQ) 58 ). Low concentration data points failing these assessments were removed and the next higher concentration was evaluated. This was repeated until a good LLOQ was found. Manual integration adjustments were only done in the cases where there were clear interferences that could be removed.</p>
<p>To determine whether the LLOQ assessed by <rs id="a12882988" type="software">MultiQuant</rs> analysis corresponded to the automated <rs id="a12882989" type="software">OpenSWATH</rs> FDRbased analysis, we plotted the LLOQ (<rs id="a12882990" type="software">MultiQuant</rs>) and the lowest concentration detected by <rs id="a12882991" type="software">OpenSWATH</rs> for the peptides in groups A and B that span the low-attomole to low-femtomole Fig. 5 Lower limit of quantification in SWATH-MS and MS1. The percentage of the 30 SIS peptides detected at each concentration in the dilution series from each site of data collection was plotted at the SWATH-MS level a and the MS1 level b. Lower limit of quantification was defined as &lt;20% CV, S/N &gt; 20, 80-120% accuracy using linear fit with 1/x weighting in the response curve. Spectral peak widths for XIC generation were 0.02 m/z for MS1 and 0.05 m/z for SWATH-MS2, and the nominal resolving power was 30,000 and 15,000, respectively. c The average % detection at each concentration for all sites was determined (bold line in a and b) and overlaid to summarize detection differences between SWATH-MS and MS1 data. For the MS1 data, the C12 and C13 XIC data was also summed for comparison. Error bars are ± 1 standard deviation. d The data from a single site (site 1) is also shown for comparison range (Supplementary Fig. 18). For eight detectable peptides in these groups, six had an LLOQ at the same concentration as the lowest detectable by the FDR-based <rs id="a12882992" type="software">OpenSWATH</rs> analysis and the remaining two peptides had a difference of one 3× dilution step, indicating a good agreement between these methods. We further examined the correspondence in linearity of all SIS peptides as determined by <rs id="a12882993" type="software">MultiQuant</rs> or <rs id="a12882994" type="software">OpenSWATH</rs> and found this to be comparable over the majority of the concentration range, however, <rs id="a12882995" type="software">OpenSWATH</rs> failed to fully integrate very wide chromatographic peaks in the 3-10 pmol range which resulted in saturation for these concentrations (Supplementary Note 3, Supplementary Fig. 19).</p>
<p>Eluent from the column was introduced to the MS system using the NanoSpray Source into a TripleTOF 5600 system with <rs id="a12882996" type="software">Analyst Software TF</rs> <rs id="a12882997" type="version" corresp="#a12882996">1.6</rs>  (<rs id="a12882998" type="publisher" corresp="#a12882996">SCIEX</rs>) and the variable window acquisition beta patch. The SWATH-MS acquisition methods were built using the SWATH-MS Acquisition method editor and a pre-defined variable window width strategy using 64 windows (Supplementary Table 15). The Q1 mass range interrogated was 400-1200 m/z, and MS2 spectra were collected from 100 to 1500 m/z with an accumulation time of 45 ms per variable width SWATH window. A TOF MS scan (250 ms, 400-1250 m/z) was acquired in every cycle for a total cycle time of ~3.2 s. Nominal resolving power for MS1 and SWATH-MS2 scans were 30,000 and 15,000 respectively. The collision energy curve was controlled across all instruments (CE = 0.0625 * m/z -3) and the collision energy spread was defined in the variable window table (Supplementary Table 15). The acquisition order is outlined in the Supplementary Table 16. SWATH-MS data files (2 out of 231) were excluded by the local operators if there was an obvious acquisition error.</p>
<p>Pilot phase quality control assessment. SWATH-MS acquisition data from the pilot study phase were processed using the <rs id="a12882999" type="software" subtype="component" corresp="#a12883001">SWATH ® Acquisition MicroApp</rs> <rs id="a12883000" type="version" corresp="#a12882999">2.0</rs> in <rs id="a12883001" type="software" subtype="environment">PeakView</rs> Software <rs id="a12883002" type="version" corresp="#a12883001">2.2</rs>. A previously published proteome library containing mass spectrometric coordinates for 10,000+ human proteins 49 was used for data processing. iRT standard peptides (Biognosys) were included in the library for automatic retention time calibration of each different sample set with the ion library retention times. Peak group detections were filtered at a 1% global FDR and metrics were compared using <rs id="a12883003" type="software">Excel</rs> (this corresponds to data in Supplementary Fig. 1</p>
<p>Automated analysis of SWATH-MS data. The SWATH-MS data analysis was performed using <rs id="a12883004" type="software" subtype="component" corresp="#a12883005">OpenSWATH</rs> (<rs id="a12883005" type="software" subtype="environment">OpenMS</rs> v <rs id="a12883006" type="version" corresp="#a12883005">2.0</rs>) essentially as described 35 except that the improved single executable <rs id="a12883039" type="software">OpenSwathWorkflow</rs> was used instead of the multi-step workflow to perform peak-picking and feature detection and the following parameters were changed: m/z extraction window = 75 ppm, RT extraction window = 900 s. The spectral library used as input for peptide queries in the <rs id="a12883007" type="software">OpenSWATH</rs> analysis was a previously published proteome library containing mass spectrometric coordinates for 10,000+ human proteins built by combining several hundred DDA analyses of various human cell and tissues types 49 .</p>
<p>Semi-supervised learning to optimally combine <rs id="a12883008" type="software">OpenSWATH</rs> peptide query scores into a single discriminant score, and q-value 50 estimation to facilitate FDR control, were performed using an extended version of <rs id="a12883009" type="software">PyProphet</rs> <rs id="a12883010" type="bibr">72</rs>  (<rs id="a12883038" type="software">PyProphet -cli</rs> v <rs id="a12883040" type="version" corresp="#a12883038">0.19</rs>- <rs id="a12883011" type="url" corresp="#a12883009">https://github.com/PyProphet</rs>). <rs id="a12883012" type="software">PyProphet</rs> was run both using the experiment-wide context (local-global option in <rs id="a12883013" type="software">PyProphet</rs>-q-values are generated for every peptide query and protein in every sample) and the global context (global-global option-only one q-value for every peptide query and protein representing the highest scoring instance over the whole experiment), with a fixed λ of 0.4. The set of peptide peak groups used for learning the score weights of <rs id="a12883014" type="software">OpenSWATH</rs> sub-scores to produce a single discriminant score were sampled with a ratio ≈1/(no. of samples) in the analysis (for aggregated analysis of all sites 0.005, and for analysis of individual sites 0.05). The sets of peak groups detected at 1% FDR and proteins detected at 1% FDR in the global context were used as a filter to restrict the set of peak groups and proteins in the experiment-wide context. The filtered table from the experiment-wide context was then filtered at 1% FDR at the peptide query level. A protein was considered as detected in a given sample if it passed these consecutive filters (see Supplementary Note 2 for further discussion on FDR control). The repeatability 7 was defined as the intersect divided by the union between the peptide or proteins detected from two data files computed pairwise within the site of data collection or across the entire data set.</p>
<p>Normalization was achieved by equalizing medians at the peak group The normalization coefficients derived from the peak groups in HEK293 matrix were also used to normalize the peak areas determined by <rs id="a12883015" type="software">MultiQuant</rs> analysis (below) of the SIS peptides. Protein abundances were inferred by summing the top five most intense fragment ion peak areas from the top three most intense peak groups using the <rs id="a12883016" type="software">aLFQ</rs> software <rs id="a12883017" type="bibr">57</rs> (v<rs id="a12883018" type="version" corresp="#a12883016">1.33</rs>). Where &lt;3 peak groups were detected, the available peak groups were summed. Coefficients of variation (% CV) were computed as 100*standard deviation/mean. Hierarchical clustering was performed using the <rs id="a12883019" type="software" subtype="component" corresp="#a12883021">dist</rs> and <rs id="a12883020" type="software" subtype="component" corresp="#a12883021">hclust</rs> functions in <rs id="a12883021" type="software" subtype="environment">R</rs> (v <rs id="a12883022" type="version" corresp="#a12883021">3.2.2</rs>) using log2 transformed protein abundances and visualized using the <rs id="a12883023" type="software" subtype="environment">R</rs> package <rs id="a12883024" type="software" subtype="component" corresp="#a12883023">ape</rs> (v <rs id="a12883025" type="version" corresp="#a12883024">3.3</rs>). Pearson correlation coefficients were computed using the <rs id="a12883026" type="software" subtype="environment">R</rs> package <rs id="a12883027" type="software" subtype="component" corresp="#a12883026">Hmisc</rs> (v <rs id="a12883028" type="version" corresp="#a12883027">3.17</rs>) and visualized using the <rs id="a12883029" type="software" subtype="environment">R</rs> package <rs id="a12883030" type="software" subtype="component" corresp="#a12883029">corrplot</rs> (v <rs id="a12883031" type="version" corresp="#a12883030">0.73</rs>).</p>
<p>Analysis of SWATH-MS data for 30 SIS peptides. The SWATH Acquisition data obtained from all sites was processed using <rs id="a12883032" type="software">MultiQuant</rs> Software <rs id="a12883033" type="version" corresp="#a12883032">3.0</rs>. The same quantification method (Supplementary Table 17) was used across all sites and consisted of three to four fragment ion XICs extracted and summed together to produce a peptide area. Spectral peak widths for XIC generation were 0.05 for MS2 and 0.02 for MS. Peak integration was done using the MQ4 algorithm. The curve for each peptide was evaluated and the LLOQ was determined in accordance with bioanalytical standards 49 (&lt;20% CV, S/N &gt; 20, 80-120% accuracy; linear fit with 1/ x weighting). A number of analytical aspects were evaluated, including the reproducibility of the peptide peak areas, the LLOQ for each peptide, the signal/ noise ratios using the relative noise approach in the <rs id="a12883034" type="software">MultiQuant</rs> Software, and the reproducibility and accuracy of the concentration.</p>
<p>We thank Alex Ebhardt for providing the SIS peptides for this study; Eric Deutsch for facilitating FTP data exchange; Isabell Bludau for discussions on FDR control; Uwe Schmitt for development of the <rs id="a12883035" type="software">PyProphet</rs> extension; Hannes Röst for discussions on normalization and data analysis; Emanual Schmid for assistance with data management. We thank Asa Wahlander and Bernd Roschitzki from the Functional Genomics Center Zurich (FGCZ) for instrument maintenance and support with the MS measurements. A.-C.G. is the Canada Research Chair in Functional Proteomics and the Lea Reichmann Chair in Cancer Proteomics. We acknowledge funding from the Government of Canada through Genome Canada and Ontario Genomics (OGI-088, OGI-097) and Canadian Institutes of Health Research (FDN-143301) to A.-C.G.; the National Cancer Institute Clinical Proteomics Tumor Analysis Consortium (CPTAC) grant U24CA160036 to D.W.C. and H.Z.; Chinese National Basic Research Programs (2014CBA02002, 2014CBA02005). N.S. is supported by funding from the European Union's Seventh Framework Program HEALTH-F4-2013-602156. We acknowledge support from the NIH shared instrumentation grant for the TripleTOF system at the Buck Institute (1S10 OD016281, B.W.G.). M.P.M. acknowledges support from the Australian Government's National Collaborative Research Infrastructure Scheme. This work was funded in part by National Institutes of Health Grant RC2 HG005805 from the National Human Genome Research Institute (NHGRI) through the American Recovery and Reinvestment Act and Grants from the National Institute of General Medical Sciences (NIGMS) grants R01GM087221, S10RR027584 and 2P50GM076547 to the Center for Systems Biology, the National Science Foundation grant MCB-1330912, AMED-CREST from Japan Agency for Medical Research and Development, and the Funding Program for Next Generation World-Leading Researchers by the Cabinet Office to M.H.-K. and S.O. B.C.C. was supported by a Swiss National Science Foundation Ambizione grant (PZ00P3_161435). R.A. was supported by ERC Proteomics v3.0 (AdG-233226 Proteomics v.3.0) and AdG-670821 Proteomics 4D), the PhosphonetX project of SystemsX. ch and the Swiss National Science Foundation (SNSF) grant number: 31003A_166435.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f201073683"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T05:58+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>This systematic review was conducted and reported according to quality standards described in the AMSTAR measurement tool [14] and the PRISMA 2009 checklist [15]. Two reviewers independently carried out study selection, evaluation, and data extraction. We resolved discrepancies in our reviews by consensus. <rs id="a12952155" type="software">Covidence</rs> systematic review software  (<rs id="a12952156" type="publisher" corresp="#a12952155">Veritas Health Innovation</rs>, Melbourne, Australia) was used to screen, select, and extract data from included studies. The review protocol was registered in the PROSPERO database (CRD42017055217).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f322482414"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:00+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>To mitigate some of the above problems we integrated and Methods: customised two existing <rs id="a12901033" type="software" subtype="environment">JavaScript</rs> <rs id="a12901034" type="software" subtype="component" corresp="#a12901033">libraries</rs> to create a new web-based graphical data extraction <rs id="a12970685" type="software" subtype="implicit">tool</rs> to assist reviewers in extracting data from graphs. This tool aims to facilitate more accurate and timely data extraction through a user interface which can be used to extract data through mouse clicks. We carried out a non-inferiority evaluation to examine its performance in comparison with participants' standard practice for extracting data from graphs in PDF documents.</p>
<p>We found that the customised graphical data extraction <rs id="a12970686" type="software" subtype="implicit">tool</rs> is not Results: inferior to users' (N=10) prior standard practice. Our study was not designed to show superiority, but suggests that, on average, participants saved around 6 minutes per graph using the new <rs id="a12970689" type="software" subtype="implicit">tool</rs>, accompanied by a substantial increase in accuracy.</p>
<p>The use of bespoke online software for conducting systematic reviews is becoming increasingly standard practice, with tools such as <rs id="a12900951" type="software">Covidence</rs>, <rs id="a12900952" type="software">DistillerSR</rs>, <rs id="a12900953" type="software">EPPI-Reviewer</rs> and <rs id="a12900954" type="software">SyRF</rs> offering support for a range of review types in commonly available browsers. None of these platforms support the extraction of data in graphical form, however, and reviewers need therefore to use other tools to extract data from graphs, and then transcribe this information into whichever tool they are using for synthesis. This causes two problems. First, additional effort is needed on the part of reviewers to determine which application to use, to use it consistently across the reviewing team, and then to copy data back for synthesis. Second, there are no graphical extraction tools especially written for the types of data and workflows encountered in systematic reviews. The data can therefore require some transformation before being suitable for incorporation in the review. Given these challenges, and the growing infrastructure of browser-based systematic review applications, we decided to evaluate the possibility of utilising browser technologies to improve the efficiency of data extraction from graphs. To do this, we: 1) identified relevant technologies; 2) compiled a dataset for evaluation; 3) developed a pilot user interface; and 4) undertook an evaluation of the user interface in terms of its efficiency and accuracy as compared with other extraction methods. The aim was not to create a new tool that was ready for widespread deployment, but to inform future development decisions, based on the evaluation, as to the utility of integrating such a tool in systematic review software.</p>
<p>1. Through a comparison of the use of our customised <rs id="a12970692" type="software" subtype="implicit">tool</rs> with the user's current method of outcome data extraction, is there a notable difference between the two methods in the following metrics? a) Time taken b) Accuracy 2. Do participants in the evaluation (with a pre-existing interest in and knowledge of systematic review) consider this to be a viable or preferential approach compared with their current practice?</p>
<p>We developed requirements for the graphical data extraction <rs id="a12970695" type="software" subtype="implicit">tool</rs> and chose a browser-based solution for ease of deployment during evaluation and because, should that evaluation prove positive, the code could be integrated within web-based systematic review software such as those mentioned above. The two main requirements were that: a) the user interface should display PDF files and support the selection of graphs from which data would be extracted; and b) the user should be able to extract data from the graphs by specifying axes values and data types, and then by clicking appropriate points on the screen with a mouse. In terms of browser requirements, we decided that we would require HTML5 compliance, since most platforms now support this standard, and if we needed to support older browsers the cost of development would have been prohibitive.</p>
<p>We developed the graphical data extraction application using two existing <rs id="a12900958" type="language" corresp="#a12900959">JavaScript</rs> libraries: <rs id="a12900959" type="software">PDF.JS</rs> (version <rs id="a12900960" type="version" corresp="#a12900959">1.5.188</rs>) and <rs id="a12900961" type="software">WebPlotDigitizer</rs> (version <rs id="a12900962" type="version" corresp="#a12900961">3.8 8</rs> ). <rs id="a12900963" type="software">PDF.JS</rs> is a widely used library for displaying PDF files in web browsers. We used this library to display the graphs to evaluation participants and to allow them to draw a box around selected graphs. <rs id="a12900964" type="software">WebPlotDigitizer</rs> is a program that can extract data from graphs that are uploaded in a PNG or JPEG format, so we used <rs id="a12970712" type="software">JavaScript</rs> to 'send' the graph image to <rs id="a12900966" type="software">WebPlotDigitizer</rs>, and this library was customised to support our workflow and the data types common in systematic reviews. We now describe in more detail the workflow in the customised <rs id="a12970715" type="software">tool</rs>, and the software development undertaken to support it.</p>
<p>Our starting point for the design of this workflow was that users would be extracting data from a PDF file and, as part of this process, would encounter graphs within the file from which they would need to extract numeric data. We simulated this initial point of entry by using <rs id="a12900968" type="software">PDF.JS</rs> to display PDF files. This tool can display the majority of PDF files, and we encountered no problems when using it. We modified the default display of the tool in two ways for the purposes of this evaluation. First, we supressed the appearance of buttons and functionality that were unnecessary for our purposes (e.g. the ability to 'zoom' into / out of the page). Second, we wrote functionality that enabled users to draw a box around content in the PDF with a mouse -in our use scenario, users were expected to draw a box around a graph -and extract this part of the PDF file as an image to be used in the next part of the workflow. Figure 2 shows the display of graphs in the <rs id="a12900969" type="software">PDF.JS</rs> tool with a 'box' drawn around the graphic. The user then clicks the box to move to the next part of the workflow where we incorporated the <rs id="a12900970" type="software">WebPlotDigitizer</rs> tool <rs id="a12900971" type="bibr">8</rs> . <rs id="a12900972" type="software">WebPlotDigitizer</rs> is an online tool which supports the extraction of numeric data from many types of graphs. We customised the tool so that it supported both the data types that systematic reviewers use explicitly, and also our expected workflow.</p>
<p>After drawing a box around their selected graph and clicking the graph, the user moves into the user interface of <rs id="a12900973" type="software">WebPlotDigitizer</rs> <rs id="a12900974" type="bibr">8</rs> . Our modifications to <rs id="a12900975" type="software">WebPlotDigitizer</rs> fell into three main areas which are outlined in detail below: 1) user selection of specific data types and structures at the outset; 2) the addition of an interactive data table, which captures the data in a structure which is suitable for use in subsequent meta-analyses; and 3) data export.</p>
<p>We modified the normal point of entry to <rs id="a12900976" type="software">WebPlotDigitizer</rs> to display a menu of data types, series and data points for users to specify exactly what type of graph they were going to extract data from (Figure 3). In the example screenshot in Figure 3, we can see that the graph has three data points for each of four series, and each data point has a mean and confidence intervals around it. The user specifies this information, as well as whether the graph has one or two axes (in the example, there is only one axis: the y-axis). The tool then utilises the standard functionality of <rs id="a12900977" type="software">WebPlotDigitizer</rs> which supports the calibration of axes. This involves clicking the mouse on the origin (i.e. the bottom left hand side of the graph in the example) and the highest value in the axis (in the example, on the 10). The user then enters the values and the software can calculate the correct values for the positions of any mouse-clicks in between the two.</p>
<p>The 'point-and-click' interface, working alongside the data table means that the user is able to extract the relevant numeric data from a graph in a matter of seconds. Moreover, in order to assist with accurate mouse positioning, <rs id="a12900978" type="software">WebPlotDigitizer</rs> <rs id="a12900979" type="bibr">8</rs> contains by default a window on the top right which shows a 'zoomed in' display of the current mouse position.</p>
<p>Development took place iteratively during November 2016 to June 2017 by a highly experienced JavaScript developer (LD-C) resulting in the customised <rs id="a12970722" type="software" subtype="implicit">tool</rs> which was placed online for evaluation in June / July 2017. The integration and customisation of the two existing <rs id="a12900982" type="language" corresp="#a12900983">JavaScript</rs> libraries, <rs id="a12900983" type="software">PDF.JS</rs> (version <rs id="a12900984" type="version" corresp="#a12900983">1.5.188</rs>) and <rs id="a12900985" type="software">WebPlotDigitizer</rs> (version <rs id="a12900986" type="version" corresp="#a12900985">3.8 8</rs> ), resulted in a prototype workflow designed specifically around the needs of systematic reviewers. The aim was not to create a new tool that was ready for widespread deployment, but to inform future development decisions, based on the evaluation, as to the utility of integrating such a tool in systematic review software.</p>
<p>We used a non-inferiority trial design to evaluate the graphical data extraction application, with each participant extracting data from graphs using their current methods of data extraction and the new, customised graphical data extraction <rs id="a12970729" type="software" subtype="implicit">application</rs>. The study was approved by the UCL Institute of Education Research Ethics Board (reference REC 944.)</p>
<p>Our primary aims were to determine whether there were differences in time taken and accuracy between a user's current approach and the new approach to data extraction. We also sought feedback from users as to the usefulness of the new, customised <rs id="a12970730" type="software" subtype="implicit">tool</rs>.</p>
<p>We identified 5 broad classes of graph and created 23 examples (5 bar, 5 line, 5 scatter, 3 dot plot, and 5 box and whisker) (Supplementary File 5) in <rs id="a12900989" type="software">SigmaPlot</rs> version <rs id="a12900990" type="version" corresp="#a12900989">10</rs> using fictitious data and expressed to 3 significant figures, so that the true value for each data point was known; the 'new <rs id="a12970802" type="software" subtype="implicit">tool</rs>' condition had an additional class of graph, ROC/AUC, for which 4 graphs were created. Participants were required to extract data from graphs using both their current methods of data extraction and the new graphical data extraction application. For each method of extraction they worked though all 23 graphs in the same order (plus the 4 AUC/ROC graphs in the 'new <rs id="a12970800" type="software" subtype="implicit">tool</rs>' condition, and whether they started with the new method or their current method (defined as their preferred method that is used most often when extracting data) was determined at random by software code embedded within the study website.</p>
<p>The evaluation aimed to compare the purpose-built workflow, described above, with current practice. Because 'current practice' varies from person to person, we did not specify exactly which method participants should use, as we wanted them to use the one that they would naturally use -whether that was a specific tool, or simply holding a ruler against the computer monitor. Participants were therefore instructed to extract data from plots in this condition using whatever methods they typically currently use. Participants reported that the following tools were used in this condition: <rs id="a12900991" type="software">Universal Desktop Ruler</rs> <rs id="a12954627" type="bibr">(3)</rs>, In-built <rs id="a12900993" type="software">Adobe Acrobat</rs> <rs id="a12900994" type="software" subtype="implicit" corresp="#a12900993">measuring tool</rs> <rs id="a12954628" type="bibr">(3)</rs>, <rs id="a12900996" type="software">WebPlotDigitizer</rs> <rs id="a12954629" type="bibr">(2)</rs>, and <rs id="a12900998" type="software">Grabit</rs> <rs id="a12954630" type="bibr">(1)</rs>. The <rs id="a12901000" type="software">Qualtrics</rs> survey platform was used to collect data for this condition, whereby the graphs were uploaded alongside a table where the participant was asked to record their extractions. This software allows an accurate timing per graph to be collected. Figure 1 is a screenshot of one of the graphs with the table for entry of extracted data shown below. A copy of the platform as presented to participants can be found at https://imperial.eu. qualtrics.com/jfe/form/SV_eXnjY1YyPSY1mDj. Because of the challenges in manual data extraction from ROC/AUC graphs, these were not offered in this set.</p>
<p>The evaluation website for the <rs id="a12901001" type="software" subtype="implicit">graphical data extraction application</rs> was hosted at: <rs id="a12901002" type="url" corresp="#a12901001">http://pdfextractorweb.azurewebsites. net/</rs>. As well as supporting the data extraction problem itself, the graphical data extraction application measured the time that participants spent extracting data from each graph automatically.</p>
<p>We used a non-inferiority trial design to seek to demonstrate that the novel process (the use of a graphical data extraction application) was not meaningfully worse than the existing process (current methods of data extraction). Data were analysed in <rs id="a12901003" type="publisher" corresp="#a12901004">Microsoft</rs> <rs id="a12901004" type="software">Excel</rs>. The analysis process is outlined below.</p>
<p>To give a summary estimate of differences in the accuracy of data extraction using the different methods, we calculated the difference between the percentage of accurate data points using the new method and that using conventional methods. We determined in advance that we would consider that the new method was inferior to current methods if the point estimate of sufficient accuracy was greater than or equal to 5% lower than current methods (i.e., the new, customised<rs id="a12970736" type="software" subtype="implicit">tool</rs> would be considered inferior if SufficientCurrentMethod -SufficientNewMethod ≥ 5%). Under such circumstances, substantial redesign of our approach would be required.</p>
<p>A secondary aim of the project was to consider users' reactions to the new, customised <rs id="a12970740" type="software" subtype="implicit">tool</rs>. Analysis of the multiple-choice questions involved examination of frequencies and percentages of participant responses.</p>
<p>As described in the methods, we calculated the difference in times as the time for the current methods condition minus the time for new graphical data extraction <rs id="a12970743" type="software" subtype="implicit">tool</rs> within a participant, so that a positive value would indicate that the current methods took longer than the new method. The mean of these differences across participants was calculated to give (Xg¯) (in seconds); the results of which are reported for each graph in Table 1.</p>
<p>For each graph, the average time taken was less when using the new graphical data extraction <rs id="a12970745" type="software" subtype="implicit">tool</rs> compared with the usual approach used by participants, with some differences of more than 10 minutes. Overall, the mean time taken to extract data was 352 s (5 min 52 s) less using the new, customised <rs id="a12970751" type="software" subtype="implicit">tool</rs> than using (Here, anything less than 5% difference is favourable to the new method). The odds ratio of getting a sufficiently accurate data point compared to an insufficient data point in the new method compared to current methods was 3.34 (95%CI = 2.51, 4.44).</p>
<p>The percentage of respondents that either 'agreed' or 'strongly agreed' with statements evaluating their satisfaction with the features of the new graphical data extraction <rs id="a12970754" type="software" subtype="implicit">tool</rs> are depicted in Figure 7. They show strong support for the tool as compared with other methods, although these and subsequent answers suggest that additional development may be needed. Raw data is available on Zenodo 9 .</p>
<p>We have shown that our new graphical data extraction <rs id="a12970756" type="software" subtype="implicit">tool</rs> 10 is not inferior to users' preferred current approaches. Our study was not designed to show superiority, but suggests that, on average, participants saved around 6 minutes per graph using the new <rs id="a12970759" type="software" subtype="implicit">tool</rs>, accompanied by a substantial increase in accuracy. Indeed, that gain in accuracy is likely to be accompanied by further time-saving, as the number of outcome measures identified for reconciliation by a third reviewer will fall as a consequence. If our findings are confirmed, this would have profound implications for the conduct of systematic reviews where extraction of data from graphs is required. Our tool also received positive feedback from users in terms of its ease of use, fitness for purpose and perceived efficiency. the conventional approach (median, 364 s; IQR, 180-469 s; range, 93-691 s).</p>
<p>As described in the Methods, we considered whether a given data point was sufficiently accurate if at least 80% of participants' responses fell within a tolerable boundary around the true value. The number of data points that were of sufficient accuracy or insufficient accuracy were summed for each graph. The results for each graph, presented by condition, are shown in Table 2. Recall that the new <rs id="a12970762" type="software" subtype="implicit">tool</rs> would be considered inferior if SufficientCurrentMethod -SufficientNewMethod ≥ 5%. Overall, the current method ascertained data with sufficient accuracy for 41% of data points, compared with 70% for the new approach, for a difference of -29%, which is substantially better than our prespecified non-inferiority value of 5%.</p>
<p>The potential cost-and time-saving aspects of the graphical data extraction <rs id="a12970764" type="software" subtype="implicit">tool</rs> are likely to be substantial. The results showed a mean reduction of nearly 6 minutes in time taken to extract data from graphs compared to existing methods, which could translate to a substantial time saving per systematic review publication, due to reduced reviewer time. In practice, this time saving would be amplified, as it is advised that data in systematic reviews should be extracted by a minimum of two reviewers to reduce errors 1 and potentially even a third reviewer to resolve discrepancies.</p>
<p>Furthermore, as the graphical data extraction <rs id="a12970767" type="software" subtype="implicit">tool</rs> showed a considerable improvement in accuracy; this will also decrease time as the third reviewer will have fewer discrepancies to resolve.</p>
<p>who evaluated an electronic data extraction <rs id="a12970770" type="software" subtype="implicit">tool</rs> with a paper-based method, we found that the use of a graph extraction <rs id="a12970772" type="software" subtype="implicit">tool</rs> leads to more accurate data extraction 11 .</p>
<p>Lastly, the qualitative survey provides evidence that reviewers prefer the new data extraction <rs id="a12970776" type="software" subtype="implicit">tool</rs>, described hereby, to several desktop electronic methods of data extraction that are currently in use. This suggests that the tool will be acceptable and credible to the proposed users, which is necessary for its uptake.</p>
<p>Ultimately, there is strong evidence from the trial of the graphical data extraction <rs id="a12970777" type="software" subtype="implicit">tool</rs> that the further development and dissemination of this technology is worthwhile. The initial costs of implementation, training, and monitoring, would be offset by the impact of widespread use, leading to increased output of accurate systematic reviews, especially in preclinical topics where a large proportion of the outcome data are extracted from graphs.</p>
<p>As it currently stands, the technology developed here has limited 'real life' use. For it to become a useful part of the systematic review process it would need integration with other platforms used to facilitate systematic review and meta-analysis. An example is the <rs id="a12901019" type="software">SyRF</rs> platform (<rs id="a12901020" type="publisher" corresp="#a12901019">CAMARADES</rs>) which allows for screening and annotations for risk of bias using technology developed in other work packages for preclinical studies. Another example is <rs id="a12901021" type="software">EPPI-Reviewer</rs> <rs id="a12901022" type="version" corresp="#a12901021">12</rs> , a tool widely used in clinical and social scientific evidence synthesis, which is the core evidence synthesis platform for the UK's National Institute for Health and Care Excellence. The new online tool will be integrated within these two platforms and, since it is open source, it is available for integration within other systematic review platforms too.</p>
<p>The ultimate aim for the future would be "living" systematic reviews, which are updated constantly as new research evidence becomes available 13 . Given the scarcity and expense of human input, the use of new technologies-including automation-is being evaluated for these types of reviews 14 . Moreover, the human/machine axis may not be considered as binary opposites, as citizen science platforms, such as <rs id="a12901023" type="software">Cochrane Crowd</rs>, have shown that workflows can be developed that maximise the efficacy of human and machine contribution.</p>
<p>Second, this is a small study. We did not set out to show the superiority of the new, customised <rs id="a12970781" type="software" subtype="implicit">tool</rs>, and no conclusions of superiority should be drawn. However, we believe that it is reasonable to characterise the effectiveness of the tool as being promising.</p>
<p>We have detailed here the motivation for, and development of, the customisation of two existing <rs id="a12901041" type="software" subtype="environment">JavaScript</rs> <rs id="a12901026" type="software" subtype="implicit" corresp="#a12901041">libraries</rs> to create a new web browser-based <rs id="a12970784" type="software" subtype="implicit">tool</rs> to facilitate the extraction of quantitative data from graphs embedded in pdf files. We evaluated its utility in terms of its efficiency and accuracy, finding that it demonstrated non-inferiority compared to current practice in both dimensions. Our study suggests that the incorporation of this type of tool in online systematic review software would be beneficial in facilitating the production of accurate and timely evidence synthesis to improve decision-making.</p>
<p>Can you explain why is the new <rs id="a12970785" type="software" subtype="implicit">tool</rs> more accurate than the electronic tools that the participants used as their current method? What is it in those other electronic methods that is inferior, compared to the new <rs id="a12970787" type="software" subtype="implicit">tool</rs>? We would like to thank Livia Puljak for her helpful review and suggestions for improving the paper. We have made the following changes.</p>
<p>"Can you explain why is the new <rs id="a12970789" type="software" subtype="implicit">tool</rs> more accurate than the electronic tools that the participants used as their current method? What is it in those other electronic methods that is inferior, compared to the new <rs id="a12970791" type="software" subtype="implicit">tool</rs>?" That is a great question -but we can't unfortunately! We didn't investigate this question in the evaluation.</p>
<p>Institute of Health and Society, Newcastle University, Newcastle, UK Well written paper, but I'm confused as to where the novelty actually lies here. <rs id="a12901028" type="software">WebPlotDigitizer</rs> is an existing and already very useful tool, and it's not clear to me what the value of this 'adapted version' actually is? Is it the ability to view the PDFs with the graphs directly in the tool? Not sure. I think you need to make clearer the differences between the original software and this evolved version. Also, no proper citation to <rs id="a12901029" type="software">WebPlotDigitizer</rs>! I'm also not sure as to what is actually being assessed here: is it an evaluation of this particular tool or are you assessing the concept of using a graph extraction tool to save time (or is it both?). If it's the former, it would be good to see a more direct comparison with other similar tools in this space.</p>
<p>We would like to acknowledge with thanks the support we have received from our funders for this work; the time and effort given by participants in the evaluation; and the developers of <rs id="a12901030" type="software">PDF.JS</rs> and <rs id="a12901031" type="software">WebPlotDigitizer</rs>.</p>
<p>We have revised the final sentence to read: "Our study was not designed to show superiority, but suggests that, on average, participants saved around 6 minutes per graph using the new <rs id="a12970793" type="software" subtype="implicit">tool</rs>, accompanied by a substantial increase in accuracy." We don't think we can go as far as to say how many seconds / minutes were saved per data point, as there are other factors when considering how long data extraction takes.</p>
<p>Author Response 14 Dec 2018 , University College London, UK James Thomas Thanks Geoffrey, we will fix the lack of citation when we revise the manuscript. I remember looking for information re how to cite <rs id="a12901032" type="software">WebPlotdigitizer</rs>, and am not sure why it didn't make it into the submitted paper.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f204508709"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T16:20+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>Information regarding authors, publication year, country, sample (number of participants, age, gender), study design (cross-sectional/prospective), measurement tools (i.e., PA and social support measures), reliability of the measures, parental gender, and reported effect sizes, were abstracted onto a Word document. Once the coded data was entered, the file was imported into the <rs type="software" id="s1">Comprehensive Meta-Analysis</rs> version <rs type="version" corresp="s1">2</rs> program for further analyses [27].</p>
<p>Both fixed and random effects models were used to determine the overall effect sizes for both uncorrected and corrected effect sizes. However, only corrected effect sizes from the random effects model will be discussed. The strength of the correlation was categorized based on Cohen's recommendations [32]. According to these guidelines, a correlation of .09 or less was considered as a null effect, .10 a small effect, .30 a medium effect, and .50 a large effect. In addition to the overall effect sizes, 95% confidence intervals were calculated. To determine heterogeneity among the effect sizes, a Q-statistic and I 2 was computed. The Q-statistic identifies whether the observed variance in effect sizes is no greater than that expected by sampling error alone, whereas the I 2 denotes the dispersion. For the purposes of this study, I 2 values of 25 were categorized as having a low dispersal, 50 as a moderate dispersal, and 75 as a high dispersal. Moderator analyses investigating the effects of child's developmental age, study design, parental gender, measurement of child PA, and quality rating were performed using the corrected r's with fixed and random effects models. A minimum of 4 studies was required in each moderator analysis to deem it as a valid moderator. To identify the correlations between the intergenerational relationships between parent and child, separate analyses were used to examine whether the parents' gender moderated boys' and girls' PA. To assess the extent of publication bias in our samples, Rosenthal's classic fail-safe N [33] and Duval and Tweedie's Trim and Fill procedures [34,35] were conducted. All data was analyzed in February 2013 using <rs type="software">Comprehensive Meta-Analysis</rs>.</p>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f81549417"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T08:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>For statistical analysis, the most relevant result was extracted from each study on the relationship between social media use and depressive symptoms. Most studies had a correlational design, but for studies presenting other statistics, these were converted to correlations using the <rs id="a12952034" type="software">compute.es</rs> package <rs id="a12952060" type="bibr">(Re 2014)</rs>. These were analyzed and forest plots generated using the <rs id="a12952035" type="software" subtype="component" corresp="#a12952037">meta</rs> <rs id="a12952061" type="bibr">(Schwarzer 2015)</rs> and <rs id="a12952036" type="software" subtype="component" corresp="#a12952037">metafor</rs> <rs id="a12952062" type="bibr">(Viechtbauer 2015)</rs> packages in <rs id="a12952037" type="software" subtype="environment">R</rs>  (<rs id="a12952038" type="publisher" corresp="#a12952037">R Core Team</rs> 2016). The metacor command was used with Fisher's z transformation for the correlation and the DerSimonian-Laird estimator for τ 2 . Because a-priori heterogeneity was assumed, a random-effects model was used for the primary analysis; although the fixed-effect equivalent was also calculated as comparison of their differing inferential assumptions can be instructive. The random-effects model provides an unconditional inference about a broader set of studies of which the studies included in the meta-analysis are assumed to be a random sample, while the fixed-effects approach makes an inference based only on and about those studies actually included in the meta-analysis (Viechtbauer 2015).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f192909631"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T06:53+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>There has been a great deal of progress in state-of-the-art software for indexing and space-group determination: <rs id="a12971889" type="software">ITO</rs> <rs id="a12971890" type="bibr">(Visser, 1969)</rs>, <rs id="a12971891" type="software">TREOR</rs> <rs id="a12971892" type="bibr">(Werner et al., 1985)</rs>, <rs id="a12971893" type="software">DICVOL</rs> <rs id="a12971894" type="bibr">(Boultif &amp; Loue ¨r, 1991)</rs>, <rs id="a12971895" type="software">McMaille</rs> <rs id="a12971896" type="bibr">(Le Bail, 2004)</rs>, <rs id="a12971897" type="software">EXPO</rs> <rs id="a12971898" type="bibr">(Altomare et al., 2009)</rs> and <rs id="a12971899" type="software">X-CELL</rs> <rs id="a12971900" type="bibr">(Neumann, 2003)</rs>. Despite this progress, correct indexing and the ensuing spacegroup determination require considerable expertise. In fact, the performance of the indexing software would be perfect under the premise that the correct choice of peaks has been secured. However, none of the auto-peak choice programs has provided us with satisfactory indexing results (please see the supporting information). Among all the above-mentioned indexing programs, <rs id="a12971901" type="software">X-CELL</rs> has been reported to be quite advantageous in terms of the consideration of impurity peaks, but this program also requires some sort of human intervention to provide impurity tolerance levels (e.g. 0-5 to reflect the number of allowed impurity peaks) during the indexing process for an acceptable outcome. This implies that human intervention is inevitable in judging peak positions and, more importantly, in sorting out peak overlap complications. There are other critical human intervention issues besides peak overlap complication, such as impurity peak identification, and these must be resolved in order to achieve a correct peak choice that will lead to reliable indexing and space-group determination. Without long-term experience, it would be nearly impossible to select only the correct peaks, which is particularly tricky for low-symmetry and large cell size materials with a certain amount of impurities.</p>
<p>Deep learning is a powerful set of techniques for learning in neural networks and it has proved to be a promising and effective tool that outperforms traditional rule-based methods in many areas, such as image classification, pattern recognition, speech recognition and natural language processing. Deep learning has recently become mainstream in the biological and pharmaceutical research fields (Spencer et al., 2015;Heffernan et al., 2015;Mamoshina et al., 2016). However, there have been no noticeable attempts to introduce deeplearning techniques into work on inorganic functional materials. Deep learning is a form of modelling that is based on a convolutional neural network (CNN) (Lecun et al., 1998). A CNN confers versatility for classification tasks and for discriminating among a number of classes (labels). In particular, a CNN works best for image classification and hand-written text identification. Weight sharing at certain layers of the network via filters (kernels) is key to a CNN, and this weight sharing makes it possible to build up a deep structure composed of many more layers than the conventional artificial neural network (ANN). Weight sharing through a kernel also allows a CNN to achieve an equivariance representation of basic feature data. In addition, either maximum-or average-pooling layers provide invariance to image (or pattern) transformations by reducing spatial resolution via down-sampling, details of which are given in the supporting information. CNNs have recently been successfully applied to large-scale image classification tasks (Krizhevsky et al., 2012) and have yielded many state-of-the-art achievements in other areas. One of the most outstanding achievements has been <rs id="a12971902" type="software">AlphaGo</rs> <rs id="a12971903" type="bibr">(Silver et al., 2016)</rs>, which employed a CNN for both the policy and value networks in reinforcement learning and thereby defeated a human champion. Inspired by such successful achievements, we have developed an appropriate CNN to be used with powder XRD pattern classification, and have utilized it for crystal-system, extinction-group and spacegroup determination.</p>
<p>We tested the performance of the CNN model using a randomly selected test data set, the size of which amounted to 20% of the total data set. The test accuracies were evaluated to be 81.14, 83.83 and 94.99% for space-group, extinctiongroup and crystal-system classifications, respectively. This represents an amazingly accurate crystal-system prediction. However, the predictions for the extinction and space groups did not reach 90%. In fact, these numbers are very similar to the accuracy of human performance for the indexing and symmetry-determination process. It may appear that deep learning is little more than a mimicry of human behaviour, but it should be noted that, while what deep learning can do cannot surpass what humans can do, the efficiency and speed of a task are greatly improved when deep learning is substituted for learning by humans. However, it is certain that the CNN outperformed indexing based on auto-peak selection, as shown in sections S1 and S2 of the supporting information. Deep learning was prepared based on a personal coding using well established libraries, such as <rs id="a12971904" type="software">Keras</rs> and <rs id="a12971905" type="software">tensorflow</rs> in <rs id="a12971906" type="language" corresp="#a12971904">Python</rs>. The complete source <rs id="a12971907" type="software" subtype="implicit">code</rs> for our CNN model has been provided in the supporting information for convenience. Interested researchers may easily reproduce our CNN architecture using the above-mentioned libraries and test their own compounds for a tentative crystal system, extinction group and space group.</p>
<p>Accurate peak selection is the most important prerequisite for reliable indexing and for determination of the exact extinction group (or space group). The correct peak selection for indexing could never be chosen without some type of human intervention (even sometimes expert intervention), because actual XRD pattern data always include distortions that cause uncertainties in judging peaks and pinpointing their exact positions. Examples include overlap (the most serious problem), a small number of impurity phases, data blurring due to the bad quality of measurement, and a researcher's lack of crystallographic knowledge. Among all the indexing programs, <rs id="a12971908" type="software">TREOR</rs> requires much less time for indexing and is much more convenient for the initial level of indexing. The overall success rate of the <rs id="a12971909" type="software">TREOR</rs> program is better than 90%, and it is even higher than this for orthorhombic and higher symmetries <rs id="a12971910" type="bibr">(Werner et al., 1985)</rs>. The <rs id="a12971911" type="software">TREOR</rs> program, however, occasionally gives rise to unsatisfactory results in more complex systems (= lower-symmetry systems). Lower-symmetry systems usually result in many solutions with identical figures of merit and cell sizes. Thus, deciding the true solution can be very tricky, particularly for low-symmetry structures (please see the supporting information).</p>
<p>In order to show that conventional indexing software programs will fail without appropriate expert intervention, we employed two novel inorganic compounds that we had recently discovered, with exact crystal structures that had been clearly proven. These will be referred to as S-1 and S-2, Ca 1.5 Ba 0.5 Si 5 N 6 O 3 (monoclinic Cm) (Park et al., 2013) and Ba(Si,Al) 5 (O,N) 8 (orthorhombic A2 1 am) (Park et al., 2014), respectively. The actual XRD patterns of these compounds even include some impurity peaks, although they are extremely small. We adopted an auto-peak-selection function to pinpoint the peak positions and used the <rs id="a12971912" type="software">TREOR</rs> program for indexing. We have tried indexing many times by varying the peak-selection conditions in the <rs id="a12971913" type="software">TREOR</rs> program, but have never had a correct indexing result. It is obvious that there is no way to index properly via auto-peak selection without human intervention. This failure could have originated from either the peak overlap or the impurity peaks. Of course, an expert in crystallography would never fail to index them correctly if many more trial-and-error efforts were made, as we did previously for these two compounds (Park et al., 2013(Park et al., , 2014)). Details of the indexing process on the synchrotron X-ray powder diffraction patterns of S-1 and S-2 are given in the supporting information.</p>
<p>Both the choice of correct peaks and the ensuing consideration of systematic absences require a great deal of human expertise. However, our CNN model allows even novices to quickly reach the correct determination of a crystal system and probable space groups for novel compounds. It should be noted that our CNN is not intended to outperform experts who have much experience but, rather, it is meant to relieve their cumbersome burden in carrying out indexing and spacegroup determination. When non-experts are faced with unknown novel structures in the inorganic science research field, they can scarcely solve the structure given the current status of software development. Precisely speaking, our CNN model competes with neither well trained experts nor the well established indexing programs. The assistance is intended either for non-experts or for use with an auto-peak-search program. It is evident that, once a peak search has been correctly completed, then the <rs id="a12971914" type="software">TREOR</rs> program, or any of the other currently available indexing programs, would work perfectly.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f387895472"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:17+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Analysis. All sections of paper and card ripped by the birds were collected and scanned. Given the quantity and the non-uniform shapes of the ripped pieces a <rs id="a12951803" type="language" corresp="#a12951804">python</rs> <rs id="a12951804" type="software" subtype="implicit">script</rs> utilizing the <rs id="a12951805" type="software">openCV</rs> computer vision library was employed to measure their area and key dimensions (script accessible from <rs id="a12951806" type="url" corresp="#a12951804">https://figshare.com/s/a6b74be-4559712fd05d8</rs>). The scanned images were first run through a thresholding algorithm that separated each piece from the background image. They were then processed by a contour finding algorithm, which programmatically determined the borders of each piece. From this information, the area of each piece was calculated, first in pixels, and then translated into millimetres. Two bounding boxes were also calculated. The first specified the maximum and minimum X and Y coordinates of each piece, and the second determined the bounding box of best fit (defined by the rectangle with the lowest surface area) by algorithmically rotating a bounding rectangle around each piece. The length and width of this bounding box were used as an approximation of the length and width of each ripped piece (Supplementary Figure S5).</p>
<p>Statistical analyses were conducted in <rs id="a12951807" type="software">SPSS</rs> v. <rs id="a12951808" type="version" corresp="#a12951807">21</rs> and <rs id="a12951809" type="software">R</rs> <rs id="a12951810" type="version" corresp="#a12951809">3.3.0</rs>. To determine whether different sized pieces were manufactured in the small and large conditions we fit a linear mixed effect model on area (log-transformed for normality), with the condition (small or large) as a fixed effect and bird as a random effect. Mann-Whitney U-tests determined whether individual birds manufactured differently sized pieces in the small and large conditions. To test for order effects, GLMMs on area (log-transformed for normality) were run with trial order as a fixed effect and bird as a random effect (due to the within-subject nature of our design, trial order was nested within bird).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f554060804"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:44+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The <rs id="a12965499" type="software" subtype="implicit">code</rs> used to generate these analyses is available on GitHub at <rs id="a12965501" type="url" corresp="#a12965499">https://github. com/DXW-sola1015/2021 _Yang_COVID-19-Vax_China_Code</rs>.</p>
<p>Policy information about availability of computer code Data collection <rs id="a12965502" type="software">EXCEL</rs> was used to collected data.</p>
<p>The <rs id="a12970909" type="software" subtype="implicit">model</rs> was specifically implemented in <rs id="a12965503" type="language" corresp="#a12970909">C</rs> by the investigators and model outcomes were analyzed in <rs id="a12965504" type="software">R</rs> (version <rs id="a12965505" type="version" corresp="#a12965504">3.6.0</rs>). Should the manuscript be accepted, all data and codes will be provided on GitHub.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f386423226"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T10:13+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The elemental composition of the NPs was determined by analysis on a Vario EL III instrument (Elementar) and expressed as carbon (C), hydrogen (H), and nitrogen (N) mass content (%). The size of the NPs was determined by transmission electron microscopy (TEM). CD samples (0.5 µL, 1.0 mg/mL in 1.5 mM NaCl pH 7.4) were deposited on glow-discharged (90 V and 2 mA for 15 s) carboncoated grids (Cu-300HD, Pacific Grid Tech). After at least 2-hour drying at rt, the grids were observed using a bench top LVEM5 microscope (Delong Instrument) operating at 5 kV. The average size of the NPs was determined by image analysis using the <rs id="a12893284" type="software">ImageJ</rs> software (v <rs id="a12893285" type="version" corresp="#a12893284">1.50i</rs>, <rs id="a12893286" type="publisher" corresp="#a12893284">NIH</rs>), from a set of 300-1000 particles. The hydrodynamic diameter and ζ-potential value of NPs were measured by dynamic light scattering (DLS) on a Zetasizer NanoZS apparatus (Malvern Instruments). Measurements were performed in triplicate on fresh samples (1.0 mg/mL in 1.5 mM NaCl pH 7.4) at 25 °C. Data were analyzed using the <rs id="a12893287" type="software" subtype="implicit">multimodal number distribution software</rs> supplied with the instrument and expressed as mean (± SD). DLS was also used to assess the aggregation of NPs in culture medium. NP dispersions were prepared at 1.0 mg/mL in complete RPMI-1640 or DMEM-F12 containing 10% fetal serum, and measurements were performed extemporaneously without sonication of the dispersions. The surface charge density of NPs was determined by means of polyelectrolyte titration [69,70], monitoring ζ-potential variation of CDs (1.0 mg/ mL, NaCl 1.5 mM pH 7.4) along spiking with a solution of poly(acrylic acid) (PAA, MW ± 1,800 Da, NaCl 1.5 mM pH 7.4). The amount of PAA required to reverse the sign of ζ-potential was approximated by linear interpolation of the titration curve at the isoelectric point. The density of surface charge (electrokinetic charge, Q ek ) of the NPs was then calculated from the amount of required PAA by use of equation:</p>
<p>For FACS experiments, cells were seeded into 24-well plates at a density of 18.10 4 (A549) or 5.10 5 (THP-1) cells/ well. PMA (10 ng/mL) was added to culture medium of THP-1 cells to induce their differentiation into macrophages. The following day, the different cultures were exposed to 25 µg/mL NPs for 4 h. At the end of the exposure period, the cells were washed with PBS, detached with trypsin, centrifuged and resuspended in 500 µL of culture medium without serum. Samples were then analyzed on a LSRFortessa X-20TM cytometer (BD Biosciences) after sample excitation at 405 nm and emission signal detection at 450 nm. Data were analysed with the <rs id="a12893288" type="software">FlowJo</rs> software. Very small and very granular events (cell debris) were excluded from the analysis. For A549 cells, cell doublets (approximately 20% of the events identified on FSC-H/ SSC-W cytograms) were also excluded.</p>
<p>Data were plotted as concentration-response curves or bar charts and were analyzed with the <rs id="a12893289" type="software">GraphPad Prism</rs> <rs id="a12893290" type="version" corresp="#a12893289">6.0</rs> software. In the bar chart representations, statistical differences between groups were determined by one or two-way ANOVA followed by the Dunnett's test. Data were considered as significantly different when p value was less than 0.05.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f201868373"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:48+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Data obtained from MALQ responses, listening test scores, and strategy use frequencies, were processed using <rs id="a12951755" type="software">SPSS</rs> to address Research question 1. The quantitative data all went through tests of normality before further analysis to examine participants' pretest-posttest changes in listening performance, metacognitive knowledge and strategy use.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f429255948"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:31+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Soil property and class maps for the continent of Africa were so far only available at very generalised scales, with many countries not mapped at all. Thanks to an increasing quantity and availability of soil samples collected at field point locations by various government and/or NGO funded projects, it is now possible to produce detailed pan-African maps of soil nutrients, including micro-nutrients at fine spatial resolutions. In this paper we describe production of a 30 m resolution Soil Information System of the African continent using, to date, the most comprehensive compilation of soil samples ( N ≈ 150, 000 ) and Earth Observation data. We produced predictions for soil pH, organic carbon (C) and total nitrogen (N), total carbon, effective Cation Exchange Capacity (eCEC), extractablephosphorus (P), potassium (K), calcium (Ca), magnesium (Mg), sulfur (S), sodium (Na), iron (Fe), zinc (Zn)-silt, clay and sand, stone content, bulk density and depth to bedrock, at three depths (0, 20 and 50 cm) and using 2-scale 3D Ensemble Machine Learning framework implemented in the <rs id="a12965898" type="software">mlr (Machine Learning in R)</rs> package. As covariate layers we used 250 m resolution (MODIS, PROBA-V and SM2RAIN products), and 30 m resolution (Sentinel-2, Landsat and DTM derivatives) images. Our fivefold spatial Cross-Validation results showed varying accuracy levels ranging from the best performing soil pH (CCC = 0.900) to more poorly predictable extractable phosphorus (CCC = 0.654) and sulphur (CCC = 0.708) and depth to bedrock. Sentinel-2 bands SWIR (B11, B12), NIR (B09, B8A), Landsat SWIR bands, and vertical depth derived from 30 m resolution DTM, were the overall most important 30 m resolution covariates. Climatic data images-SM2RAIN, bioclimatic variables and MODIS Land Surface Temperature-however, remained as the overall most important variables for predicting soil chemical variables at continental scale. This publicly available 30-m Soil Information System of Africa aims at supporting numerous applications, including soil and fertilizer policies and investments, agronomic advice to close yield gaps, environmental programs, or targeting of nutrition interventions.</p>
<p>The results of stacking various learners indicate that overall Random Forest 23 seems to perform best in the fivefold Cross Validation, followed by the Lasso and Elastic-Net Regularized Generalized Linear Models (regr . cvglmnet) 24 , while <rs id="a12965858" type="software">Xgboost</rs> <rs id="a12965859" type="bibr">25</rs> and <rs id="a12965860" type="software">deepnet</rs> <rs id="a12965861" type="bibr">26</rs> packages only marginally increase accuracy of predictions. Derived by uploading soil data as points to <rs id="a12965862" type="software">Google Earth Engine</rs>, then overlaying with Sentinel-1/2 and Landsat products and fitting individual models using the <rs id="a12965863" type="software">caret</rs> package <rs id="a12965864" type="bibr">1</rs> (see also Fig. 7).</p>
<p>Over the last decade, the AfSIS project invested considerably in producing a new generation of agronomy data for Africa via AfSIS and related projects. To further extend and derive additional benefit from this primary soil data, we created an agronomy database at a previously unprecedented spatial resolution of 30 m, covering the entire African continent. The newly produced data volumes are substantial: for illustration, one image of Africa at 30 m resolution contains over 24 billion pixels of data (if shifting sand areas such as Sahara are excluded); the average size of a Cloud-Optimized GeoTIFF with internal compression containing predicted values of properties was of the order of 10-20 GiB. By harnessing available Open Access remote sensing data (Sentinel 2, Landsat 7/8), 3D predictive machine learning techniques (ensemble between Random Forest, <rs id="a12965865" type="software">XGBoost</rs>, <rs id="a12965866" type="software">deepnet</rs>, <rs id="a12965867" type="software">Cubist</rs> and <rs id="a12965868" type="software">GLM-net</rs>), and point samples generated by the AfSIS network, as well as a number of other open access soil datasets, we have modeled and produced predictions of 18+ soil variables including: soil texture fractions, soil pH, macronutrients (soil organic carbon, nitrogen, phosphorous, and potassium, magnesium), Our experience is that the Ensemble Multi-scale Predictive Soil Mapping system is a robust, scalable system which basically can be fully automated: from feature selection, model calibration and prediction, to determining quantiles or standard deviation of the prediction error. This is mainly thanks to the flexibility of programming in the <rs id="a12965869" type="software">mlr</rs> package <rs id="a12965870" type="bibr">28</rs> . The results of comparing different learners through fitting of meta-learners indicate that Random Forest 23 is the overall best-performing learner, but also Lasso and Elastic-Net Regularized Generalized Linear Models and <rs id="a12965871" type="software">Cubist</rs> often perform equally well. Ensembling of multiple learners can be justified for most of the target soil variables.</p>
<p>A 2-scale ensemble machine learning. Predictions of soil nutrients are based on a fully automated and fully optimized 2-scale Ensemble Machine Learning (EML) framework as implemented in the <rs id="a12965872" type="software">mlr</rs> package for Machine Learning  (<rs id="a12965873" type="url" corresp="#a12965872">https ://mlr.mlr-org.com/</rs>). The entire process can be summarized in the following eight steps (Fig. 7):</p>
<p>1. Prepare point data, quality control all values and remove any artifacts or types. 2. Upload to <rs id="a12965874" type="software">Google Earth Engine</rs>, overlay the point data with the key covariates of interest and test fitting random forest or similar to get an initial estimate of relative variable importance and pre-select features of interest. 3. Decide on a final list of all covariates to use in predictions, prepare covariates for predictive modelingeither using Amazon AWS or similar. Quality control all 250 m and 30 m resolution covariates and prepare Analysis-Ready data in a tiling system to speed up overlay and prediction. 4. Run spatial overlay using 250 m and 30 m resolution covariates and generate regression matrices. 5. Fit 250 m and 30 m resolution Ensemble Machine Learning models independently per soil property using spatial blocks of 30-100 km. Run sequentially: model fine-tuning, feature selection and stacking. Generate summary accuracy assessment, variable importance, and revise if necessary. 6. Predict 250 m and 30 m resolution tiles independently using the optimized models. Downscale the 250 m predictions to 30 m resolution using <rs id="a12965877" type="software" subtype="component" corresp="#a12965878">Cubicsplines</rs> (<rs id="a12965878" type="software" subtype="environment">GDAL</rs>). 7. Combine predictions using Eq. ( 3) and generate pooled variance/s.d. using Eq. ( 4). 8. Generate all final predictions as Cloud-Optimized GeoTIFFs. Upload to the server and share through API/ <rs id="a12965879" type="software">Geoserver</rs>.</p>
<p>Ensembles are predictive models that combine predictions from two or more learners 36 . We implement ensembling within the <rs id="a12965880" type="software">mlr</rs> package by fitting a 'meta-learner' i.e. a learner that combines all individual learners. <rs id="a12965881" type="software">mlr</rs> has extensive functionality, especially for model 'stacking' i.e. to generate</p>
<p>ensemble predictions, and also incorporates spatial Cross-Validation 37 . It also provides wrapper functions to automate hyper-parameter fine-tuning and feature selection, which can all be combined into fully-automated functions to fit and optimize models and produce predictions. Parallelisation can be initiated by using the <rs id="a12965882" type="software">par-allelMap</rs> package, which automatically determines available resources and cleans-up all temporary sessions 38 .</p>
<p>For stacking multiple base learners we use the SuperLearner method 39 , which is the most computational method but allows for an independent assessment of all individual learners through k-fold cross validation with refitting. To speed up computing we typically use a linear model (<rs type="software" id="a1">predict.lm</rs>) as the meta-learner, so that in fact the final formula to derive the final ensemble prediction can be directly interpreted by printing the model summary.</p>
<p>1. Ranger: fully scalable implementation of Random Forest 23 . 2. <rs id="a12965883" type="software">XGboost</rs>: extreme gradient boosting <rs type="bibr" corresp="#a12965883">40</rs> www.nature.com/scientificreports/ 5. <rs id="a12965884" type="software">Glmnet</rs>: GLM with Lasso or Elasticnet Regularization <rs type="bibr" corresp="#a12965884">24</rs> .</p>
<p>These Open source <rs id="a12965899" type="software" subtype="implicit">libraries</rs>, with the exception of the <rs id="a12965885" type="software">Cubist</rs>, are available through a variety of programming environments including <rs id="a12965900" type="language">R</rs>, <rs id="a12965901" type="language">Python</rs> and also as standalone <rs id="a12965888" type="language">C++</rs> libraries.</p>
<p>(2) www.nature.com/scientificreports/ and the model for soil pH: Note that in this case the coarse-scale model is somewhat more accurate with RMSE = 0.463 , while the 30 m covariates achieve at best RMSE = 0.661 , hence the weights for 250 m model are about 2 × higher than for the 30 m resolution models. A step-by-step procedure explaining in detail how the 2-scale predictions are derived and merged is available at <rs id="a12965890" type="url">https ://gitla b.com/openl andma p/spati al -predi ction s-using -eml</rs>. An <rs id="a12965891" type="software" subtype="environment">R</rs> package <rs id="a12965892" type="software" subtype="component" corresp="#a12965891">landmap</rs> <rs id="a12965893" type="bibr">44</rs> that implements the procedure in a few lines of <rs id="a12965894" type="software" subtype="implicit">code</rs> is also available.</p>
<p>1. Upload points to the <rs id="a12965895" type="software">Google Earth Engine</rs> <rs id="a12965896" type="bibr">67</rs> , overlay and fit initial Random Forest models to identify and prioritize the most important bands; 2. Processed prioritized bands using Amazon AWS; this is still tens of Terrabytes of Sentinel data, but considerably less than if all bands would have been selected and processed; 3. Produce cloud free mosaics for the period 2018-2019 using Amazon AWS; download the final product as Cloud-Optimised GeoTIFFs; 4. Run spatial overlay, model fitting and prediction in a local system using Solid State Disk drive and servers with a lot of RAM.</p>
<p>We refer to this as "the hybrid Cloud-based 2-step variable selection procedure" (Fig. 7). With it we combine the power of <rs id="a12965897" type="software">Google Earth Engine</rs> with our own computing infrastructure to achieve customized processing.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f481284541"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:42+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Individuals were asked about demographics, behaviors, work and vaccination uptake (https://www.ndm.ox.ac.uk/covid-19/covid-19-infection-survey/caserecord-forms). At the first visit, participants were asked for (optional) consent for follow-up visits every week for the next month and then monthly for 12 months from enrollment. At each visit, enrolled household members provided a nose and throat self-swab following instructions from the study worker. From a random 10-20% of households, individuals age 16 years or older were invited to provide blood monthly for antibody testing from enrollment. From April 2021, additional participants were invited to provide blood samples monthly to assess vaccine responses, targeting 150,000 antibody tests per month, based on a combination of random selection and prioritization of individuals in the study for the longest period (independent of test results, vaccination or previous positive PCR tests). Throughout, individuals with a positive swab test and their household members were also invited to provide blood monthly for follow-up visits after this. Laboratory testing. Swabs were couriered directly to the UK's national Lighthouse laboratories (Glasgow and the National Biocentre in Milton Keynes (to 8 February 2021)) where samples were tested within the national testing program using identical methodology. The presence of three SARS-CoV-2 genes (ORF1ab, nucleocapsid protein (N) and spike protein (S)) was identified using RT-PCR with the TaqPath RT-PCR COVID-19 kit (Thermo Fisher Scientific), analyzed using <rs id="a12893729" type="software">UgenTec FastFinder</rs> <rs id="a12893730" type="version" corresp="#a12893729">3.300.5</rs> (TagMan 2019-nCoV assay kit V2 UK NHS ABI 7500 v2.1, UgenTec). The assay plugin contains an assay-specific algorithm and decision mechanism that allows conversion of the qualitative amplification assay raw data into test results with little manual intervention. Samples are called positive if either N or ORF1ab, or both, are detected. The S gene alone is not considered a reliable positive but could accompany other genes (that is, one, two or three gene positives).</p>
<p>All statistical analyses of VE were performed using standard functions in the following <rs id="a12893731" type="software" subtype="environment">R</rs> packages: <rs id="a12893732" type="software" subtype="component" corresp="#a12893731">ggplot2</rs> (version <rs id="a12893733" type="version" corresp="#a12893732">3.3.2</rs>), <rs id="a12893734" type="software" subtype="component" corresp="#a12893731">rms</rs> (version <rs id="a12893735" type="version" corresp="#a12893734">6.0-1</rs>), <rs id="a12893736" type="software" subtype="component" corresp="#a12893731">dplyr</rs> (version <rs id="a12893737" type="version" corresp="#a12893736">1.0.2</rs>), <rs id="a12893738" type="software" subtype="component" corresp="#a12893731">emmeans</rs> (version <rs id="a12893739" type="version" corresp="#a12893738">1.5.1</rs>), <rs id="a12893740" type="software" subtype="component" corresp="#a12893731">haven</rs> (version <rs id="a12893741" type="version" corresp="#a12893740">2.3
.1</rs>), <rs id="a12893742" type="software" subtype="component" corresp="#a12893731">sandwich</rs> (version <rs id="a12893743" type="version" corresp="#a12893742">3.0-0</rs>), <rs id="a12893744" type="software" subtype="component" corresp="#a12893731">ggeffects</rs> (version <rs id="a12893745" type="version" corresp="#a12893744">1.0
.1</rs>), <rs id="a12893746" type="software" subtype="component" corresp="#a12893731">broom</rs> (version <rs id="a12893747" type="version" corresp="#a12893746">0.7.2</rs>), <rs id="a12893748" type="software" subtype="component" corresp="#a12893731">multcomp</rs> (version <rs id="a12893749" type="version" corresp="#a12893748">1.4-14</rs>) and <rs id="a12893750" type="software" subtype="component" corresp="#a12893731">Epi</rs> (version <rs id="a12893751" type="version" corresp="#a12893750">2.44</rs>). Analyses of Ct values were performed using <rs id="a12893752" type="software" subtype="component" corresp="#a12893754">qreg</rs> and <rs id="a12893753" type="software" subtype="component" corresp="#a12893754">fmm</rs> in <rs id="a12893754" type="software" subtype="environment">Stata</rs> version <rs id="a12893755" type="version" corresp="#a12893754">16.1</rs>. <rs id="a12893756" type="software" subtype="implicit">Code</rs> used for data analysis is available upon reasonable request.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f358466133"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:21+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The projection images are pre-processed and aligned before a tomogram is reconstructed. Nowadays, preprocessing benefits from the fast readout and improved SNR provided by direct electron detectors. Recording in movie mode allows the correction of beam-induced sample motions, which otherwise limit resolution [40], and it allows for low-pass filtering of movie frames in such a way that the filter cutoff is following the gradual demise of high-resolution structural information as the total exposure to the electron beam accumulates [41]. Recently, fiducial-based motion correction has been extended to the whole tilt series, reducing the effect of out-of-plane sample deformations during exposure [42]. Next, alignment of the tilt series brings the projections into a common register. The addition of nano-sized high-contrast fiducial markers to the samples, typically 5-20 nm gold beads, increases the alignment accuracy. The tilt series alignment of FIBmilled lamellae without fiducials requires patch tracking [43] or tracking of intrinsic high-contrast features [44]. The functionality for automated tracking and tilt series alignment as well as routines for tomogram reconstruction are integrated in, for example, the widely used <rs id="a12883881" type="software">IMOD</rs> software package [<rs id="a12883882" type="bibr">43</rs>] or in the <rs id="a12883883" type="software" subtype="component" corresp="#a12883884">Protomo</rs> implementation inside <rs id="a12883884" type="software" subtype="environment">Appion</rs> [<rs id="a12883885" type="bibr">45</rs>]. For sufficient levels of phase contrast for cryo-ET, a tilt series is conventionally acquired in underfocus. To successfully restore the high-resolution image information, it is necessary to accurately determine the defocus and correct for the contrast transfer function (CTF). The simplest approaches divide each tilt image into strips or patches and estimate the defocus gradient perpendicular to the tilt axis [46][47][48]. For sub-tomogram averaging more accurate 3D CTF correction methods consider also the particle height in the tomogram [49,50].</p>
<p>Several software packages integrate various tools for sub-tomogram analysis; <rs id="a12883889" type="software">Dynamo</rs> [<rs id="a12883890" type="bibr">85</rs>], <rs id="a12883891" type="software">EMAN2</rs> [<rs id="a12883892" type="bibr">86</rs>], <rs id="a12883893" type="software">emClarity</rs> [<rs id="a12883894" type="bibr">87</rs>], <rs id="a12883895" type="software">PEET</rs> [<rs id="a12883896" type="bibr">88</rs>], <rs id="a12883897" type="software">Protomo</rs> [<rs id="a12883898" type="bibr">89</rs>], <rs id="a12883899" type="software">PyTom</rs> [<rs id="a12883900" type="bibr">90</rs>], <rs id="a12883901" type="software">RELION</rs> [<rs id="a12883902" type="bibr">91</rs>]. These packages include functionalities for different sub-tomogram averaging steps; some provide also data management, allow users to design highly customizable workflows, or they guide sub-tomogram analysis along a predefined path. A comparison of their features can be found in Chen et al. [44].</p>
<p>A with <rs id="a12883903" type="software">emClarity</rs>, a sub-tomogram averaging package [<rs id="a12883904" type="bibr">87</rs>]. In addition to sub-tomogram averaging and data-collection advances, new insights into the assembly and maturation of viral capsids have been obtained.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f555917018"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:18+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The tooth wear score for each participant was determined as the highest wear grade found in the two quadrants examined. Kruskal-Wallis tests were used to compare the mean tooth wear scores in different age groups, while Mann-Whitney U tests were used to identify possible differences in mean tooth wear scores between genders, socioeconomic statuses, tooth types, and the two surveys considered here. All analyses were performed using IBM <rs id="a12951897" type="software">SPSS Statistics</rs> <rs id="a12951898" type="version" corresp="#a12951897">22.0</rs> software  (<rs id="a12951899" type="publisher" corresp="#a12951897">IBM Corp.</rs>, Armonk, N.Y., USA).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f207643625"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T09:26+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>For each method, internal standard peak areas were monitored for quality control. <rs id="a12873240" type="software">MultiQuant</rs> software (Version <rs id="a12873241" type="version" corresp="#a12873240">1.1</rs>; <rs id="a12873242" type="publisher" corresp="#a12873240">AB SCIEX</rs>; Foster City, CA) was used for automated peak integration and metabolite peaks were manually reviewed for quality of integration and compared against a known standard to confirm identity.</p>
<p>Full microarray data have been deposited to GEO: http://www.ncbi.nlm.nih.gov/geo/query/acc. cgi?acc=GSE55311 motifADE analysis (Mootha et al., 2004) was performed using publicly available <rs id="a12873245" type="software" subtype="implicit">code</rs> (<rs id="a12873246" type="publisher" corresp="#a12873245">Broad Institute</rs>). Genes were ordered by the ratio of the average value from days 1 through 10 of dox treatment, to the average of untreated samples. Sequences flanking transcription start sites, with repeat sequences masked, were obtained from the <rs id="a12954031" type="software">UCSC genome browser</rs>. Mouse-human homology was used to improve detection of conserved transcription factor binding sites. We looked for all ungapped motifs between 6 and 8 in length, as well as 9mer motifs with single gaps. We observed the ATF4 signal regardless of whether we looked for bidirectional occurrence of the motifs or considered each direction separately; the results shown in Figure 2a and Supplementary file 2 are for bidirectional searching.</p>
<p>The N-terminal truncation of GADD34 reported in Novoa et al. (2001) was from CHO-K1 cells; we wished to obtain the analogous human version of the protein. We <rs id="a128732533" type="software">BLASTed</rs> the C. griseus GADD34 protein sequence against the human, and determined that the truncation point corresponded to position 308 in the H. sapiens GADD34 protein sequence (NCBI reference sequence symbol PPP1R15A). We amplified this fragment from T-REx-293-derived complementary DNA using the PCR primers GATGAAGAGGAGGGTGAGGTCAAG and GCCACGCCTCCCACTGAGG, performed an additional 30 cycles of PCR using Gateway-flanked primers that also incorporated an ATG start codon, and recombined the resulting PCR product into the pDONR221 Gateway entry vector using BP Clonase II (Thermo Fisher). We call the protein product of this insert GADD344N. We encountered difficulties in selecting for lentivirally-transduced GADD344N expression using puromycin resistance, and suspected that inhibition of the ATF4 response might make cells more susceptible to puromycin treatment. To work around this, we used restriction digestion to remove the puromycin resistance open reading frame from the pLX302 lentiviral expression vector (Addgene, Cambridge, MA) and used Gibson isothermal assembly (Gibson et al., 2009) to replace it with GFP. We recombined the GADD344N insert into this new vector (which we call pLX-GFP), made virus with psPAX2 (Addgene) and pCMV-VSVG (Broad Institute) helper plasmids, and infected T-Rex293 cells at MOI &lt; 1. We then selected for GFP expression with two rounds of fluorescenceactivated cell sorting on a FACSAria II (Becton Dickinson). Control infections were done similarly, except with an additional copy of GFP instead of GADD344N inserted using Gateway recombination.</p>
<p>We characterized protein changes (n = 1) for two different time points, plus a control. PolGdn cells were grown in SILAC labeled DMEM (Caisson Labs, Logan, UT) with 10% dialyzed FBS (Sigma). They were first seeded at 4.0Â10 6 each into three sets of replicate 15-cm plates with heavy (R10K8), medium (R6K4), and light (R0K0) SILAC media and grown for 3 d. They were then split into eight 15cm plates for each condition. Doxycycline was added at 1 mg/ml 2 d before the split to heavy labeled cells, and 1 d after the split to medium labeled cells. 3 d after the split, cells were trypsinized, and cells from replicate plates pooled and counted. 7Â10 6 cells from each condition were mixed, pelleted, aspirated, suspended in 8 M urea and sonicated. This sample was treated with dithiothreitol (1 mM final), and iodoacetamide (6 mM final) and proteins fractionated by SDS-PAGE. Each gel lane was cut into ten slices of approximately equal staining intensity, in-gel digested with trypsin, and analyzed by liquid chromatography-mass spectrometry on a LTQ-Orbitrap (Thermo, Inc.) following the procedure in Sancak et al. (2013). SILAC data were analyzed using <rs id="a12873249" type="software">MaxQuant</rs> ver. <rs id="a12873250" type="version" corresp="#a12873249">1.0.13.13</rs> according to the procedure described in Cox et al. (2009). A minimum of two quantified peptides was required for each quantified protein. The FDR for protein and peptide identification was set at 0.01. The IPI human database ver 3.65 was used and supplemental sequences from mitochondrial DNA and common contaminants such as keratins and serum proteins were included at search time. Raw data are publicly available at www.broadinstitute.org/proteomics H 2 S assays Sulfide (sum of H 2 S, HS -, and S 2-) levels in the T-REx-293 cells were measured using monobromobimane (MBB)-based high performance liquid chromatography (HPLC) analysis as reported previously (Marutani et al., 2012;Tokuda et al., 2012). Briefly, cells were washed with ice-cold Tris-HCl (100 mM, pH 9.5, 0.1 mM DTPA) buffer, scraped, transfered to an eppendorf tube, and centrifuged to obtain the supernatant. MBB (10 mM in acetonitrile, 50 ml) was added to 100 ml of supernatant. After 30 min of incubation at room temperature in dark, 50 ml of 200 mM 5-sulfosalicylic acid (SSA) was added. After centrifugation, supernatant was analyzed by HPLC equipped with Agilent HPLC column C18 and Waters 2475 Multi l fluorescence detector.</p>
<p>T-REx-293 cells were seeded to 6 cm plates at 2Â10 6 and allowed to attach and grow for 1 d. They were then washed with warm PBS and treated with serine-free DMEM supplemented with 3 mM Dformate (Sigma) and 10% dialyzed FBS. After 12 hr treatment, cells were aspirated, washed with icecold PBS, and metabolites extracted using 1 ml 80% methanol: 20% water. Deuterated serine and methionine were quantitated as described previously (Mascanfroni et al., 2015). Briefly, cell extracts (10 mL) were diluted using 90 mL of 74.9:24.9:0.2 vol/vol/vol acetonitrile/methanol/formic acid containing stable isotope-labeled internal standards (valine-d8, Isotec; and phenylalanine-d8, Cambridge Isotope Laboratories; Andover, MA). The samples were centrifuged (10 min, 9000 g, 4 ˚C) and the supernatants were injected directly onto a 150 Â 2 mm Atlantis HILIC column (Waters; Milford, MA). The column was eluted isocratically at a flow rate of 250 ml/min with 5% mobile phase A (10 mM ammonium formate and 0.1% formic acid in water) for 1 min followed by a linear gradient to 40% mobile phase B (acetonitrile with 0.1% formic acid) over 10 min. The electrospray ionization voltage was 3.5 kV and data were acquired using full scan analysis over m/z 70-800 at 70,000 resolution. LC-MS data were processed and visually inspected using <rs id="a12873251" type="software">TraceFinder</rs> <rs id="a12873252" type="version" corresp="#a12873251">3.1</rs> software  (<rs id="a12873253" type="publisher" corresp="#a12873251">Thermo Fisher Scientific</rs>; Waltham, MA).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f269308191"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:49+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The particular tool used by the facilitation team to do their work was a strategy map created with <rs id="a12951693" type="software">Group Explorer</rs>, a networked computer system that uses a visual causal mapping technique to support decision making in teams (Bryson et al. 2004;Eden and Ackermann 2010). The map was used by the workshop participants to capture a range of strategic issues and their perceived implications. To construct the map, participants assembled in the workshop room and sat at small tables arranged in a horseshoe-shaped layout, with a console laptop for each table. The consoles were connected to a master laptop operated by the lead facilitator, who used it to control the consoles and assemble the team's contributions, and then displayed them on a large public screen located at the front of the workshop room. The screen was visible to all participants and provided a focal point around which group discussions about strategic issues took place. Participants' contributions were gathered both anonymously through the consoles and quickly displayed on the screen as they were entered, and via the content facilitator. In addition, and assisted by the second facilitator, participants jointly structured their contributions to create the strategy map. The workshop setting, together with an excerpt of the strategy map built during the workshop, is shown in Fig. 1a,b.</p>
<p>As already stated, the formulations shown below were derived from our corpus of four workshops, though for reasons of clarity and space we are showing extracts from one setting only (<rs id="a12951694" type="software">Group Explorer</rs> workshop -see Table 1).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f79093084"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-25T07:03+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>P.J.E., K.S.H., C.C.N.K., G.D.M., N.P.R. and P.B.W. contributed to design and construction of the experimental apparatus. P.J.E. and P.B.W. collected and analyzed data. J.W.B., P.J.E., J.J.H., M.R.H., I.R.P. and P.B.W. contributed to designing the machine learning approach. P.B.W. and M.R.H. wrote the manuscript. <rs id="a12970108" type="publisher" corresp="#a12970109">M.R.H.</rs> wrote the <rs id="a12970109" type="software">M-LOOP</rs> software. A.v.d.H., J.J.H., M.R.H., A.N.L. and N.P.R. contributed to the original conception of the experiment. N.P.R. guided direction of experimental approach. All authors contributed to discussions of experiment and results, and assisted in editing the manuscript.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f207522207"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T08:17+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Descriptive statistics were used to describe specialty response rates and reasons for non-response in current case study. Chi-square analysis was used to examine differences between specialists by demographic characteristics or payment plan group. We compiled results from a secondary survey examining physicians' reasons for non-response and categorized comments into five broader themes based on degrees of commonality within responses. All statistical analyses were conducted using <rs id="a12901076" type="software">Stata IC</rs>, Version <rs id="a12901077" type="version" corresp="#a12901076">12</rs>  (<rs id="a12901078" type="publisher" corresp="#a12901076">StataCorp LP</rs>, College Station, TX).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f567416075"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:41+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The Cox regression models were fit using the <rs id="a12893779" type="software" subtype="component" corresp="#a12893780">coxph</rs> function in the <rs id="a12893780" type="software" subtype="component" corresp="#a12893782">survival</rs> package (version <rs id="a12893781" type="version" corresp="#a12893780">2.44-1.1</rs>) for <rs id="a12893782" type="software" subtype="environment">R</rs> (version <rs id="a12893783" type="version" corresp="#a12893782">3.5.1</rs>). Calibration curves using hazards regression were estimated using the <rs id="a12893784" type="software" subtype="component" corresp="#a12893786">hare</rs> and <rs id="a12893785" type="software" subtype="component" corresp="#a12893786">phare</rs> functions in the <rs id="a12893786" type="software" subtype="component" corresp="#a12893788">polspline</rs> package (version <rs id="a12893787" type="version" corresp="#a12893786">1.1.15</rs>) for <rs id="a12893788" type="software" subtype="environment">R</rs>. Restricted cubic splines were implemented using the <rs id="a12893789" type="software" subtype="component" corresp="#a12893790">rcs</rs> function from the <rs id="a12893790" type="software" subtype="component" corresp="#a12893792">rms</rs> package (version <rs id="a12893791" type="version" corresp="#a12893790">5.1-2</rs>) for <rs id="a12893792" type="software" subtype="environment">R</rs>. Note that the <rs id="a12893793" type="software" subtype="implicit" corresp="#a12893794">calibrate.* functions</rs> in the <rs id="a12893794" type="software" subtype="environment">rms</rs> package make this automatic.</p>
<p>The random survival forests were fit using the <rs id="a12893795" type="software" subtype="component" corresp="#a12893796">rfsrc</rs> function from the <rs id="a12893796" type="software" subtype="component" corresp="#a12893798">randomForestSRC</rs> package (version <rs id="a12893797" type="version" corresp="#a12893796">2.7.0</rs>) for <rs id="a12893798" type="software" subtype="environment">R</rs>. Software for conducting these analyses is provided in Appendices A and B.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f207651418"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T14:14+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Rigid body motions are initialized by greedily extracting motion estimates from sparse scene flow vectors (Geiger et al., 2011) as follows: We iteratively estimate rigid body motions using the 3point RANSAC algorithm on clusters of similar motion vectors and chose promising subsets with a large number of inliers using non-maxima suppression. The mean positions and the moving direction of the best hypotheses are used as initial values for the object pose parameters ξ. This leads to spurious object hypotheses, as evidenced by Fig. 5, which are pruned during inference because no superpixels are assigned to them. In our experiments, γ comprises two shape parameters controlling the two most significant principal components of the ASM. We initialize each object with the mean shape of the model by setting its shape parameters γ to zero. To compute the shape consistency term in Eq. 3, we use <rs id="a12969705" type="software">OpenGL</rs> to render all object proposals and compare the resulting disparity maps to those induced by the shape particles of each superpixel. In our non-optimized implementation, inference takes more than one minute on a single core, thus the method is not yet applicable to scenarios with real-time constraints.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f210887427"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:20+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Linguists and archeologists associate proto-Japonic with the beginnings of Yayoi-culture (900 BCE-300 CE) on the Japanese Islands (Hudson 2002;Robbeets 2005;Unger 2009;Whitman 2011;Miyamoto 2016). Proto-Japonic, the ancestor of Mainland Japanese and the Ryukyuan languages, is thought to have separated when Yayoi culture started to spread northeastwards over the Japanese Islands in the early centuries BCE. This chronological estimation is in line with Lee and Hasegawa's (2011) Bayesian phylogenetic analysis, dating Proto-Japonic divergence at 182 BCE. Lexicostatistic approaches such as Hattori's (1976: 43) estimated the breakup between 0 and 500 CE, while the <rs id="a12951889" type="software">Automated Similarity Judgement Program (ASJP)</rs> yielded 436 CE, be it with a margin of error of 29% (Holman et al. 2011). The ancestor of the languages now spoken in the Ryukyuan Islands is thought to have remained in northeastern Kyushu until around 900 CE, when full-scale agriculture was introduced to the Ryukyus. The derivation of Ryukyuan from an early Kyushu dialect is consistent with the distribution of the main accent types over Japan and across the Ryukyu Islands and may reflect different waves of founder populations to different islands in the Ryukyu chain at slightly different times (Unger 2009: 105-6, 211, de Boer in press, 2019). In sum, linguists estimate the breakup of proto-Japonic between 200 BCE and 500 CE.</p>
<p>Here, we apply a Bayesian method using <rs id="a12951890" type="software">BEAST</rs> <rs id="a12970903" type="bibr">(Bouckaert et al. 2014)</rs>, which is also character-based, and seeks to explain a set of observed data by quantifying how likely it is that they have been produced by a certain model of the evolution of cognates along a tree.</p>
<p>So far, we used the simple Yule model as tree prior. The birth-death skyline (BDSKY) model (Stadler et al. 2013) is a flexible alternative that allows us to explore more complex tree priors than the one parameter Yule model. We considered splitting the time range into two epochs with one birth rate for each epoch giving a two parameter model. However, comparing the 1 epoch BDSKY model with the two epoch BDSKY model (since the BDSKY is slightly differently parameteried than the Yule model in <rs id="a12951892" type="software">BEAST</rs>) gives a Bayes factor of 4.9 in favour of the 1 epoch model, so we conclude that increasing the number of parameters in the model cannot be justified. The results presented below are based on the Yule prior.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f533447945"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:20+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>In the present study, Bragg reflection and their interactions with the harbor are simulated using a fully nonlinear Boussinesq model, <rs id="a12972794" type="software">FUNWAVE</rs> <rs id="a12972795" type="version" corresp="#a12972794">2.0</rs>. For the purpose, an elongated harbor with constant depth is considered, and a series of sinusoidal bars with various amplitudes and numbers are deployed outside the harbor. The incident waves considered in this paper include regular long waves and bichromatic short wave groups. It is revealed for the first time that for both kinds of</p>
<p>In the article, all numerical experiments are carried out by using the fully nonlinear Boussinesqtype numerical model, <rs id="a12972796" type="software">FUNWAVE</rs> <rs id="a12972797" type="version" corresp="#a12972796">2.0</rs>, which has been widely used to simulate the wave transformation from the offshore area to the coastline in the community of coastal engineering. It was developed at University of Delaware by Kirby et al. (2003). This numerical model adopts a finite difference scheme to solve the fully nonlinear Boussinesq equations of Wei et al. (1995), and blends a moving reference level as performed in Kennedy et al. (2001).</p>
<p>The governing equations in <rs id="a12972798" type="software">FUNWAVE</rs> <rs id="a12972799" type="version" corresp="#a12972798">2.0</rs> are expressed as 0,</p>
<p>To examine the ability of <rs id="a12972800" type="software">FUNWAVE</rs> <rs id="a12972801" type="version" corresp="#a12972800">2.0</rs> in simulating Bragg reflection excited by water surface waves, this model is used to reproduce the laboratory experiments of Davies and Heathershaw (1984). The experiments were carried out in a glass-walled wave tank with the dimensions of 45.72 m × 0.91 m × 0.91 m. A patch of sinusoidal bars with the wavelength of S= 1.0 m was built into a false bottom in the tank. Based on their experiments, the setup of the numerical wave tank used is shown in Fig. 1, where D and N respectively denote the amplitude and the number of sinusoidal bars. Ls=NS denotes the total spatial length of the patch of bars whose left and right boundaries are respectively marked out by the symbols "BL" and "BR". The length of the numerical wave tank is set to 42 m, slightly shorter than that of the physical tank. The grid size is 0.02 m, and sponge layers with the width of 6 m are deployed at both sides to absorb the reflected and the transmitted waves. Two wave gauges (i.e., G1 and G2) are placed in front of the bars to calculate the reflection coefficient, Cr, according to the two-point method proposed by Goda and Suzuki (1976).</p>
<p>Fig. 4 presents the comparison of the present simulation results and experimental data. The linear analytical solution of Mei (1983) is also plotted here. For the lowest two resonant modes, their resonant frequencies predicted by the present model are in quite agreement with both the linear analytical solution and the experimental data. As for the resonant wave amplitudes, the simulated results also coincide well with the experimental measurements for both resonant modes overall. This proves that the <rs id="a12972802" type="software">FUNWAVE</rs> <rs id="a12972803" type="version" corresp="#a12972802">2.0</rs> model can predict the resonant frequencies and the resonant wave amplitudes accurately for various modes. Rogers and Mei (1978) carried out experiments in a physical wave tank to investigate the nonlinear oscillations of three bays (Bay 1, Bay 2, and Bay 3) whose lengths are l=0.37 m, 1.27 m, and 2.18 m, respectively. The widths of the three bays are uniform and equal to b=0.10 m, and the water depth is h=0.15 m. The regular waves with a period of 1.545 s (correspondingly, with the wavelength of 1.79 m) were produced by the wavemaker. The incident regular waves with the wave height H/h=0.03 are generated in the internal wavemaker to reproduce parts of the laboratory experiments. The grid size Δx is a constant of 0.01 m both inside and outside the harbor except in the sponge layer where Δx gradually increase from 0.01 m to 0.10 m. The grid size ∆y gradually increases from 0.01 m inside the harbor to 0.07 m outside the harbor. Fig. 6 shows the comparisons of the simulated results of the first three super harmonics with the experimental data for the three bays. It can be easily seen that, for all the three bays and for all three super harmonics, the numerical results are in good coincidence with the measured data overall. This shows that the numerical model can well simulate the nonlinear energy transfer between various harmonic components during harbor resonance.</p>
<p>In this article, the coupling interactions between the incident steady-state waves, the harbor, and the patch of sinusoidal bars outside the harbor are studied for the first time by utilizing the fully nonlinear Boussinesq model, <rs id="a12972804" type="software">FUNWAVE</rs> <rs id="a12972805" type="version" corresp="#a12972804">2.0</rs>. The incident steady-state waves considered include regular long waves and bichromatic short wave groups. Correspondingly, two kinds of harbor oscillations, that is, the harbor resonance triggered directly by the regular long waves and the nonlinear harbor resonance induced by the bichromatic short wave groups, are studied in the present study. For the first kind of harbor oscillations, the effects of the sinusoidal bars on the lowest four resonant modes are systematically investigated. For the second kind, two types of bar topographies (i.e., the long-bar and the short-bar types) are studied, and only the lowest resonant mode of the harbor is studied. The capability of Bragg reflection to alleviate both kinds of harbor oscillations is revealed first. Subsequently, the effects of the geometrical parameters (including the number and the amplitude of bars) on the best mitigation effect for harbor resonance and on the optimal wavelength of bars that can achieve the best mitigation effect are comprehensively investigated. The results of the current research have broadened the knowledge on the harbor oscillations excited by the steady-state wave conditions.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f82866372"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:47+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The same thin-slice audio clips from Study 1b were used and all phonetic measurements were conducted using the <rs id="a12951756" type="software">Praat</rs> software package <rs id="a12951761" type="bibr">(Boersma and Weenink, 2013)</rs>. The speech data were prepared for analysis by first extracting pitch and harmonicity data for the entirety of each clip. Pitch was measured using a forward cross-correlational method for the jitter and shimmer analyses and an autocorrelational method (Boersma, 1993) for the pitch analysis. Harmonicity data for the HNR analyses were measured using a forward cross-correlational method. The cross-correlational and autocorrelational techniques are recommended for voice and intonation analyses, respectively. Phonetic measurements were performed in two ways. In the first analysis phonetic measurements were taken over the entire clip, producing a single value for jitter, shimmer, etc. for each subject. T-tests were then used to determine whether the means of these measurements differed by priming condition (Black Prime, White Prime). Subsequently, a more fine-grained analysis was conducted. First, all of the vowels in each clip were automatically identified and transcribed using the <rs id="a12951757" type="software">Penn Phonetics Lab Forced Aligner</rs> <rs id="a12951762" type="bibr">(Yuan and Liberman, 2008)</rs>. The phonetic measurements were then performed for each vowel, giving multiple values for each subject. These fine-grained data were then analyzed using linear mixed-effects regressions (described below) which provided greater power and allowed us to control for a number of important nuisance variables.</p>
<p>The data were then analyzed on a token-by-token basis using linear mixed-effects modeling, a form of multiple regression where random effects may be entered into the model along with fixed effects. This technique allowed us to account for the fact that the participants' speech varied in a number of ways (e.g., number of tokens, distribution and duration of vowels) and were non-independent in that each participant produced multiple tokens. For these analyses, each dependent variable was modeled as a function of a set of six fixed effects: Vowel (as coded by the <rs id="a12951759" type="software">Penn Aligner</rs>, Baseline = ' AA'), Token Ordinal Position within the thin-slice clip, Vowel Stress (Unstressed = -1, Stressed = +1), Vowel Duration (measured in milliseconds), Speaker Sex (Male = -1, Female = +1), and Speaker Priming Condition (White Prime = -1, Black Prime = +1). In addition, the maximal random effects structure that would reliably converge was included in the model. Random intercepts for Participant and Word and random slopes for stress and duration (grouped by participant) were included in each model. Under this approach, any significant result is significant by both participants and items. Outliers were removed before analysis by fitting the model to the data and removing any data points whose standardized residual was greater than ±2.5 (Baayen, 2008).</p>
<p>Measurements were obtained from the token of I judged to be acoustically clearest for each participant. Five participants did not produce the pronoun I during the thin slice and were excluded from these analyses; two additional participants were excluded due to excessive noise during the articulation of the pronoun (three Black-primed; four White-primed). Tokens were normalized for length by dividing each vowel into 10 equal time points. Formant measurements were made using <rs id="a12951760" type="software">Praat</rs>'s automatic formant tracker augmented with hand-specified parameters for number of formants and frequency ceiling. Monophthongization was measured by calculating the difference between F2 and F1 at each of the 10 time points and fitting a regression line to these differences. A positive slope of the regression line would indicate that the difference between F2 and F1 grew over time (consistent with articulation as a diphthong), a negative slope would indicate that the difference became smaller over time, and a slope near 0 would indicate no change over time (consistent with articulation as a monophthong). An independent samples t-tests revealed no difference in average slope between Black-primed (M = 34.29, SD = 28.47) and White-primed participants (M = 45.56, SD = 31.67), t(29) = 1.04, p = 0.31; d = -0.37.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f395357142"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:46+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Longitudinal Analysis. Per country, we included only the time period for which the infection phase and airborne pollen peak overlapped (median: 22 d). The analyses were restricted to the level of country, as lower resolution included microclimatic variability, which increased the statistical noise and made any signal very weak to detect. However, for each country, all possible data points were included from different regions, when more than one of the sites were involved. GLMs and autoregressive models with multiple independent variables were run per country to test for multiple effects on infection rates. In all cases, a backward stepwise removal of independent variables was applied. Significance levels at the 95% interval, as well as the coefficient of determination and residual analysis, determined the robustness of the results obtained. Furthermore, for geographically larger countries, anomaly correlations were employed, as in similar analytical designs with high spatial statistical noise (48), to make a sensitivity analysis of pollen alone on its impact on infection rates. Finally, ridge regressions were conducted per country, using a backward stepwise removal of independent variables, to test for relationships of infection rates with 1) lockdown, 2) weekend registration underestimation errors, and 3) environmental factors (DTR, DHR, and pollen concentrations), including lag effects of 0 to -5 for all continuous variables. Ridge regression are well known for dealing with multicollinearity issues, and partial correlations aid in identifying the most significant parameters and their lag effects and synergistic effects among independent variables, as well as confounding factors (49). The dummy variable of "lockdown" was only included for all countries that had at least 5 d of "no lockdown" prior to the lockdown during the exponential phase, so as to have enough data points for the analysis. As, on several occasions, the reporting of COVID-19 daily cases was biased toward lower numbers during the weekends, we inserted a dummy variable for the weekend effect, to control for such artificially reduced registries in some countries. For the visualization, a heatmap was generated to identify the associated effects of various cofactors on infection rates. Maps were created per occasion using <rs id="a12893763" type="software">QGIS</rs> <rs id="a12893764" type="version" corresp="#a12893763">2.4.0</rs>  (<rs id="a12893765" type="url" corresp="#a12893763">https://qgis.org/en/site</rs>).</p>
<p>All analyses were performed by use of either the software <rs id="a12893766" type="software">Statistica</rs> <rs id="a12893767" type="version" corresp="#a12893766">13.3</rs>  (<rs id="a12893768" type="publisher" corresp="#a12893766">TIBCO Software Inc.</rs>) or <rs id="a12893769" type="software" subtype="environment">R</rs> <rs id="a12893770" type="software" subtype="implicit" corresp="#a12893769">scripts</rs> (see below).</p>
<p>COVID-19 cases. Given the spatial and temporal availability of the airborne pollen data and taking into account the availability of COVID-19 infection data, we obtained daily COVID-19 cases per city or metropolitan region, whenever possible, especially considering the frequent clustering of COVID-19 cases in large urban areas. When the per-region choice was not feasible, we switched to per country COVID-19 data, for example, for smaller countries or when regional COVID-19 numbers were too low in comparison to nationwide numbers. Vice versa, in very large countries, we necessarily broke down the COVID-19 cases into metropolitan regions, provinces, or states, so as to reduce the variability in microclimatic and sociological factors. This was the case in the countries of France, Germany, Italy, Spain, Switzerland, and the United States, along with Australia and South Africa in the Southern Hemisphere. The detailed data availability and level of processing are given in SI Appendix, Table S1. Confirmation bias. The data analysis was independently performed by three different groups of data analysts, from different countries, all with different approaches, who compared their findings at regular intervals. Outliers. To ensure that no "redness" of statistical noise exists (50), which, if categorized as outliers, may reduce the signal (underfitting), box plots were used to identify outliers and extreme values, particularly bag plots, to additionally interpret medians and averages of observations, their distribution, and symmetry (47). Remaining outliers were attempted to be interpreted with additional cofactors, when appropriate. Moreover, intentional outliers were created in the form of dummy variables for contact indicators, like population density and lockdown effects, which could bias the results. Because of registration errors in COVID-19 cases and lack of harmonization across the regions and countries in the study, an additional dummy variable was created, highlighting the effect of the weekend. Variability within each week was thoroughly checked among the weekdays to confirm whether the obtained variability could be a recording error or a potential signal. As, in most sites of the Northern Hemisphere, we found out that the signal was consistent regardless of the country or region examined (i.e., more cases on Wednesdays and Thursdays) and as this could not be further confirmed with local authorities as per the registration accuracy, we preferred to consider that the largest proportion of this variation would be an environmental signal, and we did not further manipulate this. Overfitting. As a sensitivity analysis, we ran bootstrapping with 1,500 iterations, using the <rs id="a12893771" type="software" subtype="environment">R</rs> package {<rs id="a12893772" type="software" subtype="component" corresp="#a12893771">boot</rs>}. Bootstrapping was run with different combinations of datasets: 1) the entire dataset, that is, daily infection rates vs. daily pollen concentrations, DTR, and DHR, each including 0-to 5-d lag effects; and 2) daily infection rates and daily pollen concentrations alone (0-to 5-d lags) without the DTR and DHR data. In addition, to test the significance of obtained correlations, we performed permutation tests on the data for the longitudinal analysis using the <rs id="a12893773" type="software" subtype="environment">R</rs> package {<rs id="a12893774" type="software" subtype="component" corresp="#a12893773">lmPerm</rs>}. To test potential overfitting of the acquired models, ridge regressions were employed, and the backward stepwise technique and the partial correlations of all factors and the significant lag effects of continuous variables were taken into account. For ensuring the robustness and lack of bias in the results, we checked the lambda (λ) values of the regularization (51), from 0.1 to 10 -6 , and the error values did not change, but only to a magnitude of the third decimal. We selected a value of λ = 0.1 so as to ensure a higher strictness in the analysis. Cofactors and confounding factors. To test for significant cofactors and confounding factors, we conducted ridge regression with a stepwise backward elimination procedure of the independent variables, and we checked the partial correlations to eliminate multicollinearity and select only the genuinely significant variables, especially in the longitudinal analysis.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f229944176"/>
<encodingDesc>
<appInfo>
<application version="0.8.0" ident="GROBID" when="2024-08-31T06:47+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The course presented an overview of assistive technology for people with disabilities. She and her co-instructor, Professor Norm Coombs at the Rochester Institute of Technology, who happens to be blind, set out to make the content and interactions fully accessible to anyone with a disability who might enroll in our course. A series of DO-IT [Disabilities, Opportunities, Internetworking, and Technology] videos that were both captioned and audio described and presented in Video Home System (VHS) format were mailed to the students. Electronic mail and a text-based listserv distribution list were used for communication. There was no world wide web, but a gopher server developed at the University of Minnesota was used to organize textbased course materials. Other online resources were accessed through Telnet and File Transfer protocols. When the instructors were asked if students with disabilities were enrolled in course offerings they were proud to say that they did not know. There was no need to disclose a disability when all of the materials and communications were in accessible formats. Dr. Coombs disclosed his blindness, but only because of its relevance to the course content. (Burgstahler, 2015a, pp. 49-50) The years since this course was taught have witnessed tremendous increases in the number of technologies used in online courses, in the number of online courses available, and in the number of students taking these courses (Allen &amp; Seaman, 2009;Kim-Rupnow, Dowrick, &amp; Burke, 2001;Kinash, Crichton, &amp; Kim-Rupnow, 2004;Phillips, Terras, Swinney, &amp; Schneweis, 2013). The rapid pace at which new technologies are introduced make accessibility issues both more complex and more important to address. However, the basic issues remain the same-pedagogical and technical issues must be addressed in order for courses to be welcoming to, accessible to, and usable by all students. For example, access barriers can emerge when the <rs id="a12952063" type="software" subtype="implicit">learning management system (LMS)</rs> that delivers the content and engagement options includes inaccessible features. In addition, teaching methods used by online instructors and the IT they employ (e.g., videos) can erect barriers to some students. Ideally, a universally designed course would support a student's preferred access methods (e.g., speech input, alternative keyboard, the keyboard alone) and output preferences (audio text, graphical, video), and be customizable.</p>
<p> Include a statement on the syllabus about how to request a disability-related accommodation and how to report a design feature of the course that is not accessible.  Make learning objectives, expectations, assignments and due dates, grading rubrics, assessment questions, and other course elements clear.  Use consistent and predictable screen layouts and single columns when possible.  Structure lesson pages and documents using the heading feature of the product you are using (e.g., <rs id="a12952064" type="publisher" corresp="#a12952065">Microsoft</rs> <rs id="a12952065" type="software">Word</rs>, PDF).  Make sure the text of links is descriptive of the resource linked to rather than use wording like "click here".  Make sure that color is not the only way to convey important information and make background screens plain and with high contrast to text.  Share definitions of terms that might be unknown to some students.  Provide alternative text to describe important content presented in images.  Caption videos or, when not possible to do so, provide transcriptions.  Design HTML, <rs id="a12952066" type="publisher" corresp="#a12952067">Microsoft</rs> <rs id="a12952067" type="software">Word</rs>, <rs id="a12952068" type="publisher" corresp="#a12952069">Microsoft</rs> <rs id="a12952069" type="software">PowerPoint</rs>, and PDF documents in accessible formats.</p>
<p>1. Has careful thought been given to the diversity of learners in the course? Are there barriers in any area of the course for learners with different abilities (e.g., artistic, numerical), circumstances (e.g., English language learners), concerns (e.g., finances) and disabilities (e.g., visual impairment)? 2. Has the accessibility of the <rs id="a12952070" type="software" subtype="implicit">LMS</rs>, including its various components, been considered for all persons, including those with different disabilities (for example, are the calendar, announcements, discussion board, chat, and quizzes accessible, can students easily distinguish new discussion threads, does the announcements tool indicate the number of new announcements posted)? 3. Has consideration been given to the variety of platforms and mobile devices students could be using to interact with the e-learning and the course material? 4. Are there alternative digital representations of course content that are accessible and usable? 5. Are there options offered for student engagement with the course content and the course objectives through accessible e-learning tools (such as online mind mapping, discussion forums)? 6. Are there alternatives offered to students to demonstrate what they have learned through accessible ICTs [information and communication technologies] or e-learning tools (such as audio, visual, written, demonstration)? 7. Has the institution's access technologist been consulted as the e-learning and digital learning modules and activities are designed (to ensure that all aspects of the course structure and components are accessible and usable-for example, how readily and easily can the web site be navigated)?</p>
<p>Faculty, distance learning designers, and support staff should also be aware of accommodations that might be required if an online tool (e.g., the <rs id="a12952071" type="software" subtype="implicit">LMS</rs> or a third-party addition) is known to be inaccessible to certain students. For example, if a graphics-based writing "wall" or animated avatar application that is not accessible to students who are blind is used in a course, the instructor should consider not using the tool or providing alternatives for a student who is blind to gain the content that is a result of use of the tool (e.g., providing a transcript, summary) if they are enrolled in an offering of the course. A campus disability services office may be able to provide assistance in this regard. Most studies of online learning do not address ac-cess issues for people with disabilities. Even studies about performance differences of student subgroups such as those defined by gender, age, and race, rarely explore differences between students with and without disabilities (e.g., Xu &amp; Jaggars, 2014). UD can be applied to the overall design of a course, but it can also be built into an assignment. For example, in an online course taught by the author of this article, small groups were assigned to complete a project and answer specific questions to report their work. The first thing they were told to do was decide which mode of communication they would employ so that all students could attend group "meetings" and fully engage in the collaboration. One group reported back that they used e-mail, at least in part, because one of the participants was deaf and could not easily engage using the synchronous communication modes offered. Actually, the majority of groups used asynchronous communication options, usually because this mode of communication, when compared to phone conferences and real-time chat sessions, worked best when group members lived in different time zones and/or had different daily schedules. Asynchronous communication also works well for individuals with slow input speeds. Even though one member disclosed her deafness, members of groups were not required to disclose disabilities or any other characteristics that contributed to their communication preference; they just needed to reach consensus on the communication tool they would use. In this course, if not for her voluntary disclosure, not even the instructor would have known she was deaf because the class was universally designed. For example, captions were provided on all video presentations. (Burgstahler, 2015a, p. 51) Most faculty members do not address accessibility issues as they develop online courses. In one study, 80% of the respondents in a survey of online learning faculty had not considered the needs of students with disabilities and less than 12% had "partially" considered the needs of these students as they developed their courses (Bissonnette, 2006). Many instructors report that they are unaware of how to make their online courses accessible to students with disabilities (Gladhart, 2010;Roberts, Park, Brown, &amp; Cook, 2011). The combined results of three studies (Burgstahler, 2007) conclude that there is a need for accessibility training for online learning personnel and suggests that topics should include access challenges for people with disabilities, legal requirements, UD guidelines, specific design techniques and pedagogical strategies, and resources. Specific training for instructors, online course designers, and other stakeholder groups should be tailored to their needs. UD instruction should be integrat-ed into more general training offerings such as how to use the campus <rs id="a12952072" type="software" subtype="implicit">LMS</rs>.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f343446413"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T12:50+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>Space-borne Synthetic Aperture Radar (SAR) Interferometry (InSAR) is now a key geophysical tool for surface deformation studies. The European Commission's Sentinel-1 Constellation began acquiring data systematically in late 2014. The data, which are free and open access, have global coverage at moderate resolution with a 6 or 12-day revisit, enabling researchers to investigate largescale surface deformation systematically through time. However, full exploitation of the potential of Sentinel-1 requires specific processing approaches as well as the efficient use of modern computing and data storage facilities. Here we present <rs id="a12897768" type="software">LiCSAR</rs>, an operational system built for large-scale interferometric processing of Sentinel-1 data. <rs id="a12897769" type="software">LiCSAR</rs> is designed to automatically produce geocoded wrapped and unwrapped interferograms and coherence estimates, for large regions, at 0.001°resolution (WGS-84 system). The products are continuously updated in a frequency depending on prioritised regions (monthly, weekly or live update strategy). The products are open and freely accessible and downloadable through an online portal. We describe the algorithms, processing, and storage solutions implemented in <rs id="a12897771" type="software">LiCSAR</rs>, and show several case studies that use <rs id="a12897770" type="software">LiCSAR</rs> products to measure tectonic and volcanic deformation. We aim to accelerate the uptake of InSAR data by researchers as well as non-expert users by mass producing interferograms and derived products.</p>
<p>Despite the opportunities provided by the increasing availability of Sentinel-1 SAR data, it is still difficult to take full advantage of these resources particularly for large-scale applications. Indeed, the full exploitation of the large amount of SAR data provided by the Sentinel-1 system, with its short revisit time and global-scale coverage (data are produced in the rate of ~13 TB/day), requires specific data preprocessing approaches (e.g. downsampling the SAR data -multilooking) or Big Data processing algorithms involving computer cluster facilities. The computing and storage demands require specific computing platforms [27]. Various research groups base their systematic processing approaches on open-source software such as <rs id="a12897646" type="software">SNAP</rs> <rs id="a12953724" type="bibr">[28]</rs>, <rs id="a12897648" type="software">ISCE</rs> <rs id="a12953725" type="bibr">[29]</rs> or <rs id="a12897650" type="software">GMTSAR</rs> <rs id="a12953726" type="bibr">[30]</rs> for generation of differential interferograms and <rs id="a12897652" type="software">GMTSAR</rs>, <rs id="a12897653" type="software">STAMPS</rs> <rs id="a12953727" type="bibr">[31]</rs> or other tools as their time series processor. Other institutions prefer commercial software equivalents such as <rs id="a12897655" type="software">GAMMA</rs> [<rs id="a12897656" type="bibr">32</rs>,<rs id="a12897657" type="bibr">33</rs>], <rs id="a12897658" type="software">ENVI SARScape</rs> <rs id="a12953728" type="bibr">[34]</rs> or <rs id="a12897660" type="software">SARPROZ</rs> <rs id="a12953729" type="bibr">[35]</rs>, to list the currently most recognized available tools. As the deployment of an InSAR processing system is strongly connected to the storage and computing facilities required, there is currently a lack of recognized deployable system solutions, although with exceptions such as IT4S1 [36], which is partly based on the metadata database approach described in this work.</p>
<p>In recent years, there has been remarkable developments in promoting the idea of using cloud computing technology to address the storage and processing of remote sensing data. Significant efforts are underway to facilitate access to high-performance computing (HPC) resources and processing of very large Earth Observation (EO) datasets by such institutions as the National Aeronautics and Space Administration (NASA), the United States Geological Survey (USGS), company-based infrastructures such as the Google Earth Engine (GEE), the Amazon Web Services (AWS), or science oriented HPC platforms such as the Earth Observation Data Center (EODC) [37]. In 2018, the European Commission publicly launched the Copernicus Data and Information Access Services (DIAS). These cloud-based systems not only allow access to EO datasets but also provide processing resources and tools for data analytics and allow for a scalable computing environment [38]. Similarly, NASA's Alaska Satellite Facility (ASF) has provided a platform for archiving and distributing Sentinel-1 data at ASF Distributed Active Archive Centers (DAAC). Besides the Sentinel-1 data, ASF DAAC is storing data from a variety of different SAR sensors, including both historic and modern missions. The data are distributed using <rs id="a12897662" type="software">Vertex</rs>, <rs id="a12897663" type="publisher" corresp="#a12897664">ASF</rs>'s <rs id="a12897664" type="software" subtype="implicit">data search website</rs>, as well as <rs id="a12897665" type="publisher" corresp="#a12897666">ASF</rs>'s <rs id="a12897666" type="software">Application Programming Interface (API)</rs>. These platforms have reduced technological barriers for conducting large-area mapping and thus may stimulate a surge of global or regional maps. With these platforms, it is much easier to process these data remotely in the cloud without downloading large datasets to a local computer. However, they are mainly focused on the provision of data with some preliminary processing tools and are not designed to mass produce products for non-specialist users and make them openly accessible.</p>
<p>Besides the above-mentioned platforms, ESA has developed "EO Exploitation Platforms (EPs)" that represent a set of research and development activities aimed at the creation of an ecosystem of interconnected "Thematic Exploitation Platforms (TEPs)". TEPs are collaborative, virtual work environments providing access to EO data and the tools, processors, and IT resources required using one coherent interface. The TEPs have been implemented to address the most important topics in remote sensing i.e. Coastal, Forestry, Hydrology, Geohazards, Polar, Urban, and Food Security [39]. For the context of this paper concerning applications to tectonics, earthquakes and volcanoes, it suffices to introduce the <rs id="a12897667" type="software">Geohazard Exploitation Platform (GEP)</rs>. <rs id="a12897668" type="software">GEP</rs> is <rs id="a12897669" type="publisher" corresp="#a12897668">ESA</rs>'s webbased platform that is specially designed to exploit EO data for assessing geohazards associated with active seismicity, volcanism, subsidence, or landslides <rs id="a12953730" type="bibr">[40]</rs>. <rs id="a12897671" type="software">GEP</rs> serves as a user-friendly interface to run various web tools implemented in the <rs id="a12897672" type="publisher" corresp="#a12897673">ESA</rs>'s <rs id="a12897673" type="software">Grid Processing on Demand (G-POD)</rs> environment <rs id="a12953731" type="bibr">[41]</rs>. Some of these web tools can be used for generation of differential interferograms (e. g. <rs id="a12897675" type="software">DIAPASON</rs>) or for multi-temporal InSAR processing, especially based on implementation of Small Baselines (SB) algorithms [42]. <rs id="a12897676" type="software">GEP</rs> is based on a collaborative work environment for the development, integration and exploitation of different services [43]. It mainly provides on-demand processing services for specific user needs and the InSAR tools do not provide interferometric products at a global scale.</p>
<p>Here, we present activities carried out for the design, development, integration, and deployment of a fully automated state-of-the-art InSAR processing chain for Sentinel-1 data developed within the Looking Inside the Continents from Space (LiCS) project by COMET, the Centre for the Observation and Modelling of Earthquakes, Volcanoes and Tectonics. The LiCS project primarily aims at understanding how the continents deform at all spatial and temporal scales, with a focus on using observations of the earthquake deformation cycle to understand how seismic hazard is distributed in space and time. For this purpose, an automated InSAR processing system, <rs id="a12897773" type="software">LiCSAR</rs>, has been developed. <rs id="a12897775" type="software">LiCSAR</rs> is capable of processing Sentinel-1 data acquired globally, with the resulting products freely accessible and downloadable through an online portal, including both wrapped and unwrapped interferograms, coherence estimates, time series and other products. Innovative algorithmic, processing and storage solutions have been implemented to allow us to reduce the computing time and the required disk space.</p>
<p>This article is organised as follows. Section 2 presents the architecture and the main features of the <rs id="a12897777" type="software">LiCSAR</rs> processing system, providing basic information about facilities, data and metadata storage system and processing chain strategies, including description of the current earthquake responder. Section 3 describes <rs id="a12897778" type="software">LiCSAR</rs> interferometric data products, their formats, structure and their update strategy. In Section 4, we will review how various tectonic, earthquake and volcanic applications benefit from the <rs id="a12897779" type="software">LiCSAR</rs> system, and illustrate this using recent results obtained in the Alpine-Himalayan belt. Finally, the conclusions and plans for further developments of the system are given in the Section 5.</p>
<p>The <rs id="a12897677" type="software">LiCSAR</rs> system consists of several interconnected modules. The <rs id="a12897780" type="software">LiCSAR</rs> processing chain, described in Section 2.1, uses various <rs id="a12897678" type="software" subtype="implicit" corresp="#a12897780">custom tools</rs> and <rs id="a12897679" type="software" subtype="implicit" corresp="#a12897780">algorithms</rs> over the core processing functionality that is based on advanced commercial software for processing SAR data, <rs id="a12897680" type="software">GAMMA</rs> <rs id="a12953732" type="bibr">[45]</rs>. <rs id="a12897783" type="software">LiCSAR</rs> processing is performed over systematic geographical spatial extents termed frames. A frame is defined as a collection of Sentinel-1 IWS burst units imaged during the satellite's pass within a given orbital track. We have created custom <rs id="a12897784" type="software">LiCSAR</rs> burst unit identifiers. Metadata for each of these burst units are extracted from Sentinel-1 Single Look Complex (SLC) acquisitions and registered in the <rs id="a12897682" type="software">LiCSInfo</rs> metadata database that handles burst and frame definitions (see Section 2.2).</p>
<p>We extract and merge bursts covering a frame into SLC mosaics for each acquisition epoch. Afterwards we coregister and resample these SLC mosaics to the geometry of a primary SLC acquisition, which is set during the initialisation of the frame. We then use the resampled SLC (RSLC) data to form interferometric products (wrapped and unwrapped interferograms, and coherence maps) by combining the new RSLC with, by default, four chronologically preceding ones, and georeference them to WGS-84 coordinate system. The whole process is automated and optimised for effective batch processing in computer clusters, and identified as <rs id="a12897683" type="software">LiCSAR FrameBatch</rs> toolbox, described in Section 2.3. <rs id="a12897684" type="software">LiCSAR FrameBatch</rs> is a standard tool used for updating frame datasets and is called by other specific tools, such as <rs id="a12897785" type="software">LiCSAR Earthquake Responder</rs>, described in Section 2.4.</p>
<p>We show a general overview of the LiCSAR system architecture in a flowchart in Figure 1. The whole system is closely aligned to the technical infrastructure offered by the Centre for Environmental Data Analysis (CEDA), see Section 2.5. Here, both data storage (CEDA Archive, internal and public LiCSAR data storages) and computing facilities are synchronised with the metadata database (<rs id="a12897685" type="software">LiCSInfo</rs>, see Section 2.2) and <rs id="a12897787" type="software">LiCSAR</rs> processing chain to prepare InSAR outputs. The flowchart in Fig. 1 also shows a connection to the COMET <rs id="a12897686" type="software">Generic Atmospheric Correction Online Service (GACOS)</rs> system <rs id="a12953733" type="bibr">[46]</rs>, allowing for routine corrections of tropospheric delay in interferograms using atmospheric weather models. The procedure to acquire <rs id="a12897688" type="software">GACOS</rs> data has been not fully automated yet, as the current API requests for generating <rs id="a12897689" type="software">GACOS</rs> data would prolong the <rs id="a12897788" type="software">LiCSAR</rs> products generation process. <rs id="a12897690" type="software">GACOS</rs> data per frame are currently being generated upon request.</p>
<p>The aim of the <rs id="a12897789" type="software">LiCSAR</rs> processing chain is to generate interferometric products (see Subsection 4.1.1). The processing workflow to generate interferometric products by <rs id="a12897790" type="software">LiCSAR</rs> is outlined graphically in Fig. 2. Prior to this workflow, each frame should is first defined and initialised within the <rs id="a12897691" type="software">LiCSInfo</rs> database. While frame definition means a logical linking of burst definitions within a frame unit, the initialisation of the frame means a status of having generated base frame data, including the primary epoch SLC and its multilooked intensity raster (MLI), height values based on a digital elevation model (DEM), and other frame-related derived products, such as the three components of the unit vector in the satellite line-of-sight (LOS) for each pixel (E-N-U files), which define the sensitivity to motion in the East North and Up/vertical directions [47]. We currently use a 1 arc-second void-filled version of the SRTM DEM as the basic DEM to derive the base frame data [48]. Some frames are prepared using other topographic models (e.g. ASTER GDEM, JAXA ALOS World 3D or DLR TanDEM-X WorldDEM). The DEM-based frame data are key for geolocation of the products and for estimation and removal of a topographic phase screen in interferograms. In the first step, we identify Sentinel-1 SLC data covering a given temporal epoch (a given date) and containing all or at least some bursts of the given frame definition. Frame burst data are extracted from related files available from some of the source data stores (see Section 2.5) and merged to form a frame epoch SLC. We perform several operations at this stage of processing. Firstly, we apply precise (21 days delay) or restituted orbit ephemerides data generated by the Sentinel-1 Quality Control Subsystem (https://qc.sentinel1.eo.esa.int) and downloaded daily from ASF DAAC. We perform a basic set of checks and corrections, such as padding of missing burst data with zeroes (in case of burst data unavailability for the given epoch), or correction of some known issues, e.g. an azimuth phase shift of -1.25 pixels in the first swath for older data (typically before April 2015) processed by <rs id="a12897692" type="software">Instrument Processing Facility</rs> software version <rs id="a12897693" type="version" corresp="#a12897692">2.36</rs>. Finally, we generate an MLI image using our default parameters, e.g. numbers of looks (4 for direction in azimuth and 20 in range), leading to a pixel spacing of 56x46 m (azimuth x range) in the LOS direction.</p>
<p>The resampling step is demanding on memory (RAM) and has the longest processing runtimeover 1 hour per epoch using a single processing core. The task of this step is to generate resampled RSLC files and additional supplementary files that can be used later to regenerate RSLC if needed for data reprocessing. The process of generating RSLC and the supplementary files from the epoch SLC is shown in Fig. 3. The following textual description uses estimated processing time (EPT) measured for a typical frame consisting of 39 bursts (13 bursts per swath) and using a single processing core (as experienced at facility described in Section 2.5). The resample procedure (including precise coregistration) follows the approach implemented within the <rs id="a12897694" type="software" subtype="environment">GAMMA</rs> command <rs id="a12897695" type="software" subtype="component" corresp="#a12897694">S1_coreg_TOPS</rs>.</p>
<p>After the first step of generating an epoch SLC (and MLI), a frame DEM (also multilooked by factors of 4x20) is used to provide a DEM-assisted SLC coregistration  (<rs id="a12897696" type="software" subtype="environment">GAMMA</rs> command <rs id="a12897697" type="software" subtype="component" corresp="#a12897696">rdc_trans</rs>, EPT ~2 minutes). A preliminary coregistration lookup table (LUT) is generated. In order to increase the precision of SLC coregistration, an intensity cross correlation is performed towards the frame's primary SLC image  (<rs id="a12897698" type="software" subtype="environment">GAMMA</rs> command <rs id="a12897699" type="software" subtype="component" corresp="#a12897698">offset_pwr_tracking</rs>, EPT ~5 minutes) and the estimated offsets are used to update the LUT.</p>
<p>Prior to the SD estimation, a subswath offset estimation (<rs id="a12897700" type="software" subtype="environment">GAMMA</rs> command <rs id="a12897701" type="software" subtype="component" corresp="#a12897700">S1_coreg_subswath_overlap</rs>, EPT 15 minutes) is applied to datasets being processed by an Instrument Processing Facility (IPF) processor differing from the original primary SLC; currently this step is applied only to data from the problematic IPF 2.36.</p>
<p>To estimate the mis-registration using SD, we determine burst overlap regions from the primary SLC metadata  (<rs id="a12897702" type="software" subtype="environment">GAMMA</rs> command <rs id="a12897703" type="software" subtype="component" corresp="#a12897702">S1_poly_overlap</rs>). Raster coordinates of the burst overlap regions are used to generate a masked LUT. The masked LUT is applied to resample only the burst overlap regions of the secondary SLC (EPT 20 minutes). The SD azimuth offset is estimated in the burst overlaps between the secondary SLC and RSLC3 applying <rs id="a12897704" type="software" subtype="environment">GAMMA</rs> command <rs id="a12897705" type="software" subtype="component" corresp="#a12897704">S1_coreg_overlap</rs> (to determine the fine coregistration offset within burst overlaps) on the overlap region resampled towards the RSLC3. If the coregistration offset changes by more than 0.0005 pixels, the resample and coregistration of the burst overlaps is repeated up to 5 times (EPT 60+ minutes). Finally, the azimuth pixel offset w.r.t. the LUT is estimated and both are used to resample the original secondary epoch SLC into the RSLC.</p>
<p>After the resampling process, the <rs id="a12897791" type="software">LiCSAR</rs> system stores the LUT and the estimated subpixel shift in azimuth direction (SD estimate) inside an offset refinement file for each RSLC. The data in the LUT can be used later if needed to quickly regenerate an RSLC from SLC data.</p>
<p>The interferogram unwrapping is performed using <rs id="a12897706" type="software">snaphu</rs> in version <rs id="a12897707" type="version" corresp="#a12897706">2</rs> <rs id="a12953734" type="bibr">[50]</rs>. Prior to the unwrapping process, the interferogram is spatially filtered using an adaptive power spectrum filter [51]  (<rs id="a12897709" type="software" subtype="environment">GAMMA</rs> command <rs id="a12897710" type="software" subtype="component" corresp="#a12897709">adf</rs> with the parameters FFT window size = 32 and alpha = 1.0). Points with interferometric coherence lower than 0.5 after filtering are removed prior to unwrapping. A map of statistical costs is generated based on a custom approach that searches for phase consistent pixels, avoiding false phase jumps within a threshold distance [52]. The unwrapping process is run on a single core with no tiling (EPT ~15 minutes/interferogram).</p>
<p>The <rs id="a12897711" type="software">LiCSInfo</rs> metadata database has been developed as the core for our autonomous Sentinel-1 processing system. It contains information on the original Sentinel-1 SLC data files, the <rs id="a12897792" type="software">LiCSAR</rs> frame definitions and the links between them through common burst units. It also stores basic information on processed interferometric products (e.g. file paths, perpendicular baseline) and other useful information (e.g. number of unwrapped pixels as a measure of the product quality). The database is also used to maintain frame update triggers if a frame is set as 'active'. The base structure of the database is depicted in Fig. 4.</p>
<p>Sentinel-1 IWS acquisitions in the form of SLC data are originally distributed as a set of focused burst units (or bursts) within three swaths. Burst metadata, including the geographic coordinates of each burst, can be directly read or inherited from Sentinel-1 annotation files provided within the distributed data. We generate custom unique <rs id="a12897793" type="software">LiCSAR</rs> burst identifiers based on the Zero Doppler azimuth time of the first line of the burst relative to the Ascending Node Crossing (ANX) time. The information is ingested to the table bursts. In the case of Sentinel-1 SM acquisitions, the whole areal coverage of the image is set as a burst.</p>
<p>Having the basic information about ingested SLC files stored in the table files and linked to bursts contained within the files through the lookup table files2bursts, it is possible to perform SQL queries such as identifying files related to requested epochs within a selected frame. These structures are also linked to a concurrent <rs id="a12897712" type="software">LiCSInfo</rs> batch processing database (<rs id="a12897713" type="software">LiCSBatch</rs> database) that is used within the <rs id="a12897714" type="software">LiCSAR FrameBatch</rs> processing chain (see Section 2.3). Here, temporary fields linking job-relevant files and bursts are stored in interconnected <rs id="a12897715" type="software">LiCSBatch</rs> tables, as shown in the right panel of Fig. 4. Final product information is stored in products metadata tables (coherence, rslc, ifg).</p>
<p>Finally, earthquake responder tables include basic information on earthquakes and related frames that are ingested to processing by the <rs id="a12897794" type="software">LiCSAR Earthquake Responder</rs> (see Section 2.4). These tables keep track of processing stages for generating pre-seismic, co-seismic and post-seismic interferograms.</p>
<p>The <rs id="a12897716" type="software">LiCSAR FrameBatch</rs> package is a set of data structures and algorithms designed to automate frame processing using LiCSAR. It is optimised to run on a computing cluster facility. Our frame processing strategy consists of four parts described below and depicted in Fig. 5. The only required user parameters for starting batch processing for a frame are the frame identifier (frame ID), a toggle for "auto-download" functionality, and, optionally, a start/end date.</p>
<p>At the initial stage, base frame data (pre-processed primary epoch SLC, MLI, DEM-derived frame products etc.) are copied from LiCSAR internal storage to a temporary BatchCache folder. Any products stored in LiCSAR internal storage covering the frame during the requested time period are either linked (interferometric products) or decompressed (7zip-compressed coregistration LUTs or RSLCs). We then use a <rs id="a12897717" type="software" subtype="implicit">data-filling script</rs> to search for the existence of relevant Sentinel-1 SLC data by querying <rs id="a12897718" type="software">Copernicus SciHub</rs>, comparing the <rs id="a12897719" type="software">SciHub</rs> list to information on the data already ingested to the <rs id="a12897720" type="software">LiCSInfo</rs> metadata database, checking and optionally auto-downloading the relevant SLC data, and then refilling the <rs id="a12897721" type="software">LiCSInfo</rs> database. Optionally, the routine can be set to request the data available at CEDA storage from their Near Line Archive system (NLA, see Section 2.5) automatically though the user is expected to perform such a request prior to the <rs id="a12897722" type="software">FrameBatch</rs> processing (non-autonomous NLA requests are preferred as the complex mechanism of the NLA may induce significant delays in the whole frame processing).</p>
<p>After the data preparation step, we generate frame batch processing job definitions. First, epochs covering the requested time period are identified based on <rs id="a12897723" type="software">LiCSInfo</rs> database entries (selecting ingested files that contain bursts related to the frame definition). The epochs are then distributed into processing job definitions for LiCSAR processing steps: SLC generation, coregistration into RSLC, generating interferograms and unwrapping. A maximum of 5 job definitions per step are generated for cases where processing covers the last 3 months (i.e. covering up to 15 epochs, thus distributed into processing of up to 3 epochs per job); a maximum of 20 jobs per step are generated in case of larger requested time scales. A special <rs id="a12897724" type="software">LiCSBatch</rs> database interconnected to <rs id="a12897725" type="software">LiCSInfo</rs> is used -it contains tables allowing us to identify epochs related to each job definition and to keep track of the progress of jobs. The interferogram generation and unwrapping steps are set to create the standard set of combinations of every epoch with the four preceding epochs.</p>
<p>After the <rs id="a12897726" type="software">LiCSBatch</rs> cache is ready, the processing jobs are started in parallel. Follow-up steps only begin once the preceding steps are finished for given epochs. The processing jobs are optimised to run for less than 24 hours each. Only one processing core is requested per job. Though this approach does not take advantage of increased effectiveness of parallel processing algorithms (e.g. <rs id="a12897819" type="software" subtype="component" corresp="#a12897820">GAMMA</rs> <rs id="a12897820" type="software" subtype="environment">OpenMPI</rs> <rs id="a12897727" type="software" subtype="implicit" corresp="#a12897819">scripts</rs> or <rs id="a12897728" type="software">snaphu</rs>), it allows requesting a larger number of parallel jobs in the computing cluster environment.</p>
<p>The final stage consists of the following operations: a gap-filling script checks for non-existing wrapped and unwrapped interferograms and runs parallel jobs to generate InSAR products in standard combinations (4 preceding epochs, based on a set of successfully generated RSLCs) and a geocoding script georeferences InSAR products in the GeoTIFF file format and their PNG/KMZ previews (coordinate system WGS-84). An optional routine stores relevant files in the internal LiCSAR storage and the public LiCSAR folder and cleans the temporary processing directory and <rs id="a12897729" type="software">LiCSBatch</rs> cache. We have also developed a state-of-the-art interferogram quality check routine that will be applied before the automatic data store.</p>
<p>The automatic Earthquake Responder (EQR) within the <rs id="a12897806" type="software">LiCSAR</rs> system works as follows (Fig. 6): a list of current earthquake events with a minimum magnitude of Mw 5.5 is requested through a <rs id="a12897730" type="software" subtype="component" corresp="#a12897731">libcomcat</rs> <rs id="a12897731" type="software" subtype="environment">python</rs> library <rs id="a12953735" type="bibr">[53]</rs> providing access to the USGS ANSS Comprehensive Earthquake Catalog (ComCat) We then generate a look-up table to estimate the potential radius of the region in which surface deformation caused by the earthquake may have occurred, given the estimated seismological magnitude and 3D location of its hypocenter, accounting for uncertainties in the seismological estimates (see Table 1). This surface radius is used to select all overlapping frames, using the frame definitions from the <rs id="a12897733" type="software">LiCSInfo</rs> database. In the case a selected frame has not been previously initialised, an automatic initialisation is attempted. We then update the EQR-related tables in <rs id="a12897734" type="software">LiCSInfo</rs> database and process at least the last month of data associated with the selected frames using standard LiCSAR parameters and the <rs id="a12897735" type="software">LiCSAR FrameBatch</rs> approach.</p>
<p>We have developed routines for the early identification and fast download of the first postearthquake Sentinel-1 data and we have created an automatic download routine that uses the <rs id="a12897736" type="software">Copernicus SciHub</rs> service as an alternative data source in order to ensure the availability of the latest data for processing -Sentinel-1 SLC data typically arrive at <rs id="a12897737" type="software">Copernicus SciHub</rs> within a few hours post acquisition, which is earlier than they appear in other accessible data mirrors.</p>
<p>As we use image cross-correlation algorithms within the LiCSAR coregistration step (see Fig. 3), the RSLCs can be generated successfully even without the use of precise orbital ephemerides. Instead, restituted ephemerides (existing already at the time of appearance of the source Sentinel-1 data) are downloaded and applied automatically. We also export co-seismic interferograms as KMZ files  (<rs id="a12897738" type="software">Google Earth</rs> data format), in addition to standard InSAR outputs. We link the co-seismic interferogram products to our web based <rs id="a12897809" type="software">LiCSAR Earthquake Responder</rs> map and prepare structures for their automatic ingestion to other community systems (see Section 3). We also aim towards integration of <rs id="a12897739" type="software">GACOS</rs> atmospheric phase screen correction estimates to the final interferograms, noting that <rs id="a12897740" type="software">GACOS</rs> data should be available with a 24 hour delay.</p>
<p>From the perspective of the system architecture, we have arranged a stable sequential procedure that generates coseismic interferograms within 24 hours after the post-event SAR data acquisition. This has been lately substituted by a solution that should allow us to reach co-seismic interferograms within 1-3 hours after the appearance of post-event Sentinel-1 SLC data on the <rs id="a12897741" type="software">Copernicus SciHub</rs> web service. The major difference is specific integration of a dedicated computing node at a distant computing facility for resampling the post-event data with the use of parallel processing and rapid generation of interferometric products.</p>
<p>The <rs id="a12897812" type="software">LiCSAR</rs> processing and storage system runs on CEDA's data analysis infrastructure JASMIN [54]. JASMIN is a computing facility designed for environmental data analysis supercomputing. The processing is carried out mainly using a Load Sharing Facility (LSF) for distributed computer clusters named LOTUS. Since September 2018, JASMIN offers over 40 PB of storage and over 10,000 computing cores distributed between the LOTUS computing cluster and a community cloud [54,55]. LOTUS is managed through IBM's batch queuing system which allows splitting of large processing jobs to run on a requested number of computing cores reserved from LOTUS computing nodes. As we use a dedicated processing queue with a limit of a maximum number of 128 reserved computing cores, we do not use parallel processing algorithms but rather send larger number of processing jobs by reserving one computing core per job.</p>
<p>A community cloud service at CEDA offers managed cloud instances, which we use to run a <rs id="a12897742" type="software">MySQL</rs>/ <rs id="a12897743" type="software">MariaDB</rs> database system dedicated to the <rs id="a12897744" type="software">LiCSInfo</rs> database.</p>
<p>Apart from a 350 TB disk area for permanent internal, publicly shared and temporary LiCSAR output files, the JASMIN infrastructure offers direct access to a CEDA Sentinel Mirror Archive (SMA), a service mirroring data from the Copernicus Sentinel programme [56]. Currently, SMA contains more than 2 PB of data or ~1.6 million individual Copernicus Sentinel data products, over 60% of which is Sentinel-1 SLC data [54]. To cater to the increasing amount of Sentinel data, <rs id="a12897745" type="publisher" corresp="#a12897746">CEDA</rs> has developed the <rs id="a12897746" type="software">Near Line Archive (NLA)</rs> system. The <rs id="a12897747" type="software">NLA</rs> is used to archive older data onto a modern tape storage system. This brings about the limitation of having only the newest data (acquisitions younger than 3 months) available on disk via instant access. Archived data can still be requested -it should take no longer than 24 hours to retrieve data from the <rs id="a12897748" type="software">NLA</rs> into its original location in the SMA directory structure. The restored data can be accessed for a limited period of time (typically 3 weeks). Therefore, the Sentinel-1 data does not have to be downloaded before processing, greatly reducing the time necessary to obtain results.</p>
<p>In cases where the requested Sentinel-1 data are not available at SMA, we use one of the optimised high speed transfer servers at the CEDA JASMIN facility to download the required data from either NASA's ASF DAAC or the <rs id="a12897749" type="software">Copernicus SciHub</rs> server. The necessary SLC datasets are normally available on <rs id="a12897750" type="software">Copernicus SciHub</rs> within a few hours of the satellite acquisition.</p>
<p>Finally, we have established a dedicated computing node at University of Leeds supercomputer (ARC4, http://arc.leeds.ac.uk) that serves as a stable extension of the <rs id="a12897813" type="software">LiCSAR</rs> system, primarily running at CEDA environment. We use the node for running the <rs id="a12897814" type="software">LiCSAR Earthquake Responder</rs>.</p>
<p>The basic InSAR products generated by <rs id="a12897815" type="software">LiCSAR</rs> are original and spatially-filtered wrapped, as well as unwrapped, interferograms and original coherence maps, MLI images for each epoch, and complementary specialised frame images, including incidence angle map files needed for motion vector extraction [47], height values from the DEM used in processing, preprocessed <rs id="a12897751" type="software">GACOS</rs> products, and metadata information (e.g. perpendicular baseline list, date and acquisition time of the primary epoch image). Provided products are georeferenced to the WGS-84 geographic coordinate system. After the processing, results are shared in the form of georeferenced TIFF (GeoTIFF) files and preview bitmap rasters (in PNG format, downsampled to 30% of the original GeoTIFF's dimensions). Some products of special interest (e.g. co-seismic interferograms) are converted into <rs id="a12897752" type="software">Google Earth</rs> KMZ files. In Section 3.1 we elaborate on the contents and coverage of the products.</p>
<p>The <rs id="a12897816" type="software">LiCSAR</rs> products are publicly available through the COMET LiCS products web portal (currently at https://comet.nerc.ac.uk/COMET-LiCS-portal) in the structure described in Section 3.2. Selected InSAR products are or will be available within the European Plate Observing System (EPOS) (http://www.ics-c.epos-eu.org), and the CEDA Archive (https://catalogue.ceda.ac.uk), as well as other platforms (e.g. <rs id="a12897753" type="software">Google Earth Engine</rs>).</p>
<p><rs id="a12897817" type="software">LiCSAR</rs> systematically uses Sentinel-1 IWS SLC data to generate large-scale multilooked interferograms, georeferenced to the ground resolution of a pixel size of of 10 -3 x10 -3 degrees in WGS-84 geographic coordinate system (corresponding to ~100x100 m at the equator). Sentinel-1 datasets are processed, organised and catalogued in frame units. Default frames consist of 39 bursts (13 bursts within each of three observation swaths) -such a standard frame covers an area of around 220x250 km. Our standard frame definitions include overlap of one burst per swath with each neighbouring frame along the orbital track. This enables us to seamlessly merge interferometric outputs from the frames.</p>
<p>We have defined frames globally, but only carry out systematic <rs id="a12897818" type="software">LiCSAR</rs> InSAR analysis on a selection of frames within our current priority areas. The tectonic priorities are the Alpine-Himalayan Belt (572 frames) and East African Rift System (Fig. 7). These frames are currently in the process of being systematic backfilled to a monthly 'rolling' status, in which data will be no more than 1 month out of date. This default status allows us to use the precise orbit ephemerides, which are available 21 days after each acquisition. Frames of a special interest can be switched to a weekly 'rolling' status with interferograms generated using the latest available data (using restituted orbit ephemerides).</p>
<p>Due to ESA's acquisition strategy for Sentinel-1, some of the data collected over certain small islands is acquired in stripmap (SM) mode. SM acquisitions are obtained in one of six possible beams. These beams cover a range of incidence angles of approx. 22 -44°and acquire data in a finer pixel spacing of 1.5-3.1 x 3.6-4.2 (slant range x azimuth) [59]. LiCSAR automated processing produces interferograms for these regions, multi-looked to ~30x30 m resolution, and the same output files and metadata as are generated for IWS acquisition mode products. We have added an automatic processing functionality for SM acquisitions to incorporate the following volcanic islands to the LiCSAR product database: La Réunion (French territory, Indian Ocean), Fogo (Cabo Verde), Tristan da Cunha (British Overseas Territory, south Atlantic Ocean), Mussau Island (Papua New Guinea), Marion Island (South Africa, sub-antarctic Indian Ocean) and Raoul Island (New Zealand). To keep SM frames consistent with the LiCSAR system architecture originally designed for IWS data only, we use the geographic area of the SM image as a "burst" in the <rs id="a12897754" type="software">LiCSInfo</rs> database and a subset definition (geographic coordinates of corners covering area of observed island) as a "frame".</p>
<p>One of the major limiting factors of the use of the InSAR in most of tectonic and volcanic applications is the spatiotemporal variability of tropospheric properties. This is of importance especially in cases where deformation and topography are correlated [60]. To address this limitation, we have developed tools for including products for an atmospheric correction, based on the COMET <rs id="a12897755" type="software">GACOS</rs> system developed at the <rs id="a12897756" type="publisher" corresp="#a12897755">University of Newcastle</rs> <rs id="a12953736" type="bibr">[46]</rs>. <rs id="a12897758" type="software">GACOS</rs> uses an iterative tropospheric decomposition interpolation model that decouples the elevation and turbulent tropospheric delay components estimated from high-resolution ECMWF and GPS data. <rs id="a12897759" type="software">GACOS</rs> corrections are computed for each LiCSAR frame with the same image sizes to facilitate direct use.</p>
<p>-yyyymmdd_yyyymmdd.kmz: an optional <rs id="a12897760" type="software">Google Earth</rs> KMZ output is typically generated from full resolution (0.001°) raster previews of the generated interferogram products.</p>
<p>As an example, Figure 9 shows three coseismic interferograms from continental earthquakes in different tectonic settings generated in both ascending (left) and descending (right) orbits. They correspond to the July 4, 2019, M w 7.1 right-lateral strike-slip earthquake in Ridgecrest, California (Fig. 9a), the November 12, 2017, M w 7.3 dip-slip earthquake in Iran-Iraq border (Fig. 9b), and September 16, 2015, M w 8.3 dip-slip earthquake in Illapel, Chile (Fig. 9c). Each colour cycle can be interpreted as representing 2.8 centimeters of relative ground displacement in the LOS direction (i.e. towards or away from the satellite). Because the LiCSAR metadata folder includes grids of the unit vector in the satellite LOS at each pixel, the data can easily be used for earthquake source modelling, for example using tools such as <rs id="a12897761" type="software">Pyrocko</rs> <rs id="a12953737" type="bibr">[62]</rs>, which automatically can ingest LiCSAR products.</p>
<p>As an example of other generated InSAR products, Figures 10a and10b show the unwrapped phase and coherence images corresponding to the Ridgecrest interferogram in Fig. 9b respectively. It should be noted that the phases in Fig. 10a are rewrapped to 6π and therefore the colour cycle here is equal to a 6π phase variation (8.3 cm if it is caused by movement in the LOS). The white areas in the unwrapped image show the areas that were masked based on a coherence threshold to avoid unwrapping errors. These low coherence regions (visible as dark spots in Fig. 10b) can be due to large changes in the ground surface due to surface rupture, ground shaking and high displacement gradients. Fig. 10c is the intensity image of the same frame corresponding to the postseismic Sentinel-1 image, acquired on August 21, 2019. An InSAR displacement time series serves as an example of products that can be generated using LiCSAR products. Interferometric products of LiCSAR over Turkey have been used to study the North Anatolian Fault (NAF), a major right-lateral, strike-slip fault accommodating the relative motion between the Anatolian and Eurasian tectonic plates at a rate of ~25 mm/yr [63]. We have processed LiCSAR frames for Anatolia starting with the first Sentinel-1A acquisitions in October 2014 until October 2019 to obtain the average satellite LOS velocities using <rs id="a12897763" type="software">LiCSBAS</rs> <rs id="a12953738" type="bibr">[61]</rs>. An example of a LOS velocity map for a selected frame, overlain by the main faults, clearly shows the right-lateral interseismic motion across the NAF (Fig. 11a). Figure 11b shows the time-series of cumulative displacement for a sample pixel north of the NAF with respect to a reference pixel located south of the fault. The best-fit LOS velocity of -15.2 mm/year for this pixel is representative of westward movement of the Anatolian microplate. We also see a clear seasonality to the relative LOS motion in this case.</p>
<p>Acknowledgments: This work used JASMIN, the UK's collaborative data analysis environment (http://jasmin.ac.uk). This paper contains modified Copernicus Sentinel data 2014-2019, processed by ESA, retrieved from NASA ASF DAAC, <rs id="a12897765" type="software">Copernicus SciHub</rs> or CEDA Archive, and analysed by COMET. COMET is the UK Natural Environment Research Council's Centre for the Observation and Modelling of Earthquakes, Volcanoes and Tectonics. Orbital ephemerides by Sentinel-1 Quality Control Subsystem. ASTER GDEM is a product of NASA and METI. Some of the Stripmap and other frames were processed using the ALOS World 3D -1 arcsec DEM provided by the Japan Aerospace Exploration Agency. This work was partially undertaken on ARC4, part of the High Performance Computing facilities at the University of Leeds, UK.</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f326509939"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T11:37+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The brain MRI protocol is performed using a 3 Tesla Siemens Skyra scanner (<rs type="publisher" corresp="#a12897821">Siemens Healthineers</rs>, Erlangen, Germany) with <rs id="a12897821" type="software">VD13</rs> software and a 32-channel head coil. The full examination lasts approximately 35 min. Table 2 reports the selected parameters of the brain MRI protocols. The protocol includes three structural MRI scans; T1, T2 fluid attenuation inversion recovery (FLAIR) and susceptibility-weighted MRI (swMRI), as well as diffusion MRI (dMRI) and resting and task functional MRI (fMRI). T1 scans allow precise volumetric measures of the whole brain, as well as specific cortical and subcortical regions. The T2 FLAIR scan identifies changes that might be indicative of inflammation or tissue damage. For instance. an increased signal in the white matter is associated with an increased risk of dementia and stroke 15 . swMRI is sensitive to increased iron content as a result of microbleeds or chronic microglial activation in the context of neurodegeneration 16 . dMRI reflects structural connectivity and tissue microstructural features describing white matter integrity. Resting fMRI is performed on an individual who is not engaged in any particular activity or task and can provide indices related to the functional connectivity between brain regions independent of external stimuli. By contrast, task fMRI is performed on an individual to whom stimuli are repetitively delivered that engage sensory-motor and cognitive processes of interest. The UKB task fMRI protocol is based on the Hariri faces/ shapes 'emotion' task, selected because it engages a wide range of cognitive and sensory-motor systems and a wide range of normative data is available 17 .</p>
<p>An automated processing pipeline for brain image analysis and quality control was established for UKB at the University of Oxford's Wellcome Centre for Integrative Neuroimaging (WIN / FMRIB). This pipeline is primarily based around <rs id="a12897822" type="software">FSL (FMRIB's Software Library)</rs>, and other packages such as <rs id="a12897823" type="software">FreeSurfer</rs> <rs id="a12897824" type="bibr">18</rs>,<rs id="a12897825" type="bibr">19</rs> . When acquired at the imaging centres, the images are reconstructed from k-space on the scanner computer and saved initially as DICOM files. The processing pipeline then converts these files to the NIFTI format and undertakes pre-processing (e.g., correcting for head motion and other artefacts) as well as automated quality control that identifies issue with the equipment (e.g., coil failure) and artefacts specific to the participant or scanning session (e.g., excessive head movement). The NIFTI files for the T1 and T2 scans are the default version provided to researchers, as these are suitably "defaced" to remove the possibility of re-identification of any individual participant. In 99.5% of cases, the defaced mask does not overlap with the brain mask 19 . The pipeline also automatically generates thousands of IDPs, such as regional grey matter volume from T1 scans, volume of white matter hyperintensities from T2 scans, fractional anisotropy measures from dMRI scans and signal changes in response to stimuli from task fMRI scans. These IDPs have been made available to researchers in batched uploads to the resource since the imaging enhancement began. In-depth information on the brain MRI protocol and quality control process have been published elsewhere 18,19 .</p>
<p>Although these studies are valuable resources for population health research, their main focus is on cardiovascular disease and risk factors. The sheer size of UKB offers unique opportunities to investigate the subclinical cardiovascular mechanisms related to a wide range of cardiovascular and non-cardiovascular diseases, including research to identify early markers of pathology and their genetic and lifestyle determinants. The cardiac MRI scan is performed using a Siemens 1.5 Tesla MAGNETOM Aera scanner (<rs type="publisher" corresp="#a12897826">Siemens Healthineers</rs>, Erlangen, Germany) with <rs id="a12897826" type="software">VD13A</rs> software and a spine and body flex matrix coil. No pharmacological stressor or contrast agent is used. The protocol lasts ~20 min and provides structural and functional measures of the left and right ventricles, left and right atria and the aorta, including volumes, changes in volumes during cardiac cycle, cardiac wall thickness and mass, tissue motion using tagging and thoracic aorta size and distensibility. Table 3 the selected parameters of the cardiac MRI protocols.</p>
<p>At present, only a limited range of features are automatically extracted from the cardiac scanner, such as inline ventricular function (which assesses left ventricular contours and volume). A group based at Queen Mary University, London, and the University of Oxford has created a cardiac structural MRI segmentation reference by manual analysis of the first 5000 scans 26,27 . However, the scale of the imaging enhancement has accelerated efforts to develop automated processing tools that can extract a wider range of cardiac phenotypes in order to maximise the scientific utility of these data. A range of algorithms to automatically segment and assess the quality of the remaining cine cardiac MR images are now being made openly available [28][29][30] . An automated large-scale image quality control, analytics and image-based phenotype extraction has been established in collaboration with the University of Leeds Centre for Computational Imaging &amp; Simulation Technologies in Biomedicine (CISTIB) based on a private deployment of the <rs id="a1" type="software" subtype="environment">MULTI-X</rs> securebased platform (<rs type="url" corresp="#a1">www.multi-x.org</rs>) <rs type="bibr">30,31</rs> . In-depth information on the cardiac MRI protocol have been published elsewhere 26,32 .</p>
<p>Localisation is performed relative to the jugular notch, which is the centre position of the first stage of the Dixon imaging. The examination includes the <rs type="software" id="a2">LiverMultiScan</rs> protocol, developed by <rs type="publisher" corresp="#a2">Perspectum Diagnostics</rs> (Oxford, UK), which images the liver by a single transverse slice at the porta hepatisis using two different sequences 39 . A single breath-hold cardiac-gated Modified Look-Locker Inversion Recovery sequence (shMOLLI) for T1 mapping is acquired. A single breath-held spoiled-gradient-multi-echo sequence in the same slice position is performed. Together, these allow multiple measures sensitive to liver fibrosis, iron content and fat 39 . For volumetric evaluations of the pancreas, a 3D VIBE is acquired in transverse orientation centred at the position of the pancreas. A shMOLLI sequence is performed using the same parameters as for the liver. Finally, multi-echo sequence is used (10 different echoes) to allow measurements of iron and fat content.</p>
<p>12-lead electrocardiogram. Participants also undertake a 12-lead ECG assessment (GE Cardiac Acquisition Module CAM-14) during the imaging assessment. ECG can be used to detect abnormalities related to heart rhythm and electrical activity and to make inferences regarding cardiac structure 55 . Both major and minor ECG abnormalities have been associated with an increased risk of coronary heart disease 56 and cardiovascular-related mortality 57 . In UKB, the ECG is performed with participants at rest on the same couch used for the carotid ultrasound. The leads are placed on the right and left forearms proximal to wrists, right and left lower legs proximal to ankles and chest with the measurement lasting 20 s. After acquisition, a summary page displays the results for the operating staff member to either mark as 'complete' or provide a reason for incomplete assessment. The ECG system includes interpretation software (<rs id="a12897827" type="publisher" corresp="#a12897828">GE</rs> <rs id="a12897828" type="software">CardioSoft</rs> system) that provides an automated output for the detection of arrhythmias and metrics reflecting electrical activity, such as PR interval, QRS duration and QT interval. The raw ECG datasets are also made available for research use. Characteristics and data completeness for the first 40,000 participants. Table 5 summarises selected demographic and lifestyle characteristics for the participants who completed imaging between 2014 and early 2020. A high proportion have undertaken other UKB data enhancements, with almost half (44%) having worn the 7-day accelerometer, compared with 19% of the whole UKB cohort, and most have completed the webbased questionnaires. More than 80% of participants who have undertaken imaging have complete 'core' datasets for each of the imaging modalities, and over 90% have complete 'core' datasets for the DXA and carotid ultrasound (Fig. 1). For the small proportion of participants with incomplete data, approximately half arise from participant specific issues, such as inability to comply with the demands of the protocol; for example, failure to complete the brain MRI because of excessive movement (1%) or a sudden episode of claustrophobia (2.2%). Other reasons for missing data for the brain MRI include scanner failures (2 %), staffing issues (0.4%) or scheduling problems (1.1%).</p>
</body>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f300328147"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:56+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<p>The recommendations are considered for the application of CMR in clinical routine in adult patients. For some applications, quantification is considered as providing added information but is not mandatory (e.g., perfusion), whereas for others quantification is required for all clinical reports (e.g., T2* assessment in iron overload). In general, the intention of this Task Force is to describe the scenarios in which quantitative analysis should be performed and how it is performed. Quantification itself is a moving target as artificial intelligence approaches to quantification are presently being instituted within <rs type="software">CMR</rs> analysis software programs and will impact techniques in this arena in the future. The recommendations respect societal recommendations for structured reporting of cardiovascular imaging studies in general (ACCF / ACR / AHA / ASE / ASNC / HRS / NASCI / RSNA / SAIP / SCAI / SCCT / SCMR) [2] and specifically for CMR studies (SCMR) [3]. The recommendations do not supersede clinical judgment regarding the contents of individual interpretation of imaging studies. The Task Force made every effort to avoid conflicts of interest and, where present, to disclose potential conflicts.</p>
<p>2. Post-processing software with regulatory approval for use in patients, ideally providing the following tools: a) Full DICOM send/retrieve functionality, network connection with local <rs type="software">Picture Archiving and Communication System (PACS)</rs> or server solution with compliant patient security properties b) View all short-axis cines as movies in a single display, zoom, pan and change contrast for single images as well as image series c) Perform endocardial and epicardial contour tracings on cines d) Correct for atrioventricular annular location from the long-axis slice onto the most basal left ventricular (LV) short-axis location in contour tracings e) Cross-referencing of structures for confirmation of slice position and anatomy f) Simultaneously view cine, late gadolinium enhancement (LGE) and/or perfusion images from the same location g) Simultaneously view short-and long-axis images of the same region h) Simultaneously view images of the approximate same location on the current and prior study for serial studies i) Perform quantitative signal intensity (SI) and derived analyses j) Perform standardized segmentation of the myocardium according to the segment model of the American Heart Association (AHA) [5] k) Measure flow velocities and flow volumes l) Manually correct or enter heart rate, blood pressure, height, weight, body surface area m) Calculate volumes in stacked or 3D datasets with minimal user interaction, including and excluding trabecular tissue and papillary muscles from the LV volume [6] n) Document important findings in screenshots for the report o) For evaluation of angiography the software ideally provides the following tools: i) 3D multiplanar and maximum intensity projection (MIP) capabilities ii) Volume rendering and surface shaded reconstructions optional for reporting but not mandatory for quantitative analysis iii) Measurement of distances and areas in 3D-MR angiography (MRA) images iv) MIP reconstruction based on nonsubtracted or subtracted 3D-MRA datasets v) Multiplanar reformatting (MPR)</p>
</text>
</tei>
<tei>
<teiHeader>
<fileDesc id="f365584111"/>
<encodingDesc>
<appInfo>
<application version="0.8.1-SNAPSHOT" ident="GROBID" when="2024-06-24T15:09+0000">
<ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref>
</application>
</appInfo>
</encodingDesc>
</teiHeader>
<text lang="en">
<body>
<p>The data, originally in a polygon format (Protectshape), was converted to 5 arc-minute grids (Protecti) using <rs id="a12972983" type="software">GIS</rs> software. Protected areas are mapped in Figure S4. Source: Developed by authors using data from the World Database on Protected Areas (Deguignet et al., 2014).</p>
</body>
</text>
</tei>
</teiCorpus>
